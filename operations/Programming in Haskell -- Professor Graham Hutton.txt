c⃝Graham Hutton
Version of August 30, 2005
NOT FOR DISTRIBUTION

For Annette, Callum and Tom

Contents
Preface
7
1
Introduction
9
1.1
Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.2
Functional programming . . . . . . . . . . . . . . . . . . . . . .
10
1.3
Features of Haskell . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.4
Historical background
. . . . . . . . . . . . . . . . . . . . . . .
14
1.5
A taste of Haskell . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.6
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
17
1.7
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
2
First Steps
19
2.1
The Hugs system . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.2
The standard prelude
. . . . . . . . . . . . . . . . . . . . . . .
19
2.3
Function application . . . . . . . . . . . . . . . . . . . . . . . .
22
2.4
Haskell scripts
. . . . . . . . . . . . . . . . . . . . . . . . . . .
22
2.5
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
25
2.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
3
Types and Classes
27
3.1
Basic concepts
. . . . . . . . . . . . . . . . . . . . . . . . . . .
27
3.2
Basic types
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
3.3
List types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
3.4
Tuple types . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
3.5
Function types
. . . . . . . . . . . . . . . . . . . . . . . . . . .
31
3.6
Curried functions . . . . . . . . . . . . . . . . . . . . . . . . . .
32
3.7
Polymorphic types . . . . . . . . . . . . . . . . . . . . . . . . .
33
3.8
Overloaded types . . . . . . . . . . . . . . . . . . . . . . . . . .
34
3.9
Basic classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
3.10 Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
39
3.11 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
4
Deﬁning Functions
41
4.1
New from old . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
4.2
Conditional expressions
. . . . . . . . . . . . . . . . . . . . . .
42
3

4
CONTENTS
4.3
Guarded equations . . . . . . . . . . . . . . . . . . . . . . . . .
42
4.4
Pattern matching . . . . . . . . . . . . . . . . . . . . . . . . . .
43
4.5
Lambda expressions
. . . . . . . . . . . . . . . . . . . . . . . .
46
4.6
Sections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
4.7
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
48
4.8
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
5
List Comprehensions
51
5.1
Generators
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
5.2
Guards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
5.3
The zip function
. . . . . . . . . . . . . . . . . . . . . . . . . .
54
5.4
String comprehensions . . . . . . . . . . . . . . . . . . . . . . .
55
5.5
The Caesar cipher
. . . . . . . . . . . . . . . . . . . . . . . . .
55
5.6
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
60
5.7
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
6
Recursive Functions
63
6.1
Basic concepts
. . . . . . . . . . . . . . . . . . . . . . . . . . .
63
6.2
Recursion on lists . . . . . . . . . . . . . . . . . . . . . . . . . .
65
6.3
Multiple arguments . . . . . . . . . . . . . . . . . . . . . . . . .
67
6.4
Multiple recursion
. . . . . . . . . . . . . . . . . . . . . . . . .
68
6.5
Mutual recursion . . . . . . . . . . . . . . . . . . . . . . . . . .
69
6.6
Advice on recursion
. . . . . . . . . . . . . . . . . . . . . . . .
70
6.7
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
75
6.8
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
7
Higher-Order Functions
77
7.1
Basic concepts
. . . . . . . . . . . . . . . . . . . . . . . . . . .
77
7.2
Processing lists . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
7.3
The foldr function
. . . . . . . . . . . . . . . . . . . . . . . . .
80
7.4
The foldl function
. . . . . . . . . . . . . . . . . . . . . . . . .
83
7.5
The composition operator . . . . . . . . . . . . . . . . . . . . .
85
7.6
String transmitter
. . . . . . . . . . . . . . . . . . . . . . . . .
86
7.7
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . .
89
7.8
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
8
Functional Parsers
91
8.1
Parsers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
8.2
The parser type . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
8.3
Basic parsers
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
8.4
Sequencing
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
8.5
Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
8.6
Derived primitives
. . . . . . . . . . . . . . . . . . . . . . . . .
96
8.7
Handling spacing . . . . . . . . . . . . . . . . . . . . . . . . . .
98
8.8
Arithmetic expressions . . . . . . . . . . . . . . . . . . . . . . .
99
8.9
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 103

CONTENTS
5
8.10 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
9
Interactive Programs
105
9.1
Interaction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
9.2
The input/output type . . . . . . . . . . . . . . . . . . . . . . . 106
9.3
Basic actions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
9.4
Sequencing
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
9.5
Derived primitives
. . . . . . . . . . . . . . . . . . . . . . . . . 108
9.6
Calculator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
9.7
Game of life . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
9.8
Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 116
9.9
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
10 Declaring Types and Classes
119
10.1 Type declarations . . . . . . . . . . . . . . . . . . . . . . . . . . 119
10.2 Data declarations . . . . . . . . . . . . . . . . . . . . . . . . . . 120
10.3 Recursive types . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
10.4 Tautology checker
. . . . . . . . . . . . . . . . . . . . . . . . . 125
10.5 Abstract machine . . . . . . . . . . . . . . . . . . . . . . . . . . 130
10.6 Class and instance declarations . . . . . . . . . . . . . . . . . . 132
10.7 Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 135
10.8 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
11 The Countdown Problem
137
11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
11.2 Formalising the problem . . . . . . . . . . . . . . . . . . . . . . 138
11.3 Brute force solution
. . . . . . . . . . . . . . . . . . . . . . . . 140
11.4 Combining generation and evaluation . . . . . . . . . . . . . . . 142
11.5 Exploiting algebraic properties
. . . . . . . . . . . . . . . . . . 143
11.6 Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 144
11.7 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
12 Lazy Evaluation
147
12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
12.2 Evaluation strategies . . . . . . . . . . . . . . . . . . . . . . . . 148
12.3 Termination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
12.4 Number of reductions
. . . . . . . . . . . . . . . . . . . . . . . 152
12.5 Inﬁnite structures . . . . . . . . . . . . . . . . . . . . . . . . . . 154
12.6 Modular programming . . . . . . . . . . . . . . . . . . . . . . . 155
12.7 Strict application . . . . . . . . . . . . . . . . . . . . . . . . . . 158
12.8 Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 161
12.9 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

6
CONTENTS
13 Reasoning About Programs
163
13.1 Equational reasoning . . . . . . . . . . . . . . . . . . . . . . . . 163
13.2 Reasoning about Haskell . . . . . . . . . . . . . . . . . . . . . . 164
13.3 Simple examples
. . . . . . . . . . . . . . . . . . . . . . . . . . 165
13.4 Induction on numbers
. . . . . . . . . . . . . . . . . . . . . . . 166
13.5 Induction on lists . . . . . . . . . . . . . . . . . . . . . . . . . . 169
13.6 Making append vanish . . . . . . . . . . . . . . . . . . . . . . . 171
13.7 Compiler correctness . . . . . . . . . . . . . . . . . . . . . . . . 174
13.8 Chapter remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 179
13.9 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
A Standard Prelude
181
A.1 Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
A.2 Logical values . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
A.3 Characters and strings . . . . . . . . . . . . . . . . . . . . . . . 183
A.4 Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
A.5 Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
A.6 Maybe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
A.7 Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
A.8 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
A.9 Input/Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
B Symbol Table
191
Bibliography
192
Index
196

Preface
. . . there are two ways of constructing a software design: One way
is to make it so simple that there are obviously no deﬁciencies and
the other way is to make it so complicated that there are no obvious
deﬁciencies. The ﬁrst method is far more diﬃcult.
— Tony Hoare, 1980 ACM Turing Award Lecture
This book is about an approach to programming in which simplicity, clarity
and elegance are the key goals. More speciﬁcally, it is an introduction to the
functional style of programming, using the language Haskell.
The functional style is quite diﬀerent to that promoted by most current
languages, such as Java, C++, C, and Visual Basic. In particular, most current
languages are closely linked to the underlying hardware, in the sense that
programming is based upon the idea of changing stored values. In contrast,
Haskell promotes a more abstract style of programming, based upon the idea of
applying functions to arguments. As we shall see, moving to this higher-level
leads to considerably simpler programs, and supports a number of powerful
new ways to structure and reason about programs.
The book is primarily aimed at students studying computing science at
university level, but is also appropriate for a broader spectrum of readers who
would like to learn about programming in Haskell. No previous programming
experience is required or assumed, and all the concepts are explained from
ﬁrst principles, with the aid of carefully chosen examples.
The version of Haskell used in the book is Haskell 98, the standard version
of the language, for which the recently published deﬁnition is the culmination
of ﬁfteen years of work by its designers. As this is an introductory text, we
do not attempt to cover all aspects of Haskell 98 and its associated libraries.
Around half of the book is dedicated to introducing the main features of the
language, while the other half comprises examples and case studies of program-
ming of Haskell. Each chapter includes a series of exercises, and suggestions
for further reading on more advanced and specialist topics.
The book is based upon course material that has been reﬁned and class-
tested over many years at the University of Nottingham. Most of the material
from the book can be covered in twenty hours of lectures, supported by ap-
proximately forty hours of private study, practical sessions in a supervised
7

8
CONTENTS
laboratory, and take-home programming courseworks.
However, additional
time would be required to cover some of the later chapters in more detail,
along with some of the later programming examples.
The web site for the book, www.cs.nott.ac.uk/~gmh/book.html, provides
a range of supporting material, including lecture slides for each chapter, and
Haskell code for each of the extended examples. Instructors can also obtain
model answers to the exercises for each chapter, together with a large collection
of exam questions and their model answers.
Acknowledgements
The Foundations of Programming group at the University of Nottingham is
an excellent environment in which to do research and teaching on functional
programming. I am grateful to the University for providing a sabbatical to
start work on this book; all the students and tutors on my Haskell courses for
their feedback; and Thorsten Altenkirch, Mark Jones (now in Oregon), Conor
McBride and Henrik Nilsson in the FOP group for our many discussions about
functional ideas and how to present them.
I would also like to thank Rik van Geldrop and Jaap van der Woude for
their feedback on using draft versions of the book; Ian Bayley for providing
useful comments; Kees van den Broek, Frank Heitmann and Bill Tonkin for
pointing out errors; Mark Jones for the Hugs interpreter for Haskell; Ralf
Hinze and Andres L¨oh for the lhs2TeX system for typesetting Haskell; and
Fritz Ruehr for producing the cover design.
Graham Hutton
Nottingham, Summer 2005

Chapter 1
Introduction
In this chapter we set the stage for the rest of the book. We start by reviewing
the notion of a function, then introduce the concept of functional program-
ming, summarise the main features of Haskell and its history, and conclude
with two small examples that give a taste of Haskell.
1.1
Functions
In Haskell, a function is a mapping that takes one or more arguments and
produces a single result, and is deﬁned using an equation that gives a name
for the function, a name for each of its arguments, and a body that speciﬁes
how the result can be calculated in terms of the arguments.
For example, a function double that takes a number x as its argument, and
produces the result x + x, can be deﬁned by the following equation:
double x
=
x + x
When a function is applied to actual arguments, the result is obtained by
substituting these arguments into the body of the function in place of the
argument names. This process may immediately produce a result that cannot
be further simpliﬁed, such as a number. More commonly, however, the result
will be an expression containing other function applications, which must then
be processed in the same way to produce the ﬁnal result.
For example, the result of the application double 3 of the function double
to the number 3 can be determined by the following calculation, in which each
step is explained by a short comment in curly parentheses:
double 3
=
{ applying double }
3 + 3
=
{ applying + }
6
Similarly, the result of the nested application double (double 2) in which the
function double is applied twice can be calculated as follows:
9

10
CHAPTER 1. INTRODUCTION
double (double 2)
=
{ applying the inner double }
double (2 + 2)
=
{ applying + }
double 4
=
{ applying double }
4 + 4
=
{ applying + }
8
Alternatively, the same result could also be calculated by starting with the
outer application of the function double rather than the inner:
double (double 2)
=
{ applying the outer double }
double 2 + double 2
=
{ applying the ﬁrst double }
(2 + 2) + double 2
=
{ applying the ﬁrst + }
4 + double 2
=
{ applying double }
4 + (2 + 2)
=
{ applying the second + }
4 + 4
=
{ applying + }
8
However, this calculation requires two more steps than our original version,
because the expression double 2 is duplicated in the ﬁrst step and hence simpli-
ﬁed twice. In general, the order in which functions are applied in a calculation
does not aﬀect the value of the ﬁnal result, but it may aﬀect the number
of steps required, and may aﬀect whether the calculation process terminates.
These issues are explored in more detail in chapter 12.
1.2
Functional programming
What is functional programming? Opinions diﬀer, and it is diﬃcult to give a
precise deﬁnition. Generally speaking, however, functional programming can
be viewed as a style of programming in which the basic method of computation
is the application of functions to arguments. In turn, a functional program-
ming language is one that supports and encourages the functional style.
To illustrate these ideas, let us consider the task of computing the sum of
the integers (whole numbers) between one and some larger number n. In most
current programming languages, this would normally be achieved using two
variables that store values that can be changed over time, one such variable
used to count up to n, and the other used to accumulate the total.

1.2. FUNCTIONAL PROGRAMMING
11
For example, if we use the assignment symbol := to change the value of a
variable, and the keywords repeat and until to repeatedly execute a sequence
of instructions until a condition is satisﬁed, then the following sequence of
instructions computes the required sum:
count := 0
total := 0
repeat
count := count + 1
total := total + count
until
count = n
That is, we ﬁrst initialise both the counter and the total to zero, and then
repeatedly increment the counter and add this value to the total until the
counter reaches n, at which point the computation stops.
In the above program, the basic method of computation is changing stored
values, in the sense that executing the program results in a sequence of assign-
ments. For example, the case of n = 5 gives the following sequence, in which
the ﬁnal value assigned to the variable total is the required sum:
count
:=
0
total
:=
0
count
:=
1
total
:=
1
count
:=
2
total
:=
3
count
:=
3
total
:=
6
count
:=
4
total
:=
10
count
:=
5
total
:=
15
In general, programming languages in which the basic method of computation
is changing stored values are called imperative languages, because programs
in such languages are constructed from imperative instructions that specify
precisely how the computation should proceed.
Now let us consider computing the sum of the numbers between one and
n using Haskell. This would normally be achieved using two library functions,
one called [ . . ] used to produce the list of numbers between one and n, and
the other called sum used to produce the sum of this list:
sum [1 . . n ]
In this program, the basic method of computation is applying functions to
arguments, in the sense that executing the program results in a sequence of
applications. For example, the case of n = 5 gives the following sequence, in
which the ﬁnal result is the required sum:

12
CHAPTER 1. INTRODUCTION
sum [1 . . 5]
=
{ applying [ . . ] }
sum [1, 2, 3, 4, 5]
=
{ applying sum }
1 + 2 + 3 + 4 + 5
=
{ applying + }
15
Most imperative languages support some form of programming with func-
tions, so the Haskell program sum [1 . . n ] could be translated into such lan-
guages. However, most imperative languages do not encourage programming
in the functional style. For example, many languages discourage or prohibit
functions from being stored in data structures such as lists, from construct-
ing intermediate structures such as the list of numbers in the above example,
from taking functions as arguments or producing functions as results, or from
being deﬁned in terms of themselves. In contrast, Haskell imposes no such
restrictions on how functions can be used, and provides a range of features to
make programming with functions both simple and powerful.
1.3
Features of Haskell
For reference, the main features of Haskell are listed below, along with the
particular chapters of this book that give further details.
• Concise programs (chapters 2 and 4)
Due to the high-level nature of the functional style, programs written
in Haskell are often much more concise than in other languages, as il-
lustrated by the example in the previous section. Moreover, the syntax
of Haskell has been designed with concise programs in mind, in partic-
ular by having few keywords, and by allowing indentation to be used to
indicate the structure of programs. Although it is diﬃcult to make an
objective comparison, Haskell programs are often between two and ten
times shorter than programs written in other current languages.
• Powerful type system (chapters 3 and 10)
Most modern programming languages include some form of type system
to detect incompatibility errors, such as attempting to add a number and
a character. Haskell has a type system that requires little type informa-
tion from the programmer, but allows a large class of incompatibility
errors in programs to be automatically detected prior to their execution,
using a sophisticated process called type inference. The Haskell type
system is also more powerful than most current languages, by allowing
functions to be "polymorphic" and "overloaded".
• List comprehensions (chapter 5)

1.3. FEATURES OF HASKELL
13
One of the most common ways to structure and manipulate data in com-
puting is using lists. To this end, Haskell provides lists as a basic concept
in the language, together with a simple but powerful comprehension no-
tation that constructs new lists by selecting and ﬁltering elements from
one or more existing lists.
Using the comprehension notation allows
many common functions on lists to be deﬁned in a clear and concise
manner, without the need for explicit recursion.
• Recursive functions (chapter 6)
Most non-trivial programs involve some form of repetition or looping.
In Haskell, the basic mechanism by which looping is achieved is by us-
ing recursive functions that are deﬁned in terms of themselves. Many
computations have a simple and natural deﬁnition in terms of recursive
functions, particularly when "pattern matching" and "guards" are used
to separate diﬀerent cases into diﬀerent equations.
• Higher-order functions (chapter 7)
Haskell is a higher-order functional language, which means that func-
tions can freely take functions as arguments and produce functions as
results. Using higher-order functions allows common programming pat-
terns, such as composing two functions, to be deﬁned as functions within
the language itself. More generally, higher-order functions can be used
to deﬁne "domain speciﬁc languages" within Haskell, such as for list
processing, parsing, and interactive programming.
• Monadic eﬀects (chapters 8 and 9)
Functions in Haskell are pure functions that take all their input as argu-
ments and produce all their output as results. However, many programs
require some form of side eﬀect that would appear to be at odds with
purity, such as reading input from the keyboard, or writing output to the
screen, while the program is running. Haskell provides a uniform frame-
work for handling eﬀects without compromising the purity of functions,
based upon the mathematical notion of a monad.
• Lazy evaluation (chapter 12)
Haskell programs are executed using a technique called lazy evaluation,
which is based upon the idea that no computation should be performed
until its result is actually required.
As well as avoiding unnecessary
computation, lazy evaluation ensures that programs terminate whenever
possible, encourages programming in a modular style using intermediate
data structures, and even allows data structures with an inﬁnite number
of elements, such as an inﬁnite list of numbers.
• Reasoning about programs (chapter 13)
Because programs in Haskell are pure functions, simple equational rea-
soning can be used to execute programs, to transform programs, to

14
CHAPTER 1. INTRODUCTION
prove properties of programs, and even to derive programs directly from
speciﬁcations of their behaviour. Equational reasoning is particularly
powerful when combined with the use of "induction" to reason about
functions that are deﬁned using recursion.
1.4
Historical background
Many of the features of Haskell are not new, but were ﬁrst introduced by
other languages. To help place Haskell in context, some of the main historical
developments related to the language are brieﬂy summarised below.
• In the 1930s, Alonzo Church developed the lambda calculus, a simple
but powerful mathematical theory of functions.
• In the 1950s, John McCarthy developed Lisp ("LISt Processor"), gener-
ally regarded as being the ﬁrst functional programming language. Lisp
had some inﬂuences from the lambda calculus, but still adopted variable
assignments as a central feature of the language.
• In the 1960s, Peter Landin developed ISWIM ("If you See What I
Mean"), the ﬁrst pure functional programming language, based strongly
on the lambda calculus and having no variable assignments.
• In the 1970s, John Backus developed FP ("Functional Programming"), a
functional programming language that particularly emphasised the idea
of higher-order functions and reasoning about programs.
• Also in the 1970s, Robin Milner and others developed ML ("Meta-
Language"), the ﬁrst of the modern functional programming languages,
which introduced the idea of polymorphic types and type inference.
• In the 1970s and 1980s, David Turner developed a number of lazy func-
tional programming languages, culminating in the commercially pro-
duced language Miranda (meaning "admirable").
• In 1987, an international committee of researchers initiated the devel-
opment of Haskell (named after the logician Haskell Curry), a standard
lazy functional programming language.
• In 2003, the committee published the Haskell Report, which deﬁnes a
long-awaited stable version of Haskell, and is the culmination of ﬁfteen
years of work on the language by its designers.
It is worthy of note that three of the above researchers — McCarthy, Backus
and Milner — have each received the ACM Turing Award, which is generally
regarded as being the computing equivalent of a Nobel prize.

1.5. A TASTE OF HASKELL
15
1.5
A taste of Haskell
We conclude this chapter with two small examples that give a taste of pro-
gramming in Haskell. First of all, recall the function sum used earlier in this
chapter, which produces the sum of a list of numbers. In Haskell, this function
can be deﬁned using the following two equations:
sum [ ]
=
0
sum (x : xs)
=
x + sum xs
The ﬁrst equation states that the sum of the empty list is zero, while the
second states that the sum of any non-empty list comprising a ﬁrst number x
and a remaining list of numbers xs is given by adding x and the sum of xs.
For example, the result of sum [1, 2, 3] can be calculated as follows:
sum [1, 2, 3]
=
{ applying sum }
1 + sum [2, 3]
=
{ applying sum }
1 + (2 + sum [3])
=
{ applying sum }
1 + (2 + (3 + sum [ ]))
=
{ applying sum }
1 + (2 + (3 + 0))
=
{ applying + }
6
Note that even though the function sum is deﬁned in terms of itself and is
hence recursive, it does not loop forever. In particular, each application of
sum reduces the length of the argument list by one, until the list eventually
becomes empty at which point the recursion stops. Returning zero as the sum
of the empty list is appropriate because zero is the identity for addition. That
is, 0 + x = x and x + 0 = x for any number x.
In Haskell, every function has a type that speciﬁes the nature of its argu-
ments and results, which is automatically inferred from the deﬁnition of the
function. For example, the function sum has the following type:
Num a ⇒[a ] →a
This type states that for any type a of numbers, sum is a function that maps a
list of such numbers to a single such number. Haskell supports many diﬀerent
types of numbers, including integers such as 123, and "ﬂoating-point" numbers
such as 3.14159. Hence, for example, sum could be applied to a list of integers,
as in the calculation above, or to a list of ﬂoating-point numbers.
Types provide useful information about the nature of functions, but more
importantly, their use allows many errors in programs to be automatically
detected prior to executing the programs themselves. In particular, for every

16
CHAPTER 1. INTRODUCTION
function application in a program, a check is made that the type of the actual
arguments is compatible with the type of the function itself. For example,
attempting to apply the function sum to a list of characters would be reported
as an error, because characters are not a type of numbers.
Now let us consider a more interesting function concerning lists, which
illustrates a number of other aspects of Haskell. Suppose that we deﬁne a
function called qsort by the following two equations:
qsort [ ]
=
[ ]
qsort (x : xs)
=
qsort smaller ++ [x ] ++ qsort larger
where
smaller = [a | a ←xs, a ⩽x ]
larger = [b | b ←xs, b > x ]
In this deﬁnition, ++ is an operator that appends two lists; for example,
[1, 2, 3] ++ [4, 5] = [1, 2, 3, 4, 5]. In turn, where is a keyword that introduces
local deﬁnitions, in this case a list smaller that consists of all elements a from
the list xs that are less than or equal to x, together with a list larger that
consists of all elements b from xs that are greater than x. For example, if
x = 3 and xs = [5, 1, 4, 2], then smaller = [1, 2] and larger = [5, 4].
What does qsort actually do? First of all, we show that it has no eﬀect on
lists with a single element, in the sense that qsort [x ] = [x ] for any x:
qsort [x ]
=
{ applying qsort }
qsort [ ] ++ [x ] ++ qsort [ ]
=
{ applying qsort }
[ ] ++ [x ] ++ [ ]
=
{ applying ++ }
[x ]
In turn, we now work through the application of qsort to an example list,
using the above property to simplify the calculation:
qsort [3, 5, 1, 4, 2]
=
{ applying qsort }
qsort [1, 2] ++ [3] ++ qsort [5, 4]
=
{ applying qsort }
(qsort [ ] ++ [1] ++ qsort [2]) ++ [3] ++ (qsort [4] ++ [5] ++ qsort [ ])
=
{ applying qsort, above property }
([ ] ++ [1] ++ [2]) ++ [3] ++ ([4] ++ [5] ++ [ ])
=
{ applying ++ }
[1, 2] ++ [3] ++ [4, 5]
=
{ applying ++ }
[1, 2, 3, 4, 5]

1.6. CHAPTER REMARKS
17
In summary, qsort has sorted the example list into numerical order. More
generally, this function produces a sorted version of any list of numbers. The
ﬁrst equation for qsort states that the empty list is already sorted, while the
second states that any non-empty list can be sorted by inserting the ﬁrst
number between the two lists that result from sorting the remaining numbers
that are smaller and larger than this number. This method of sorting is called
quicksort, and is one of the best such methods known.
The above implementation of quicksort is an excellent example of the power
of Haskell, being both clear and concise. Moreover, the function qsort is also
more general than might be expected, being applicable not just with numbers,
but with any type of ordered values. More precisely, the type
qsort :: Ord a ⇒[a ] →[a ]
states that for any type a of ordered values, qsort is a function that maps
between lists of such values. Haskell supports many diﬀerent types of ordered
values, including numbers, single characters such as 'a', and strings of char-
acters such as "abcde". Hence, for example, the function qsort could also be
used to sort a list of characters, or a list of strings.
1.6
Chapter remarks
The Haskell Report is freely available on the web from the Haskell home page,
www.haskell.org, and has also been published as a book [26]. A more detailed
historical account of the development of functional programming languages is
given in Hudak's survey article [11].
1.7
Exercises
1. Give another possible calculation for the result of double (double 2).
2. Show that sum [x ] = x for any number x.
3. Deﬁne a function product that produces the product of a list of numbers,
and show using your deﬁnition that product [2, 3, 4] = 24.
4. How should the deﬁnition of the function qsort be modiﬁed so that it
produces a reverse sorted version of a list?
5. What would be the eﬀect of replacing ⩽by < in the deﬁnition of qsort?
Hint: consider the example qsort [2, 2, 3, 1, 1].

18
CHAPTER 1. INTRODUCTION

Chapter 2
First Steps
In this chapter we take our ﬁrst proper steps with Haskell. We start by intro-
ducing the Hugs system and the standard prelude, then explain the notation
for function application, develop our ﬁrst Haskell script, and conclude by dis-
cussing a number of syntactic conventions concerning scripts.
2.1
The Hugs system
As we saw in the previous chapter, small Haskell examples can be executed by
hand. In practice, however, we usually require an implementation of Haskell
that can execute programs automatically.
In this book we use an interac-
tive system called Hugs, which is the most widely used implementation of
Haskell 98, the recently deﬁned stable version of the language.
The interactive nature of Hugs makes it well suited for teaching and proto-
typing purposes, and its performance is suﬃcient for most applications. How-
ever, if greater performance or a stand-alone executable version of a Haskell
program is required, a number of compilers for Haskell 98 are also available,
of which the most widely used is the Glasgow Haskell Compiler.
2.2
The standard prelude
When the Hugs system is started it ﬁrst loads a library ﬁle called Prelude.hs,
and then displays a > prompt to indicate that the system is waiting for the
user to enter an expression to be evaluated.
For example, the library ﬁle
deﬁnes many familiar functions that operate on integers, including the ﬁve
main arithmetic operations of addition, subtraction, multiplication, division,
and exponentiation, as illustrated below:
> 2 + 3
5
19

20
CHAPTER 2. FIRST STEPS
> 2 −3
−1
> 2 ∗3
6
> 7 'div' 2
3
> 2 ↑3
8
Note that the integer division operator is written as 'div', and rounds down
to the nearest integer if the result is a proper fraction.
Following normal mathematical convention, exponentiation has higher pri-
ority than multiplication and division, which in turn have higher priority than
addition and subtraction. For example, 2∗3↑4 means 2∗(3↑4), while 2+3∗4
means 2+ (3∗4). Moreover, exponentiation associates (brackets) to the right,
while the other four arithmetic operators associate to the left. For example,
2↑3↑4 means 2↑(3↑4), while 2−3+4 means (2−3)+4. In practice, however,
it is often clearer to use explicit parentheses in such arithmetic expressions,
rather than relying on the above conventions.
In addition to functions on integers, the library ﬁle also provides a range
of useful functions that operate on lists. In Haskell, the elements of a list are
enclosed in square parentheses, and are separated by commas. Some of the
most commonly used library functions on lists are illustrated below.
• Select the ﬁrst element of a non-empty list:
> head [1, 2, 3, 4, 5]
1
• Remove the ﬁrst element from a non-empty list:
> tail [1, 2, 3, 4, 5]
[2, 3, 4, 5]
• Select the nth element of list (counting from zero):
> [1, 2, 3, 4, 5] !! 2
3
• Select the ﬁrst n elements of a list:
> take 3 [1, 2, 3, 4, 5]
[1, 2, 3]

2.2. THE STANDARD PRELUDE
21
• Remove the ﬁrst n elements from a list:
> drop 3 [1, 2, 3, 4, 5]
[4, 5]
• Calculate the length of a list:
> length [1, 2, 3, 4, 5]
5
• Calculate the sum of a list of numbers:
> sum [1, 2, 3, 4, 5]
15
• Calculate the product of a list of numbers:
> product [1, 2, 3, 4, 5]
120
• Append two lists:
> [1, 2, 3] ++ [4, 5]
[1, 2, 3, 4, 5]
• Reverse a list:
> reverse [1, 2, 3, 4, 5]
[5, 4, 3, 2, 1]
Some of the functions in the standard prelude may produce an error for
certain values of their arguments. For example, attempting to divide by zero
or select the ﬁrst element of an empty list will produce an error:
> 1 'div' 0
Error
> head [ ]
Error
In practice, when an error occurs the Hugs system also produces a message
that provides some information about the likely cause, but these messages are
often rather technical, and are not discussed further in this book.
For reference, appendix A presents some of the most commonly used deﬁ-
nitions from the standard prelude, and appendix B shows how special Haskell
symbols, such as ↑and ++, are typed using a normal keyboard.

22
CHAPTER 2. FIRST STEPS
2.3
Function application
In mathematics, the application of a function to its arguments is usually de-
noted by enclosing the arguments in parentheses, while the multiplication of
two values is often denoted silently, by writing the two values next to one
another. For example, in mathematics the expression
f(a, b) + c d
means apply the function f to two arguments a and b, and add the result
to the product of c and d.
Reﬂecting its primary status in the language,
function application in Haskell is denoted silently using spacing, while the
multiplication of two values is denoted explicitly using the operator ∗. For
example, the expression above would be written in Haskell as follows:
f a b + c ∗d
Moreover, function application has higher priority than all other operators.
For example, f a + b means (f a) + b. The following table gives a few fur-
ther examples to illustrate the diﬀerences between the notation for function
application in mathematics and in Haskell:
Mathematics
Haskell
f(x)
f x
f(x, y)
f x y
f(g(x))
f (g x)
f(x, g(y))
f x (g y)
f(x) g(y)
f x ∗g y
Note that parentheses are still required in the Haskell expression f (g x)
above, because f g x on its own would be interpreted as the application of
the function f to two arguments g and x, whereas the intention is that f is
applied to one argument, namely the result of applying the function g to an
argument x. A similar remark holds for the expression f x (g y).
2.4
Haskell scripts
As well as the functions provided in the standard prelude, it is also possible to
deﬁne new functions. New functions cannot be deﬁned at the > prompt within
Hugs, but must be deﬁned within a script, a text ﬁle comprising a sequence
of deﬁnitions. By convention, Haskell scripts usually have a .hs suﬃx on their
ﬁlename to diﬀerentiate them from other kinds of ﬁles.
My ﬁrst script
When developing a Haskell script, it is useful to keep two windows open, one
running an editor for the script, and the other running Hugs. As an example,

2.4. HASKELL SCRIPTS
23
suppose that we start a text editor and type in the following two function
deﬁnitions, and save the script to a ﬁle called test.hs:
double x
=
x + x
quadruple x
=
double (double x)
In turn, suppose that we leave the editor open, and in another window start
up the Hugs system and instruct it to load the new script:
> :load test.hs
Now both Prelude.hs and test.hs are loaded, and functions from both scripts
can be freely used. For example:
> quadruple 10
40
> take (double 2) [1, 2, 3, 4, 5, 6]
[1, 2, 3, 4]
Now suppose that we leave Hugs open, return to the editor, add the following
two function deﬁnitions to those already typed in, and then resave the ﬁle:
factorial n
=
product [1 . . n ]
average ns
=
sum ns 'div' length ns
We could equally well have deﬁned average ns = div (sum ns) (length ns), but
writing div between its two arguments is more natural. In general, any func-
tion with two arguments can be written between its arguments by enclosing
the name of the function in single back quotes ' '.
Hugs does not automatically reload scripts when they are modiﬁed, so a
reload command must be executed before the new deﬁnitions can be used:
> :reload
> factorial 10
3628800
> average [1, 2, 3, 4, 5]
3
For reference, the table below summarises the meaning of some of the most
commonly used Hugs commands. Note that any command can be abbreviated
by its ﬁrst character.
For example, :load can be abbreviated by :l.
The
command :type is explained in more detail in the next chapter.

24
CHAPTER 2. FIRST STEPS
Command
Meaning
:load name
load script name
:reload
reload current script
:edit name
edit script name
:edit
edit current script
:type expr
show type of expr
:?
show all commands
:quit
quit Hugs
Naming requirements
When deﬁning a new function, the names of the function and its arguments
must begin with a lower-case letter, but can then be followed by zero or more
letters (both lower and upper-case), digits, underscores, and forward single
quotes. For example, the following are all valid names:
myFun
fun1
arg 2
x ′
The following list of keywords have a special meaning in the language, and
cannot be used as the names of functions or their arguments:
case
class
data
default
deriving
do
else
if
import
in
inﬁx
inﬁxl
inﬁxr
instance
let
module
newtype
of
then
type
where
By convention, list arguments in Haskell usually have the suﬃx s on their
name to indicate that they may contain multiple values. For example, a list
of numbers might be named ns, a list of arbitrary values might be named xs,
and a list of list of characters might be named css.
The layout rule
When constructing a script, each deﬁnition must begin in precisely the same
column. This layout rule makes it possible to determine the grouping of deﬁ-
nitions from their indentation. For example, in the script
a
=
b + c
where
b = 1
c = 2
d
=
a ∗2
it is clear from the indentation that b and c are local deﬁnitions for use within
the body of a. If desired, such grouping can be made explicit by enclosing a
sequence of deﬁnitions in curly parentheses and separating each deﬁnition by

2.5. CHAPTER REMARKS
25
a semi-colon. For example, the above script could also be written as:
a = b + c
where
{b = 1;
c = 2}
d = a ∗2
In general, however, it is usually clearer to rely on the layout rule to determine
the grouping of deﬁnitions, rather than use explicit syntax.
Comments
In addition to new deﬁnitions, scripts can also contain comments that will be
ignored by Hugs. Haskell provides two kinds of comments, called ordinary and
nested. Ordinary comments begin with the symbol -- and extend to the end
of the current line, as in the following examples:
-- Factorial of a positive integer:
factorial n
=
product [1 . . n ]
-- Average of a list of integers:
average ns
=
sum ns 'div' length ns
Nested comments begin and end with the symbols {- and -}, may span mul-
tiple lines, and may be nested in the sense that comments can contain other
comments. Nested comments are particularly useful for temporarily removing
sections of deﬁnitions from a script, as in the following example:
{-
double x
=
x + x
quadruple x
=
double (double x)
-}
2.5
Chapter remarks
The Hugs system is freely available on the web from the Haskell home page,
www.haskell.org, which also contains a wealth of other useful resources.
2.6
Exercises
1. Parenthesise the following arithmetic expressions:
2 ↑3 ∗4
2 ∗3 + 4 ∗5
2 + 3 ∗4 ↑5

26
CHAPTER 2. FIRST STEPS
2. Work through the examples from this chapter using Hugs.
3. The script below contains three syntactic errors. Correct these errors
and then check that your script works properly using Hugs.
N
=
a 'div' length xs
where
a = 10
xs = [1, 2, 3, 4, 5]
4. Show how the library function last that selects the last element of a non-
empty list could be deﬁned in terms of the library functions introduced
in this chapter. Can you think of another possible deﬁnition?
5. Show how the library function init that removes the last element from
a non-empty list could similarly be deﬁned in two diﬀerent ways.

Chapter 3
Types and Classes
In this chapter we introduce types and classes, two of the most fundamental
concepts in Haskell. We start by explaining what types are and how they are
used in Haskell, then present a number of basic types and ways to build larger
types by combining smaller types, discuss function types in more detail, and
conclude with the concepts of polymorphic types and type classes.
3.1
Basic concepts
A type is a collection of related values. For example, the type Bool contains
the two logical values False and True, while the type Bool →Bool contains
all functions that map arguments from Bool to results from Bool, such as the
logical negation function ¬. We use the notation v :: T to mean that v is a
value in the type T, and say that v "has type" T. For example:
False
::
Bool
True
::
Bool
¬
::
Bool →Bool
More generally, the symbol :: can also be used with expressions that have not
yet been evaluated, in which case e::T means that evaluation of the expression
e will produce a value of type T. For example:
¬ False
::
Bool
¬ True
::
Bool
¬ (¬ False)
::
Bool
In Haskell, every expression must have a type, which is calculated prior
to evaluating the expression by a process called type inference. The key to
this process is a typing rule for function application, which states that if f is
a function that maps arguments of type A to results of type B, and e is an
expression of type A, then the application f e has type B:
f :: A →B
e :: A
f e :: B
27

28
CHAPTER 3. TYPES AND CLASSES
For example, the typing ¬ False ::Bool can be inferred from this rule using the
fact that ¬::Bool →Bool and False ::Bool. On the other hand, the expression
¬ 3 does not have a type under the above rule for function application, because
this would require that 3 :: Bool, which is not valid because 3 is not a logical
value. Expressions such as ¬ 3 that do not have a type are said to contain a
type error, and are deemed to be invalid expressions.
Because type inference precedes evaluation, Haskell programs are type safe,
in the sense that type errors can never occur during evaluation. In practice,
type inference detects a very large class of program errors, and is one of the
most useful features of Haskell. Note, however, that the use of type inference
does not eliminate the possibility that other kinds of error may occur during
evaluation. For example, the expression 1 'div' 0 is free from type errors, but
produces an error when evaluated because division by zero is undeﬁned.
The downside of type safety is that some expressions that evaluate success-
fully will be rejected on type grounds. For example, the conditional expression
if True then 1 else False evaluates to the number 1, but contains a type error
and is hence deemed invalid. In particular, the typing rule for a conditional
expression requires that both possible results have the same type, whereas in
this case the ﬁrst such result, 1, is a number and the second, False, is a logical
value. In practice, however, programmers quickly learn how to work within
the limits of the type system and avoid such problems.
In Hugs, the type of any expression can be displayed by preceding the
expression by the command :type. For example:
> :type ¬
¬ :: Bool →Bool
> :type ¬ False
¬ False :: Bool
> :type ¬ 3
Error
3.2
Basic types
Haskell provides a number of basic types that are built-in to the language, of
which the most commonly used are described below.
Bool - logical values
This type contains the two logical values False and True.
Char - single characters
This type contains all single characters that are available from a normal key-
board, such as 'a', 'A', '3' and '_', as well as a number of control characters

3.2. BASIC TYPES
29
that have a special eﬀect, such as '\n' (move to a new line) and '\t' (move
to the next tab stop). As is standard in most programming languages, single
characters must be enclosed in single forward quotes ' '.
String - strings of characters
This type contains all sequences of characters, such as "abc", "1+2=3", and
the empty string "". Again, as is standard in most programming languages,
strings of characters must be enclosed in double quotes " ".
Int - ﬁxed-precision integers
This type contains integers such as −100, 0, and 999, with a ﬁxed amount of
computer memory being used for their storage. For example, the Hugs system
has values of type Int in the range −231 to 231 −1. Going outside this range
can give unexpected results. For example, evaluating 2 ↑31 :: Int using Hugs
(the use of :: forces the result to an Int rather than some other numeric type)
gives a negative number as the result, which is incorrect.
Integer - arbitrary-precision integers
This type contains all integers, with as much memory are necessary being used
for their storage, thus avoiding the imposition of lower and upper limits on the
range of numbers. For example, evaluating 2 ↑31 :: Integer using any Haskell
system will produce the correct result.
Apart from the diﬀerent memory requirements and precision for numbers
of type Int and Integer, the choice between these two types is also one of per-
formance. In particular, most computers have built-in hardware for processing
ﬁxed-precision integers, whereas arbitrary-precision integers must usually be
processed using the slower medium of software, as sequences of digits.
Float - single-precision ﬂoating-point numbers
This type contains numbers with a decimal point, such as −12.34, 1.0, and
3.14159, with a ﬁxed amount of memory being used for their storage. The
term ﬂoating-point comes from the fact that the number of digits permitted
after the decimal point depends upon the magnitude of the number. For exam-
ple, evaluating sqrt 2 :: Float using Hugs gives the result 1.41421 (the library
function sqrt calculates the square root of a number), which has ﬁve digits
after the point, whereas sqrt 99999 :: Float gives 316.226, which only has three
digits after the point. Programming with ﬂoating-point numbers is a specialist
topic that requires a careful treatment of rounding errors, and we say little
more about such numbers in this introductory text.
We conclude this section by noting a single number may have more than
one numeric type. For example, 3 :: Int, 3 :: Integer, and 3 :: Float are all valid
typings for the number 3. This raises the question of what type such numbers

30
CHAPTER 3. TYPES AND CLASSES
should be assigned during type inference, which will be answered later in this
chapter when we consider type classes.
3.3
List types
A list is a sequence of elements of the same type, with the elements being
enclosed in square parentheses and separated by commas. We write [T ] for
the type of all lists whose elements have type T. For example:
[False, True, False ]
::
[Bool ]
['a', 'b', 'c', 'd']
::
[Char ]
["One", "Two", "Three"]
::
[String ]
The number of elements in a list is called its length. The list [ ] of length
zero is called the empty list, while lists of length one, such as such as [False ]
and ['a'], are called singleton lists. Note that [[ ]] and [ ] are diﬀerent lists,
the former being a singleton list comprising the empty list as its only element,
and the latter being simply the empty list.
There are three further points to note about list types. First of all, the
type of a list conveys no information about its length. For example, the lists
[False, True ] and [False, True, False ] both have type [Bool ], even though they
have diﬀerent lengths. Secondly, there are no restrictions on the type of the
elements of a list. At present we are limited in the range of examples that
we can give because the only non-basic type that we have introduced at this
point is list types, but we can have lists of lists, such as:
[['a', 'b'], ['c', 'd', 'e']]
::
[[Char ]]
Finally, there is no restriction that a list must have a ﬁnite length. In partic-
ular, due to the use of lazy evaluation in Haskell, lists with an inﬁnite length
are both natural and practical, as we shall see in chapter 12.
3.4
Tuple types
A tuple is a ﬁnite sequence of components of possibly diﬀerent types, with the
components being enclosed in round parentheses and separated by commas.
We write (T1, T2, . . . , Tn) for the type of all tuples whose ith components have
type Ti for any i in the range 1 to n. For example:
(False, True)
::
(Bool, Bool)
(False, 'a', True)
::
(Bool, Char, Bool)
("Yes", True, 'a')
::
(String, Bool, Char)
The number of components in a tuple is called its arity. The tuple () of
arity zero is called the empty tuple, tuples of arity two are called pairs, tuples

3.5. FUNCTION TYPES
31
of arity three are called triples, and so on. Tuples of arity one, such as (False),
are not permitted because they would conﬂict with the use of parentheses to
make evaluation order explicit, such as in (1 + 2) ∗3.
As with list types, there are three further points to note about tuple types.
First of all, the type of a tuple conveys its arity.
For example, the type
(Bool, Char) contains all pairs comprising a ﬁrst component of type Bool and
a second component of type Char. Secondly, there are no restrictions on the
types of the components of a tuple. For example, we can now have tuples of
tuples, tuples of lists, and lists of tuples:
('a', (False, 'b'))
::
(Char, (Bool, Char))
(['a', 'b'], [False, True ])
::
([Char ], [Bool ])
[('a', False), ('b', True)]
::
[(Char, Bool)]
Finally, note that tuples must have a ﬁnite arity, in order to ensure that tuple
types can always be calculated prior to evaluation.
3.5
Function types
A function is a mapping from arguments of one type to results of another
type. We write T1 →T2 for the type of all functions that map arguments of
type T1 to results of type T2. For example:
¬
::
Bool →Bool
isDigit
::
Char →Bool
(The library function isDigit decides if a character is a numeric digit.) Because
there are no restrictions on the types of the arguments and results of a function,
the simple notion of a function with a single argument and result is already
suﬃcient to handle multiple arguments and results, by packaging multiple
values using lists or tuples. For example, we can deﬁne a function add that
calculates the sum of a pair of integers, and a function zeroto that returns the
list of integers from zero to a given limit, as follows:
add
::
(Int, Int) →Int
add (x, y)
=
x + y
zeroto
::
Int →[Int ]
zeroto n
=
[0 . . n ]
In these examples we have followed the Haskell convention of preceding func-
tion deﬁnitions by their types, which serves as useful documentation. Any
such types provided manually by the user are checked for consistency with the
types calculated automatically using type inference.
Note that there is no restriction that functions must be total on their
argument type, in the sense that there may be some arguments for which the
result of a function is not deﬁned. For example, the result of library function
head that selects the ﬁrst element of a list is undeﬁned if the list is empty.

32
CHAPTER 3. TYPES AND CLASSES
3.6
Curried functions
Functions with multiple arguments can also be handled in another, perhaps
less obvious way, by exploiting the fact that functions are free to return func-
tions as results. For example, consider the following deﬁnition:
add′
::
Int →(Int →Int)
add′ x y
=
x + y
The type states that add′ is a function that takes an argument of type Int,
and returns a result that is a function of type Int →Int. The deﬁnition itself
states that add′ takes an integer x followed by an integer y, and returns the
result x + y. More precisely, add′ takes an integer x and returns a function,
which in turn takes an integer y and returns the result x + y.
Note that the function add′ produces the same ﬁnal result as the function
add from the previous section, but whereas add takes its two arguments at
the same time packaged as a pair, add′ takes its two arguments one at a time,
as reﬂected in the diﬀerent types of the two functions:
add
::
(Int, Int) →Int
add′
::
Int →(Int →Int)
Functions with more than two arguments can also be handled using the same
technique, by returning functions that return functions, and so on. For exam-
ple, a function mult that takes three integers, one at a time, and returns their
product, can be deﬁned as follows:
mult
::
Int →(Int →(Int →Int))
mult x y z
=
x ∗y ∗z
This deﬁnition states that mult takes an integer x and returns a function,
which in turn takes an integer y and returns another function, which ﬁnally
takes an integer z and returns the result x ∗y ∗z.
Functions such as add′ and mult that take their arguments one at a time are
called curried. As well as being interesting in their own right, curried functions
are also more ﬂexible than functions on tuples, because useful functions can
often be made by partially applying a curried function with less than its full
complement of arguments. For example, a function that increments an integer
is given by the partial application add′ 1 :: Int →Int of the curried function
add′ with only one of its two arguments.
To avoid excess parentheses when working with curried functions, two sim-
ple conventions are adopted. First of all, the function arrow →in types is
assumed to associate to the right. For example,
Int →Int →Int →Int
means
Int →(Int →(Int →Int))

3.7. POLYMORPHIC TYPES
33
Consequently, function application, which is denoted silently using spacing, is
assumed to associate to the left. For example,
mult x y z
means
((mult x) y) z
Unless tupling is explicitly required, all functions in Haskell with multiple
arguments are normally deﬁned as curried functions, and the two conventions
above are used to reduce the number of parentheses that are required.
3.7
Polymorphic types
The library function length calculates the length of any list, irrespective of the
type of the elements of the list. For example, it can be used to calculate the
length of a list of integers, a list of strings, or even a list of functions:
> length [1, 3, 5, 7]
4
> length ["Yes", "No"]
2
> length [isDigit, isLower, isUpper ]
3
The idea that the function length can be applied to lists whose elements have
any type is made precise in its type by the inclusion of a type variable. Type
variables must begin with a lower-case letter, and are usually simply named
a, b, c, and so on. For example, the type of length is as follows:
length :: [a ] →Int
That is, for any type a, the function length has type [a ] →Int. A type that
contains one or more type variables is called polymorphic ("of many forms"),
as is an expression with such a type. Hence, [a ] →Int is a polymorphic type
and length is a polymorphic function. More generally, many of the functions
provided in the standard prelude are polymorphic. For example:
fst
::
(a, b) →a
head
::
[a ] →a
take
::
Int →[a ] →[a ]
zip
::
[a ] →[b] →[(a, b)]
id
::
a →a

34
CHAPTER 3. TYPES AND CLASSES
3.8
Overloaded types
The arithmetic operator + calculates the sum of any two numbers of the same
numeric type. For example, it can be used to calculate the sum of two integers,
or the sum of two ﬂoating-point numbers:
> 1 + 2
3
> 1.1 + 2.2
3.3
The idea that the operator + can be applied to numbers of any numeric type is
made precise in its type by the inclusion of a class constraint. Class constraints
are written in the form C a, where C is the name of a class and a is a type
variable. For example, the type of + is as follows:
(+)
::
Num a ⇒a →a →a
That is, for any type a that is a instance of the class Num of numeric types,
the function (+) has type a →a →a. (Parenthesising an operator converts
it into a curried function, and is explained in more detail in the next chapter.)
A type that contains one or more class constraints is called overloaded, as is
an expression with such a type. Hence, Num a ⇒a →a →a is an overloaded
type and (+) is an overloaded function. More generally, most of the numeric
functions provided in the standard prelude are overloaded. For example:
(−)
::
Num a ⇒a →a →a
(∗)
::
Num a ⇒a →a →a
negate
::
Num a ⇒a →a
abs
::
Num a ⇒a →a
signum
::
Num a ⇒a →a
Moreover, numbers themselves are also overloaded. For example, 3::Num a ⇒
a means that for any numeric type a, the number 3 has type a.
3.9
Basic classes
Recall that a type is a collection of related values. Building upon this notion, a
class is a collection of types that support certain overloaded operations called
methods. Haskell provides a number of basic classes that are built-in to the
language, of which the most commonly used are described below.
Eq - equality types
This class contains types whose values can be compared for equality and in-
equality using the following two methods:
(==)
::
a →a →Bool
(̸=)
::
a →a →Bool

3.9. BASIC CLASSES
35
All the basic types Bool, Char, String, Int, Integer, and Float are instances
of the Eq class, as are list and tuple types, provided that their element and
component types are instances of the class. For example:
> False == False
True
> 'a' == 'b'
False
> "abc" == "abc"
True
> [1, 2] == [1, 2, 3]
False
> ('a', False) == ('a', False)
True
Note that function types are not in general instances of the Eq class, because
it is not feasible in general to compare two functions for equality.
Ord - ordered types
This class contains types that are instances of the equality class Eq, but in ad-
dition whose values are totally (linearly) ordered, and as such can be compared
and processed using the following six methods:
(<)
::
a →a →Bool
(⩽)
::
a →a →Bool
(>)
::
a →a →Bool
(⩾)
::
a →a →Bool
min
::
a →a →a
max
::
a →a →a
All the basic types Bool, Char, String, Int, Integer, and Float are instances
of the Ord class, as are list types and tuple types, provided that their element
and component types are instances of the class. For example:
> False < True
True
> min 'a' 'b'
'a'
> "elegant" < "elephant"
True

36
CHAPTER 3. TYPES AND CLASSES
> [1, 2, 3] < [1, 2]
False
> ('a', 2) < ('b', 1)
True
> ('a', 2) < ('a', 1)
False
Note that strings, lists and tuples are ordered lexicographically, that is, in the
same way as words in a dictionary. For example, two pairs of the same type
are in order if their ﬁrst components are in order, in which case their second
components are not considered, or if their ﬁrst components are equal, in which
case their second components must be in order.
Show - showable types
This class contains types whose values can be converted into strings of char-
acters using the following method:
show
::
a →String
All the basic types Bool, Char, String, Int, Integer, and Float are instances of
the Show class, as are list types and tuple types, provided that their element
and component types are instances of the class. For example:
> show False
"False"
> show 'a'
"'a'"
> show 123
"123"
> show [1, 2, 3]
"[1,2,3]"
> show ('a', False)
"('a',False)"
Read - readable types
This class is dual to Show, and contains types whose values can be converted
from strings of characters using the following method:
read
::
String →a

3.9. BASIC CLASSES
37
All the basic types Bool, Char, String, Int, Integer, and Float are instances of
the Read class, as are list types and tuple types, provided that their element
and component types are instances of the class. For example:
> read "False" :: Bool
False
> read "'a'" :: Char
'a'
> read "123" :: Int
123
> read "[1,2,3]" :: [Int ]
[1, 2, 3]
> read "('a',False)" :: (Char, Bool)
('a', False)
The use of :: in these examples resolves the type of the result. In practice,
however, the necessary type information can usually be inferred automatically
from the context.
For example, the expression ¬ (read "False") requires
no explicit type information, because the application of the logical negation
function ¬ implies that read "False" must have type Bool.
Note that the result of read is undeﬁned if its argument is not syntactically
valid. For example, the expression ¬ (read "hello") produces an error when
evaluated, because "hello" cannot be read as a logical value.
Num - numeric types
This class contains types that are instances of the equality class Eq and show-
able class Show, but in addition whose values are numeric, and as such can
be processed using the following six methods:
(+)
::
a →a →a
(−)
::
a →a →a
(∗)
::
a →a →a
negate
::
a →a
abs
::
a →a
signum
::
a →a
(The method negate returns the negation of a number, abs returns the absolute
value, while signum returns the sign.) The basic types Int, Integer and Float
are instances of the Num class. For example:
> 1 + 2
3

38
CHAPTER 3. TYPES AND CLASSES
> 1.1 + 2.2
3.3
> negate 3.3
−3.3
> abs (−3)
3
> signum (−3)
−1
Note that the Num class does not provide a division method, but as we shall
now see, division is handled separately using two special classes, one for inte-
gral numbers and one for fractional numbers.
Integral - integral types
This class contains types that are instances of the numeric class Num, but in
addition whose values are integers, and as such support the methods of integer
division and integer remainder:
div
::
a →a →a
mod
::
a →a →a
In practice, these two methods are often written between their two arguments
by enclosing their names in single back quotes. The basic types Int and Integer
are instances of the Integral class. For example:
> 7 'div' 2
3
> 7 'mod' 2
1
For eﬃciency reasons, a number of prelude functions that involve both lists
and integers (such as length, take and drop) are restricted to the type Int of
ﬁnite-precision integers, rather than being applicable to any instance of the
Integral class. If required, however, such generic versions of these functions
are provided as part of an additional library ﬁle called List.hs.
Fractional - fractional types
This class contains types that are instances of the numeric class Num, but in
addition whose values are non-integral, and as such support the methods of
fractional division and fractional reciprocation:
(/)
::
a →a →a
recip
::
a →a

3.10.
CHAPTER REMARKS
39
The basic type Float is an instance of the Fractional class. For example:
> 7.0 / 2.0
3.5
> recip 2.0
0.5
3.10
Chapter remarks
The term Bool for the type of logical values celebrates the pioneering work
of George Boole on symbolic logic, while the term curried for functions that
take their arguments one at a time celebrates the work of Haskell Curry (after
whom the language Haskell itself is named) on such functions. A more de-
tailed account of the type system is given in Haskell Report [26], while formal
descriptions for specialists can be found in [21, 6].
3.11
Exercises
1. What are the types of the following values?
['a', 'b', 'c']
('a', 'b', 'c')
[(False, 'O'), (True, '1')]
([False, True ], ['0', '1'])
[tail, init, reverse ]
2. What are the types of the following functions?
second xs
=
head (tail xs)
swap (x, y)
=
(y, x)
pair x y
=
(x, y)
double x
=
x ∗2
palindrome xs
=
reverse xs == xs
twice f x
=
f (f x)
Hint: take care to include the necessary class constraints if the functions
are deﬁned using overloaded operators.
3. Check your answers to the preceding two questions using Hugs.
4. Why is it not feasible in general for function types to be instances of the
Eq class? When is it feasible? Hint: two functions of the same type are
equal if they always return equal results for equal arguments.

40
CHAPTER 3. TYPES AND CLASSES

Chapter 4
Deﬁning Functions
In this chapter we introduce a range of mechanisms for deﬁning functions in
Haskell. We start with conditional expressions and guarded equations, then
introduce the simple but powerful idea of pattern matching, and conclude with
the concepts of lambda expressions and sections.
4.1
New from old
Perhaps the most straightforward way to deﬁne new functions is simply by
combining one or more existing functions. For example, a number of library
functions that are deﬁned in this way are shown below.
• Decide if a character is a digit:
isDigit
::
Char →Bool
isDigit c
=
c ⩾'0' ∧c ⩽'9'
• Decide if an integer is even:
even
::
Integral a ⇒a →Bool
even n
=
n 'mod' 2 == 0
• Split a list at the nth element:
splitAt
::
Int →[a ] →([a ], [a ])
splitAt n xs
=
(take n xs, drop n xs)
• Reciprocation:
recip
::
Fractional a ⇒a →a
recip n
=
1 / n
Note the use of the class constraints in the types for even and recip above,
which make precise the idea that these functions can be applied to numbers
of any integral and fractional types, respectively.
41

42
CHAPTER 4. DEFINING FUNCTIONS
4.2
Conditional expressions
Haskell provides a range of diﬀerent ways to deﬁne functions that choose be-
tween a number of possible results. The simplest are conditional expressions,
which use a logical expression called a condition to choose between two results
of the same type. If the condition is True then the ﬁrst result is chosen, other-
wise the second is chosen. For example, the library function abs that returns
the absolute value of an integer can be deﬁned as follows:
abs
::
Int →Int
abs n
=
if n ⩾0 then n else −n
Conditional expressions may be nested, in the sense that they can contain
other conditional expressions. For example, the library function signum that
returns the sign of an integer can be deﬁned as follows:
signum
::
Int →Int
signum n
=
if n < 0 then −1 else
if n == 0 then 0 else 1
Note that unlike in some programming languages, conditional expressions
in Haskell must always have an else branch, which avoids the well-known
"dangling else" problem. For example, if else branches were optional then
the expression if True then if False then 1 else 2 could either return the
result 2 or produce an error, depending upon whether the single else branch
was assumed to be part of the inner or outer conditional expression.
4.3
Guarded equations
As an alternative to using conditional expressions, functions can also be de-
ﬁned using guarded equations, in which a sequence of logical expressions called
guards is used to choose between a sequence of results of the same type. If
the ﬁrst guard is True then the ﬁrst result is chosen, otherwise if the second
is True then the second result is chosen, and so on. For example, the library
function abs can also be deﬁned as follows:
abs n | n ⩾0
=
n
| otherwise
=
−n
The symbol | is read as "such that", and the guard otherwise is deﬁned in the
standard prelude simply by otherwise = True. Ending a sequence of guards
with otherwise is not necessary, but provides a convenient way of handling
"all other cases", as well as clearly avoiding the possibility that none of the
guards in the sequence are True, which would result in an error.
The main beneﬁt of guarded equations over conditional expressions is that
deﬁnitions with multiple guards are easier to read. For example, the library

4.4. PATTERN MATCHING
43
function signum is easier to understand when deﬁned as follows:
signum n | n < 0
=
−1
| n == 0
=
0
| otherwise
=
1
4.4
Pattern matching
Many functions have a particularly simple and intuitive deﬁnition using pattern
matching, in which a sequence of syntactic expressions called patterns is used
to choose between a sequence of results of the same type. If the ﬁrst pattern
is matched then the ﬁrst result is chosen, otherwise if the second is matched
then the second result is chosen, and so on. For example, the library function
¬ that returns the negation of a logical value is deﬁned as follows:
¬
::
Bool →Bool
¬ False
=
True
¬ True
=
False
Functions with more than one argument can also be deﬁned using pattern
matching, in which case the patterns for each argument are matched in order
within each equation. For example, the library operator ∧that returns the
conjunction of two logical values can be deﬁned as follows:
(∧)
::
Bool →Bool →Bool
True ∧True
=
True
True ∧False
=
False
False ∧True
=
False
False ∧False
=
False
However, this deﬁnition can be simpliﬁed by combining the last three equations
into a single equation that returns False independent of the values of the two
arguments, using the wildcard pattern
that matches any value:
True ∧True
=
True
∧
=
False
This version also has the beneﬁt that, under lazy evaluation as discussed in
chapter 12, if the ﬁrst argument is False then the result False is returned
without the need to evaluate the second argument. In practice, the prelude
deﬁnes ∧using equations that have this same property, but make the choice
about which equation applies using the value of the ﬁrst argument only:
True ∧b
=
b
False ∧
=
False
That is, if the ﬁrst argument is True then the result is the value of the second
argument, and if the ﬁrst argument is False then the result is False.

44
CHAPTER 4. DEFINING FUNCTIONS
Note that for technical reasons, the same name may not be used for more
than one argument in a single equation. For example, the following deﬁnition
for the operator ∧is based upon the observation that if the two arguments
are equal then the result is the same value, otherwise the result is False, but
is invalid because of the above naming requirement:
b ∧b
=
b
∧
=
False
If desired, however, a valid version of this deﬁnition can be obtained by using
a guard to decide if the two arguments are equal:
b ∧c | b == c
=
b
| otherwise
=
False
So far, we have only considered basic patterns that are either values, vari-
ables, or the wildcard pattern. In the remainder of this section we introduce
three useful ways to build larger patterns by combining smaller patterns.
Tuple patterns
A tuple of patterns is itself a pattern, which matches any tuple of the same
arity whose components all match the corresponding patterns in order. For
example, the library functions fst and snd that select the ﬁrst and second
components of a pair are deﬁned as follows:
fst
::
(a, b) →a
fst (x, )
=
x
snd
::
(a, b) →b
snd ( , y)
=
y
List patterns
Similarly, a list of patterns is itself a pattern, which matches any list of the
same length whose elements all match the corresponding patterns in order.
For example, a function test that decides if a list contains precisely three
characters beginning with 'a' can be deﬁned as follows:
test
::
[Char ] →Bool
test ['a', ,
]
=
True
test
=
False
Up to this point we have viewed lists as a primitive notion in Haskell. In
fact they are not primitive as such, but are actually constructed one element
at a time starting from the empty list [ ] using an operator : called cons that
constructs a new list by prepending a new element to the start of an existing
list. For example, the list [1, 2, 3] can be decomposed as follows:

4.4. PATTERN MATCHING
45
[1, 2, 3]
=
{ list notation }
1 : [2, 3]
=
{ list notation }
1 : (2 : [3])
=
{ list notation }
1 : (2 : (3 : [ ]))
That is, [1, 2, 3] is just an abbreviation for 1 : (2 : (3 : [ ])). To avoid excess
parentheses when working with such lists, the cons operator is assumed to
associate to the right. For example, 1 : 2 : 3 : [ ] means 1 : (2 : (3 : [ ])).
As well as being used to construct lists, the cons operator can also be
used to construct patterns, which match any non-empty list whose ﬁrst and
remaining elements match the corresponding patterns in order. For example,
we can now deﬁne a more general version of the function test that decides if
a list containing any number of characters begins with 'a':
test
::
[Char ] →Bool
test ('a' : )
=
True
test
=
False
Similarly, the library functions null, head and tail that decide if a list is empty,
select the ﬁrst element of a non-empty list, and remove the ﬁrst element of a
non-empty list are deﬁned as follows:
null
::
[a ] →Bool
null [ ]
=
True
null ( : )
=
False
head
::
[a ] →a
head (x : )
=
x
tail
::
[a ] →[a ]
tail ( : xs)
=
xs
Note that cons patterns must be parenthesised, because function applica-
tion has higher priority than all other operators. For example, the deﬁnition
tail
: xs = xs without parentheses means (tail
) : xs = xs, which is both the
incorrect meaning and an invalid deﬁnition.
Integer patterns
As a special case that is sometimes useful, Haskell also allows integer patterns
of the form n+k, where n is an integer variable and k >0 is an integer constant.
For example, a function pred that maps zero to itself and any strictly positive
integer to its predecessor can be deﬁned as follows:
pred
::
Int →Int
pred 0
=
0
pred (n + 1)
=
n

46
CHAPTER 4. DEFINING FUNCTIONS
There are two points to note about n + k patterns. First of all, they only
match integers ⩾k. For example, evaluating pred (−1) produces an error,
because neither of the two patterns in the deﬁnition for pred matches negative
integers.
Secondly, for the same reason as cons patterns, integer patterns
must be parenthesised. For example, the deﬁnition pred n + 1 = n without
parentheses means (pred n) + 1 = n, which is an invalid deﬁnition.
4.5
Lambda expressions
As an alternative to deﬁning functions using equations, functions can also be
constructed using lambda expressions, which comprise a pattern for each of
the arguments, a body that speciﬁes how the result can be calculated in terms
of the arguments, but do not give a name for the function itself. In other
words, lambda expressions are nameless functions.
For example, a nameless function that takes a single number x as its ar-
gument, and produces the result x + x, can be constructed as follows:
λx →x + x
The symbol λ is the lower-case Greek letter "lambda". Despite the fact that
they have no names, functions constructed using lambda expressions can be
used in the same way as any other functions. For example:
> (λx →x + x) 2
4
As well as being interesting in their own right, lambda expressions have a
number of practical applications. First of all, they can be used to formalise
the meaning of curried function deﬁnitions. For example, the deﬁnition
add x y
=
x + y
can be understood as meaning
add
=
λx →(λy →x + y)
which makes precise that add is a function that takes a number x and returns
a function, which in turn takes a number y and returns the result x + y.
Secondly, lambda expressions are also useful when deﬁning functions that
return functions as results by their very nature, rather than as a consequence
of currying. For example, the library function const that returns a constant
function that always produces a given value can be deﬁned as follows:
const
::
a →b →a
const x
=
x

4.6. SECTIONS
47
However, it is more appealing to deﬁne const in a way that makes explicit
that it returns a function as its result, by including parentheses in the type
and using a lambda expression in the deﬁnition itself:
const
::
a →(b →a)
const x
=
λ
→x
Finally, lambda expressions can be used to avoid having to name a function
that is only referenced once. For example, a function odds that returns the
ﬁrst n odd integers can be deﬁned as follows:
odds
::
Int →[Int ]
odds n
=
map f [0 . . n −1]
where f x = x ∗2 + 1
(The library function map applies a function to all elements of a list.) However,
because the locally deﬁned function f is only referenced once, the deﬁnition
for odds can be simpliﬁed by using a lambda expression:
odds n
=
map (λx →x ∗2 + 1) [0 . . n −1]
4.6
Sections
Functions such as + that are written between their two arguments are called
operators. As we have already seen, any function with two arguments can be
converted into an operator by enclosing the name of the function in single back
quotes, as in 7 'div' 2. However, the converse is also possible. In particular,
any operator can be converted into a curried function that is written before its
arguments by enclosing the name of the operator in parentheses, as in (+) 1 2.
Moreover, this convention also allows one of the arguments to be included in
the parentheses if desired, as in (1+) 2 and (+2) 1.
In general, if ⊕is an operator then expressions of the form (⊕), (x ⊕) and
(⊕y) for arguments x and y are called sections, whose meaning as functions
can be formalised using lambda expressions as follows:
(⊕)
=
λx →(λy →x ⊕y)
(x ⊕)
=
λy →x ⊕y
(⊕y)
=
λx →x ⊕y
Sections have three main applications. First of all, they can be used to
construct a number of simple but useful functions in a particularly compact
way, as shown in the following examples:
(+)
is the addition function λx →(λy →x + y)
(1+)
is the successor function λy →1 + y
(1/)
is the reciprocation function λy →1 / y
(∗2)
is the doubling function λx →x ∗2
(/2)
is the halving function λx →x / 2

48
CHAPTER 4. DEFINING FUNCTIONS
Secondly, sections are necessary when stating the type of operators, be-
cause an operator itself is not a valid expression in Haskell. For example, the
type of the logical conjunction operator ∧is stated as follows:
(∧)
::
Bool →Bool →Bool
Finally, sections are also necessary when using operators as arguments to
other functions. For example, the library function and that decides if all logical
values in a list are True is deﬁned by using the operator ∧as an argument to
the library function foldr, which is itself discussed in chapter 7:
and
::
[Bool ] →Bool
and
=
foldr (∧) True
4.7
Chapter remarks
A formal meaning for pattern matching by translation using more primitive
features of the language is given in the Haskell Report [26]. The Greek letter λ
used when deﬁning nameless functions comes from the lambda calculus, the
mathematical theory of functions upon which Haskell is founded.
4.8
Exercises
1. Using library functions, deﬁne a function halve :: [a ] →([a ], [a ]) that
splits an even-lengthed list into two halves. For example:
> halve [1, 2, 3, 4, 5, 6]
([1, 2, 3], [4, 5, 6])
2. Consider a function safetail :: [a ] →[a ] that behaves as the library
function tail, except that safetail maps the empty list to itself, whereas
tail produces an error in this case. Deﬁne safetail using:
(a) a conditional expression;
(b) guarded equations;
(c) pattern matching.
Hint: make use of the library function null.
3. In a similar way to ∧, show how the logical disjunction operator ∨can
be deﬁned in four diﬀerent ways using pattern matching.
4. Redeﬁne the following version of the conjunction operator using condi-
tional expressions rather than pattern matching:
True ∧True
=
True
∧
=
False

4.8. EXERCISES
49
5. Do the same for the following version, and note the diﬀerence in the
number of conditional expressions required:
True ∧b
=
b
False ∧
=
False
6. Show how the curried function deﬁnition mult x y z = x ∗y ∗z can be
understood in terms of lambda expressions.

50
CHAPTER 4. DEFINING FUNCTIONS

Chapter 5
List Comprehensions
In this chapter we introduce list comprehensions, which allow many functions
on lists to be deﬁned in simple manner. We start by explaining generators and
guards, then introduce the function zip and the idea of string comprehensions,
and conclude by developing a program to crack the Caesar cipher.
5.1
Generators
In mathematics, the comprehension notation can be used to construct new
sets from existing sets. For example, the comprehension {x2 | x ∈{1..5}}
produces the set {1, 4, 9, 16, 25} of all numbers x2 such that x is an element
of the set {1..5}. In Haskell, a similar comprehension notation can be used to
construct new lists from existing lists. For example:
> [x ↑2 | x ←[1 . . 5]]
[1, 4, 9, 16, 25]
The symbols | and ←are read as "such that" and "is drawn from" respectively,
and the expression x ←[1 . . 5] is called a generator. A list comprehension can
have more than one generator, with successive generators being separated by
commas. For example, the list of all possible pairings of an element from the
list [1, 2, 3] with an element from [4, 5] can be produced as follows:
> [(x, y) | x ←[1, 2, 3], y ←[4, 5]]
[(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]
Changing the order of the two generators in this example produces the same
set of pairs, but arranged in a diﬀerent order:
> [(x, y) | y ←[4, 5], x ←[1, 2, 3]]
[(1, 4), (2, 4), (3, 4), (1, 5), (2, 5), (3, 5)]
In particular, whereas in this case the x components of the pairs change more
frequently than the y components (1,2,3,1,2,3 versus 4,4,4,5,5,5), in the pre-
vious case the y components change more frequently than the x components
51

52
CHAPTER 5. LIST COMPREHENSIONS
(4,5,4,5,4,5 versus 1,1,2,2,3,3). These behaviours can be understood by think-
ing of later generators as being more deeply nested, and hence changing the
values of their variables more frequently than earlier generators.
Later generators can also depend upon the values of variables from earlier
generators. For example, the list of all possible ordered pairings of elements
from the list [1 . . 3] can be produced as follows:
> [(x, y) | x ←[1 . . 3], y ←[x . . 3]]
[(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]
As another example of this idea, the library function concat that concatenates
a list of lists can be deﬁned by using one generator to select each list in turn,
and another to select each element from each list:
concat
::
[[a ]] →[a ]
concat xss
=
[x | xs ←xss, x ←xs ]
The wildcard pattern
is sometimes useful in generators to discard cer-
tain elements from a list. For example, a function that selects all the ﬁrst
components from a list of pairs can be deﬁned as follows:
ﬁrsts
::
[(a, b)] →[a ]
ﬁrsts ps
=
[x | (x, ) ←ps ]
Similarly, the library function that calculates the length of a list can be deﬁned
by replacing each element by one and summing the resulting list:
length
::
[a ] →Int
length xs
=
sum [1 |
←xs ]
In this case, the generator
←xs simply serves as a counter to govern the
production of the appropriate number of ones.
5.2
Guards
List comprehensions can also use logical expressions called guards to ﬁlter the
values produced by earlier generators. If a guard is True then the current
values are retained, otherwise they are discarded. For example, the compre-
hension [x | x ←[1 . . 10], even x ] produces the list [2, 4, 6, 8, 10] of all even
numbers from the list [1 . . 10].
Similarly, a function that maps a positive
integer to its list of positive factors can be deﬁned as follows:
factors
::
Int →[Int ]
factors n
=
[x | x ←[1 . . n ], n 'mod' x == 0]
For example:

5.2. GUARDS
53
> factors 15
[1, 3, 5, 15]
> factors 7
[1, 7]
Recall than an integer greater than one is prime if its only positive factors are
one and the number itself. Hence, using factors a simple function that decides
if an integer is prime can be deﬁned as follows:
prime
::
Int →Bool
prime n
=
factors n == [1, n ]
For example:
> prime 15
False
> prime 7
True
Note that deciding that a number such as 15 is not prime does not require the
function prime to produce all of its factors, because under lazy evaluation the
result False is returned as soon as any factor other than one or the number
itself is produced, which for this example is given by the factor 3.
Returning to list comprehensions, using prime we can now deﬁne a function
that produces the list of all prime numbers up to a given limit:
primes
::
Int →[Int ]
primes n
=
[x | x ←[2 . . n ], prime x ]
For example:
> primes 40
[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37]
In chapter 12 we will present a more eﬃcient program to generate prime
numbers using the famous "sieve of Eratosthenes", which has a particularly
clear and concise implementation in Haskell.
As a ﬁnal example concerning guards, suppose that we represent a lookup
table by a list of pairs comprising keys and values. Then for any type of keys
that is an equality type, a function ﬁnd that returns the list of all values that
are associated with a given key in a table can be deﬁned as follows:
ﬁnd
::
Eq a ⇒a →[(a, b)] →[b]
ﬁnd k t
=
[v | (k ′, v) ←t, k == k ′]
For example:
> ﬁnd 'b' [('a', 1), ('b', 2), ('c', 3), ('b', 4)]
[2, 4]

54
CHAPTER 5. LIST COMPREHENSIONS
5.3
The zip function
The library function zip produces a new list by pairing successive elements
from two existing lists until either or both are exhausted. For example:
> zip ['a', 'b', 'c'] [1, 2, 3, 4]
[('a', 1), ('b', 2), ('c', 3)]
The function zip is often useful when programming with list comprehensions.
For example, suppose that we deﬁne a function pairs that returns the list of
all pairs of adjacent elements from a list as follows:
pairs
::
[a ] →[(a, a)]
pairs xs
=
zip xs (tail xs)
For example:
> pairs [1, 2, 3, 4]
[(1, 2), (2, 3), (3, 4)]
Then using pairs we can now deﬁne a function that decides if a list of elements
of any ordered type is sorted by simply checking that all pairs of adjacent
elements from the list are in the correct order:
sorted
::
Ord a ⇒[a ] →Bool
sorted xs
=
and [x ⩽y | (x, y) ←pairs xs ]
For example:
> sorted [1, 2, 3, 4]
True
> sorted [1, 3, 2, 4]
False
Similarly to the function prime, deciding that a list such as [1, 3, 2, 4] is not
sorted may not require the function sorted to produce all pairs of adjacent
elements, because the result False is returned as soon as any non-ordered pair
is produced, which in this example is given by the pair (3, 2).
Using zip we can also deﬁne a function that returns the list of all positions
at which a value occurs in a list, by pairing each element with its position,
and selecting those positions at which the desired value occurs:
positions
::
Eq a ⇒a →[a ] →[Int ]
positions x xs
=
[i | (x ′, i) ←zip xs [0 . . n ], x == x ′]
where n = length xs −1
For example:
> positions False [True, False, True, False ]
[1, 3]

5.4. STRING COMPREHENSIONS
55
5.4
String comprehensions
Up to this point we have viewed strings as a primitive notion in Haskell. In fact
they are not primitive as such, but are actually constructed as lists of charac-
ters. For example, "abc" :: String is just an abbreviation for ['a', 'b', 'c'] ::
[Char ]. Because strings are just special kinds of lists, any polymorphic func-
tion on lists can also be used with strings. For example:
> "abcde" !! 2
'c'
> take 3 "abcde"
"abc"
> length "abcde"
5
> zip "abc" [1, 2, 3, 4]
[('a', 1), ('b', 2), ('c', 3)]
For the same reason, list comprehensions can also be used to deﬁne functions
on strings, such as functions that return the number of lower-case letters and
particular characters that occur in a string, respectively:
lowers
::
String →Int
lowers xs
=
length [x | x ←xs, isLower x ]
count
::
Char →String →Int
count x xs
=
length [x ′ | x ′ ←xs, x == x ′]
For example:
> lowers "Haskell␣98"
6
> count 's' "Mississippi"
4
5.5
The Caesar cipher
We conclude this chapter with an extended example. Consider the problem
of encoding a string in order to disguise its contents from unintended readers.
A well-known encoding method is the Caesar cipher, named after its use by
Julius Caesar. To encode a string, Caesar simply replaced each letter in the
string by the letter three places further down in the alphabet, wrapping around
at the end of the alphabet. For example, the string
"haskell␣is␣fun"

56
CHAPTER 5. LIST COMPREHENSIONS
would be encoded as
"kdvnhoo␣lv␣ixq"
More generally, the shift factor of three used by Caesar can be replaced by
any integer between one and twenty-ﬁve, thereby giving twenty-ﬁve diﬀerent
ways of encoding a string. For example, with a shift factor of ten, the original
string above would be encoded as
"rkcuovv␣sc␣pex"
In the remainder of this section we show how Haskell can be used to imple-
ment the Caesar cipher, and how the cipher itself can easily be "cracked" by
exploiting information about letter frequencies.
Encoding and decoding
For simplicity, we will only encode the lower-case letters within a string, leaving
other characters such as upper-case letters and punctuation unchanged. We
begin by deﬁning a function let2int that converts a lower-case letter between
'a' and 'z' into the corresponding integer between 0 and 25, together with
a function int2let that performs the opposite conversion:
let2int
::
Char →Int
let2int c
=
ord c −ord 'a'
int2let
::
Int →Char
int2let n
=
chr (ord 'a' + n)
(The library functions ord ::Char →Int and chr ::Int →Char convert between
characters and their Unicode representation as integers.) For example:
> let2int 'a'
0
> int2let 0
'a'
Using these two functions, we can deﬁne a function shift that applies a shift
factor to a lower-case letter by converting the letter into the corresponding
integer, adding on the shift factor and taking the remainder when divided
by twenty-six (thereby wrapping around at the end of the alphabet), and
converting the resulting integer back into a lower-case letter:
shift
::
Int →Char →Char
shift n c | isLower c
=
int2let ((let2int c + n) 'mod' 26)
| otherwise
=
c
Note that this function accepts both positive and negative shift factors, and
that only lower-case letters are changed. For example:

5.5. THE CAESAR CIPHER
57
> shift 3 'a'
'd'
> shift 3 'z'
'c'
> shift (−3) 'c'
'z'
> shift 3 '␣'
'␣'
Using shift within a string comprehension, it is now easy to deﬁne a function
that encodes a string using a given shift factor:
encode
::
Int →String →String
encode n xs
=
[shift n x | x ←xs ]
A separate function to decode a string is not required, because this can be
achieved by simply using a negative shift factor. For example:
> encode 3 "haskell␣is␣fun"
"kdvnhoo␣lv␣ixq"
> encode (−3) "kdvnhoo␣lv␣ixq"
"haskell␣is␣fun"
Frequency tables
Some letters in English are used more frequently than others. By analysing
a large volume of text, one can derive the following table of approximate
percentage frequencies of the twenty-six letters of alphabet:
table
::
[Float ]
table
=
[8.2, 1.5, 2.8, 4.3, 12.7, 2.2, 2.0, 6.1, 7.0, 0.2, 0.8, 4.0, 2.4,
6.7, 7.5, 1.9, 0.1, 6.0, 6.3, 9.1, 2.8, 1.0, 2.4, 0.2, 2.0, 0.1]
For example, the letter 'e' occurs most often, with a frequency of 12.7%,
while 'q' and 'z' occur least often, with a frequency of just 0.1%. It is also
useful to produce frequency tables for individual strings. To this end, we ﬁrst
deﬁne a function that calculates the percentage of one integer with respect to
another, returning the result as a ﬂoating-point number:
percent
::
Int →Int →Float
percent n m
=
(fromInt n / fromInt m) ∗100

58
CHAPTER 5. LIST COMPREHENSIONS
(The library function fromInt :: Int →Float converts an integer into the cor-
responding ﬂoating-point number.) Using percent within a string comprehen-
sion, together with the functions lowers and count from the previous section,
we can deﬁne a function that returns the frequency table for any string:
freqs
::
String →[Float ]
freqs xs
=
[percent (count x xs) n | x ←['a' . . 'z']]
where n = lowers xs
For example:
> freqs "abbcccddddeeeee"
[6.7, 13.3, 20.0, 26.7, 33.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, · · · , 0.0]
That is, the letter 'a' occurs with a frequency of 6.7%, the letter 'b' with a
frequency of 13.3%, and so on. The use of the local deﬁnition n = lowers xs
within freqs ensures that the number of lower-case letters in the argument
string is calculated once, rather than each of the twenty-six times that this
number is used within the string comprehension.
Cracking the cipher
A standard method for comparing a list of observed frequencies os with a list
of expected frequencies es is the chi-square statistic, deﬁned by the following
formulae in which n denotes the length of the two lists, and xsi denotes the
ith element of a list xs counting from zero:
n−1

i=0
(osi −esi)2
esi
The details of chi-square statistic need not concern us here, only the fact
that the smaller the value it produces the better the match between the two
frequency lists. Using the library function zip and a list comprehension, it is
easy to translate the above formula into a function deﬁnition:
chisqr
::
[Float ] →[Float ] →Float
chisqr os es
=
sum [((o −e) ↑2) / e | (o, e) ←zip os es ]
In turn, we deﬁne a function that rotates the elements of a list n places
to the left, wrapping around at the start of the list, and assuming that n is
between zero and the length of the list:
rotate
::
Int →[a ] →[a ]
rotate n xs
=
drop n xs ++ take n xs
For example:
> rotate 3 [1, 2, 3, 4, 5]
[4, 5, 1, 2, 3]

5.5. THE CAESAR CIPHER
59
Now suppose that we are given an encoded string, but not the shift factor
that was used to encode it, and wish to determine this number in order that we
can decode the string. This can usually be achieved by producing the frequency
table of the encoded string, calculating the chi-square statistic for each possible
rotation of this table with respect to the table of expected frequencies, and
using the position of the minimum chi-square value as the shift factor. For
example, if table′ = freqs "kdvnhoo␣lv␣ixq" then
[chisqr (rotate n table′) table | n ←[0 . . 25]]
gives the result
[1408.8, 640.3, 612.4, 202.6, 1439.8, 4247.2, 651.3, · · · , 626.7]
in which the minimum value, 202.6, appears at position three in this list.
Hence, we conclude that three is the most likely shift factor that can be used
to decode the string. Using the function positions from earlier in this chapter,
this procedure can be implemented as follows:
crack
::
String →String
crack xs
=
encode (−factor) xs
where
factor = head (positions (minimum chitab) chitab)
chitab = [chisqr (rotate n table′) table | n ←[0 . . 25]]
table′ = freqs xs
For example:
> crack "kdvnhoo␣lv␣ixq"
"haskell␣is␣fun"
> crack "vscd␣mywzboroxcsyxc␣kbo␣ecopev"
"list␣comprehensions␣are␣useful"
More generally, the crack function can decode most strings produced using
the Caesar cipher. Note, however, that it may not be successful if the string
is short or has an unusual distribution of letters. For example:
> crack (encode 3 "haskell")
"piasmtt"
> crack (encode 3 "the␣five␣boxing␣wizards␣jump␣quickly")
"dro␣psfo␣lyhsxq␣gsjkbnc␣tewz␣aesmuvi"

60
CHAPTER 5. LIST COMPREHENSIONS
5.6
Chapter remarks
The term comprehension comes from the "axiom of comprehension" in set
theory, which makes precise the idea of constructing a set by selecting all values
satisfying a particular property. A formal meaning for list comprehensions by
translation using more primitive features of the language is given in the Haskell
Report [26]. A popular account of the Caesar cipher, and many other famous
cryptographic methods, is given in The Code Book [30].
5.7
Exercises
1. Using a list comprehension, give an expression that calculates the sum
12 + 22 + . . . 1002 of the ﬁrst one hundred integer squares.
2. In a similar way to the function length, show how the library function
replicate :: Int →a →[a ] that produces a list of identical elements can
be deﬁned using a list comprehension. For example:
> replicate 3 True
[True, True, True ]
3. A triple (x, y, z) of positive integers can be termed pythagorean if x2 +
y2 = z2. Using a list comprehension, deﬁne a function pyths :: Int →
[(Int, Int, Int)] that returns the list of all pythagorean triples whose
components are at most a given limit. For example:
> pyths 10
[(3, 4, 5), (4, 3, 5), (6, 8, 10), (8, 6, 10)]
4. A positive integer is perfect if it equals the sum of its factors, excluding
the number itself. Using a list comprehension and the function factors,
deﬁne a function perfects ::Int →[Int ] that returns the list of all perfect
numbers up to a given limit. For example:
> perfects 500
[6, 28, 496]
5. Show how the single comprehension [(x, y) | x ←[1, 2, 3], y ←[4, 5, 6]]
with two generators can be re-expressed using two comprehensions with
single generators. Hint: make use of the library function concat and nest
one comprehension within the other.
6. Redeﬁne the function positions using the function ﬁnd.
7. The scalar product of two lists of integers xs and ys of length n is given
by the sum of the products of corresponding integers:

5.7. EXERCISES
61
n−1

i=0
(xsi ∗ysi)
In a similar manner to the function chisqr, show how a list comprehen-
sion can be used to deﬁne a function scalarproduct ::[Int ] →[Int ] →Int
that returns the scalar product of two lists. For example:
> scalarproduct [1, 2, 3] [4, 5, 6]
32
8. Modify the Caesar cipher program to also handle upper-case letters.

62
CHAPTER 5. LIST COMPREHENSIONS

Chapter 6
Recursive Functions
In this chapter we introduce recursion, the basic mechanism for looping in
Haskell.
We start with recursion on integers, then extend the idea to re-
cursion on lists, consider multiple arguments, multiple recursion, and mutual
recursion, and conclude with some advice on deﬁning recursive functions.
6.1
Basic concepts
As we have seen in previous chapters, many functions can naturally be deﬁned
in terms of other functions. For example, a function that returns the factorial
of a non-negative integer can be deﬁned by using library functions to calculate
the product of the integers between one and the number itself:
factorial
::
Int →Int
factorial n
=
product [1 . . n ]
In Haskell, it is also permissible to deﬁne functions in terms of themselves,
in which case the functions are called recursive. For example, the factorial
function can be deﬁned in this manner as follows:
factorial 0
=
1
factorial (n + 1)
=
(n + 1) ∗factorial n
The ﬁrst equation states that the factorial of zero is one, and is called a base
case. The second equation states that the factorial of any strictly positive
integer is the product of that number and the factorial of its predecessor, and
is called a recursive case. For example, the following calculation shows how
the factorial of three is computed using this deﬁnition:
factorial 3
=
{ applying factorial }
3 ∗factorial 2
=
{ applying factorial }
3 ∗(2 ∗factorial 1)
63

64
CHAPTER 6. RECURSIVE FUNCTIONS
=
{ applying factorial }
3 ∗(2 ∗(1 ∗factorial 0))
=
{ applying factorial }
3 ∗(2 ∗(1 ∗1))
=
{ applying ∗}
6
Note that even though the factorial function is deﬁned in terms of itself, it
does not loop forever. In particular, each application of factorial reduces the
integer argument by one, until it eventually reaches zero at which point the
recursion stops and the multiplications are performed. Returning one as the
factorial of zero is appropriate because one is the identity for multiplication.
That is, 1 ∗x = x and x ∗1 = x for any integer x.
For the case of the factorial function, the original deﬁnition using library
functions is simpler than the deﬁnition using recursion. However, as we shall
see in the remainder of this book, many functions have a simple and natu-
ral deﬁnition using recursion. For example, many of the library functions in
Haskell are deﬁned in this way. Moreover, as we shall see in chapter 13, deﬁn-
ing functions using recursion also allows properties of those functions to be
proved using the powerful mathematical technique of induction.
As another example of recursion on integers, consider the multiplication
operator ∗used above. For eﬃciency reasons, this operator is provided as a
primitive in Haskell. However, for non-negative integers it can also be deﬁned
using recursion on either of its two arguments, such as the second:
(∗)
::
Int →Int →Int
m ∗0
=
0
m ∗(n + 1)
=
m + (m ∗n)
For example:
4 ∗3
=
{ applying ∗}
4 + (4 ∗2)
=
{ applying ∗}
4 + (4 + (4 ∗1))
=
{ applying ∗}
4 + (4 + (4 + (4 ∗0)))
=
{ applying ∗}
4 + (4 + (4 + 0))
=
{ applying + }
12
That is, the recursive deﬁnition for the ∗operator formalises the idea that
multiplication can be reduced to repeated addition.

6.2. RECURSION ON LISTS
65
6.2
Recursion on lists
Recursion is not restricted to functions on integers, but can also be used to
deﬁne functions on lists. For example, the library function product used in the
preceding section can be deﬁned as follows:
product
::
Num a ⇒[a ] →a
product [ ]
=
1
product (n : ns)
=
n ∗product ns
The ﬁrst equation states that the product of the empty list is one, which is
appropriate because one is the identity for multiplication. The second equation
states that the product of any non-empty list is given by multiplying the ﬁrst
number and the product of the remaining list of numbers. For example:
product [2, 3, 4]
=
{ applying product }
2 ∗product [3, 4]
=
{ applying product }
2 ∗(3 ∗product [4])
=
{ applying product }
2 ∗(3 ∗(4 ∗product [ ]))
=
{ applying product }
2 ∗(3 ∗(4 ∗1))
=
{ applying ∗}
24
Recall that lists in Haskell are actually constructed one element at a time using
the cons operator. Hence, [2, 3, 4] is just an abbreviation for 2: (3: (4: [ ])). As
another simple example of recursion on lists, the library function length can
be deﬁned using the same pattern of recursion as product:
length
::
[a ] →Int
length [ ]
=
0
length ( : xs)
=
1 + length xs
That is, the length of the empty list is zero, and the length of any non-empty
list is the successor of the length of its tail.
Note the use of the wildcard
pattern
in the recursive case, which reﬂects the fact that the length of a list
does not depend upon the value of its elements.
Now let us consider the library function that reverses a list. This function
can be deﬁned using recursion as follows:
reverse
::
[a ] →[a ]
reverse [ ]
=
[ ]
reverse (x : xs)
=
reverse xs ++ [x ]
That is, the reverse of the empty list is simply the empty list, and the reverse
of any non-empty list is given by appending the reverse of its tail to a singleton
list comprising the head of the list. For example:

66
CHAPTER 6. RECURSIVE FUNCTIONS
reverse [1, 2, 3]
=
{ applying reverse }
reverse [2, 3] ++ [1]
=
{ applying reverse }
(reverse [3] ++ [2]) ++ [1]
=
{ applying reverse }
((reverse [ ] ++ [3]) ++ [2]) ++ [1]
=
{ applying reverse }
(([ ] ++ [3]) ++ [2]) ++ [1]
=
{ applying ++ }
[3, 2, 1]
In turn, the append operator ++ used in the above deﬁnition of reverse can
itself be deﬁned using recursion on its ﬁrst argument:
(++)
::
[a ] →[a ] →[a ]
[ ] ++ ys
=
ys
(x : xs) ++ ys
=
x : (xs ++ ys)
For example:
[1, 2, 3] ++ [4, 5]
=
{ applying ++ }
1 : ([2, 3] ++ [4, 5])
=
{ applying ++ }
1 : (2 : ([3] ++ [4, 5]))
=
{ applying ++ }
1 : (2 : (3 : ([ ] ++ [4, 5])))
=
{ applying ++ }
1 : (2 : (3 : [4, 5]))
=
{ list notation }
[1, 2, 3, 4, 5]
That is, the recursive deﬁnition for ++ formalises the idea that two lists can
be appended by copying elements from the ﬁrst list until it is exhausted, at
which point the second list is joined on at the end.
We conclude this section with two examples of recursion on sorted lists.
First of all, a function that inserts a new element of any ordered type into a
sorted list to give another sorted list can be deﬁned as follows:
insert
::
Ord a ⇒a →[a ] →[a ]
insert x [ ]
=
[x ]
insert x (y : ys) | x ⩽y
=
x : y : ys
| otherwise
=
y : insert x ys
That is, inserting a new element into the empty list gives a singleton list, while
for a non-empty list the result depends upon the ordering of the new element
x and the head of the list y. In particular, if x ⩽y then the new element

6.3. MULTIPLE ARGUMENTS
67
x is simply prepended to the start of the list, otherwise the head y becomes
the ﬁrst element of the resulting list, and we then proceed to insert the new
element into the tail of the given list. For example:
insert 3 [1, 2, 4, 5]
=
{ applying insert }
1 : insert 3 [2, 4, 5]
=
{ applying insert }
1 : 2 : insert 3 [4, 5]
=
{ applying insert }
1 : 2 : 3 : [4, 5]
=
{ list notation }
[1, 2, 3, 4, 5]
Using insert we can now deﬁne a function that implements insertion sort,
in which the empty list is already sorted, and any non-empty list is sorted by
inserting its head into the list that results from sorting its tail:
isort
::
Ord a ⇒[a ] →[a ]
isort [ ]
=
[ ]
isort (x : xs)
=
insert x (isort xs)
For example:
isort [3, 2, 1, 4]
=
{ applying isort }
insert 3 (insert 2 (insert 1 (insert 4 [ ])))
=
{ applying insert }
insert 3 (insert 2 (insert 1 [4]))
=
{ applying insert }
insert 3 (insert 2 [1, 4])
=
{ applying insert }
insert 3 [1, 2, 4]
=
{ applying insert }
[1, 2, 3, 4]
6.3
Multiple arguments
Functions with multiple arguments can also be deﬁned using recursion on more
than one argument at the same time. For example, the library function zip
that takes two lists and produces a list of pairs is deﬁned as follows:
zip
::
[a ] →[b] →[(a, b)]
zip [ ]
=
[ ]
zip
[ ]
=
[ ]
zip (x : xs) (y : ys)
=
(x, y) : zip xs ys
For example:

68
CHAPTER 6. RECURSIVE FUNCTIONS
zip ['a', 'b', 'c'] [1, 2, 3, 4]
=
{ applying zip }
('a', 1) : zip ['b', 'c'] [2, 3, 4]
=
{ applying zip }
('a', 1) : ('b', 2) : zip ['c'] [3, 4]
=
{ applying zip }
('a', 1) : ('b', 2) : ('c', 3) : zip [ ] [4]
=
{ applying zip }
('a', 1) : ('b', 2) : ('c', 3) : [ ]
=
{ list notation }
[('a', 1), ('b', 2), ('c', 3)]
Note that two base cases are required in the deﬁnition of zip, because either
of the two argument lists may be empty. As another example of recursion on
multiple arguments, the library function drop that removes a given number of
elements from the start of a list is deﬁned as follows:
drop
::
Int →[a ] →[a ]
drop 0 xs
=
xs
drop (n + 1) [ ]
=
[ ]
drop (n + 1) ( : xs)
=
drop n xs
Again, two base cases are required, one for removing zero elements, and one
for attempting to remove one or more elements from the empty list.
6.4
Multiple recursion
Functions can also be deﬁned using multiple recursion, in which a function is
applied more than once in its own deﬁnition. For example, recall the Fibonacci
sequence 0, 1, 1, 2, 3, 5, 8, 13, . . ., in which the ﬁrst two numbers are 0 and 1,
and each subsequent number is given by adding the preceding two numbers in
the sequence. In Haskell, a function that calculates the nth Fibonacci number
for any integer n ⩾0 can be deﬁned using double recursion as follows:
ﬁbonacci
::
Int →Int
ﬁbonacci 0
=
0
ﬁbonacci 1
=
1
ﬁbonacci (n + 2)
=
ﬁbonacci n + ﬁbonacci (n + 1)
As another example, in chapter 1 we showed how to implement another
well-known method of sorting a list, called quicksort:
qsort
::
Ord a ⇒[a ] →[a ]
qsort [ ]
=
[ ]
qsort (x : xs)
=
qsort smaller ++ [x ] ++ qsort larger
where
smaller = [a | a ←xs, a ⩽x ]
larger = [b | b ←xs, b > x ]

6.5. MUTUAL RECURSION
69
That is, the empty list is already sorted, and any non-empty list can be sorted
by placing its head between the two lists that result from sorting those elements
of its tail that are smaller and larger than the head.
6.5
Mutual recursion
Functions can also be deﬁned using mutual recursion, in which two or more
functions are all deﬁned in terms of each other. For example, consider the
library functions even and odd. For eﬃciency, these functions are normally
deﬁned using the remainder after dividing by two. However, for non-negative
integers they can also be deﬁned using mutual recursion:
even
::
Int →Bool
even 0
=
True
even (n + 1)
=
odd n
odd
::
Int →Bool
odd 0
=
False
odd (n + 1)
=
even n
That is, zero is even but not odd, and any strictly positive integer is even if
its predecessor is odd, and odd if its predecessor is even. For example:
even 4
=
{ applying even }
odd 3
=
{ applying odd }
even 2
=
{ applying even }
odd 1
=
{ applying odd }
even 0
=
{ applying even }
True
Similarly, functions that select the elements from a list at all even and odd
positions (counting from zero) can be deﬁned as follows:
evens
::
[a ] →[a ]
evens [ ]
=
[ ]
evens (x : xs)
=
x : odds xs
odds
::
[a ] →[a ]
odds [ ]
=
[ ]
odds ( : xs)
=
evens xs
For example:

70
CHAPTER 6. RECURSIVE FUNCTIONS
evens "abcde"
=
{ applying evens }
'a' : odds "bcde"
=
{ applying odds }
'a' : evens "cde"
=
{ applying evens }
'a' : 'c' : odds "de"
=
{ applying odds }
'a' : 'c' : evens "e"
=
{ applying evens }
'a' : 'c' : 'e' : odds [ ]
=
{ applying odds }
'a' : 'c' : 'e' : [ ]
=
{ string notation }
"ace"
Recall that strings in Haskell are actually constructed as lists of characters.
Hence, "abcde" is just an abbreviation for ['a', 'b', 'c', 'd', 'e'].
6.6
Advice on recursion
Deﬁning recursive functions is like riding a bicycle: it looks easy when someone
else is doing it, may seem impossible when you ﬁrst try to do it yourself, but
becomes simple and natural with practice. In this section we oﬀer some advice
for deﬁning functions in general, and recursive functions in particular, using a
ﬁve step process that we introduce by means of examples.
Example - product
As a simple ﬁrst example, we show how the deﬁnition given earlier in this
chapter for the library function that calculates the product of a list of numbers
can be constructed in a stepwise manner.
Step 1: deﬁne the type
Thinking about types is very helpful when deﬁning functions, so it is good
practice to deﬁne the type of a function prior to starting to deﬁne the function
itself. In this case, we begin with the type
product
::
[Int ] →Int
that states that product takes a list of integers and produces a single integer.
As in this example, it is often useful to begin with a simple type, which can
be reﬁned or generalised later on as appropriate.

6.6. ADVICE ON RECURSION
71
Step 2: enumerate the cases
For most types of argument, there are a number of standard cases to consider.
For lists, the standard cases are the empty list and non-empty lists, so we can
write down the following skeleton deﬁnition using pattern matching:
product [ ]
=
product (n : ns)
=
For non-negative integers, the standard cases are 0 and n +1, for logical values
they are False and True, and so on. As with the type, we may need to reﬁne
the cases later on, but it is useful to begin with the standard cases.
Step 3: deﬁne the simple cases
By deﬁnition, the product of zero integers is one, because one is the identity
for multiplication. Hence it is straightforward to deﬁne the empty list case:
product [ ]
=
1
product (n : ns)
=
As in this example, the simple cases often become base cases.
Step 4: deﬁne the other cases
How can we calculate the product of a non-empty list of integers? For this
step, it is useful to ﬁrst consider the ingredients that can be used, such as the
function itself (product), the arguments (n and ns), and library functions of
relevant types (+, −, ∗, and so on.) In this case, we simply multiply the ﬁrst
integer and the product of the remaining list of integers:
product [ ]
=
1
product (n : ns)
=
n ∗product ns
As in this example, the other cases often become recursive cases.
Step 5: generalise and simplify
Once a function has been deﬁned using the above process, it often becomes
clear that it can be generalised and simpliﬁed.
For example, the function
product does not depend on the precise kind of numbers to which it is applied,
so its type can be generalised from integers to any numeric type:
product
::
Num a ⇒[a ] →a
In terms of simpliﬁcation, we will see in chapter 7 that the pattern of recursion
used in product is encapsulated by a library function called foldr, using which
product can be redeﬁned by a single equation:
product
=
foldr (∗) 1

72
CHAPTER 6. RECURSIVE FUNCTIONS
In conclusion, our ﬁnal deﬁnition for product is as follows:
product
::
Num a ⇒[a ] →a
product
=
foldr (∗) 1
This is precisely the deﬁnition from the standard prelude in appendix A, except
that for eﬃciency reasons the use of foldr is replaced by the related library
function foldl, which is also discussed in chapter 7.
Example - drop
As a more substantial example, we now show how the deﬁnition given earlier
for the library function drop that removes a given number of elements from
the start of a list can be constructed using the ﬁve step process.
Step 1: deﬁne the type
Let us begin with a type that states that drop takes an integer and a list of
values of some type a, and produces another list of such values:
drop
::
Int →[a ] →[a ]
Note that we have made four decisions in deﬁning this type: using integers
rather than a more general numeric type, for simplicity; using currying rather
than taking the arguments as a pair, for ﬂexibility (see section 3.6); supplying
the integer argument before the list argument, for readability (drop n xs
can be read as "drop n elements from xs"); and ﬁnally, making the function
polymorphic in the type of the list elements, for generality.
Step 2: enumerate the cases
As there are two standard cases for the integer argument (0 and n + 1) and
two for the list argument ([ ] and x : xs), writing down a skeleton deﬁnition
using pattern matching requires four cases in total:
drop 0 [ ]
=
drop 0 (x : xs)
=
drop (n + 1) [ ]
=
drop (n + 1) (x : xs)
=
Step 3: deﬁne the simple cases
By deﬁnition, removing zero elements from the start of any list gives the same
list, so it is straightforward to deﬁne the ﬁrst two cases:
drop 0 [ ]
=
[ ]
drop 0 (x : xs)
=
x : xs
drop (n + 1) [ ]
=
drop (n + 1) (x : xs)
=

6.6. ADVICE ON RECURSION
73
Attempting to removing one or more elements from the empty list is invalid, so
the third case could be omitted, which would result in an error being produced
if this situation arises. In practice, however, we choose to avoid the production
of an error by returning the empty list in this case:
drop 0 [ ]
=
[ ]
drop 0 (x : xs)
=
x : xs
drop (n + 1) [ ]
=
[ ]
drop (n + 1) (x : xs)
=
Step 4: deﬁne the other cases
How can we remove one or more elements from a non-empty list? By simply
removing one less element from the tail of the list:
drop 0 [ ]
=
[ ]
drop 0 (x : xs)
=
x : xs
drop (n + 1) [ ]
=
[ ]
drop (n + 1) (x : xs)
=
drop n xs
Step 5: generalise and simplify
Because the function drop does not depend on the precise kind of integers to
which it is applied, its type can be generalised to any integral type, of which
Int and Integer are the standard instances:
drop
::
Integral b ⇒b →[a ] →[a ]
For eﬃciency reasons, however, this generalisation is not in fact made in the
standard prelude, as noted in section 3.9. In terms of simpliﬁcation, the ﬁrst
two equations for drop can be combined into a single equation that states that
removing zero elements from any list gives the same list:
drop 0 xs
=
xs
drop (n + 1) [ ]
=
[ ]
drop (n + 1) (x : xs)
=
drop n xs
Moreover, the variable x in the last equation can be replaced by the wildcard
pattern
, because this variable is not used in the body of the equation:
drop 0 xs
=
xs
drop (n + 1) [ ]
=
[ ]
drop (n + 1) ( : xs)
=
drop n xs
We might similarly expect n in the second equation to be replaced by
, but
this would make the deﬁnition invalid, because patterns of the form n + k
require that n is a variable. This constraint could be avoided by replacing the
entire pattern n + 1 in the second equation by
, but this would change the

74
CHAPTER 6. RECURSIVE FUNCTIONS
behaviour of the function. For example, evaluating drop (−1) [ ] would then
produce the empty list whereas it currently produces an error, because
can
match any integer whereas n + 1 only matches integers ⩾1.
In conclusion, our ﬁnal deﬁnition for drop is as follows, which is precisely
the deﬁnition from the standard prelude in appendix A:
drop
::
Int →[a ] →[a ]
drop 0 xs
=
xs
drop (n + 1) [ ]
=
[ ]
drop (n + 1) ( : xs)
=
drop n xs
Example - init
As a ﬁnal example, let us consider how the deﬁnition for library function init
that removes the last element from a non-empty list can be constructed.
Step 1: deﬁne the type
We begin with a type that states that init takes a list of values of some type a,
and produces another list of such values:
init
::
[a ] →[a ]
Step 2: enumerate the cases
As the empty list is not a valid argument for init, writing down a skeleton
deﬁnition using pattern matching requires just one case:
init (x : xs)
=
Step 3: deﬁne the simple cases
Whereas in the previous two examples this step was straightforward, a little
more thought is required for the function init. By deﬁnition, however, remov-
ing the last element from a list with one element gives the empty list, so we
can introduce a guard to handle this simple case:
init (x : xs) | null xs
=
[ ]
| otherwise
=
Recall that the library function null decides if a list is empty or not.
Step 4: deﬁne the other cases
How can we remove the last element from a list with at least two elements?
By simply retaining the head and removing the last element from the tail:
init (x : xs) | null xs
=
[ ]
| otherwise
=
x : init xs

6.7. CHAPTER REMARKS
75
Step 5: generalise and simplify
The type for init is already as general as possible, but the deﬁnition itself can
now be simpliﬁed by using pattern matching rather than guards, and by using
a wildcard pattern in the ﬁrst equation rather than a variable:
init
::
[a ] →[a ]
init [ ]
=
[ ]
init (x : xs)
=
x : init xs
Again, this is precisely the deﬁnition from the standard prelude.
6.7
Chapter remarks
The recursive deﬁnitions presented in this chapter emphasise clarity, but many
can be improved in terms of eﬃciency, using techniques from chapters 12
and 13. The ﬁve step process for deﬁning functions is based upon [10].
6.8
Exercises
1. Deﬁne the exponentiation operator ↑for non-negative integers using the
same pattern of recursion as the multiplication operator ∗, and show
how 2 ↑3 is evaluated using your deﬁnition.
2. Using the deﬁnitions given in this chapter, show how length [1, 2, 3],
drop 3 [1, 2, 3, 4, 5], and init [1, 2, 3] are evaluated.
3. Without looking at the deﬁnitions from the standard prelude, deﬁne the
following library functions using recursion:
• Decide if all logical values in a list are True:
and
::
[Bool ] →Bool
• Concatenate a list of lists:
concat
::
[[a ]] →[a ]
• Produce a list with n identical elements:
replicate
::
Int →a →[a ]
• Select the nth element of a list:
(!!)
::
[a ] →Int →a
• Decide if a value is an element of a list:
elem
::
Eq a ⇒a →[a ] →Bool

76
CHAPTER 6. RECURSIVE FUNCTIONS
Note: most of these functions are in fact deﬁned in the prelude using
other library functions, rather than using explicit recursion.
4. Deﬁne a recursive function merge :: Ord a ⇒[a ] →[a ] →[a ] that
merges two sorted lists to give a single sorted list. For example:
> merge [2, 5, 6] [1, 3, 4]
[1, 2, 3, 4, 5, 6]
Note: your deﬁnition should not use other functions on sorted lists such
as insert or isort, but should be deﬁned using explicit recursion.
5. Using merge, deﬁne a recursive function msort :: Ord a ⇒[a ] →[a ]
that implements merge sort, in which the empty list and singleton lists
are already sorted, and any other list is sorted by merging together the
two lists that result from sorting the two halves of the list separately.
Hint: ﬁrst deﬁne a function halve :: [a ] →[([a ], [a ])] that splits a list
into two halves whose length diﬀers by at most one.
6. Using the ﬁve step process, deﬁne the library functions that calculate
the sum of a list of numbers, take a given number of elements from the
start of a list, and select the last element of a non-empty list.

Chapter 7
Higher-Order Functions
In this chapter we introduce higher-order functions, which allow common pro-
gramming patterns to be encapsulated as functions. We start by explaining
what higher-order functions are and why they are useful, then introduce a
number of standard higher-order functions for processing lists, consider func-
tion composition, and conclude by developing a string transmitter.
7.1
Basic concepts
As we have seen in previous chapters, functions with multiple arguments are
usually deﬁned in Haskell using the notion of currying. That is, the argu-
ments are taken one at a time by exploiting the fact that functions can return
functions as results. For example, the deﬁnition
add
::
Int →Int →Int
add x y
=
x + y
means
add
::
Int →(Int →Int)
add
=
λx →(λy →x + y)
and states that add is a function that takes an integer x and returns a function,
which in turn takes another integer y and returns their sum x +y. In Haskell,
it is also permissible to deﬁne functions that take functions as arguments. For
example, a function that takes a function and a value, and returns the result
of applying the function twice to the value, can be deﬁned as follows:
twice
::
(a →a) →a →a
twice f x
=
f (f x)
For example:
> twice (∗2) 3
12
77

78
CHAPTER 7. HIGHER-ORDER FUNCTIONS
> twice reverse [1, 2, 3]
[1, 2, 3]
Moreover, because twice is a curried function, it can be partially applied with
just one argument to build other useful functions. For example, a function
that quadruples a number is given by twice (∗2), and the fact that reversing a
(ﬁnite) list twice has no eﬀect is captured by the equation twice reverse = id,
where id is the identity function deﬁned by id x = x.
Formally speaking, a function that takes a function as an argument or
returns a function as a result is called higher-order.
In practice, however,
because the term curried already exists for returning functions as results, the
term higher-order is often just used for taking functions as arguments. It is
this latter interpretation that is the subject of this chapter.
Using higher-order functions considerably increases the power of Haskell,
by allowing common programming patterns to be encapsulated as functions
within the language itself. More generally, higher-order functions can be used
to deﬁne "domain speciﬁc" languages within Haskell. For example, in this
chapter we present a simple language for processing lists, and in chapters 8
and 9 we do the same for building parsers and interactive programs.
7.2
Processing lists
The standard prelude deﬁnes a number of useful higher-order functions for pro-
cessing lists. For example, the function map applies a function to all elements
of a list, and can be deﬁned using a list comprehension as follows:
map
::
(a →b) →[a ] →[b]
map f xs
=
[f x | x ←xs ]
That is, map f xs returns the list of all values f x such that x is an element
of the list xs. For example, we have:
> map (+1) [1, 3, 5, 7]
[2, 4, 6, 8]
> map isDigit ['a', '1', 'b', '2']
[False, True, False, True ]
> map reverse ["abc", "def", "ghi"]
["cba", "fed", "ihg"]
There are three further points to note about map. First of all, it is a polymor-
phic function that can be applied to lists of any type, as are most higher-order
functions on lists. Secondly, it can be applied to itself to process nested lists.
For example, the function map (map (+1)) increments each number in a list
of lists of numbers, as shown in the following calculation:

7.2. PROCESSING LISTS
79
map (map (+1)) [[1, 2, 3], [4, 5]]
=
{ applying the outer map }
[map (+1) [1, 2, 3], map (+1) [4, 5]]
=
{ applying map }
[[2, 3, 4], [5, 6]]
And ﬁnally, the function map can also be deﬁned using recursion:
map f [ ]
=
[ ]
map f (x : xs)
=
f x : map f xs
That is, applying a function to all elements of the empty list gives the empty
list, while for a non-empty list the function is simply applied to the head of
the list, and we then proceed to apply the function to all elements of the tail.
The original deﬁnition for map using a list comprehension is simpler, but the
recursive deﬁnition is preferable for reasoning purposes (see chapter 13.)
Another useful library function is ﬁlter, which selects all elements of a list
that satisfy a predicate, where a predicate (or property) is a function that
returns a logical value. As with map, the function ﬁlter also has a simple
deﬁnition using a list comprehension:
ﬁlter
::
(a →Bool) →[a ] →[a ]
ﬁlter p xs
=
[x | x ←xs, p x ]
That is, ﬁlter p xs returns the list of all values x such that x is an element of
the list xs and the value of p x is True. For example:
> ﬁlter even [1 . . 10]
[2, 4, 6, 8, 10]
> ﬁlter (>5) [1 . . 10]
[6, 7, 8, 9, 10]
> ﬁlter (̸= '␣') "abc␣def␣ghi"
"abcdefghi"
As with map, the function ﬁlter can be applied to lists of any type, and can
be deﬁned using recursion for the purposes of reasoning:
ﬁlter p [ ]
=
[ ]
ﬁlter p (x : xs) | p x
=
x : ﬁlter p xs
| otherwise
=
ﬁlter p xs
That is, selecting all elements that satisfy a predicate from the empty list gives
the empty list, while for a non-empty list the result depends upon whether
the head satisﬁes the predicate. If it does then the head is retained and we
then proceed to ﬁlter elements from the tail of the list, otherwise the head is
discarded and we simply ﬁlter elements from the tail.

80
CHAPTER 7. HIGHER-ORDER FUNCTIONS
The functions map and ﬁlter are often used together in programs, with
ﬁlter being used to select certain elements from a list, each of which is then
transformed using map. For example, a function that returns the sum of the
squares of the even integers from a list could be deﬁned as follows:
sumsqreven
::
[Int ] →Int
sumsqreven ns
=
sum (map (↑2) (ﬁlter even ns))
We conclude this section by illustrating a number of other higher-order func-
tions for processing lists that are deﬁned in the standard prelude.
• Decide if all elements of a list satisfy a predicate:
> all even [2, 4, 6, 8]
True
• Decide if any element of a list satisﬁes a predicate:
> any odd [2, 4, 6, 8]
False
• Select elements from a list while they satisfy a predicate:
> takeWhile isLower "abc␣def"
"abc"
• Remove elements from a list while they satisfy a predicate:
> dropWhile isLower "abc␣def"
"␣def"
7.3
The foldr function
Many functions that take a list as their argument can be deﬁned using the
following simple pattern of recursion on lists:
f [ ]
=
v
f (x : xs)
=
x ⊕f xs
That is, the function maps the empty list to some value v, and any non-
empty list to some operator ⊕applied to the head of the list and the result
of recursively processing the tail. For example, a number of familiar library

7.3. THE FOLDR FUNCTION
81
functions on lists can be deﬁned using this pattern:
sum [ ]
=
0
sum (x : xs)
=
x + sum xs
product [ ]
=
1
product (x : xs)
=
x ∗product xs
or [ ]
=
False
or (x : xs)
=
x ∨or xs
and [ ]
=
True
and (x : xs)
=
x ∧and xs
The higher-order library function foldr (abbreviating "fold right") encapsu-
lates this pattern of recursion for deﬁning functions on lists, with the op-
erator ⊕and the value v as arguments. For example, using foldr the four
deﬁnitions above can be rewritten more compactly as follows:
sum
=
foldr (+) 0
product
=
foldr (∗) 1
or
=
foldr (∨) False
and
=
foldr (∧) True
(Recall that operators must be parenthesised when used as arguments.) These
new deﬁnitions could also include explicit list arguments, as in sum xs =
foldr (+) 0 xs, but we prefer the above deﬁnitions in which these arguments
are made implicit using partial application because they are simpler.
The foldr function itself is deﬁned using recursion:
foldr
::
(a →b →b) →b →[a ] →b
foldr f v [ ]
=
v
foldr f v (x : xs)
=
f x (foldr f v xs)
That is, the function foldr f v maps the empty list to the value v, and any non-
empty list to the function f applied to the head of the list and the recursively
processed tail. In practice, however, it is best to think of the behaviour of
foldr f v in a non-recursive manner, as simply replacing each cons operator
in a list by the function f , and the empty list at the end by the value v. For
example, applying the function foldr (+) 0 to the list
1 : (2 : (3 : [ ]))
gives the result
1 + (2 + (3 + 0))
in which : and [ ] have been replaced by + and 0, respectively. Hence, the
deﬁnition sum = foldr (+) 0 states that summing a list of numbers amounts
to replacing each cons by addition and the empty list by zero.

82
CHAPTER 7. HIGHER-ORDER FUNCTIONS
Even though foldr encapsulates a simple pattern of recursion, it can be
used to deﬁne many more functions than might ﬁrst be expected. First of all,
recall the following deﬁnition for the library function length:
length
::
[a ] →Int
length [ ]
=
0
length ( : xs)
=
1 + length xs
For example, applying length to the list
1 : (2 : (3 : [ ]))
gives the result
1 + (1 + (1 + 0))
That is, calculating the length of a list amounts to replacing each cons by the
function that adds one to its second argument, and the empty list by zero.
Hence, the deﬁnition for length can be rewritten using foldr:
length
=
foldr (λ
n →1 + n) 0
Now let us consider the library function that reverses a list, which can be
deﬁned using explicit recursion as follows:
reverse
::
[a ] →[a ]
reverse [ ]
=
[ ]
reverse (x : xs)
=
reverse xs ++ [x ]
For example, applying reverse to the list
1 : (2 : (3 : [ ]))
gives the result
(([ ] ++ [3]) ++ [2]) ++ [1]
It is perhaps not immediately clear from the deﬁnition, or the example, how
reverse can be deﬁned using foldr. However, if we deﬁne a function snoc x xs =
xs ++ [x ] that adds a new element at the end of a list rather than at the start
("snoc" is cons backwards), then reverse can be redeﬁned as
reverse [ ]
=
[ ]
reverse (x : xs)
=
snoc x (reverse xs)
from which a deﬁnition using foldr is then immediate:
reverse
=
foldr snoc [ ]

7.4. THE FOLDL FUNCTION
83
That is, reversing a list amounts to replacing each cons by snoc and the empty
list by itself. The append operator ++ used in the deﬁnition of snoc can itself
be deﬁned in a particularly compact manner using foldr:
(++ ys)
=
foldr (:) ys
That is, appending ys to the end of a list amounts to replacing each cons in
the list by itself, and the empty list at the end by ys.
We conclude this section by noting that the name fold right reﬂects the
use of an operator that is assumed to associate to the right. For example,
evaluating foldr (+) 0 [1, 2, 3] gives the result 1 + (2 + (3 + 0)), in which the
bracketing speciﬁes that addition here is assumed to associate to the right.
More generally, the behaviour of foldr can be summarised as follows:
foldr (⊕) v [x0, x1, · · · , xn]
=
x0 ⊕(x1 ⊕(· · · (xn ⊕v) · · ·))
7.4
The foldl function
It is also possible to deﬁne a recursive function on lists using an operator that
is assumed to associate to the left. For example, the function sum can be
redeﬁned in this manner by using an auxiliary function sum′ that takes an
extra argument v that is used to accumulate the ﬁnal result:
sum
=
sum′ 0
where
sum′ v [ ] = v
sum′ v (x : xs) = sum′ (v + x) xs
For example:
sum [1, 2, 3]
=
{ applying sum }
sum′ 0 [1, 2, 3]
=
{ applying sum′ }
sum′ (0 + 1) [2, 3]
=
{ applying sum′ }
sum′ ((0 + 1) + 2) [3]
=
{ applying sum′ }
sum′ (((0 + 1) + 2) + 3) [ ]
=
{ applying sum′ }
((0 + 1) + 2) + 3
=
{ applying + }
6
The bracketing in this calculation speciﬁes that addition is now assumed to
associate to the left. In practice, however, the order of association does not

84
CHAPTER 7. HIGHER-ORDER FUNCTIONS
aﬀect the value of the result in this case, because addition is associative. That
is, x + (y + z) = (x + y) + z for any numbers x, y and z.
Generalising from the sum example, many functions on lists can be deﬁned
using the following simple pattern of recursion:
f v [ ]
=
v
f v (x : xs)
=
f (v ⊕x) xs
That is, the function maps the empty list to the accumulator value v, and
any non-empty list to the result of recursively processing the tail using a new
accumulator value obtained by applying some operator ⊕to the current value
and the head of the list. The higher-order library function foldl (abbreviating
"fold left") encapsulates this pattern of recursion, with the operator ⊕and
the accumulator v as arguments. For example, using foldl the above deﬁnition
for sum can be rewritten more compactly as follows:
sum
=
foldl (+) 0
Similarly, we have:
product
=
foldl (∗) 1
or
=
foldl (∨) False
and
=
foldl (∧) True
The other foldr examples from the previous section can also be redeﬁned
using foldl, by supplying the appropriate operators:
length
=
foldl (λn
→n + 1) 0
reverse
=
foldl (λxs x →x : xs) [ ]
(xs++)
=
foldl (λys y →ys ++ [y ]) xs
For example, with these new deﬁnitions:
length [1, 2, 3]
=
((0 + 1) + 1) + 1
reverse [1, 2, 3]
=
3 : (2 : (1 : [ ]))
[1, 2, 3] ++ [4, 5]
=
([1, 2, 3] ++ [4]) ++ [5]
When a function can be deﬁned using both foldr and foldl, as in the
above examples, the choice of which deﬁnition is preferable is usually made
on grounds of eﬃciency and requires careful consideration of the evaluation
mechanism underlying Haskell, which is discussed in chapter 12.
The foldl function itself is deﬁned using recursion:
foldl
::
(a →b →a) →a →[b] →a
foldl f v [ ]
=
v
foldl f v (x : xs)
=
foldl f (f v x) xs
In practice, however, as with foldr it is best to think of the behaviour of
foldl in a non-recursive manner, in terms of an operator ⊕that is assumed to
associate to the left, as summarised by the following equation:
foldl (⊕) v [x0, x1, · · · , xn]
=
(· · · ((v ⊕x0) ⊕x1) · · ·) ⊕xn

7.5. THE COMPOSITION OPERATOR
85
7.5
The composition operator
The higher-order library operator ◦returns the composition of two functions
as a single function, and can be deﬁned as follows:
(◦)
::
(b →c) →(a →b) →(a →c)
f ◦g
=
λx →f (g x)
That is, f ◦g (read as "f composed with g") is the function that takes an
argument x, applies the function g to this argument, and applies the function
f to the result. This operator could also be deﬁned by (f ◦g) x = f (g x).
However, we prefer the above deﬁnition in which the x argument is shunted to
the body of the deﬁnition using a lambda expression, because it makes explicit
the idea that composition returns a function as its result.
Composition can be used to simplify nested function applications, by re-
ducing parentheses and avoiding the need to explicitly refer to the initial ar-
gument. For example, using composition the deﬁnitions
odd n
=
¬ (even n)
twice f x
=
f (f x)
sumsqreven ns
=
sum (map (↑2) (ﬁlter even ns))
can be rewritten more simply:
odd
=
¬ ◦even
twice f
=
f ◦f
sumsqreven
=
sum ◦map (↑2) ◦ﬁlter even
The last deﬁnition exploits the fact that composition is associative. That is,
f ◦(g ◦h) = (f ◦g) ◦h for any functions f , g and h of the appropriate types.
Hence, in a composition of three of more functions, as in sumsqreven, there
is no need to include parentheses to indicate the order of association, because
associativity ensures that this does not aﬀect the result.
Composition also has an identity, given by the identity function:
id
::
a →a
id
=
λx →x
That is, id is the function that simply returns its argument unchanged, and
has the property that id ◦f = f and f ◦id = f for any function f . The identity
function is often useful when reasoning about programs, and in programming
itself provides a suitable starting point for a sequence of compositions. For
example, the composition of a list of functions can be deﬁned as follows:
compose
::
[a →a ] →(a →a)
compose
=
foldr (◦) id

86
CHAPTER 7. HIGHER-ORDER FUNCTIONS
7.6
String transmitter
We conclude this chapter with an extended example. Consider the problem of
simulating the transmission of a string using zeros and ones. More precisely,
we seek to deﬁne a function that converts a string into a list of zeros and ones,
together with a function that performs the opposite conversion.
Binary numbers
As a consequence of having ten ﬁngers, people normally ﬁnd it most convenient
to use numbers written in base-ten or decimal notation. A decimal number is
sequence of digits in the range zero to nine, in which the rightmost digit has
a weight of one, and successive digits as we move to the left in the number
increase in weight by a factor of ten. For example, the decimal number 2345
can be understood in these terms as follows:
2345
=
(1000 ∗2) + (100 ∗3) + (10 ∗4) + (1 ∗5)
That is, 2345 represents the sum of the products of the weights 1000,100,10,1
with the digits 2,3,4,5, which evaluates to the integer 2345.
In contrast, computers normally ﬁnd it more convenient to use numbers
written in the more primitive base-two or binary notation. A binary number
is a sequence of zeros and ones, called binary digits or bits, in which successive
bits as we move to the left increase in weight by a factor of two. For example,
the binary number 1101 can be understood as follows:
1101
=
(8 ∗1) + (4 ∗1) + (2 ∗0) + (1 ∗1)
That is, 1101 represents the sum of the products of the weights 8,4,2,1 with
the bits 1,1,0,1, which evaluates to the integer 13.
To simplify the deﬁnition of certain functions, we assume for the remainder
of this example that binary numbers are written in reverse order to normal.
For example, 1101 would now be written as 1011, with successive bits as we
move to the right increasing in weight by a factor of two:
1011
=
(1 ∗1) + (2 ∗0) + (4 ∗1) + (8 ∗1)
Base conversion
To make the types of the functions that we deﬁne more meaningful, we declare
a type for bits as a synonym for the type of integers:
type Bit
=
Int
A binary number, represented as a list of such bits, can be converted into an
integer by simply evaluating the required weighted sum:
bin2int
::
[Bit ] →Int
bin2int bits
=
sum [w ∗b | (w, b) ←zip weights bits ]
where weights = iterate (∗2) 1

7.6. STRING TRANSMITTER
87
The higher-order library function iterate produces a list by applying a function
an increasing number of times to a value:
iterate f x
=
[x, f x, f (f x), f (f (f x)), · · ·]
Hence the expression iterate (∗2) 1 used within the deﬁnition of bin2int pro-
duces the list of weights [1, 2, 4, 8, · · ·].
This list is notionally inﬁnite, but
under lazy evaluation as discussed in chapter 12, only as many elements as
required by the context in which it is used — in this case zipping with the list
of bits — will actually be produced. For example:
> bin2int [1, 0, 1, 1]
13
There is, however, a simpler way to deﬁne bin2int, which can be revealed
with the aid of a little algebra. Consider an arbitrary four-bit binary number
[a, b, c, d ]. Applying bin2int to this list will produce the weighted sum
(1 ∗a) + (2 ∗b) + (4 ∗c) + (8 ∗d)
which can be restructured as follows:
(1 ∗a) + (2 ∗b) + (4 ∗c) + (8 ∗d)
=
{ simplifying 1 ∗a }
a + (2 ∗b) + (4 ∗c) + (8 ∗d)
=
{ factoring out 2 ∗}
a + 2 ∗(b + (2 ∗c) + (4 ∗d))
=
{ factoring out 2 ∗}
a + 2 ∗(b + 2 ∗(c + (2 ∗d)))
=
{ complicating d }
a + 2 ∗(b + 2 ∗(c + 2 ∗(d + (2 ∗0))))
The ﬁnal result shows that converting a list of bits [a, b, c, d ] into an integer
amounts to replacing each cons by the function that adds its ﬁrst argument
to twice its second argument, and replacing the empty list by zero.
More
generally, we conclude that bin2int can be rewritten using foldr:
bin2int
=
foldr (λx y →x + 2 ∗y) 0
Now let us consider the opposite conversion, from a non-negative integer
into a binary number. This can be achieved by repeatedly dividing the integer
by two and taking the remainder, until the integer becomes zero. For example,
starting with the integer 13 we proceed as follows:
13
divided by
2
=
6
remainder
1
6
divided by
2
=
3
remainder
0
3
divided by
2
=
1
remainder
1
1
divided by
2
=
0
remainder
1

88
CHAPTER 7. HIGHER-ORDER FUNCTIONS
The sequence of remainders, 1011, provides the binary representation of the
integer 13. It is easy to implement this procedure using recursion:
int2bin
::
Int →[Bit ]
int2bin 0
=
[ ]
int2bin n
=
n 'mod' 2 : int2bin (n 'div' 2)
For example:
> int2bin 13
[1, 0, 1, 1]
We will ensure that all our binary numbers have the same length, eight
bits, by using a function make8 that truncates or extends a binary number as
appropriate to make it precisely eight bits:
make8
::
[Bit ] →[Bit ]
make8 bits
=
take 8 (bits ++ repeat 0)
The library function repeat produces an inﬁnite list of copies of a value, but
once again lazy evaluation ensures that only as many elements as required by
the context will actually be produced. For example:
> make8 [1, 0, 1, 1]
[1, 0, 1, 1, 0, 0, 0, 0]
Transmission
We can now deﬁne a function that encodes a string of characters as a list
of bits by converting each character into a Unicode number, converting each
such number into an eight-bit binary number, and concatenating each of these
numbers together to produce a list of bits. Using the higher-order functions
map and composition, this conversion can be implemented as follows:
encode
::
String →[Bit ]
encode
=
concat ◦map (make8 ◦int2bin ◦ord)
For example:
> encode "abc"
[1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]
To decode a list of bits produced using encode, we ﬁrst deﬁne a function
chop8 that chops such a list up into eight-bit binary numbers:
chop8
::
[Bit ] →[[Bit ]]
chop8 [ ]
=
[ ]
chop8 bits
=
take 8 bits : chop8 (drop 8 bits)

7.7. CHAPTER REMARKS
89
It is now easy to deﬁne a function that decodes a list of bits as a string
of characters by chopping the list up, and converting each resulting binary
number into a Unicode number and then a character:
decode
::
[Bit ] →String
decode
=
map (chr ◦bin2int) ◦chop8
For example:
> decode [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0]
"abc"
Finally, we deﬁne a function transmit that simulates the transmission of
a string of characters as a list of bits, using a perfect communication channel
that we model using the identity function:
transmit
::
String →String
transmit
=
decode ◦channel ◦encode
channel
::
[Bit ] →[Bit ]
channel
=
id
For example:
> transmit "higher-order␣functions␣are␣easy"
"higher-order␣functions␣are␣easy"
7.7
Chapter remarks
Further applications of higher-order functions, including the production of
computer music, ﬁnancial contracts, graphical images, hardware descriptions,
logic programs, and pretty printers can be found in The Fun of Program-
ming [7]. A more in-depth tutorial on foldr is given in [15].
7.8
Exercises
1. Show how the list comprehension [f x | x ←xs, p x ] can be re-expressed
using the higher-order functions map and ﬁlter.
2. Without looking at the deﬁnitions from the standard prelude, deﬁne the
higher-order functions all, any, takeWhile and dropWhile.
3. Redeﬁne the functions map f and ﬁlter p using foldr.
4. Using foldl, deﬁne a function dec2int :: [Int ] →Int that converts a
decimal number into an integer. For example:
> dec2int [2, 3, 4, 5]
2345

90
CHAPTER 7. HIGHER-ORDER FUNCTIONS
5. Explain why the following deﬁnition is invalid:
sumsqreven
=
compose [sum, map (↑2), ﬁlter even ]
6. Without looking at the standard prelude, deﬁne the higher-order library
function curry that converts a function on pairs into a curried function,
and conversely, the function uncurry that converts a curried function
with two arguments into a function on pairs.
Hint: ﬁrst write down the types of the two functions.
7. A higher-order function unfold that encapsulates a simple pattern of
recursion for producing a list can be deﬁned as follows:
unfold p h t x | p x
=
[ ]
| otherwise
=
h x : unfold p h t (t x)
That is, the function unfold p h t produces the empty list if the pred-
icate p is true of the argument, and otherwise produces a non-empty
list by applying the function h to give the head, and the function t to
generate another argument that is recursively processed in the same way
to produce the tail of the list. For example, the function int2bin can be
rewritten more compactly using unfold as follows:
int2bin
=
unfold (== 0) ('mod'2) ('div'2)
Redeﬁne the functions chop8, map f and iterate f using unfold.
8. Modify the string transmitter program to detect simple transmission
errors using parity bits. That is, each eight-bit binary number produced
during encoding is extended with a parity bit, set to one if the number
contains an odd number of ones, and to zero otherwise. In turn, each
resulting nine-bit binary number consumed during decoding is checked
to ensure that its parity bit is correct, with the parity bit being discarded
if this is the case, and a parity error reported otherwise.
Hint: the library function error :: String →a terminates evaluation and
displays the given string as an error message.
9. Test your new string transmitter program from the previous exercise
using a faulty communication channel that forgets the ﬁrst bit, which
can be modelled using the tail function on lists of bits.

Chapter 8
Functional Parsers
In this chapter we show how Haskell can be used to program simple parsers.
We start by explaining what parsers are and why they are useful, show how
parsers can naturally be viewed as functions, deﬁne a number of basic parsers
and higher-order functions for combining parsers in various ways, and conclude
by developing a parser for arithmetic expressions.
8.1
Parsers
A parser is a program that takes a string of characters, and produces some
form of tree that makes the syntactic structure of the string explicit.
For
example, given the string 2 ∗3 + 4, a parser for arithmetic expressions might
produce a tree of the following form, in which the numbers appear at the leaves
of the tree, and the operators appear at the branches:
+


∗


4
2
3
The structure of this tree makes explicit that + and ∗are operators with two
arguments, and that ∗has higher priority than +.
Parsers are an important topic in computing, because most real-life pro-
grams use a parser to pre-process their input. For example, a calculator pro-
gram parses numeric expressions prior to evaluating them, the Hugs system
parses Haskell programs prior to executing them, and a web browser parses
hypertext documents prior to displaying them. In each case, making the struc-
ture of the input explicit considerably simpliﬁes its further processing. For
example, once a numeric expression has been parsed into a tree structure such
as in the example above, evaluating the expression is straightforward.
91

92
CHAPTER 8. FUNCTIONAL PARSERS
8.2
The parser type
In Haskell, a parser can naturally be viewed directly as a function that takes
a string and produces a tree. Hence, given a suitable type Tree of trees, the
notion of a parser can be represented as a function of type String →Tree,
which we abbreviate as Parser using the following declaration:
type Parser
=
String →Tree
In general, however, a parser might not always consume its entire argument
string. For example, a parser for numbers might be applied to a string com-
prising a number followed by a word. For this reason, we generalise our type
for parsers to also return any unconsumed part of the argument string:
type Parser
=
String →(Tree, String)
Similarly, a parser might not always succeed. For example, a parser for num-
bers might be applied to a string comprising a word. To handle this, we further
generalise our type for parsers to return a list of results, with the convention
that the empty list denotes failure, and a singleton list denotes success:
type Parser
=
String →[(Tree, String)]
Returning a list also opens up the possibility of returning more than one result
if the argument string can be parsed in more than one way. For simplicity,
however, we only consider parsers that return at most one result.
Finally, diﬀerent parsers will likely return diﬀerent kinds of trees, or more
generally, any kind of value. For example, a parser for numbers might return
an integer value. Hence, it is useful to abstract from the speciﬁc type Tree of
result values, and make this into a parameter of the Parser type:
type Parser a
=
String →[(a, String)]
In summary, this declaration states that a parser of type a is a function that
takes an input string and produces a list of results, each of which is a pair
comprising a result value of type a and an output string. Alternatively, the
parser type can also be read as a rhyme in the style of Dr Seuss!
A parser for things
Is a function from strings
To lists of pairs
Of things and strings
8.3
Basic parsers
We now deﬁne three basic parsers that will be used as the building blocks for
all other parsers. First of all, the parser return v always succeeds with the

8.3. BASIC PARSERS
93
result value v, without consuming any of the input string:
return
::
a →Parser a
return v
=
λinp →[(v, inp)]
This function could equally well be deﬁned by result v inp = [(v, inp)].
However, we prefer the above deﬁnition in which the second argument inp
is shunted to the body of the deﬁnition using a lambda expression, because
it makes explicit that return is a function that takes a single argument and
returns a parser, as expressed by the type a →Parser a.
Whereas return v always succeeds, the dual parser failure always fails,
regardless of the contents of the input string:
failure
::
Parser a
failure
=
λinp →[ ]
Our ﬁnal basic parser is item, which fails if the input string is empty, and
succeeds with the ﬁrst character as the result value otherwise:
item
::
Parser Char
item
=
λinp →case inp of
[ ] →[ ]
(x : xs) →[(x, xs)]
The case mechanism of Haskell used in this deﬁnition allows pattern matching
to be used in the body of a deﬁnition, in this example by matching the string
inp against two patterns to choose between two possible results. The case
mechanism is not used much in this book, but can sometimes be useful.
Because parsers are functions, they could be applied to a string using
normal function application, but we prefer to abstract from the representation
of parsers by deﬁning our own application function:
parse
::
Parser a →String →[(a, String)]
parse p inp
=
p inp
Using parse, we conclude this section with some examples that illustrate the
behaviour of the three basic parsers deﬁned above:
> parse (return 1) "abc"
[(1, "hello")]
> parse failure "abc"
[ ]
> parse item ""
[ ]
> parse item "abc"
[('a', "bc")]

94
CHAPTER 8. FUNCTIONAL PARSERS
8.4
Sequencing
Perhaps the simplest way of combining two parsers is to apply one after the
other in sequence, with the output string returned by the ﬁrst parser becoming
the input string to the second. But how should the result values from the two
parsers be handled? One approach would be to combine the two values as a
pair, using a sequencing operator for parsers with the following type:
Parser a →Parser b →Parser (a, b)
In practice, however, it turns out to be more convenient to combine the se-
quencing of parsers with the processing of their result values, by means of a
sequencing operator >>= (read as "then") deﬁned as follows:
(>>=)
::
Parser a →(a →Parser b) →Parser b
p >>= f
=
λinp →case parse p inp of
[ ] →[ ]
[(v, out)] →parse (f v) out
That is, the parser p >>= f fails if the application of the parser p to the input
string fails, and otherwise applies the function f to the result value to give
a second parser, which is then applied to the output string to give the ﬁnal
result. In this manner, the result value produced by the ﬁrst parser is made
directly available for processing by the second.
A typical parser built using >>= has the following structure:
p1 >>= λv1 →
p2 >>= λv2 →
...
pn >>= λvn →
return (f v1 v2 ... vn)
That is, apply the parser p1 and call its result value v1; then apply the parser
p2 and call its result value v2; ...; then apply the parser pn and call its result
value vn; and ﬁnally, combine all the results into a single value by applying
the function f . Haskell provides a special syntax for such parsers, allowing
them to be expressed in the following, more appealing, form:
do v1 ←p1
v2 ←p2
...
vn ←pn
return (f v1 v2 ... vn)
As with list comprehensions, the expressions vi ←pi are called generators. If
the result value produced by a generator vi ←pi is not required, the generator

8.5. CHOICE
95
can be abbreviated simply by pi. Note also that the layout rule applies to
the do notation for sequencing parsers, in the sense that each parser in the
sequence must begin in precisely the same column.
For example, a parser that consumes three characters, discards the second,
and returns the ﬁrst and third as a pair can now be deﬁned as follows:
p
::
Parser (Char, Char)
p
=
do x ←item
item
y ←item
return (x, y)
Note that p only succeeds if every parser in its deﬁning sequence succeeds,
which requires at least three characters in the input string:
> parse p "abcdef"
[(('a', 'c'), "def")]
> parse p "ab"
[ ]
8.5
Choice
Another natural way of combining two parsers is to apply the ﬁrst parser to
the input string, and if this fails then apply the second instead. Such a choice
operator +++ (read as "or else") can be deﬁned as follows:
(+++)
::
Parser a →Parser a →Parser a
p +++ q
=
λinp →case parse p inp of
[ ] →parse q inp
[(v, out)] →[(v, out)]
For example:
> parse (item +++ return 'd') "abc"
[('a', "bc")]
> parse (failure +++ return 'd') "abc"
[('d', "abc")]
> parse (failure +++ failure) "abc"
[ ]

96
CHAPTER 8. FUNCTIONAL PARSERS
8.6
Derived primitives
Using the three basic parsers together with sequencing and choice, we can now
deﬁne a number of other useful parsing primitives. First of all, we deﬁne a
parser sat p for single characters that satisfy the predicate p:
sat
::
(Char →Bool) →Parser Char
sat p
=
do x ←item
if p x then return x else failure
Using sat and appropriate predicates from the standard prelude, we can deﬁne
parsers for single digits, lower-case letters, upper-case letters, arbitrary letters,
alphanumeric characters, and speciﬁc characters:
digit
::
Parser Char
digit
=
sat isDigit
lower
::
Parser Char
lower
=
sat isLower
upper
::
Parser Char
upper
=
sat isUpper
letter
::
Parser Char
letter
=
sat isAlpha
alphanum
::
Parser Char
alphanum
=
sat isAlphaNum
char
::
Char →Parser Char
char x
=
sat (== x)
For example:
> parse digit "123"
[('1', "23")]
> parse digit "abc"
[ ]
> parse (char 'a') "abc"
[('a', "bc")]
> parse (char 'a') "123"
[ ]

8.6. DERIVED PRIMITIVES
97
In turn, using char we can deﬁne a parser string xs for the string of
characters xs, with the string itself returned as the result value:
string
::
String →Parser String
string [ ]
=
return [ ]
string (x : xs)
=
do char x
string xs
return (x : xs)
Note that string is deﬁned using recursion, and only succeeds if the entire
target string is consumed. The base case states that the empty string can
always be parsed. The recursive case states that a non-empty string can be
parsed by parsing the ﬁrst character, parsing the remaining characters, and
returning the entire string as the result value. For example:
> parse (string "abc") "abcdef"
[("abc", "def")]
> parse (string "abc") "ab1234"
[ ]
Our next two parsers, many p and many1 p, apply a parser p as many
times as possible until it fails, with the result values from by each successful
application of p being combined as a list. The diﬀerence between these two
repetition primitives is that many permits zero or more applications of p,
whereas many1 requires at least one successful application:
many
::
Parser a →Parser [a ]
many p
=
many1 p +++ return [ ]
many1
::
Parser a →Parser [a ]
many1 p
=
do v ←p
vs ←many p
return (v : vs)
Note that many and many1 are deﬁned using mutual recursion. In particular,
the deﬁnition for many p states that p can either be applied at least once or
not at all, while the deﬁnition for many1 p states that p can be applied once
and then zero or more times. For example:
> parse (many digit) "123abc"
[("123", "abc")]
> parse (many digit) "abcdef"
[("", "abcdef")]
> parse (many1 digit) "abcdef"
[ ]

98
CHAPTER 8. FUNCTIONAL PARSERS
Using many and many1, we can deﬁne parsers for identiﬁers (or variable
names) comprising a lower-case letter followed by zero or more alphanumeric
characters, natural numbers comprising one or more digits, and spacing com-
prising zero or more space, tab, and newline characters:
ident
::
Parser String
ident
=
do x ←lower
xs ←many alphanum
return (x : xs)
nat
::
Parser Int
nat
=
do xs ←many1 digit
return (read xs)
space
::
Parser ()
space
=
do many (sat isSpace)
return ()
For example:
> parse ident "abc␣def"
[("abc", "␣def")]
> parse nat "123␣abc"
[(123, "␣abc")]
> parse space "␣␣␣abc"
[((), "abc")]
Note that space returns the empty tuple () as a dummy result value, reﬂecting
the fact that the details of spacing are not usually important.
8.7
Handling spacing
Most real-life parsers allow spacing to be freely used around the basic tokens
in their input string. For example, the strings 1+2 and 1 + 2 are both parsed
in the same way by Hugs. To handle such spacing, we deﬁne a new primitive
that ignores any space before and after applying a parser for a token:
token
::
Parser a →Parser a
token p
=
do space
v ←p
space
return v

8.8. ARITHMETIC EXPRESSIONS
99
Using token, it is now easy to deﬁne parsers that ignore spacing around iden-
tiﬁers, natural numbers, and special symbols:
identiﬁer
::
Parser String
identiﬁer
=
token ident
natural
::
Parser Int
natural
=
token nat
symbol
::
String →Parser String
symbol xs
=
token (string xs)
For example, a parser for a non-empty list of natural numbers that ignores
spacing around tokens can be deﬁned as follows:
p
::
Parser [Int ]
p
=
do symbol "["
n ←natural
ns ←many (do symbol ","
natural)
symbol "]"
return (n : ns)
This deﬁnition states that such a list begins with an opening square bracket
and a natural number, followed by zero or more commas and natural numbers,
and concludes with a closing square bracket. Note that p only succeeds if a
complete list in precisely this format is consumed:
> parse p "␣[1,␣2,␣3]␣"
[([1, 2, 3], "")]
> parse p "[1,2,]"
[ ]
8.8
Arithmetic expressions
We conclude this chapter with an extended example. Consider a simple form of
arithmetic expressions built up from natural numbers using addition, multipli-
cation and parentheses. We assume that addition and multiplication associate
to the right, and that multiplication has higher priority than addition. For
example, 2 + 3 + 4 means 2 + (3 + 4), while 2 ∗3 + 4 means (2 ∗3) + 4.
The syntactic structure of a language can be formalised using the mathe-
matical notion of a grammar, which is a set of rules that describes how strings
of the language can be constructed. For example, a grammar for our language
of arithmetic expressions can be deﬁned by the following two rules:
expr
::=
expr + expr | expr ∗expr | (expr) | nat
nat
::=
0 | 1 | 2 | · · ·

100
CHAPTER 8. FUNCTIONAL PARSERS
The ﬁrst rule states that an expression is either the addition or multiplication
of two expressions, a parenthesised expression, or a natural number. In turn,
the second rule states that a natural number is either zero, one, two, etc.
For example, using this grammar the construction of the expression 2 ∗3 + 4
can be represented by the following parse tree, in which the tokens in the
expression appear at the leaves, and the grammatical rules applied to construct
the expression give rise to the branching structure:
expr







expr







+
expr

expr

∗
expr

nat

nat

nat

4
2
3
The structure of this tree makes explicit that 2 ∗3 + 4 can be constructed
from the addition of two expressions, the ﬁrst given by the multiplication of
two further expressions which are in turn given by the numbers two and three,
and the second expression given by the number four. However, the grammar
also permits another possible parse tree for this example, which corresponds
to the erroneous interpretation of the expression as 2 ∗(3 + 4):
expr







expr

∗
expr







nat

expr

+
expr

2
nat

nat

3
4
The problem is that our grammar for expressions does not take account of
the fact that multiplication has higher priority than addition. However, this
can easily be ﬁxed by modifying the grammar to have a separate rule for each
level of priority, with addition at the lowest level of priority, multiplication at
the middle level, and parentheses and numbers at the highest level:
expr
::=
expr + expr | term
term
::=
term ∗term | factor
factor
::=
(expr) | nat
nat
::=
0 | 1 | 2 | · · ·

8.8. ARITHMETIC EXPRESSIONS
101
Using this new grammar, 2 ∗3 + 4 indeed has a single parse tree, which cor-
responds to the correct interpretation of the expression as (2 ∗3) + 4:
expr







expr

+
expr

term
							








term

term

∗
term

factor

factor

factor

nat

nat

nat

4
2
3
We have now dealt with the issue of priority, but our grammar does not
yet take account of the fact that addition and multiplication associate to the
right. For example, the expression 2 + 3 + 4 currently has two possible parse
trees, corresponding to (2+3)+4 and 2+(3+4). However, this can also easily
be ﬁxed by modifying the grammatical rules for addition and multiplication
to be recursive in their right argument only, rather than both arguments:
expr
::=
term + expr | term
term
::=
factor ∗term | factor
Using these new rules, 2+3+4 now has a single parse tree, which corresponds
to the correct interpretation of the expression as 2 + (3 + 4):
expr







term

+
expr
	







factor

term

+
expr

nat

factor

term

2
nat

factor

3
nat

4
In fact, our grammar for expressions is now unambiguous, in the sense that
every well-formed expression has precisely one parse tree.

102
CHAPTER 8. FUNCTIONAL PARSERS
Our ﬁnal modiﬁcation to the grammar is one of simpliﬁcation. For ex-
ample, consider the rule expr ::= term + expr | term, which states that an
expression is either the addition of a term and an expression, or is a term.
In other words, an expression always begins with a term, which can then be
followed by the addition of an expression or by nothing. Hence, the rule for
expressions can be simpliﬁed to expr ::= term (+ expr | ϵ), in which the sym-
bol ϵ denotes the empty string. Simplifying the rule for terms in a similar
manner gives our ﬁnal grammar for arithmetic expressions:
expr
::=
term (+ expr | ϵ)
term
::=
factor (∗term | ϵ)
factor
::=
(expr) | nat
nat
::=
0 | 1 | 2 | · · ·
It is now straightforward to translate this grammar into a parser for ex-
pressions, by simply rewriting the rules using our parsing primitives. In fact,
we choose to have the parser itself evaluate the expression being parsed to its
integer value, rather than returning some form of tree:
expr
::
Parser Int
expr
=
do t ←term
do symbol "+"
e ←expr
return (t + e)
+++ return t
term
::
Parser Int
term
=
do f ←factor
do symbol "*"
t ←term
return (f ∗t)
+++ return f
factor
::
Parser Int
factor
=
do symbol "("
e ←expr
symbol ")"
return e
+++ natural
For example, the parser expr ﬁrst parses a term with value t, then parses a
plus symbol followed by an expression with value e and returns the value t +e,
or else parses nothing further and simply returns the value t. The parsers term
and factor can be read in a similar manner.
Finally, using expr we deﬁne a function eval :: String →Int that evaluates
an arithmetic expression to its integer value. To handle the cases of uncon-
sumed and invalid input, we use the library function error :: String →a that

8.9. CHAPTER REMARKS
103
displays an error message and then terminates the program:
eval
::
String →Int
eval xs
=
case parse expr xs of
[(n, [ ])] →n
[( , out)] →error ("unconsumed␣input␣" ++ out)
[ ] →error "invalid␣input"
For example:
> eval "2*3+4"
10
> eval "2*(3+4)"
14
> eval "2␣*␣(3␣+␣4)"
14
> eval "2*3-4"
Error : unconsumed input −4
> eval "-1"
Error : invalid input
8.9
Chapter remarks
A library ﬁle comprising the parsing primitives from this chapter is available on
the web [14]. For technical reasons concerning the monadic nature of parsers,
a number of the basic deﬁnitions in this library are slightly diﬀerent to those
give here. Further details are available in [17, 18], upon which this chapter is
based. More information concerning grammars can be found in [28], and more
advanced approaches to building parsers in Haskell are given in [23, 9]. The
reading of the parser type as a rhyme is due to Fritz Ruehr.
8.10
Exercises
1. The library ﬁle also deﬁnes a parser int :: Parser Int for an integer.
Without looking at this deﬁnition, deﬁne int. Hint: an integer is either
a minus symbol followed by a natural number, or a natural number.
2. Deﬁne a parser comment ::Parser () for ordinary Haskell comments that
begin with the symbol -- and extend to the end of the current line, which
is represented by the control character '\n'.
3. Using our second grammar for arithmetic expressions, draw the two pos-
sible parse trees for the expression 2 + 3 + 4.

104
CHAPTER 8. FUNCTIONAL PARSERS
4. Using our third grammar for arithmetic expressions, draw the parse trees
for the expressions 2 + 3, 2 ∗3 ∗4 and (2 + 3) + 4.
5. Explain why the ﬁnal simpliﬁcation of the grammar for arithmetic ex-
pressions has a dramatic eﬀect on the eﬃciency of the resulting parser.
Hint: begin by considering how an expression comprising a single num-
ber would be parsed if this step had not been made.
6. Extend the parser for arithmetic expressions to support subtraction and
division, based upon the following extensions to the grammar:
expr
::=
term (+ expr | −expr | ϵ)
term
::=
factor (∗term | / term | ϵ)
7. Further extend the grammar and parser for arithmetic expressions to
support exponentiation, which is assumed to associate to the right and
have higher priority than multiplication and division, but lower priority
than parentheses and numbers. For example, 2 ↑3 ∗4 means (2 ↑3) ∗4.
Hint: the new level of priority requires a new rule in the grammar.
8. Consider expressions built up from natural numbers using a subtraction
operator that is assumed to associate to the left.
(a) Deﬁne a natural grammar for such expressions.
(b) Translate this grammar into a parser expr :: Parser Int.
(c) What is the problem with this parser?
(d) Show how it can be ﬁxed. Hint: rewrite the parser using the repe-
tition primitive many and the library function foldl.

Chapter 9
Interactive Programs
In this chapter we show how Haskell can be used to write interactive programs.
We start by explaining what interactive programs are, show how such programs
can naturally be viewed as functions, deﬁne a number of basic interactive
programs and higher-order functions for combining interactive programs, and
conclude by developing a calculator and the game of life.
9.1
Interaction
A batch program is one that does not interact with the user while it is running.
In the early days of computing, most programs were batch programs, run in
isolation from their users in order to maximise the amount of time that the
computer was performing useful work. For example, a route planning program
may take start and ﬁnish points as its input, silently perform a large number
of calculations, and then produce a recommended route as its output.
Up to this point in the book we have considered how Haskell can be used
to write batch programs. In Haskell such programs, and more generally all
programs, are modelled as pure functions that take all their input as explicit
arguments, and produce all their output as explicit results. For example, a
route planner may be modelled as a function of type (Point, Point) →Route
that takes a pair of points and produces a route between them.
In contrast, an interactive program is one that may take additional input
from the user, and produce additional output for the user, while the program
is running. In the modern era of computing, most programs are interactive
programs, run as a dialogue with their users in order to provide increased
ﬂexibility.
For example, a calculator program may allow the user to enter
numeric expressions interactively using the keyboard, and immediately display
the value of such expressions on the screen.
At ﬁrst sight, modelling interactive programs as pure functions may seem
infeasible, because such programs by their very nature require the side eﬀects
of taking additional input and producing additional output while the pro-
gram is running. For example, what is an appropriate type for the calculator
program described above as a pure function from arguments to results?
105

106
CHAPTER 9. INTERACTIVE PROGRAMS
Over the years there have been many proposed solutions to the problem
of combining the notion of pure functions with that of side eﬀects. In the
remainder of this chapter we present the solution that is adopted in Haskell,
which is based upon the use of a new type in conjunction with a small number
of primitives. As we shall see, this approach shares much in common with the
approach to parsers presented in the previous chapter.
9.2
The input/output type
In Haskell, an interactive program is viewed as a pure function that takes the
current "state of the world" as its argument, and produces a modiﬁed world
as its result, in which the modiﬁed world reﬂects any side eﬀects performed
by the program. Hence, given a suitable type World whose values represent
the current state of the world, the notion of an interactive program can be
represented by a function of type World →World, which we abbreviate as
IO (short for "Input/Output") as follows:
type IO
=
World →World
In general, however, an interactive program may return a result value in addi-
tion to performing side eﬀects. For example, a program for reading a character
from the keyboard may return the character that was read. For this reason,
we generalise our type for interactive programs to also return a result value,
with the type of such values being a parameter of the IO type:
type IO a
=
World →(a, World)
Expressions of type IO a are called actions. For example, IO Char is the
type of actions that return a character, while IO () is the type of actions that
return the empty tuple () as a dummy result value. Actions of the latter type
can be thought of as purely side eﬀecting actions that return no result value,
and are frequently used when writing interactive programs.
In addition to returning a result value, interactive programs may also re-
quire argument values. However, there is no need to generalise the type of ac-
tions to take account of this, because this behaviour can already be achieved by
exploiting currying. For example, an interactive program that takes a charac-
ter and returns an integer would have type Char →IO Int, which abbreviates
the curried function type Char →World →(Int, World).
At this point the reader may, quite understandably, be concerned about
the feasibility of passing around the entire state of the world when program-
ming with actions. In reality, Haskell systems such as Hugs implement actions
in a more eﬃcient manner than describe above, but for the purposes of un-
derstanding the behaviour of actions, this abstract view will suﬃce.

9.3. BASIC ACTIONS
107
9.3
Basic actions
We now introduce three basic actions for building interactive programs. First
of all, the action getChar reads a character from the keyboard, echoes it to
the screen, and returns the character as its result value:
getChar
::
IO Char
getChar
=
· · ·
The actual deﬁnition for getChar is built-in to the Hugs system, and cannot
be deﬁned within Haskell itself. If there are no characters waiting to be read
from the keyboard, getChar waits until one is typed.
The dual action, putChar c, writes the character c to the screen, and
returns no result value, represented by the empty tuple:
putChar
::
Char →IO ()
putChar c
=
· · ·
Our ﬁnal basic action is return v, which simply returns the result value v
without performing any interaction:
return
::
a →IO a
return v
=
λworld →(v, world)
The function return provides a bridge from the setting of pure expressions
without side eﬀects to that of impure actions with side eﬀects.
Crucially,
however, there is no bridge back — once we are impure we are impure for
ever, with no possibility for redemption! As a result, one may suspect that
impurity quickly permeates entire programs, but in practice this is usually not
the case. For most Haskell programs, the vast majority of functions do not
involve interaction, with this being handled by a relatively small number of
interactive functions at the outermost level.
We conclude this section by noting that evaluating an action using Hugs
performs its side eﬀects, and discards the result value produced by the action.
For example, evaluating putChar 'a' writes the character 'a' to the screen,
discards the result value from this action, and then terminates:
> putChar 'a'
'a'
9.4
Sequencing
As with parsers, the natural way of combining two actions is to perform one
after the other in sequence, with the modiﬁed world returned by the ﬁrst
action becoming the current world for the second, by means of a sequencing

108
CHAPTER 9. INTERACTIVE PROGRAMS
operator >>= (read as "then") deﬁned as follows:
(>>=)
::
IO a →(a →IO b) →IO b
f >>= g
=
λworld →case f world of
(v, world′) →g v world′
That is, we apply the action f to the current world, then apply the function
g to the result value to give a second action, which is then applied to the
modiﬁed world to give the ﬁnal result. In practice, however, as with parsers
in the previous chapter, the do notation is normally used to express actions
deﬁned using >>= in a more appealing form.
For example, using the do notation the primitive getChar can be decom-
posed into its three component parts of reading a character from the keyboard,
echoing it to the screen, and returning the character as the result:
getChar
::
IO Char
getChar
=
do x ←getCh
putChar x
return x
The action getCh that reads a character without echoing is not part of the
standard prelude, but is provided as an extension by Hugs and can be made
available in any script by including the following special line:
primitive getCh :: IO Char
9.5
Derived primitives
Using the three basic actions together with sequencing, we can now deﬁne
a number of other useful action primitives. First of all, we deﬁne an action
getLine that reads a string of characters from the keyboard:
getLine
::
IO String
getLine
=
do x ←getChar
if x == '\n' then
return [ ]
else
do xs ←getLine
return (x : xs)
(The symbol '\n' represents a newline character.) Dually, we deﬁne actions
putStr and putStrLn that write a string to the screen, with the latter action

9.5. DERIVED PRIMITIVES
109
also moving onto a new line afterwards:
putStr
::
String →IO ()
putStr [ ]
=
return ()
putStr (x : xs)
=
do putChar x
putStr xs
putStrLn
::
String →IO ()
putStrLn xs
=
do putStr xs
putChar '\n'
For example, using these primitives we can now deﬁne an action that prompts
for a string to be entered from the keyboard, and then displays its length:
strlen
::
IO ()
strlen
=
do putStr "Enter␣a␣string:␣"
xs ←getLine
putStr "The␣string␣has␣"
putStr (show (length xs))
putStrLn "␣characters"
For example:
> strlen
Enter a string : abcde
The string has 5 characters
In addition to the library primitives deﬁned above, for the purposes of
examples in the remainder of this chapter it is also useful to deﬁne a number
of other primitives. First of all, we deﬁne actions that sound a beep and clear
the screen, by displaying the appropriate control characters:
beep
::
IO ()
beep
=
putStr "\BEL"
cls
::
IO ()
cls
=
putStr "\ESC[2J"
By convention, the position of each character on the screen is given by
a pair (x, y) of positive integers, with (1, 1) being the top-left corner. The
notion of such a position can be represented by the following type:
type Pos
=
(Int, Int)
Using the appropriate control characters, we can now deﬁne a function that
moves the cursor to a given position, where the cursor is a marker that indi-
cates where the next character displayed will appear:
goto
::
Pos →IO ()
goto (x, y)
=
putStr ("\ESC[" ++ show y ++ ";" ++ show x ++ "H")

110
CHAPTER 9. INTERACTIVE PROGRAMS
In turn, we deﬁne a function that displays a string at a given position:
writeat
::
Pos →String →IO ()
writeat p xs
=
do goto p
putStr xs
Finally, we deﬁne a function seqn that performs a list of actions in sequence,
discarding their result values and returning no result:
seqn
::
[IO a ] →IO ()
seqn [ ]
=
return ()
seqn (a : as)
=
do a
seqn as
For example, using seqn and a list comprehension, the above deﬁnition for
putStr can be rewritten more compactly as follows:
putStr xs
=
seqn [putChar x | x ←xs ]
9.6
Calculator
At the end of the previous chapter we developed a parser for arithmetic ex-
pressions. We now extend this example to produce a simple calculator, which
allows the user to enter arithmetic expressions interactively using the key-
board, and displays the value of such expressions on the screen.
Our calculator will handle expressions built up from integers using addi-
tion, subtraction, multiplication, division and parentheses. As the subject of
this chapter is interactive programs, we do not concern ourselves the details
of parsing and evaluating expressions, assuming that we are given a suitable
parser expr :: Parser Int for this purpose. Such a parser can be obtained by
solving some of the exercises from the previous chapter.
We begin by considering the user interface of the calculator. First of all,
we deﬁne the box of the calculator as a list of strings:
box
::
[String ]
box
=
["+---------------+",
"|␣␣␣␣␣␣␣␣␣␣␣␣␣␣␣|",
"+---+---+---+---+",
"|␣q␣|␣c␣|␣d␣|␣=␣|",
"+---+---+---+---+",
"|␣1␣|␣2␣|␣3␣|␣+␣|",
"+---+---+---+---+",
"|␣4␣|␣5␣|␣6␣|␣-␣|",
"+---+---+---+---+",
"|␣7␣|␣8␣|␣9␣|␣*␣|",
"+---+---+---+---+",
"|␣0␣|␣(␣|␣)␣|␣/␣|",
"+---+---+---+---+"]

9.6. CALCULATOR
111
The ﬁrst four buttons on the calculator, q, c, d, and =, allow the user to quit,
clear the display, delete a character, and evaluate an expression, while the
remaining sixteen buttons allow the user to enter expressions.
We also deﬁne the buttons on the calculator as a list of characters, compris-
ing both the twenty standard buttons that appear on the box itself, together
with a number of extra characters that will be allowed for ﬂexibility, namely
Q, C, D, space, escape, backspace, delete and newline:
buttons
::
[Char ]
buttons
=
standard ++ extra
where
standard = "qcd=123+456-789*0()/"
extra = "QCD␣\ESC\BS\DEL\n"
Using a list comprehension, we can deﬁne an action that displays the cal-
culator box in the top-left corner of the screen:
showbox
::
IO ()
showbox
=
seqn [writeat (1, y) xs | (y, xs) ←zip [1 . . 13] box ]
The last part of the user interface is to deﬁne a function that shows a
string in the display of the calculator, by ﬁrst clearing the display and then
showing the last thirteen characters of the string. In this manner, if the user
deletes characters from the string they will automatically be removed from the
display, and if the user types more than thirteen characters, the display will
appear to scroll to the left as additional characters are typed.
display
::
String →IO ()
display xs
=
do writeat (3, 2) "␣␣␣␣␣␣␣␣␣␣␣␣␣"
writeat (3, 2) (reverse (take 13 (reverse xs)))
The calculator itself is controlled by a function calc that displays the cur-
rent string, and then reads a character from the keyboard without echoing it.
If this character is a valid button then it is processed, otherwise we sound a
beep to indicate an error and continue with the same string:
calc
::
String →IO ()
calc xs
=
do display xs
c ←getCh
if elem c buttons then
process c xs
else
do beep
calc xs
The function process takes a valid character and the current string, and per-

112
CHAPTER 9. INTERACTIVE PROGRAMS
forms the appropriate action depending upon the character:
process
::
Char →String →IO ()
process c xs
| elem c "qQ\ESC"
=
quit
| elem c "dD\BS\DEL"
=
delete xs
| elem c "=\n"
=
eval xs
| elem c "cC"
=
clear
| otherwise
=
press c xs
We now consider each of the ﬁve possible actions in turn.
• Quitting moves the cursor below the calculator box and terminates:
quit
::
IO ()
quit
=
goto (1, 14)
• Deleting has no eﬀect if the current string is empty, and otherwise re-
moves the last character from this string:
delete
::
String →IO ()
delete ""
=
calc ""
delete xs
=
calc (init xs)
• Evaluation displays the result of parsing and evaluating the current
string, sounding a beep if this process is unsuccessful:
eval
::
String →IO ()
eval xs
=
case parse expr xs of
[(n, "")] →calc (show n)
→do beep
calc xs
• Clearing the display resets the current string to empty:
clear
::
IO ()
clear
=
calc ""
• Any other character is appended to the end of the current string:
press
::
Char →String →IO ()
press c xs
=
calc (xs ++ [c])
Finally, we deﬁne a function that runs the calculator, by clearing the screen,
displaying the box, and starting with an empty display:
run
::
IO ()
run
=
do cls
showbox
clear

9.7. GAME OF LIFE
113
9.7
Game of life
The game of life is a simple example of an evolutionary system, played on a
two-dimensional board. Each square on the board is either empty, or contains
a single living cell, as shown in the following example:
◦
◦
◦
◦
◦
Each internal square on the board has eight immediate neighbours:












For uniformity, each square on the edge of the board is also viewed as hav-
ing eight neighbours, by assuming that the board wraps around from top-to-
bottom and from left-to-right. That is, we can think of the board as really
being a torus, a three-dimensional doughnut shaped object.
Given an initial conﬁguration of the board, the next generation is given
by simultaneously applying the following rules to all squares:
• A living cell survives if it has precisely two or three neighbouring squares
that contain living cells, and dies (becomes empty) otherwise;
• An empty square gives birth to a living cell if it has precisely three
neighbours that contain living cells, and remains empty otherwise.
For example, applying these rules to the above board gives:
◦
◦
◦
◦
◦
By repeating this procedure with the new board, an inﬁnite sequence of gen-
erations can be produced. By careful design of the initial conﬁguration, all
sorts of interesting patterns of behaviour can be observed in this sequence. For
example, the above arrangement of cells is called a glider, and over successive
generations will move diagonally down the board.
Despite its simplicity, the game of life is in fact computationally complete,
in the sense that any computational process can be simulated within it by
means of a suitable encoding. In the remainder of this section we show how
the game of life can be implemented in Haskell.

114
CHAPTER 9. INTERACTIVE PROGRAMS
To allow the size of the board to be easily modiﬁed, we deﬁne two integer
values that determine the width and height of the board in squares:
width
::
Int
width
=
5
height
::
Int
height
=
5
We represent a board as a list of the (x, y) positions at which there is a
living cell, using the same coordinate convention as the screen:
type Board
=
[Pos ]
For example, the initial example board above would be represented by:
glider
::
Board
glider
=
[(4, 2), (2, 3), (4, 3), (3, 4), (4, 4)]
Using this representation of a board, it is easy to display the living cells
on the screen, and to decide if a given position is alive or empty:
showcells
::
Board →IO ()
showcells b
=
seqn [writeat p "O" | p ←b]
isAlive
::
Board →Pos →Bool
isAlive b p
=
elem p b
isEmpty
::
Board →Pos →Bool
isEmpty b p
=
¬ (isAlive b p)
Next, we deﬁne a function that returns the neighbours of a position:
neighbs
::
Pos →[Pos ]
neighbs (x, y)
=
map wrap [(x −1, y −1), (x, y −1),
(x + 1, y −1), (x −1, y),
(x + 1, y), (x −1, y + 1),
(x, y + 1), (x + 1, y + 1)]
The auxiliary function wrap takes account of the wrapping around at the edges
of the board, by subtracting one from each component of the given position,
taking the remainder when divided by the width and height of the board, and
then adding one to each component again:
wrap
::
Pos →Pos
wrap (x, y)
=
(((x −1) 'mod' width) + 1,
((y −1) 'mod' height) + 1)
Using function composition, we can now deﬁne a function that calculates
the number of live neighbours for a given position by producing the list of its
neighbours, retaining those that are alive, and counting their number:
liveneighbs
::
Board →Pos →Int
liveneighbs b
=
length ◦ﬁlter (isAlive b) ◦neighbs

9.7. GAME OF LIFE
115
Using this function, it is then straightforward to produce the list of living
positions in a board that have precisely two or three living neighbours, and
hence survive to the next generation:
survivors
::
Board →[Pos ]
survivors b
=
[p | p ←b, elem (liveneighbs b p) [2, 3]]
In turn, the list of empty positions in a board that have precisely three living
neighbours, and hence give birth to a new cell, can be produced as follows:
births
::
Board →[Pos ]
births b
=
[(x, y) | x ←[1 . . width ],
y ←[1 . . height ],
isEmpty b (x, y),
liveneighbs b (x, y) == 3]
However, this deﬁnition considers every possible position on the board. A
more reﬁned approach, which may be more eﬃcient for larger boards, is to
only consider the neighbours of living cells on the board, because only such
positions can potentially give rise to new births. Using this approach, the
function births can be rewritten as follows:
births b
=
[p | p ←rmdups (concat (map neighbs b)),
isEmpty b p,
liveneighbs b p == 3]
The auxiliary function rmdups removes duplicates from a list, and is used
above to ensure that each potential new cell is only considered once:
rmdups
::
Eq a ⇒[a ] →[a ]
rmdups [ ]
=
[ ]
rmdups (x : xs)
=
x : rmdups (ﬁlter (̸= x) xs)
The next generation of a board can now be produced simply by appending
the list of survivors and the list of new births:
nextgen
::
Board →Board
nextgen b
=
survivors b ++ births b
Finally, we deﬁne a function life that implements the game of life itself, by
clearing the screen, showing the living cells in the current board, waiting for
a moment, and then continuing with the next generation:
life
::
Board →IO ()
life b
=
do cls
showcells b
wait 5000
life (nextgen b)

116
CHAPTER 9. INTERACTIVE PROGRAMS
The function wait is used to slow down the game to a reasonable speed, and
can be implemented by performing a given number of dummy actions:
wait
::
Int →IO ()
wait n
=
seqn [return () |
←[1 . . n ]]
For fun, you may like to try out the life function with the glider example, and
experiment with some patterns of your own.
9.8
Chapter remarks
The use of the IO type to perform other forms of side eﬀects, including reading
and writing from ﬁles, and handling exceptional events, is discussed in the
Haskell Report [26]. A formal meaning for input/output and other forms of
side eﬀects is given in [25].
A variety of libraries for performing graphical
interaction are available from the Haskell home page, www.haskell.org. The
game of life was invented by John Conway, and popularised by Martin Gardner
in the October 1970 edition of Scientiﬁc American.
9.9
Exercises
1. Deﬁne an action readLine :: IO String that behaves in the same way as
getLine, except that it also permits the delete key to be used to remove
characters. Hint: the delete character is '\DEL', and the control string
for moving the cursor back one character is "\ESC[1D".
2. Modify the calculator program to indicate the approximate position of
an error rather than just sounding a beep, by using the fact that the
parser returns the unconsumed part of the input string.
3. One some systems the game of life may ﬂicker, due to the entire screen
being cleared each generation. Modify the game to avoid such ﬂicker by
only redisplaying positions whose status changes.
4. Produce an editor that allows the user to interactively create and modify
the content of the board in the game of life.
5. Produce graphical versions of the calculator and game of life programs,
using one of the graphics libraries available from www.haskell.org.
6. Nim is a game that is played on a board comprising ﬁve numbered rows
of stars, which is initially set up as follows:
1 : ∗∗∗∗∗
2 : ∗∗∗∗
3 : ∗∗∗
4 : ∗∗
5 : ∗

9.9. EXERCISES
117
Two players take it in turn to remove one or more stars from the end of
a single row. The winner is the player who removes the last star or stars
from the board. Implement the game of nim in Haskell. Hint: represent
the board as a list comprising the number of stars remaining on each
row, with the initial board being [5, 4, 3, 2, 1].

118
CHAPTER 9. INTERACTIVE PROGRAMS

Chapter 10
Declaring Types and Classes
In this chapter we introduce mechanisms for declaring new types and classes
in Haskell. We start with two approaches to declaring types, then consider
recursive types, develop a tautology checker and an abstract machine, and
conclude by showing how to declare classes and their instances.
10.1
Type declarations
The simplest way of declaring a new type is to introduce a new name for
an existing type, using the type mechanism of Haskell.
For example, the
following declaration from the standard library states that the type String is
just a synonym for the type [Char ] of lists of characters:
type String
=
[Char ]
As in this example, the name of a new type must begin with a capital letter.
Type declarations can be nested, in the sense that one such type can be de-
clared in terms of another. For example, in the previous chapter a type for
boards was declared in terms of a type for positions:
type Board
=
[Pos ]
type Pos
=
(Int, Int)
For technical reasons, however, type declarations cannot be recursive.
For
example, consider the following erroneous declaration:
type Tree
=
(Int, [Tree ])
That is, a tree is a pair comprising an integer and a list of subtrees. While
this declaration is perfectly reasonable, with the empty list of subtrees forming
the base case for the recursion, it is not permitted in Haskell because it is
recursive. If required, recursive types can be declared using the more powerful
data mechanism, which will be introduced shortly.
119

120
CHAPTER 10. DECLARING TYPES AND CLASSES
Type declarations can also be parameterised by other types. For example,
in the previous two chapters we declared the following types for parsers and
interactive programs in terms of a type parameter:
type Parser a
=
String →[(a, String)]
type IO a
=
World →(a, World)
Declarations with more than one type parameter are also permitted.
For
example, a type of lookup tables that associate keys of one type to values of
another type can be declared as a list of (key,value) pairs:
type Assoc k v
=
[(k, v)]
Using this type, a function that returns the ﬁrst value that is associated with
a given key in a table can then be deﬁned as follows:
ﬁnd
::
Eq k ⇒k →Assoc k v →v
ﬁnd k t
=
head [v | (k ′, v) ←t, k == k ′]
10.2
Data declarations
A completely new type, as opposed to a synonym for an existing type, can be
declared by specifying its values using the data mechanism of Haskell. For
example, the following declaration from the standard library states that the
type Bool comprises two new values, named False and True:
data Bool
=
False | True
In such declarations, the symbol | is read as "or", and the new values of the
type are called its constructors. As with new types themselves, the names
of new constructors must begin with a capital letter.
Moreover, the same
constructor name cannot be used in more than one type.
Note that the names given to new types and constructors have no inherent
meaning to the Hugs system. For example, the above declaration could equally
well be written as data A = B | C, because the precise details of the names
are not relevant, other than the fact that they haven't been use before. The
meaning of names such as Bool, False and True is assigned by the programmer,
via the functions that they deﬁne on new types.
Values of new types can be used in precisely the same way as those of built-
in types. In particular, they can freely be passed as arguments to functions,
returned as results from functions, stored in data structures such as lists, and
used in patterns. For example, given the declaration
data Move
=
Left | Right | Up | Down
functions that apply a move to a position (recalling that positions are relative
to the top-left corner of the screen), apply a list of moves to a position, and

10.2.
DATA DECLARATIONS
121
ﬂip the direction of a move, can be deﬁned as follows:
move
::
Move →Pos →Pos
move Left (x, y)
=
(x −1, y)
move Right (x, y)
=
(x + 1, y)
move Up (x, y)
=
(x, y −1)
move Down (x, y)
=
(x, y + 1)
moves
::
[Move ] →Pos →Pos
moves [ ] p
=
p
moves (m : ms) p
=
moves ms (move m p)
ﬂip
::
Move →Move
ﬂip Left
=
Right
ﬂip Right
=
Left
ﬂip Up
=
Down
ﬂip Down
=
Up
The constructors in a data declaration can also have arguments. For exam-
ple, a type of shapes that comprise circles with a given radius and rectangles
with given dimensions can be declared by:
data Shape
=
Circle Float | Rect Float Float
That is, the type Shape has values of the form Circle r, where r is a ﬂoating-
point number, and Rect x y, where x and y are ﬂoating-point numbers. These
constructors can then be used to deﬁne functions on shapes, such as to produce
a square of a given size, and to calculate the area of a shape:
square
::
Float →Shape
square n
=
Rect n n
area
::
Shape →Float
area (Circle r)
=
pi ∗r ↑2
area (Rect x y)
=
x ∗y
Because of their use of arguments, the constructors Circle and Rect are
actually constructor functions, which produce results of type Shape from ar-
guments of type Float, as can be demonstrated using Hugs:
> :type Circle
Circle :: Float →Shape
> :type Rect
Rect :: Float →Float →Shape
The diﬀerence between normal functions and constructor functions is that the
latter have no deﬁning equations, and exist solely for the purpose of building
pieces of data. For example, whereas the expression negate 1.0 can be evalu-
ated to −1.0 by applying the deﬁnition of negate, the expression Circle 1.0 is

122
CHAPTER 10. DECLARING TYPES AND CLASSES
already fully evaluated, and hence cannot be further simpliﬁed, because there
are no deﬁning equations for Circle. Rather, the expression Circle 1.0 is just
a piece of data, in the same way that 1.0 itself is just data.
Not surprisingly, data declarations themselves can also be parameterised.
For example, the standard library declares the following type:
data Maybe a
=
Nothing | Just a
That is, a value of type Maybe a is either Nothing, or of the form Just x for
some value x of type a. We can think of values of type Maybe a as being
values of type a that may fail, with Nothing representing failure, and Just
representing success. For example, using this type we can deﬁne safe versions
of the library functions div and head, which return Nothing in the case of
invalid arguments, rather than producing an error:
safediv
::
Int →Int →Maybe Int
safediv
0
=
Nothing
safediv m n
=
Just (m 'div' n)
safehead
::
[a ] →Maybe a
safehead [ ]
=
Nothing
safehead xs
=
Just (head xs)
10.3
Recursive types
Types declared using the data mechanism can also be recursive. By way of a
simple ﬁrst example, consider the following recursive type:
data Nat = Zero | Succ Nat
That is, a value of type Nat is either Zero, or of the form Succ n for some
value n of type Nat. Hence, this declaration gives rise to an inﬁnite sequence
of values, starting with the value Zero, and continuing by applying the con-
structor function Succ to the previous value in the sequence:
Zero
Succ Zero
Succ (Succ Zero)
Succ (Succ (Succ Zero))
...
As suggested by the choice of names, values of type Nat can be thought of
as natural numbers (non-negative integers), with Zero representing the natural
number 0, and Succ representing the successor function 1+ on such numbers.
For example, Succ (Succ (Succ Zero)) represents 1 + (1 + (1 + 0)) = 3. More

10.3.
RECURSIVE TYPES
123
formally, we can deﬁne the following conversion functions:
nat2int
::
Nat →Int
nat2int Zero
=
0
nat2int (Succ n)
=
1 + nat2int n
int2nat
::
Int →Nat
int2nat 0
=
Zero
int2nat (n + 1)
=
Succ (int2nat n)
For example, using these functions two natural numbers can be added to-
gether by ﬁrst converting them into integers, adding these integers, and then
converting the result back into a natural number:
add
::
Nat →Nat →Nat
add m n
=
int2nat (nat2int m + nat2int n)
However, using recursion the function add can be redeﬁned without the need
for such conversions, and hence more eﬃciently:
add Zero n
=
n
add (Succ m) n
=
Succ (add m n)
This deﬁnition formalises the idea that two natural numbers can be added
by copying Succ constructors from the ﬁrst number until they are exhausted,
at which point the Zero at the end is replaced by the second number. For
example, showing that 2 + 1 = 3 proceeds as follows:
add (Succ (Succ Zero)) (Succ Zero)
=
{ applying add }
Succ (add (Succ Zero) (Succ Zero))
=
{ applying add }
Succ (Succ (add Zero (Succ Zero)))
=
{ applying add }
Succ (Succ (Succ Zero))
As another example, the data mechanism can be used to declare our own
version of the built-in type of lists, parameterised by an arbitrary type:
data List a
=
Nil | Cons a (List a)
That is, a value of type List a is either Nil, representing the empty list, or
of the form Cons x xs for some values x :: a and xs :: List a, representing a
non-empty list. Using this type, we can then also deﬁne our own versions of
library functions on lists, such as to calculate the length of a list:
len
::
List a →Int
len Nil
=
0
len (Cons
xs)
=
1 + len xs

124
CHAPTER 10. DECLARING TYPES AND CLASSES
While lists are perhaps the most commonly used data structure in com-
puting, it is often useful to store data in a two-way branching structure, or
binary tree, as depicted in the following example:
5







3


7


1
4
6
9
In this example, the numbers 1, 4, 6, 9 appear at the external leaves of the
tree, and the numbers 5, 3, 7 appear at the internal nodes. Using recursion, a
suitable type for representing such trees can be declared by:
data Tree
=
Leaf Int | Node Tree Int Tree
For simplicity, we have ﬁxed the type of the values to integers, but this could
easily be generalised by parameterising the declaration. Using this type, the
tree pictured above can be represented as follows:
t
::
Tree
t
=
Node (Node (Leaf 1) 3 (Leaf 4)) 5 (Node (Leaf 6) 7 (Leaf 9))
We now consider a number of functions on such trees.
First of all, we
deﬁne a function that decides if a given integer occurs in a tree:
occurs
::
Int →Tree →Bool
occurs m (Leaf n)
=
m == n
occurs m (Node l n r)
=
m == n ∨occurs m l ∨occurs m r
That is, an integer occurs in a leaf if it matches the value at the leaf, and
occurs in a node if it either matches the value at the node, occurs in the left
subtree, or occurs in the right subtree. Note that under lazy evaluation, if
either of the ﬁrst two conditions in the node case is True, then the result True
is returned without the need to evaluate the remaining conditions.
In the worst case, however, the function occurs may still traverse the entire
tree, in particular when the given integer does not occur in the tree. Now
consider a function that ﬂattens a tree to a list:
ﬂatten
::
Tree →[Int ]
ﬂatten (Leaf n)
=
[n ]
ﬂatten (Node l n r)
=
ﬂatten l ++ [n ] ++ ﬂatten r
If applying this function results in a sorted list, then the tree itself is called a
search tree. For instance, our example tree is a search tree, because:
ﬂatten t
=
[1, 3, 4, 5, 6, 7, 9]

10.4.
TAUTOLOGY CHECKER
125
Search trees have the important property that, when trying to decide if a given
integer occurs in a tree, which of the two subtrees of a node it may occur in
can always be determined. In particular, if the integer is less than the value
at the node, then it can only occur in the left subtree, and if it is greater than
this value, it can only occur in the right subtree. Hence, for search trees the
occurs function can be rewritten as follows:
occurs m (Leaf n)
=
m == n
occurs m (Node l n r)
| m == n
=
True
| m < n
=
occurs m l
| otherwise
=
occurs m r
This deﬁnition is more eﬃcient than the previous version, because it only
traverses one path down the tree, rather than potentially the entire tree.
We conclude this section by noting that, as in nature, trees in computing
come in many diﬀerent forms. For example, we can declare types for trees
that have data only in their leaves, data only in their nodes, data in both
their leaves and nodes (as above), or have a list of subtrees:
data Tree a
=
Leaf a | Node (Tree a) (Tree a)
data Tree a
=
Leaf | Node (Tree a) a (Tree a)
data Tree a b
=
Leaf a | Node (Tree a b) b (Tree a b)
data Tree a
=
Node a [Tree a ]
Which form of tree is most appropriate depends upon the situation. Note that
in the last example, there is no constructor for leaves, because a node with an
empty list of subtrees can play the role of a leaf.
10.4
Tautology checker
In practice, tree types often occur as a representation of some kind of language.
In this section we present an extended example concerning such a type, by
developing a function that decides if simple logical propositions are always
true. Such propositions are called tautologies.
Consider a language of propositions built up from basic values (False,True)
and variables (A, B, · · · , Z) using negation (¬), conjunction (∧), implication
(⇒) and parentheses. For example, the following are all propositions:
A ∧¬ A
(A ∧B) ⇒A
A ⇒(A ∧B)
(A ∧(A ⇒B)) ⇒B

126
CHAPTER 10. DECLARING TYPES AND CLASSES
The meaning of the logical operators can be deﬁned using truth tables,
which give the resulting value for each combination of argument values:
A
¬ A
F
T
T
F
A
B
A ∧B
F
F
F
F
T
F
T
F
F
T
T
T
A
B
A ⇒B
F
F
T
F
T
T
T
F
F
T
T
T
For example, the truth table for conjunction states that A ∧B returns True if
both A and B are True, and False otherwise. (To save space in such tables, we
abbreviate the basic values by F and T.) Using these deﬁnitions, the truth
table for any proposition can then be constructed. In the case of our four
example propositions, the resulting tables are as follows:
A
A ∧¬ A
F
F
T
F
A
B
(A ∧B) ⇒A
F
F
T
F
T
T
T
F
T
T
T
T
A
B
A ⇒(A ∧B)
F
F
T
F
T
T
T
F
F
T
T
T
A
B
(A ∧(A ⇒B)) ⇒B
F
F
T
F
T
T
T
F
T
T
T
T
These tables show that the second and fourth propositions are tautologies,
because their result value is always True, while the ﬁrst and third are not
tautologies, because their result is False in at least one case.
The ﬁrst step towards deﬁning a function that decides if a proposition is a
tautology is to declare a type for propositions, with one constructor for each
of the ﬁve possible forms that a proposition can have:
data Prop
=
Const Bool
|
Var Char
|
Not Prop
|
And Prop Prop
|
Imply Prop Prop
Note that an explicit constructor for parentheses is not required, as parentheses
within Haskell itself can be used to indicate grouping. For example, the four

10.4.
TAUTOLOGY CHECKER
127
propositions above can be represented as follows:
p1
::
Prop
p1
=
And (Var 'A') (Not (Var 'A'))
p2
::
Prop
p2
=
Imply (And (Var 'A') (Var 'B')) (Var 'A')
p3
::
Prop
p3
=
Imply (Var 'A') (And (Var 'A') (Var 'B'))
p4
::
Prop
p4
=
Imply (And (Var 'A') (Imply (Var 'A') (Var 'B'))) (Var 'B')
In order to evaluate a proposition to a logical value, we need to know the
value of each of its variables. For this purpose, we declare a substitution as a
lookup table that associates variable names to logical values, using the Assoc
type that was introduced at the start of this chapter:
type Subst
=
Assoc Char Bool
For example, the substitution [('A', False), ('B', True)] assigns the variable
A to False, and B to True. A function that evaluates a proposition given a
substitution for its variables can now be deﬁned by pattern matching on the
ﬁve possible forms that the proposition can have:
eval
::
Subst →Prop →Bool
eval
(Const b)
=
b
eval s (Var x)
=
ﬁnd x s
eval s (Not p)
=
¬ (eval s p)
eval s (And p q)
=
eval s p ∧eval s q
eval s (Imply p q)
=
eval s p ⩽eval s q
For example, the value of a constant proposition is simply the constant itself,
the value of a variable is obtained by looking up its value in the substitu-
tion, and the value of a conjunction is given by taking the conjunction of the
values of the two argument propositions. Note that logical implication ⇒is
implemented by the ⩽operator on logical values.
To decide if a proposition is a tautology, we will consider all possible sub-
stitutions for the variables that it contains. First of all, we deﬁne a function
that returns the variables in a proposition:
vars
::
Prop →[Char ]
vars (Const
)
=
[ ]
vars (Var x)
=
[x ]
vars (Not p)
=
vars p
vars (And p q)
=
vars p ++ vars q
vars (Imply p q)
=
vars p ++ vars q
For example, vars p2 = ['A', 'B', 'A'].
Note that this function does not
remove duplicates, which will be done separately later on.

128
CHAPTER 10. DECLARING TYPES AND CLASSES
The key to generating substitutions is generating lists of logical values of a
given length. To this end, we seek to deﬁne a function bools :: Int →[[Bool ]]
which, for example, will return all eight lists of three logical values:
> bools 3
[[False, False, False ],
[False, False, True ],
[False, True, False ],
[False, True, True ],
[True, False, False ],
[True, False, True ],
[True, True, False ],
[True, True, True ]]
The order in which the lists are produced is not important. One way to achieve
this behaviour is to observe that each list corresponds to a binary number,
by interpreting False and True as the binary digits 0 and 1. For example,
the list [True, False, True ] corresponds to the binary number 101. Given this
interpretation, we can think of the function bools as simply counting in binary,
starting from zero and proceeding upwards to the appropriate limit.
This idea leads to the following deﬁnition for bools, in terms of the function
int2bin :: Int →[Bit ] from chapter 7, which converts a non-negative integer
into a binary number represented as a list of bits.
bools
::
Int →[[Bool ]]
bools n
=
map (map conv ◦make n ◦int2bin) [0 . . limit ]
where
limit = (2 ↑n) −1
make n bs = take n (bs ++ repeat 0)
conv 0 = False
conv 1 = True
There is, however, a simpler way to deﬁne bools, which can be revealed
by thinking about the structure of the resulting lists. For example, we can
observe that bools 3 contains two copies of bools 2, the ﬁrst preceded by False
in each case, and the second preceded by True in each case:
False
False
False
False
False
True
False
True
False
False
True
True
True
False
False
True
False
True
True
True
False
True
True
True

10.4.
TAUTOLOGY CHECKER
129
This observation naturally leads to a recursive deﬁnition for bools. In the base
case, bools 0, we return all lists of zero logical values, of which the empty list
is the only one. In the recursive case, bools (n + 1), we take two copies of the
lists produced by bools n, place False in front of each list in the ﬁrst copy,
True in front of each list in the second, and append the results.
bools
::
Int →[[Bool ]]
bools 0
=
[[ ]]
bools (n + 1)
=
map (False:) bss ++ map (True:) bss
where bss = bools n
Using bools, it is now straightforward to deﬁne a function that generates
all substitutions for a proposition by extracting its variables, removing dupli-
cates from this list (using the function rmdups from chapter 9), generating all
possible lists of logical values for this many variables, and then zipping the list
of variables with each of the resulting lists:
substs
::
Prop →[Subst ]
substs p
=
map (zip vs) (bools (length vs))
where vs = rmdups (vars p)
For example:
> substs p2
[[('A', False), ('B', False)],
[('A', False), ('B', True)],
[('A', True), ('B', False)],
[('A', True), ('B', True)]]
Finally, we deﬁne a function that decides if a proposition is a tautology,
by checking if it evaluates to True for all possible substitutions:
isTaut
::
Prop →Bool
isTaut p
=
and [eval s p | s ←substs p]
For example:
> isTaut p1
False
> isTaut p2
True
> isTaut p3
False
> isTaut p4
True

130
CHAPTER 10. DECLARING TYPES AND CLASSES
10.5
Abstract machine
As a second extended example, consider a type of simple arithmetic expressions
built up from integers using an addition operator, together with a function that
evaluates such an expression to an integer value:
data Expr
=
Val Int | Add Expr Expr
value
::
Expr →Int
value (Val n)
=
n
value (Add x y)
=
value x + value y
For example, the expression (2 + 3) + 4 is evaluated as follows:
value (Add (Add (Val 2) (Val 3)) (Val 4))
=
{ applying value }
value (Add (Val 2) (Val 3)) + value (Val 4)
=
{ applying the ﬁrst value }
(value (Val 2) + value (Val 3)) + value (Val 4)
=
{ applying the ﬁrst value }
(2 + value (Val 3)) + value (Val 4)
=
{ applying the ﬁrst value }
(2 + 3) + value (Val 4)
=
{ applying the ﬁrst + }
5 + value (Val 4)
=
{ applying value }
5 + 4
=
{ applying + }
9
Note that the deﬁnition of the value function does not specify that the left ar-
gument of an addition should be evaluated before the right, or more generally,
what the next step of evaluation should be at any point. Rather, the order of
evaluation is determined by Haskell. If desired, however, such control infor-
mation can be made explicit by deﬁning an abstract machine for expressions,
which speciﬁes the step-by-step process of their evaluation.
To this end, we ﬁrst declare a type of control stacks for the abstract ma-
chine, which comprise a list of operations to be performed by the machine
after the current evaluation has been completed:
type Cont
=
[Op]
data Op
=
EVAL Expr | ADD Int
The meaning of the two operations will be explained shortly. We now deﬁne
a function that evaluates an expression in the context of a control stack:
eval
::
Expr →Cont →Int
eval (Val n) c
=
exec c n
eval (Add x y) c
=
eval x (EVAL y : c)

10.5.
ABSTRACT MACHINE
131
That is, if the expression is an integer it is already fully evaluated, and we
begin executing the control stack. If the expression is an addition, we evaluate
the ﬁrst argument, x, placing the operation EVAL y on top of the control stack
to indicate that the second argument, y, should be evaluated once that of the
ﬁrst argument is completed. In turn, we deﬁne the function that executes a
control stack in the context of an integer argument:
exec
::
Cont →Int →Int
exec [ ] n
=
n
exec (EVAL y : c) n
=
eval y (ADD n : c)
exec (ADD n : c) m
=
exec c (n + m)
That is, if the stack is empty, we return the integer argument as the result of
the execution. If the top of the stack is an operation EVAL y, we evaluate the
expression y, placing the instruction ADD n on top of the remaining stack to
indicate that the current integer argument, n, should be added together with
the result of evaluating y once this is completed. And ﬁnally, if the top of the
stack is an operation ADD n, evaluation of the two arguments of an addition
is now complete, and we execute the remaining control stack in the context of
the sum of the two resulting integer values.
Finally, we deﬁne a function that evaluates an expression to an integer, by
invoking eval with the given expression and the empty control stack:
value
::
Expr →Int
value e
=
eval e [ ]
The fact that our abstract machine uses two mutually recursive functions, eval
and exec, reﬂects the fact that it has two states, depending upon whether it
is being driven by the structure of the expression or the control stack. To
illustrate the machine, here is how it evaluates (2 + 3) + 4:
value (Add (Add (Val 2) (Val 3)) (Val 4))
=
{ applying value }
eval (Add (Add (Val 2) (Val 3)) (Val 4)) [ ]
=
{ applying eval }
eval (Add (Val 2) (Val 3)) [EVAL (Val 4)]
=
{ applying eval }
eval (Val 2) [EVAL (Val 3), EVAL (Val 4)]
=
{ applying eval }
exec [EVAL (Val 3), EVAL (Val 4)] 2
=
{ applying exec }
eval (Val 3) [ADD 2, EVAL (Val 4)]
=
{ applying eval }
exec [ADD 2, EVAL (Val 4)] 3
=
{ applying exec }
exec [EVAL (Val 4)] 5
=
{ applying exec }

132
CHAPTER 10. DECLARING TYPES AND CLASSES
eval (Val 4) [ADD 5]
=
{ applying eval }
exec [ADD 5] 4
=
{ applying exec }
exec [ ] 9
=
{ applying exec }
9
Note how eval proceeds downwards to the leftmost integer in the expression,
maintaining a trail of the pending right-hand expressions on the control stack.
In turn, exec then proceeds upwards through the trail, transferring control
back to eval and performing additions as appropriate.
10.6
Class and instance declarations
We now turn our attention from types to classes. In Haskell, a new class can
be declared using the class mechanism. For example, the class Eq of equality
types is declared in the standard library as follows:
class Eq a where
(==), (̸=)
::
a →a →Bool
x ̸= y
=
¬ (x == y)
This declaration states that for a type a to be an instance of the class Eq,
it must support equality and inequality operators of the speciﬁed types. In
fact, because a default deﬁnition has already been included for ̸=, declaring
an instance of this class only requires a deﬁnition for ==. For example, the
type Bool can be made into an equality type as follows:
instance Eq Bool where
False == False
=
True
True == True
=
True
==
=
False
For technical reasons, only types declared using the data mechanism can
be made into instances of classes. Note also that default deﬁnitions can be
overridden in instance declarations if desired. For example, for some equality
types there may be a more eﬃcient or appropriate way to decide if two values
are diﬀerent than simply checking if they are not equal.
Classes can also be extended to form new classes. For example, the class
Ord of types whose values are totally ordered is declared in the standard

10.6.
CLASS AND INSTANCE DECLARATIONS
133
library as an extension of the class Eq as follows:
class Eq a ⇒Ord a where
(<), (⩽), (>), (⩾)
::
a →a →Bool
min, max
::
a →a →a
min x y | x ⩽y
=
x
| otherwise
=
y
max x y | x ⩽y
=
y
| otherwise
=
x
That is, for a type to be an instance of Ord it must be an instance of Eq, and
support six additional operators.
Because default deﬁnitions have already
been included for min and max, declaring an equality type (such as Bool) as
an ordered type only requires deﬁning the four comparison operators:
instance Ord Bool where
False < True
=
True
<
=
False
b ⩽c
=
(b < c) ∨(b == c)
b > c
=
c < b
b ⩾c
=
c ⩽b
Derived instances
When new types are declared, it is usually appropriate to make them into
instances of a number of built-in classes. Haskell provides a simple facility for
automatically making new types into instances of the classes Eq, Ord, Show
and Read, in the form of the deriving mechanism. For example, the type
Bool is actually declared in the standard library as follows:
data Bool
=
False | True
deriving (Eq, Ord, Show, Read)
As a result, all the member functions from the four derived classes can then
be used with logical values. For example:
> False == False
True
> False < True
True
> show False
"False"
> read "False" :: Bool
False

134
CHAPTER 10. DECLARING TYPES AND CLASSES
The use of :: in the last example is required to resolve the type of the result,
which in this case cannot be inferred from the context.
Note that for the
purposes of deriving instances of the class Ord of ordered types, the ordering
on the constructors of a type is determined by their position in its declaration.
Hence, the above declaration for the type Bool, in which False appears before
True, results in the ordering False < True.
In the case of constructors with arguments, the types of these arguments
must also be instances of any derived classes. For example, recall the following
declarations from earlier in this chapter:
data Shape
=
Circle Float | Rect Float Float
data Maybe a
=
Nothing | Just a
To derive Shape as an equality type requires that the type Float is also an
equality type, which is indeed the case. Similarly, to derive Maybe a as an
equality type requires that the type a is also such a type, which then becomes
a class constraint on this parameter. In the same manner as lists and tuples,
values built using constructors with arguments are ordered lexicographically.
For example, if Shape is derived as an ordered type, then we have:
> Rect 1.0 4.0 < Rect 2.0 3.0
True
> Rent 1.0 4.0 < Rect 1.0 3.0
False
Monadic types
We conclude this chapter by returning once again to parsers and interactive
programs, the subjects of the previous two chapters. As the reader may recall,
the functions return and >>= were deﬁned for both parsers,
return
::
a →Parser a
(>>=)
::
Parser a →(a →Parser b) →Parser b
and interactive programs:
return
::
a →IO a
(>>=)
::
IO a →(a →IO b) →IO b
The use of the same function names and analagous types is not coincidental.
In particular, generalising from the speciﬁc cases of Parser and IO to an
arbitrary parameterised type gives the notion of a monad, which in Haskell is
captured by the following class declaration:
class Monad m where
return
::
a →m a
(>>=)
::
m a →(a →m b) →m b

10.7.
CHAPTER REMARKS
135
That is, a monad is a parameterised type m that supports return and >>=
functions of the speciﬁed types. The fact that m must be a parameterised
type, rather than just a type, is inferred from its use in the types for the
two functions. Using this declaration, parsers and interactive programs can
then be made into instances of the class of monadic types, by deﬁning the two
member functions in the appropriate manner:
instance Monad Parser where
return v
=
· · ·
p >>= f
=
· · ·
instance Monad IO where
return v
=
· · ·
f >>= g
=
· · ·
It is because of these declarations that the do notation can be used to sequence
parsers and interactive programs. More generally, Haskell supports the use of
this notation with any monadic type, allowing expressions of the form
e1 >>= λv1 →
e2 >>= λv2 →
...
en >>= λvn →
return (f v1 v2 ... vn)
to be written as:
do v1 ←e1
v2 ←e2
...
vn ←en
return (f v1 v2 ... vn)
10.7
Chapter remarks
The abstract machine example is derived from [20], and the type of control
stacks used in this example is a special case of the zipper data structure for
traversing values of recursive types [12]. The term monad comes from a branch
of mathematics known as category theory [24].
For further details on the
theory and application of monads in functional programming, see [32, 25]. As
well as the basic mechanisms for declaring new types and classes introduced
in this chapter, the Hugs system also supports a number of more advanced
and experimental typing features; see www.haskell.org/hugs.
10.8
Exercises
1. Using recursion and the function add, deﬁne a multiplication function
mult :: Nat →Nat →Nat for natural numbers.

136
CHAPTER 10. DECLARING TYPES AND CLASSES
2. Although not included in appendix A, the standard library deﬁnes
data Ordering
=
LT | EQ | GT
together with a function
compare
::
Ord a ⇒a →a →Ordering
that decides if one value in an ordered type is less than (LT), equal
(EQ), or greater than (GT) another such value. Using this function,
redeﬁne the function occurs :: Int →Tree →Bool for search trees. Why
is this new deﬁnition more eﬃcient than the original version?
3. Consider the following type of binary trees:
type Tree
=
Leaf Int | Node Tree Tree
Let us say that such a tree is balanced if the number of leaves in the
left and right subtree of every node diﬀers by at most one, with leaves
themselves being trivially balanced. Deﬁne a function balanced ::Tree →
Bool that decides if a tree is balanced or not. Hint: ﬁrst deﬁne a function
that returns the number of leaves in a tree.
4. Deﬁne a function balance :: [Int ] →Tree that converts a non-empty list
of integers into a balanced tree. Hint: ﬁrst deﬁne a function that splits
a list into two halves whose length diﬀers by at most one.
5. Extend the tautology checker to support the use of logical disjunction
(∨) and equivalence (⇔) in propositions.
6. Using the function isTaut together with the parsing and interaction li-
braries from the previous two chapters, deﬁne an interactive tautology
checker that allows propositions to be entered from the keyboard in a
user-friendly syntax. Hint: build a parser for propositions by modifying
the parser for arithmetic expressions given in chapter 8.
7. Extend the abstract machine to support the use of multiplication.
8. Complete the following instance declarations:
instance Monad Maybe where
· · ·
instance Monad [ ] where
· · ·
In this context, [ ] denotes the list type [a ] without its parameter. Hint:
ﬁrst write down the types of return and >>= for each instance.

Chapter 11
The Countdown Problem
In this chapter we show how Haskell can be used to solve the countdown
problem, a numbers game in which the aim is to construct numeric expressions
satisfying certain constraints. We start by formalising the rules of the problem
in Haskell, and then present a simple but ineﬃcient program that solves the
problem, whose eﬃciency is then improved in two stages.
11.1
Introduction
Countdown is a popular quiz programme that has been running on British
television since 1982, and includes a numbers game that we shall refer to as
the countdown problem. The essence of the problem is as follows:
Given a sequence of numbers and a target number, attempt to
construct an expression whose value is the target, by combining one
or more numbers from the sequence using addition, subtraction,
multiplication, division and parentheses.
Each number in the sequence can only be used at most once in the expression,
and all of the numbers involved, including intermediate values, must be posi-
tive natural numbers (1, 2, 3, . . .). In particular, the use of negative numbers,
zero, and proper fractions such as 2 ÷ 3, is not permitted.
For example, suppose that we are given the sequence 1, 3, 7, 10, 25, 50 and
the target 765. Then one possible solution is given by the expression (1+50)∗
(25 −10), as shown by the following simple calculation:
(1 + 50) ∗(25 −10)
=
{ applying + }
51 ∗(25 −10)
=
{ applying −}
51 ∗15
=
{ applying ∗}
765
137

138
CHAPTER 11. THE COUNTDOWN PROBLEM
In fact, for this example it can be shown that there are 780 diﬀerent solutions.
On the other hand, keeping the same sequence but changing the target to 831
gives an example that can be shown to have no solutions.
In the television version of the countdown problem, a number of additional
rules are adopted to make the problem suitable for human players on a quiz
programme.
In particular, there are always six numbers selected from the
sequence 1..10, 1..10, 25, 50, 75, 100, the target is always in the range 100..999,
and there is a time limit of 30 seconds. It is natural to abstract from such
constraints when developing computer players, so none of the programs that
we develop in this chapter enforces or depends upon these extra rules. Note,
however, that we do not abstract from the positive naturals to a richer numeric
domain such as the integers or rationals, as this would fundamentally change
the computational complexity of the problem.
11.2
Formalising the problem
We start by deﬁning a type for the four numeric operators:
data Op
=
Add | Sub | Mul | Div
deriving Show
The derived instance ensures that values of type Op can be displayed. Using
this type, we deﬁne a function valid that decides if the application of an
operator to two positive naturals gives another positive natural, and a function
apply that actually performs such a valid application:
valid
::
Op →Int →Int →Bool
valid Add
=
True
valid Sub x y
=
x > y
valid Mul
=
True
valid Div x y
=
x 'mod' y == 0
apply
::
Op →Int →Int →Int
apply Add x y
=
x + y
apply Sub x y
=
x −y
apply Mul x y
=
x ∗y
apply Div x y
=
x 'div' y
For example, the application Sub 2 3 is invalid because 2−3 is negative, while
Div 2 3 is invalid because 2 ÷ 3 is rational.
In turn, we deﬁne a type for
numeric expressions, which can either be an integer value or the application
of an operator to two argument expressions:
data Expr
=
Val Int | App Op Expr Expr
deriving Show
Using this type, we deﬁne a function that returns the list of values in an
expression, and a function eval that returns the overall value of an expression,

11.2.
FORMALISING THE PROBLEM
139
provided that this value is a positive natural number:
values
::
Expr →[Int ]
values (Val n)
=
[n ]
values (App
l r)
=
values l ++ values r
eval
::
Expr →[Int ]
eval (Val n)
=
[n | n > 0]
eval (App o l r)
=
[apply o x y | x ←eval l,
y ←eval r,
valid o x y ]
Note that the possibility of failure within eval is handled by returning a list
of results, with the convention that a singleton list denotes success, and the
empty list denotes failure. For example, for 2 + 3 and 2 −3, we have:
> eval (App Add (Val 2) (Val 3))
[5]
> eval (App Sub (Val 2) (Val 3))
[ ]
Failure within eval could also be handled by using the Maybe type, but we
prefer to use the list type in this case because the comprehension notation
then provides a convenient way to deﬁne the eval function.
We now deﬁne a number of useful combinatorial functions that return
all possible lists satisfying certain properties. The function subs returns all
subsequences of a list, which are given by all possible combinations of excluding
or including each element, interleave returns all possible ways of inserting a
new element into a list, and perms returns all permutations of a list, which
are given by all possible reorderings of the elements:
subs
::
[a ] →[[a ]]
subs [ ]
=
[[ ]]
subs (x : xs)
=
yss ++ map (x:) yss
where yss = subs xs
interleave
::
a →[a ] →[[a ]]
interleave x [ ]
=
[[x ]]
interleave x (y : ys)
=
(x : y : ys) : map (y:) (interleave x ys)
perms
::
[a ] →[[a ]]
perms [ ]
=
[[ ]]
perms (x : xs)
=
concat (map (interleave x) (perms xs))
For example:
> subs [1, 2, 3]
[[ ], [3], [2], [2, 3], [1], [1, 3], [1, 2], [1, 2, 3]]

140
CHAPTER 11. THE COUNTDOWN PROBLEM
> interleave 1 [2, 3, 4]
[[1, 2, 3, 4], [2, 1, 3, 4], [2, 3, 1, 4], [2, 3, 4, 1]]
> perms [1, 2, 3]
[[1, 2, 3], [2, 1, 3], [2, 3, 1], [1, 3, 2], [3, 1, 2], [3, 2, 1]]
In turn, a function that returns all choices from a list, which are given by
all possible ways of selecting zero or more elements in any order, can then be
deﬁned simply by considering all permutations of all subsequences:
choices
::
[a ] →[[a ]]
choices xs
=
concat (map perms (subs xs))
For example:
> choices [1, 2, 3]
[[ ], [3], [2], [2, 3], [3, 2], [1], [1, 3], [3, 1], [1, 2], [2, 1],
[1, 2, 3], [2, 1, 3], [2, 3, 1], [1, 3, 2], [3, 1, 2], [3, 2, 1]]
Finally, we can now deﬁne a function solution that formalises what it
means to solve an instance of the countdown problem:
solution
::
Expr →[Int ] →Int →Bool
solution e ns n
=
elem (values e) (choices ns) ∧eval e == [n ]
That is, an expression is a solution for a given list of numbers and a target if
the list of values in the expression is chosen from the list of numbers, and the
expression successfully evaluates to give the target. For example, if e :: Expr
represents the expression (1 + 50) ∗(25 −10), then we have:
> solution e [1, 3, 7, 10, 25, 50] 765
True
The eﬃciency of solution could be improved by using a function isChoice
that decides if one list is chosen from another directly, rather than doing so
indirectly using the function choices that returns all possible choices from a
list. However, eﬃciency is not important at this stage, and choices itself is
used to deﬁne a number of other functions in this chapter.
11.3
Brute force solution
Our ﬁrst approach to solving the countdown problem is by brute force, using
the idea of generating all possible expressions over the given list of numbers.
We start by deﬁning a function split that returns all possible ways of splitting
a list into two non-empty lists that append to give the original list:
split
::
[a ] →[([a ], [a ])]
split [ ]
=
[ ]
split [ ]
=
[ ]
split (x : xs)
=
([x ], xs) : [(x : ls, rs) | (ls, rs) ←split xs ]

11.3.
BRUTE FORCE SOLUTION
141
For example:
> split [1, 2, 3, 4]
[([1], [2, 3, 4]), ([1, 2], [3, 4]), ([1, 2, 3], [4])]
Using split we can then deﬁne the key function, exprs, which returns all pos-
sible expressions whose list of values is precisely a given list:
exprs
::
[Int ] →[Expr ]
exprs [ ]
=
[ ]
exprs [n ]
=
[Val n ]
exprs ns
=
[e | (ls, rs) ←split ns,
l ←exprs ls,
r ←exprs rs,
e ←combine l r ]
That is, for the empty list of numbers there are no possible expressions, while
for a single number there is a single expression comprising that number. Oth-
erwise, for a list of two or more numbers we ﬁrst produce all splittings of the
list, then recursively calculate all possible expressions for each of these lists,
and ﬁnally combine each pair of expressions using each of the four numeric
operators, using an auxiliary function deﬁned as follows:
combine
::
Expr →Expr →[Expr ]
combine l r
=
[App o l r | o ←ops ]
ops
::
[Op]
ops
=
[Add, Sub, Mul, Div ]
Finally, we can now deﬁne a function solutions that returns all possible
expressions that solve an instance of the countdown problem, by ﬁrst gener-
ating all expressions over each choice from the given list of numbers, and then
selecting those expressions that successfully evaluate to give the target:
solutions
::
[Int ] →Int →[Expr ]
solutions ns n
=
[e | ns′ ←choices ns,
e ←exprs ns′,
eval e == [n ]]
For the purposes of testing our programs in this chapter, the performance
of Hugs is somewhat limited, so instead we use the Glasgow Haskell Com-
piler. For example, using GHC version 5.04.1 on a 1.5GHz Pentium 4 laptop,
solutions [1, 3, 7, 10, 25, 50] 765 returns the ﬁrst solution in 0.62 seconds, and
all 780 solutions in 74.08 seconds, while if the target is changed to 831 then
the empty list of solutions is returned in 69.52 seconds.

142
CHAPTER 11. THE COUNTDOWN PROBLEM
11.4
Combining generation and evaluation
The function solutions generates all possible expressions over the given num-
bers, but in practice many of these expressions will fail to evaluate, due to the
fact that subtraction and division are not always valid for positive naturals.
For example, it can be shown that there are 33, 665, 406 possible expressions
over the numbers 1, 3, 7, 10, 25, 50, but only 4, 672, 540 of these expressions
evaluate successfully, which is just under 14%.
Based upon this observation, our second approach to solving the count-
down problem is to improve our brute force program by combining the gener-
ation of expressions with their evaluation, such that both tasks are performed
simultaneously. In this way, expressions that fail to evaluate are rejected at
an earlier stage, and more importantly, are not used to generate further such
expressions. We start by declaring a type Result of expressions that evaluate
successfully paired with their overall values:
type Result
=
(Expr, Int)
Using this type, we then deﬁne a function results that returns all possible
results comprising expressions whose list of values is precisely a given list:
results
::
[Int ] →[Result ]
results [ ]
=
[ ]
results [n ]
=
[(Val n, n) | n > 0]
results ns
=
[res | (ls, rs) ←split ns,
lx ←results ls,
ry ←results rs,
res ←combine′ lx ry ]
That is, for the empty list there are no possible results, while for a single
number there is a single result formed from that number, provided that the
number itself is a positive natural. Otherwise, for two or more numbers we
ﬁrst produce all splittings of the list, then recursively calculate all possible
results for each of these lists, and ﬁnally combine each pair of results using
each of the four numeric operators that are valid:
combine′
::
Result →Result →[Result ]
combine′ (l, x) (r, y)
=
[(App o l r, apply o x y) | o ←ops, valid o x y ]
Using results we can now deﬁne a new function solutions′ that returns
all possible expressions that solve an instance of the countdown problem, by
ﬁrst generating all results over each choice from the given numbers, and then
selecting those expressions whose value is the target:
solutions′
::
[Int ] →Int →[Expr ]
solutions′ ns n
=
[e | ns′ ←choices ns,
(e, m) ←results ns′,
m == n ]

11.5.
EXPLOITING ALGEBRAIC PROPERTIES
143
In terms of performance, solutions′ [1, 3, 7, 10, 25, 50] 765 returns the ﬁrst
solution in 0.06 seconds (10 times faster than solutions) and all solutions in
7.52 seconds (almost 10 times faster), while if the target is changed to 831 the
empty list is returned in 5.46 seconds (almost 13 times faster).
11.5
Exploiting algebraic properties
The function solutions′ generates all possible expressions over the given num-
bers whose evaluation is successful, but in practice many of these expressions
will be essentially the same, due to the fact that the numeric operators have
algebraic properties. For example, the expressions 2 + 3 and 3 + 2 are essen-
tially the same because the result of an addition does not depend upon the
order of the two arguments, while 2÷1 and 2 are essentially the same because
dividing any number by one has no eﬀect on that number.
Based upon this observation, our ﬁnal approach to solving the countdown
problem is to improve our second program by exploiting such properties to
reduce the number of generated expressions.
In particular, we exploit the
following ﬁve commutativity and identity properties:
x + y
=
y + x
x ∗y
=
y ∗x
x ∗1
=
x
1 ∗y
=
y
x ÷ 1
=
x
We start by recalling the function valid that decides if the application of
an operator to two positive naturals gives another such:
valid
::
Op →Int →Int →Bool
valid Add
=
True
valid Sub x y
=
x > y
valid Mul
=
True
valid Div x y
=
x 'mod' y == 0
This deﬁnition can be modiﬁed to exploit the commutativity of addition and
multiplication simply by requiring that their arguments are in numeric order
(x ⩽y), and the identity properties of multiplication and division simply by
requiring that the appropriate arguments are non-unitary (̸= 1):
valid Add x y
=
x ⩽y
valid Sub x y
=
x > y
valid Mul x y
=
x ̸= 1 ∧y ̸= 1 ∧x ⩽y
valid Div x y
=
y ̸= 1 ∧x 'mod' y == 0
For example, using this new deﬁnition Add 3 2 is now invalid because it is
essentially the same as Add 2 3 using the commutativity of addition, while

144
CHAPTER 11. THE COUNTDOWN PROBLEM
Div 2 1 is now invalid because it is essentially the same as the number 2 on
its own using the identity property for division.
Using the new version of valid gives a new version of our function solutions′
that solves the countdown problem, which we write as solutions′′. Using this
new function can considerably reduce the number of generated expressions
and the number of solutions. For example, solutions′′ [1, 3, 7, 10, 25, 50] 765
only generates 245, 644 expressions, of which just 49 are solutions, which is
just over 5% and 6% respectively of the numbers using solutions′.
As regards performance, solutions′′ [1, 3, 7, 10, 25, 50] 765 now returns the
ﬁrst solution in 0.03 seconds (twice as fast as solutions′) and all solutions in
0.80 seconds (9 times faster), while for the target number 831 the empty list
is returned in 0.66 seconds (8 times faster). More generally, given any num-
bers from the television version of the countdown problem, our ﬁnal program
solutions′′ typically returns all solutions in under one second.
11.6
Chapter remarks
Countdown is based upon an original version on French television called "Des
Chiﬀres et des Lettres", while the countdown problem itself is related to the
childrens arithmetic games called "krypto" and "four fours". This chapter is
based upon [16], which also includes proofs of correctness of the three programs
produced. A number of more advanced approaches to solving the countdown
problem are explored by Bird and Mu [2]. The deﬁnitions for the functions
subs, interleave and perms are due to Bird and Wadler [3].
11.7
Exercises
1. Redeﬁne the combinatorial function choices using a list comprehension
rather than the library functions concat and map.
2. Deﬁne a recursive function isChoice :: Eq a ⇒[a ] →[a ] →Bool that
decides if one list is chosen from another, without using the combinato-
rial functions perms and subs. Hint: start by deﬁning a function that
removes the ﬁrst occurrence of a value from a list.
3. What eﬀect would generalising the function split to also return pairs
containing the empty list have on the behaviour of solutions?
4. Using choices, exprs and eval, verify that there are 33, 665, 406 possible
expressions over the numbers 1, 3, 7, 10, 25, 50, and that only 4, 672, 540
of these expressions evaluate successfully.
5. Similarly, verify that the number of expressions that evaluate successfully
increases to 10, 839, 369 if the numeric domain is generalised to arbitrary
integers. Hint: modify the deﬁnition of valid.
6. Modify the ﬁnal program to:

11.7.
EXERCISES
145
(a) allow the use of exponentiation in expressions;
(b) produce the nearest solutions if no exact solution is possible;
(c) order the solutions using a suitable measure of simplicity.

146
CHAPTER 11. THE COUNTDOWN PROBLEM

Chapter 12
Lazy Evaluation
In this chapter we introduce lazy evaluation, the mechanism used to evalu-
ate expressions in Haskell. We start by reviewing the notion of evaluation,
then consider evaluation strategies and their properties, discuss inﬁnite struc-
tures and modular programming, and conclude with a special form of function
application that can improve the space performance of programs.
12.1
Introduction
As we have seen throughout this book, the basic method of computation in
Haskell is the application of functions to arguments. For example, suppose
that we deﬁne a function that increments an integer:
inc
::
Int →Int
inc n
=
n + 1
Then the expression inc (2 ∗3) can be evaluated as follows:
inc (2 ∗3)
=
{ applying ∗}
inc 6
=
{ applying inc }
6 + 1
=
{ applying + }
7
Alternatively, the same result can also be obtained by performing the ﬁrst two
function applications in the opposite order:
inc (2 ∗3)
=
{ applying inc }
(2 ∗3) + 1
=
{ applying ∗}
6 + 1
147

148
CHAPTER 12. LAZY EVALUATION
=
{ applying + }
7
The fact that changing the order in which functions are applied does not aﬀect
the ﬁnal result is not speciﬁc to such simple examples, but is an important
general property of function application in Haskell. More formally, in Haskell
any two diﬀerent ways of evaluating the same expression will always produce
the same ﬁnal value, provided that they both terminate. We will return to
the issue of termination later on in this chapter.
Note that the above property does not hold for most imperative program-
ming languages, in which the basic method of computation is changing stored
values.
For example, consider the imperative expression n + (n := 1) that
adds the current value of the variable n to the result of changing its value to
one, assuming that n initially has the value zero. Then this expression can be
evaluated by ﬁrst performing the left-hand side of the addition
n + (n := 1)
=
{ applying n }
0 + (n := 1)
=
{ applying := }
0 + 1
=
{ applying + }
1
or alternatively, by ﬁrst performing the right-hand side:
n + (n := 1)
=
{ applying := }
n + 1
=
{ applying n }
1 + 1
=
{ applying + }
2
The ﬁnal value is diﬀerent in each case. The general problem illustrated by
this example is that the precise time at which an assignment is performed in
an imperative language may aﬀect the value that results from a computation.
In contrast, the time at which a function is applied to an argument in Haskell
never aﬀects the value that results from a computation. Nonetheless, as we
shall see in the remainder of this chapter, there are important practical issues
concerning the order and nature of evaluation.
12.2
Evaluation strategies
An expression that has the form of a function applied to one or more arguments
that can be "reduced" by performing the application is called a reducible

12.2.
EVALUATION STRATEGIES
149
expression, or redex for short. As indicated by the use of quotations marks in
the preceding sentence, such reductions do not necessarily decrease the size of
an expression, although in practice this is often the case.
By way of example, suppose that we deﬁne a function mult that takes a
pair of integers and returns their product:
mult
::
(Int, Int) →Int
mult (x, y)
=
x ∗y
Now consider the expression mult (1 + 2, 2 + 3).
This expression contains
three redexes, namely the subexpressions 1 + 2 and 2 + 3, which have the
form of the function + applied to two arguments, and the entire expression
mult (1 + 2, 2 + 3) itself, which has the form of the function mult applied
to a pair of arguments. Performing the corresponding reductions gives the
expressions mult (3, 2 + 3), mult (1 + 2, 5), and (1 + 2) ∗(2 + 3).
When evaluating an expression, in what order should reductions be per-
formed?
One common strategy, called innermost evaluation, is to always
choose a redex that is innermost, in the sense that it contains no other redex.
If there is more than one innermost redex, by convention we choose that which
begins at the leftmost position in the expression.
For example, both 1 + 2 and 2 + 3 contain no other redexes and are hence
innermost within the expression mult (1 + 2, 2 + 3), with the redex 1 + 2
beginning at the leftmost position. More generally, our example expression is
evaluated using innermost evaluation as follows:
mult (1 + 2, 2 + 3)
=
{ applying the ﬁrst + }
mult (3, 2 + 3)
=
{ applying + }
mult (3, 5)
=
{ applying mult }
3 ∗5
=
{ applying ∗}
15
Innermost evaluation can also be characterised in terms of how arguments
are passed to functions. In particular, using this strategy ensures that the
argument of a function is always fully evaluated before the function itself is
applied.
That is, arguments are passed by value.
For example, as shown
above, evaluating mult (1 + 2, 2 + 3) using innermost evaluation proceeds by
ﬁrst evaluating the argument expressions 1 + 2 and 2 + 3, and then applying
the function mult. The fact that we always choose the leftmost innermost
redex ensures that the ﬁrst argument is evaluated before the second.
Another common strategy for evaluating an expression, dual to innermost
evaluation, is to always choose a redex that is outermost, in the sense that it is

150
CHAPTER 12. LAZY EVALUATION
contained in no other redex. If there is more than one such redex then as pre-
viously we choose that which begins at the leftmost position. Not surprisingly,
this evaluation strategy is called outermost evaluation.
For example, the expression mult (1 + 2, 2 + 3) is contained in no other
redex and is hence outermost within itself. More generally, evaluating this
expression using outermost evaluation proceeds as follows:
mult (1 + 2, 2 + 3)
=
{ applying mult }
(1 + 2) ∗(2 + 3)
=
{ applying the ﬁrst + }
3 ∗(2 + 3)
=
{ applying + }
3 ∗5
=
{ applying ∗}
15
In terms of how arguments are passed to functions, using outermost evalu-
ation allows functions to be applied before their arguments are evaluated. For
this reason, we say that arguments are passed by name. For example, as shown
above, evaluating mult (1 + 2, 2 + 3) using outermost evaluation proceeds by
ﬁrst applying the function mult to the two unevaluated arguments 1 + 2 and
2 + 3, and then evaluating these two expressions in turn.
Note, however, that many built-in functions require their arguments to be
evaluated before being applied, even when using outermost evaluation. For
example, as illustrated in the calculation above, built-in arithmetic operators
such as ∗and + cannot be applied until their two arguments have been eval-
uated to numbers. Functions with this property are called strict, and will be
discussed in further detail at the end of this chapter.
Lambda expressions
Let us now deﬁne a curried version of mult that takes its arguments one at a
time, using a lambda expression to make the use of currying explicit:
mult
::
Int →Int →Int
mult x
=
λy →x ∗y
Then using innermost evaluation, for example, we have:
mult (1 + 2) (2 + 3)
=
{ applying the ﬁrst + }
mult 3 (2 + 3)
=
{ applying mult }
(λy →3 ∗y) (2 + 3)
=
{ applying + }

12.3.
TERMINATION
151
(λy →3 ∗y) 5
=
{ applying λy →3 ∗y }
3 ∗5
=
{ applying ∗}
15
That is, the two arguments are now substituted into the body of the function
mult one at a time, as we would expect using currying, rather than at the
same time as in the previous section. This behaviour arises because mult 3 is
the leftmost innermost redex in the expression mult 3 (2 + 3), as opposed to
2+3 in the expression mult (3, 2+3). Performing a reduction on mult 3 in the
second step of the calculation above gives the lambda expression (λy →3∗y),
which awaits the result of evaluating the second argument.
Note that in Haskell, the selection of redexes within lambda expressions is
prohibited. The rational for not "reducing under lambdas" is that functions
are viewed as black boxes that we are not permitted to look inside. More
formally, the only operation that can be performed on a function is that of
applying it to an argument. As such, reduction within the body of a func-
tion is only permitted once the function has been applied. For example, the
lambda expression λx →1 + 2 is deemed to be fully evaluated, even though
its body contains the redex 1 + 2, but once this function has been applied to
an argument, evaluation of this redex can then proceed:
(λx →1 + 2) 0
=
{ applying λx →1 + 2 }
1 + 2
=
{ applying + }
3
Using innermost and outermost evaluation, but not under lambdas, is nor-
mally referred to as call-by-value and call-by-name evaluation, respectively. In
the next two sections we explore how these two evaluation strategies compare
in terms of two important properties, namely their termination behaviour and
the number of reduction steps that they require.
12.3
Termination
Consider the following recursive deﬁnition:
inf
::
Int
inf
=
1 + inf
That is, the integer inf (abbreviating "inﬁnity") is deﬁned as the successor
of itself. Evaluating inf produces a larger and larger expression, regardless of
the evaluation strategy, and hence does not terminate:

152
CHAPTER 12. LAZY EVALUATION
inf
=
{ applying inf }
1 + inf
=
{ applying inf }
1 + (1 + inf )
=
{ applying inf }
1 + (1 + (1 + inf ))
=
{ applying inf }
...
In practice, evaluating inf using Hugs will quickly exhaust the available mem-
ory and produce an error message. Now consider the expression fst (0, inf ),
where fst is the library function that selects the ﬁrst component of a pair,
deﬁned by fst (x, y) = x. Using call-by-value evaluation with this expression
also results in non-termination in a similar manner:
fst (0, inf )
=
{ applying inf }
fst (0, 1 + inf )
=
{ applying inf }
fst (0, 1 + (1 + inf ))
=
{ applying inf }
fst (0, 1 + (1 + (1 + inf )))
=
{ applying inf }
...
In contrast, using call-by-name evaluation results in termination in just one
step, by immediately applying the deﬁnition of fst and hence avoiding the
evaluation of the non-terminating expression inf :
fst (0, inf )
=
{ applying fst }
0
This simple example shows that call-by-name evaluation may produce a re-
sult when call-by-value evaluation fails to terminate. More generally, we have
the following important property: if there exists any evaluation sequence that
terminates for a given expression, then call-by-name evaluation will also ter-
minate for this expression, and produce the same ﬁnal result.
In summary, call-by-name evaluation is preferable to call-by-value for the
purpose of ensuring that evaluation terminates as often as possible.
12.4
Number of reductions
Now consider the following deﬁnition:
square
::
Int →Int
square n
=
n ∗n

12.4.
NUMBER OF REDUCTIONS
153
For example, using call-by-value evaluation, we have:
square (1 + 2)
=
{ applying + }
square 3
=
{ applying square }
3 ∗3
=
{ applying ∗}
9
In contrast, using call-by-name evaluation with the same expression requires
one extra reduction step, due to the fact that 1 + 2 is duplicated when the
function square is applied, and hence must be evaluated twice:
square (1 + 2)
=
{ applying square }
(1 + 2) ∗(1 + 2)
=
{ applying the ﬁrst + }
3 ∗(1 + 2)
=
{ applying + }
3 ∗3
=
{ applying ∗}
9
This example shows that call-by-name evaluation may require more steps than
call-by-value evaluation, in particular when an argument is used more than
once in the body of a function. More generally, we have the following property:
arguments are evaluated precisely once using call-by-value evaluation, but may
be evaluated many times using call-by-name.
Fortunately, the above eﬃciency problem with call-by-name evaluation can
easily be solved, by using pointers to indicate sharing of expressions during
evaluation. Rather than physically copying an argument if it is used many
times in the body of a function, we simply keep one copy of the argument and
make many pointers to it. In this manner, any reductions that are performed
on the argument are automatically shared between each of the pointers to that
argument. For example, using this strategy we have:
square (1 + 2)
=
{ applying square }
•
 
∗•
 
1 + 2
=
{ applying + }
•
 

∗•  

3
=
{ applying ∗}

154
CHAPTER 12. LAZY EVALUATION
9
That is, when applying the deﬁnition square n = n ∗n in the ﬁrst step, we
keep a single copy of the argument expression 1 + 2, and make two pointers
to it. In this manner, when the expression 1+ 2 is reduced in the second step,
both pointers in the expression share the result.
The use of call-by-name evaluation in conjunction with sharing is called
lazy evaluation. This is the evaluation strategy that is used in Haskell, as a re-
sult of which Haskell is called a lazy programming language. Being based upon
call-by-name evaluation, lazy evaluation has the property that it ensures that
evaluation terminates as often as possible. Moreover, using sharing ensures
that lazy evaluation never requires more steps than call-by-value evaluation.
The use of the term "lazy" will be explained shortly.
12.5
Inﬁnite structures
An additional property of call-by-name evaluation, and hence lazy evaluation,
is that it allows what at ﬁrst sight may seem impossible: programming with
inﬁnite structures. We have already seen a simple example of this idea ear-
lier in this chapter, in the form of the evaluation of fst (0, inf ) avoiding the
production of the inﬁnite structure 1 + (1 + (1 + · · ·)) deﬁned by inf .
More interesting forms of behaviour occur when we consider inﬁnite lists.
For example, consider the following recursive deﬁnition:
ones
::
[Int ]
ones
=
1 : ones
That is, the list ones is deﬁned as a single one followed by itself. As with inf ,
evaluating ones does not terminate, regardless of the strategy used:
ones
=
{ applying ones }
1 : ones
=
{ applying ones }
1 : (1 : ones)
=
{ applying ones }
1 : (1 : (1 : ones))
=
{ applying ones }
...
In practice, evaluating ones using Hugs will produce a never ending list of
ones, until the user eventually decides to terminate this process:
> ones
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, · · ·

12.6.
MODULAR PROGRAMMING
155
Now consider the expression head ones, which attempts to select the ﬁrst
element of this inﬁnite list of ones. Using call-by-value evaluation with this
expression also results in non-termination:
head ones
=
{ applying ones }
head (1 : ones)
=
{ applying ones }
head (1 : (1 : ones))
=
{ applying ones }
head (1 : (1 : (1 : ones)))
=
{ applying ones }
...
In contrast, using lazy evaluation (or call-by-name evaluation, as sharing is
not required in this example) results in termination in two steps:
head ones
=
{ applying ones }
head (1 : ones)
=
{ applying head }
1
This behaviour arises because lazy evaluation proceeds in a lazy manner as
its name suggests, only evaluating arguments as and when strictly necessary
to produce results. For example, when selecting the ﬁrst element of a list, the
remainder of the list is not required, and hence in head (1 : ones) the further
evaluation of the inﬁnite list ones is avoided. More generally, we have the
following property: using lazy evaluation, expressions are only evaluated as
much as required by the context in which they are used.
Using this idea, we now see that under lazy evaluation ones is not an
inﬁnite list as such, but rather a potentially inﬁnite list, which is only evaluated
as much as required by the context. This idea is not restricted to lists, but
applies equally to any form of data structure in Haskell. For example, the last
exercise for this chapter involves potentially inﬁnite trees.
12.6
Modular programming
Lazy evaluation also allows us to separate control from data in our computa-
tions. For example, a list of three ones can be produced by selecting the ﬁrst
three elements (control) of the inﬁnite list of ones (data):
> take 3 ones
[1, 1, 1]

156
CHAPTER 12. LAZY EVALUATION
Using the deﬁnition of take from the standard prelude
take 0
=
[ ]
take (n + 1) [ ]
=
[ ]
take (n + 1) (x : xs)
=
x : take n xs
this behaviour arises using lazy evaluation as follows:
take 3 ones
=
{ applying ones }
take 3 (1 : ones)
=
{ applying take }
1 : take 2 ones
=
{ applying ones }
1 : take 2 (1 : ones)
=
{ applying take }
1 : 1 : take 1 ones
=
{ applying ones }
1 : 1 : take 1 (1 : ones)
=
{ applying take }
1 : 1 : 1 : take 0 ones
=
{ applying take }
1 : 1 : 1 : [ ]
=
{ list notation }
[1, 1, 1]
That is, the data is only evaluated as much as required by the control, and
these two parts take it in turn to perform reductions. Without lazy evaluation,
the control and data parts would need to be combined in the form of a single
function that produces a list of n identical elements, such as:
replicate
::
Int →a →[a ]
replicate 0
=
[ ]
replicate (n + 1) x
=
x : replicate n x
Being able to modularise programs by separating them into logically distinct
parts is an important goal in programming, and being able to separate control
from data is one of the most important beneﬁts of lazy evaluation.
Note that care is still required when programming with inﬁnite lists, to
avoid non-termination. For example, the expression
ﬁlter (⩽5) [1 . .]
(where [n . .] produces the inﬁnite list of integers beginning with n) will
produce the integers 1, 2, 3, 4, 5 and then loop forever, because the function
ﬁlter (⩽5) keeps testing elements of the inﬁnite list in a vain attempt to ﬁnd
another that is less than or equal to ﬁve. In contrast, the expression
takeWhile (⩽5) [1 . .]

12.6.
MODULAR PROGRAMMING
157
will produce the same integers and then terminate, because takeWhile (⩽5)
stops as soon as it ﬁnds an element of the list that is greater than ﬁve.
We conclude this section with an example concerning prime numbers. In
chapter 5 we wrote a function to generate prime numbers up to a given limit.
Here is a simple procedure for generating the inﬁnite sequence of all prime
numbers, as opposed to some ﬁnite preﬁx of this sequence:
• Write down the inﬁnite sequence 2, 3, 4, 5, 6, · · ·;
• Mark the ﬁrst number, p, in the sequence as prime;
• Delete all multiples of p from the sequence;
• Return to the second step.
Note that the ﬁrst and third steps require an inﬁnite amount of work, and
hence in practice the steps must be interleaved. The ﬁrst few iterations of this
procedure can be illustrated as follows:
2
3
4
5
6
7
8
9
10
11
12
13
14
15
· · ·
3
5
7
9
11
13
15
· · ·
5
7
11
13
· · ·
7
11
13
· · ·
11
13
· · ·
13
· · ·
Each row corresponds to one iteration, with the ﬁrst row being the initial
sequence (step one), the ﬁrst number in each row being written in bold to
indicate its primality (step two), and all multiples of this number being un-
derlined to indicate their deletion (step three) prior to the next iteration. In
this manner, we can imagine the initial sequence of numbers falling downwards,
with certain numbers being sieved out at each stage by the underlining, and
the bold numbers forming the inﬁnite sequence of primes:
2, 3, 5, 7, 11, 13, · · ·
The above procedure for generating prime numbers is known as the sieve
of Eratosthenes, after the Greek mathematician who ﬁrst described it. This
procedure can be translated directly into Haskell:
primes
::
[Int ]
primes
=
sieve [2 . .]
sieve
::
[Int ] →[Int ]
sieve (p : xs)
=
p : sieve [x | x ←xs, x 'mod' p ̸= 0]

158
CHAPTER 12. LAZY EVALUATION
That is, starting with the inﬁnite list [2 . .] (step one), we apply the function
sieve that retains the ﬁrst number p as being prime (step two), and then calls
itself recursively with a new list obtained by ﬁltering all multiples of p from
this list (steps three and four). Lazy evaluation ensures that this program
does indeed produce the inﬁnite list of all prime numbers:
> primes
[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, · · ·
By freeing the generation of prime numbers from the constraint of ﬁniteness,
we have obtained a modular program on which diﬀerent control parts can be
used in diﬀerent situations. For example, the ﬁrst ten prime numbers, and the
prime numbers less than ten, can be produced as follows:
> take 10 primes
[2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
> takeWhile (<10) primes
[2, 3, 5, 7]
12.7
Strict application
Haskell uses lazy evaluation by default, but also provides a special strict ver-
sion of function application, written as $!, which can sometimes be useful.
Informally, an expression of the form f $! x behaves in the same way as the
normal application f x, except that the top-level of evaluation of the argument
expression x is forced before the function f is applied.
For example, if the argument has a basic type, such as Int or Bool, then
top-level evaluation is simply complete evaluation. On the other hand, for a
pair type such as (Int, Bool), evaluation is performed until a pair of expressions
is obtained, but no further. Similarly, for a list type, evaluation is performed
until the empty list or the cons of two expressions is obtained.
More formally, an expression of the form f $! x is only a redex once evalua-
tion of the argument x, using lazy evaluation as normal, has reached the point
where it is known that the result is not an undeﬁned value, at which point the
expression can be reduced to the normal application f x. For example, using
the deﬁnition square n = n ∗n, evaluation of square $! (1 + 2) proceeds in a
call-by-value manner, by ﬁrst evaluating the argument expression 1+2 to give
the value 3, and then applying the function square:
square $! (1 + 2)
=
{ applying + }
square $! 3
=
{ applying $! }
square 3
=
{ applying square }

12.7.
STRICT APPLICATION
159
3 ∗3
=
{ applying ∗}
9
When used with a curried function with multiple arguments, strict applica-
tion can be used to force top-level evaluation of any combination of arguments.
For example, if f is a curried function with two arguments, an application of
the form f x y can be modiﬁed to have three diﬀerent behaviours:
(f $! x) y
forces top-level evaluation of x
(f x) $! y
forces top-level evaluation of y
(f $! x) $! y
forces top-level evaluation of x and y
In Haskell, strict application is mainly used to improve the space perfor-
mance of programs. For example, consider a function sumwith that calculates
the sum of a list of integers using an accumulator value:
sumwith
::
Int →[Int ] →Int
sumwith v [ ]
=
v
sumwith v (x : xs)
=
sumwith (v + x) xs
Then using lazy evaluation, we have:
sumwith 0 [1, 2, 3]
=
{ applying sumwith }
sumwith (0 + 1) [2, 3]
=
{ applying sumwith }
sumwith ((0 + 1) + 2) [3]
=
{ applying sumwith }
sumwith (((0 + 1) + 2) + 3) [ ]
=
{ applying sumwith }
((0 + 1) + 2) + 3
=
{ applying the ﬁrst + }
(1 + 2) + 3
=
{ applying the ﬁrst + }
3 + 3
=
{ applying + }
6
Note that the entire summation ((0 + 1) + 2) + 3 is constructed before any
additions are actually performed. More generally, sumwith will construct a
summation whose size is proportional to the number of integers in the original
list. For example, evaluating sumwith 0 [1 . . 10000] using Hugs will quickly
exhaust the available memory and produce an error message. In practice, it
would be preferable to perform each addition as soon as it is introduced, in
order to avoid running out of memory in this way.

160
CHAPTER 12. LAZY EVALUATION
This behaviour can be achieved by redeﬁning sumwith using strict appli-
cation, to force evaluation of its accumulator value:
sumwith v [ ]
=
v
sumwith v (x : xs)
=
(sumwith $! (v + x)) xs
For example, we now have:
sumwith 0 [1, 2, 3]
=
{ applying sumwith }
sumwith $! (0 + 1) [2, 3]
=
{ applying + }
sumwith $! 1 [2, 3]
=
{ applying $! }
sumwith 1 [2, 3]
=
{ applying sumwith }
sumwith $! (1 + 2) [3]
=
{ applying + }
sumwith $! 3 [3]
=
{ applying $! }
sumwith 3 [3]
=
{ applying sumwith }
sumwith $! (3 + 3) [ ]
=
{ applying + }
sumwith $! 6 [ ]
=
{ applying $! }
sumwith 6 [ ]
=
{ applying sumwith }
6
This evaluation requires more steps than previously, due to the additional
overhead of using strict application, but now performs each addition as soon
as it is introduced, rather than constructing a large summation. For example,
evaluating sumwith 0 [1 . . 10000] using Hugs now gives the correct result, as
opposed to producing an error as previously.
Generalising from the above example, one may wish to deﬁne a strict
version of the higher-order library function foldl that forces evaluation of its
accumulator prior to processing the tail of the list:
foldl′
::
(a →b →a) →a →[b] →a
foldl′ f v [ ]
=
v
foldl′ f v (x : xs)
=
((foldl′ f ) $! (f v x)) xs
For example, we can now deﬁne sumwith = foldl′ (+).
It is important to
note, however, that strict application is not a silver bullet that automatically
improves the space behaviour of Haskell programs. Even for relatively simple
examples, the use of strict application is a specialist topic that requires careful
consideration of the behaviour of lazy evaluation.

12.8.
CHAPTER REMARKS
161
12.8
Chapter remarks
Further details about evaluation orders and their properties can be found
in [29], and further examples of the use of lazy evaluation for modular pro-
gramming in the classic Why Functional Programming Matters [13]. A formal
meaning for lazy evaluation is given in [22], and a comprehensive tutorial on
the eﬃcient implementation of lazy evaluation in [27].
12.9
Exercises
1. Identify the redexes in the following expressions, and determine whether
each redex is innermost, outermost, neither, or both:
1 + (2 ∗3)
(1 + 2) ∗(2 + 3)
fst (1 + 2, 2 + 3)
(λx →1 + x) (2 ∗3)
2. Show why outermost evaluation is preferable to innermost for the pur-
poses of evaluating the expression fst (1 + 2, 2 + 3).
3. Given the deﬁnition mult = λx →(λy →x ∗y), show how the evaluation
of mult 3 4 can be broken down into four separate steps.
4. Using a list comprehension, deﬁne an expression ﬁbs :: [Integer ] that
generates the inﬁnite sequence of Fibonacci numbers
0, 1, 1, 2, 3, 5, 8, 13, 21, 34, · · ·
using the following simple procedure:
• The ﬁrst two numbers are 0 and 1;
• The next is the sum of the previous two;
• Return to the second step.
Hint: make use of the library functions zip and tail. Note that numbers
in the Fibonacci sequence quickly become large, hence the use of the
type Integer of arbitrary-precision integers above.
5. Using ﬁbs, deﬁne a function ﬁb :: Int →Integer that returns the nth Fi-
bonnaci number (counting from zero), and an expression that calculates
the ﬁrst Fibonacci number greater than one thousand.

162
CHAPTER 12. LAZY EVALUATION
6. Deﬁne appropriate versions of the library functions
repeat
::
a →[a ]
repeat x
=
xs where xs = x : xs
take
::
Int →[a ] →[a ]
take 0
=
[ ]
take (n + 1) [ ]
=
[ ]
take (n + 1) (x : xs)
=
x : take n xs
replicate
::
Int →a →[a ]
replicate n
=
take n ◦repeat
for the following type of binary trees:
data Tree a
=
Leaf | Node (Tree a) a (Tree a)

Chapter 13
Reasoning About Programs
In this ﬁnal chapter we introduce the idea of reasoning about Haskell programs.
We start by reviewing the notion of equational reasoning, then consider how
it can be applied in Haskell, introduce the important technique of induction,
show how induction can be used to eliminate uses of the append operator, and
conclude by proving the correctness of a simple compiler.
13.1
Equational reasoning
At school we learn basic algebraic properties of numbers, such as the fact
that multiplication is commutative, addition is associative, and multiplication
distributes over addition on both the left and right-hand sides:
x y
=
y x
x + (y + z)
=
(x + y) + z
x (y + z)
=
x y + x z
(x + y) z
=
x z + y z
For example, using these properties we can show that a product of the form
(x + a) (x + b) can be expanded to a summation x2 + (a + b) x + a b:
(x + a) (x + b)
=
{ left distributivity }
(x + a) x + (x + a) b
=
{ right distributivity }
x x + a x + x b + a b
=
{ squaring }
x2 + a x + x b + a b
=
{ commutativity }
x2 + a x + b x + a b
=
{ right distributivity }
x2 + (a + b) x + a b
163

164
CHAPTER 13. REASONING ABOUT PROGRAMS
Note that in this calculation we follow the common practice of implicitly ex-
ploiting associativity properties, in this case the associativity of addition by
omitting parentheses when more than one addition is used in sequence.
As well as being interesting in their their own right, algebraic properties can
also have a computational signiﬁcance. For example, the expression x (y + z)
requires two operations (one multiplication and one addition), whereas the
equivalent expression x y + x z requires three (two multiplications and one
addition). Hence even though these two expressions are algebraically equal,
in terms of eﬃciency the former is preferable to the latter.
13.2
Reasoning about Haskell
The same style of equational reasoning can also be used in Haskell. For exam-
ple, in this context the equation x ∗y = y ∗x means that for any expressions
x and y of the same numeric types, evaluation of x ∗y and y ∗x will al-
ways produce the same numeric value. Note that the equality operator ==
provided within Haskell itself is not used when stating such properties, as in
x ∗y == y ∗x, because we are aiming to use mathematics as a language to
reason about Haskell, rather than using Haskell as a language to reason about
itself, which would be somewhat circular.
When reasoning about Haskell, we don't just use properties of built-in
operations of the language such as addition and multiplication, but also use
the equations from which user-deﬁned functions are constructed. For example,
consider the following function that doubles an integer:
double
::
Int →Int
double x
=
x + x
As well as being viewed as the deﬁnition of a function, this equation can also
be viewed as a property that can be used when reasoning about this function.
In particular, as a logical property the above equation states that for any
integer expression x, the expression double x can freely be replaced by x + x,
and conversely, that the expression x + x can freely be replaced by double x.
In this manner, when reasoning about programs, function deﬁnitions can be
both applied from left-to-right and unapplied from right-to-left.
However, some care is required when reasoning about functions that are
deﬁned using multiple equations. For example, consider a function that decides
if an integer is zero, deﬁned using two equations:
isZero
::
Int →Bool
isZero 0
=
True
isZero n
=
False
The ﬁrst equation, isZero 0 = True, can freely be viewed as a logical property
that can be applied in both directions. However, this is not the case for the
second equation, isZero n = False. In particular, because the order in which

13.3.
SIMPLE EXAMPLES
165
the equations are written is signiﬁcant, an expression of the form isZero n can
only be replaced by False provided that n ̸= 0, as in the case when n = 0
the ﬁrst equation applies. Dually, it is only valid to unapply the equation
isZero n = False and replace False by an expression of the form isZero n in
the case when n ̸= 0, for the same reason.
More generally, when a function is deﬁned using multiple equations, the
equations cannot be viewed as logical properties in isolation from one another,
but need to be interpreted in light of the order in which patterns are matched
within the equations. For this reason, it is preferable to deﬁne functions in a
manner that does not rely on the order in which their equations are written.
For example, if we rewrite the above deﬁnition using a guard
isZero 0
=
True
isZero n | n ̸= 0
=
False
then it is now explicitly clear that isZero n can only be replaced by False, and
conversely that False can only be replaced by isZero n, when the guard n ̸= 0
is satisﬁed. Patterns that do not rely on the order in which they are matched
are called disjoint or non-overlapping.
In order to simplify the process of
reasoning about programs, it is good practice to use non-overlapping patterns
whenever possible. For example, most of the functions in the standard library
given in appendix A are deﬁned in this manner.
13.3
Simple examples
As a simple example of equational reasoning in Haskell, recall the following
deﬁnition of the library function that reverses a list:
reverse
::
[a ] →[a ]
reverse [ ]
=
[ ]
reverse (x : xs)
=
reverse xs ++ [x ]
Using this deﬁnition, we can show that reverse has no eﬀect on singleton lists,
in the sense that reverse [x ] = [x ] for any element x:
reverse [x ]
=
{ list notation }
reverse (x : [ ])
=
{ applying reverse }
reverse [ ] ++ [x ]
=
{ applying reverse }
[ ] ++ [x ]
=
{ applying ++ }
[x ]
Hence any expression of the form reverse [x ] in a program can freely be
replaced by [x ] without change in meaning, but with a change in eﬃciency by
avoiding the need to apply the reverse function.

166
CHAPTER 13. REASONING ABOUT PROGRAMS
Equational reasoning is often combined with some form of case analysis.
For example, consider the logical negation function:
¬
::
Bool →Bool
¬ False
=
True
¬ True
=
False
Because this function is deﬁned by pattern matching, properties of ¬ are
normally proved by case analysis on its argument.
For example, the fact
that ¬ is its own inverse, ¬ (¬ b) = b for all logical values b, can be shown
by case analysis on the two possible values for b. For example, the case when
b = False is veriﬁed below, and b = True follows similarly:
¬ (¬ False)
=
{ applying the inner ¬ }
¬ True
=
{ applying ¬ }
False
13.4
Induction on numbers
Most interesting functional programs involve some form of recursion. Rea-
soning about such programs normally proceeds using the simple but powerful
technique of induction. Let us begin by recalling the simplest example of a
recursive type, namely the type of natural numbers:
data Nat
=
Zero | Succ Nat
This declaration states that Zero is a value of type Nat (the base case), and
that if n is a value of type Nat then so is Succ n (the recursive case). Implicit
in the declaration is the fact that Zero and Succ are the only constructors for
the type Nat. Hence, the values of Nat can be enumerated as follows:
Zero
Succ Zero
Succ (Succ Zero)
Succ (Succ (Succ Zero))
...
For simplicity, we only consider the ﬁnite natural numbers, obtained by start-
ing with Zero and applying Succ a ﬁnite number of times. In particular, we do
not consider inﬁnity, deﬁned by inf = Succ inf . A similar comment applies
to all the other recursive types that we consider in this chapter.
Now suppose we want to prove that some property, p say, holds for all
(ﬁnite) natural numbers.
Then the principle of induction states that it is
suﬃcient to show that p holds for Zero, called the base case, and that p is

13.4.
INDUCTION ON NUMBERS
167
preserved by Succ, called the inductive case. More precisely, in the inductive
case one is required to show that if the property p holds for any natural
number n, called the induction hypothesis, then it also holds for Succ n.
Why is induction suﬃcient to show that p holds for all natural numbers?
For example, how does it then follow that p holds for Succ (Succ Zero).
Starting from the base case that p holds for Zero, we can apply the inductive
case once to conclude that p holds for Succ Zero, by taking n = Zero, and
then apply the inductive case a second time to conclude that p holds for
Succ (Succ Zero), by taking n = Succ Zero. In a similar manner, it can be
established that p holds for any natural number.
It is useful to drawn an analogy with the "domino eﬀect". Suppose there
is a line of dominoes standing on end and you know that the ﬁrst domino will
fall, and that whenever a domino falls then its next neighbour will also fall.
Then it is clear that all the dominoes will fall, by applying the ﬁrst fact to get
the process started, and repeatedly applying the second to keep it going. The
same pattern of reasoning occurs with induction: we ﬁrst verify the required
property for Zero (the ﬁrst domino falls), then that the property is preserved
by Succ (if any domino falls then so will its neighbour), and conclude that the
property holds for all natural numbers (all dominoes fall).
As a concrete example, consider the deﬁnition of a recursive function that
takes two natural numbers and adds them together:
add
::
Nat →Nat →Nat
add Zero m
=
m
add (Succ n) m
=
Succ (add n m)
From the ﬁrst equation it is immediate that add Zero m = m holds for any
natural number m. Now let us show that the dual property, add n Zero = n,
which we abbreviate by p, also holds for all natural numbers n. We proceed
by induction on n. The base case, showing that p Zero holds, amounts to
showing that add Zero Zero = Zero, which is immediate:
add Zero Zero
=
{ applying add }
Zero
For the inductive case, we must show that if p holds for any natural num-
ber n, then p (Succ n) also holds. That is, using the induction hypothesis
add n Zero = n as an assumption, we must show that add (Succ n) Zero =
Succ n, which can be veriﬁed by the following calculation:
add (Succ n) Zero
=
{ applying add }
Succ (add n Zero)
=
{ induction hypothesis }
Succ n

168
CHAPTER 13. REASONING ABOUT PROGRAMS
⊓⊔
Because proofs by induction normally involve more than one calculation, it is
useful to explicitly indicate the end of the proof. For this purpose, we use a
square box ⊓⊔in the right-hand margin, as illustrated above.
As another example, let us now show that addition of natural numbers
is associative. That is, add x (add y z) = add (add x y) z for all natural
numbers x, y and z. There are three arguments to choose from, so which
should induction be performed over? Note that the add function is deﬁned by
pattern matching on its ﬁrst argument, so it is natural to try induction on x,
which appears twice as the ﬁrst argument to add in the associativity equation,
whereas y only appears once as such and z never. Using induction on x, the
proof of the associativity of add proceeds as follows.
Base case:
add Zero (add y z)
=
{ applying the outer add }
add y z
=
{ unapplying add }
add (add Zero y) z
Inductive case:
add (Succ x) (add y z)
=
{ applying the outer add }
Succ (add x (add y z))
=
{ induction hypothesis }
Succ (add (add x y) z)
=
{ unapplying the outer add }
add (Succ (add x y) z)
=
{ unapplying the inner add }
add (add (Succ x) y) z
⊓⊔
Note that both cases start by applying deﬁnitions, and conclude by unapplying
deﬁnitions.
This pattern is typical in proofs by induction, but the latter
part may seem somewhat mysterious at ﬁrst. In particular, knowing which
deﬁnitions to unapply seems to require a degree of foresight.
In practice,
however, if one becomes stuck at a certain point during such a calculation,
progress can often be made by focusing on the desired end result and trying
to work backwards to the point where one became stuck.
For example, after applying the induction hypothesis in the inductive case
above to obtain Succ (add (add x y) z), it may not be clear how to proceed,
as there are no more deﬁnitions that can be applied. However, if we then
focus on the expression that we are aiming towards, add (add (Succ x) y) z,
we can simply apply the inner add and then the outer add to produce the
expression at which we became stuck, which process can then be reversed
(turning applying into unapplying) to complete the calculation.

13.5.
INDUCTION ON LISTS
169
Although we have introduced induction using the recursive type Nat, the
same principle can also be used with the integers that are built-in to Haskell.
In particular, to prove that some property p holds for all integers n ⩾0, it is
suﬃcient to show that p holds for 0, the base case, and that if p holds for any
n ⩾0 then it also holds for n + 1, the inductive case.
For example, consider the following deﬁnition for the library function
replicate that produces a list with n identical elements:
replicate
::
Int →a →[a ]
replicate 0
=
[ ]
replicate (n + 1) x
=
x : replicate n x
Then it is easy to show that this function does indeed produce a list with n
elements, that is length (replicate n x) = n, by induction on n ⩾0.
Base case:
length (replicate 0 x)
=
{ applying replicate }
length [ ]
=
{ applying length }
0
Inductive case:
length (replicate (n + 1) x)
=
{ applying replicate }
length (x : replicate n x)
=
{ applying length }
1 + length (replicate n x)
=
{ induction hypothesis }
1 + n
=
{ commutativity of + }
n + 1
⊓⊔
13.5
Induction on lists
Induction is not restricted to natural numbers, but can also be used to reason
about other recursive types, such as the type of lists. Just as natural numbers
are built up recursively from zero by applying the successor function, so lists
are built up from the empty list by applying the cons operator.
Suppose we want to prove that some property p holds for all lists. Then
the induction principle for lists states that it is suﬃcient to show that p holds
for the empty list [ ], the base case, and that if p holds for any list xs then it
also holds for x : xs for any element x, the inductive case. Of course, both the
element x and the list xs must be of the appropriate types.

170
CHAPTER 13. REASONING ABOUT PROGRAMS
As an example, let us show that the function reverse deﬁned earlier in this
chapter is its own inverse, reverse (reverse xs) = xs, by induction on xs. The
base case is veriﬁed simply by applying the deﬁnition of reverse:
reverse (reverse [ ])
=
{ applying the inner reverse }
reverse [ ]
=
{ applying reverse }
[ ]
For the inductive case, using the assumption reverse (reverse xs) = xs, we
show that reverse (reverse (x : xs)) = x : xs, as follows:
reverse (reverse (x : xs))
=
{ applying the inner reverse }
reverse (reverse xs ++ [x ])
=
{ distributivity - see below }
reverse [x ] ++ reverse (reverse xs)
=
{ singleton lists - see below }
[x ] ++ reverse (reverse xs)
=
{ induction hypothesis }
[x ] ++ ys
=
{ applying ++ }
x : xs
⊓⊔
This calculation uses two auxiliary properties of the function reverse, namely
our earlier result that reverse preserves singleton lists, reverse [x ] = [x ],
together with a new result that reverse distributes over append, except that
the order of the two argument lists is then swapped:
reverse (xs ++ ys)
=
reverse ys ++ reverse xs
Technically, we say that the distribution is contravariant. Because the append
operator ++ is deﬁned by pattern matching on its ﬁrst argument, it is natural
to attempt to verify this property by induction on xs.
Base case:
reverse ([ ] ++ ys)
=
{ applying ++ }
reverse ys
=
{ unapplying ++ }
[ ] ++ reverse ys
=
{ unapplying reverse }
reverse [ ] ++ reverse ys
Inductive case:

13.6.
MAKING APPEND VANISH
171
reverse ((x : xs) ++ ys)
=
{ applying ++ }
reverse (x : (xs ++ ys))
=
{ applying reverse }
reverse (xs ++ ys) ++ [x ]
=
{ induction hypothesis }
(reverse ys ++ reverse xs) ++ [x ]
=
{ associativity of ++ }
reverse ys ++ (reverse xs ++ [x ])
=
{ unapplying the second reverse }
reverse ys ++ reverse (x : xs)
⊓⊔
This calculation in turn uses the fact that ++ is associative, which can be
veriﬁed by induction in a similar manner to our earlier result that add is
associative (see exercise 5 for this chapter.)
13.6
Making append vanish
Many recursive functions are naturally deﬁned using the append operator ++
on lists, but this operator carries a considerable eﬃciency cost when used
recursively. In this section, we show how induction can be used to eliminate
such uses of append, and hence make functions more eﬃcient.
As a ﬁrst
example, consider again the following deﬁnition:
reverse
::
[a ] →[a ]
reverse [ ]
=
[ ]
reverse (x : xs)
=
reverse xs ++ [x ]
How eﬃcient is reverse? First of all, it is easy to show that the number of
reduction steps required to evaluate xs ++ ys is one greater than the length of
xs, assuming for simplicity that both xs and ys are already fully evaluated. As
a result, we say that ++ takes linear time in the length of its ﬁrst argument. In
turn, the number of steps required by reverse xs for a list of length n can be
shown to be the sum of the integers from 1 to n + 1, which is (n + 1)(n + 2)/2.
Multiplying out the brackets using the equation veriﬁed at the start of this
chapter gives (n2 + 3n + 2)/2, as a result of which we say that that reverse
takes quadratic time in the length of its argument.
Quadratic time is bad. For example, reversing a list with ten thousand
elements will take approximately ﬁfty million reduction steps. Fortunately,
however, through the use of induction it is easy to eliminate the use of append
in the deﬁnition of reverse, and hence improve its eﬃciency.
The trick is to attempt to deﬁne a more general function, which combines
the behaviours of reverse and ++. In particular, we seek to deﬁne a recursive
function reverse′ that satisﬁes the following equation:
reverse′ xs ys
=
reverse xs ++ ys

172
CHAPTER 13. REASONING ABOUT PROGRAMS
That is, applying reverse′ to two lists should give the result of reversing the
ﬁrst list, appended together with the second list.
If we can deﬁne such a
function, then reverse itself can be redeﬁned by reverse xs = reverse′ xs [ ],
using the fact that the empty list is the identity for append.
Rather the giving the deﬁnition for reverse′, and then showing that it sat-
isﬁes the above equation, we can in fact use this equation as the driving force
for constructing the deﬁnition itself. In particular, we simply attempt to verify
this equation by induction on xs. The base case results in an equation that
gives the deﬁnition for reverse′ [ ] ys, while the inductive case results in an
equation that gives the deﬁnition for reverse′ (x : xs) ys.
Base case:
reverse′ [ ] ys
=
{ speciﬁcation of reverse′ }
reverse [ ] ++ ys
=
{ applying reverse }
[ ] ++ ys
=
{ applying ++ }
ys
Inductive case:
reverse′ (x : xs) ys
=
{ speciﬁcation of reverse′ }
reverse (x : xs) ++ ys
=
{ applying reverse }
(reverse xs ++ [x ]) ++ ys
=
{ associativity of ++ }
reverse xs ++ ([x ] ++ ys)
=
{ induction hypothesis }
reverse′ xs ([x ] ++ ys)
=
{ applying ++ }
reverse′ xs (x : ys)
⊓⊔
We conclude from this proof that the deﬁnition
reverse′
::
[a ] →[a ] →[a ]
reverse′ [ ] ys
=
ys
reverse′ (x : xs) ys
=
reverse′ xs (x : ys)
suﬃces to show that reverse′ xs ys = reverse xs ++ ys by induction. Note that
the deﬁnition for reverse′ does not refer to the original reverse function, or
append. Hence, reverse itself can now be redeﬁned as follows:
reverse
::
[a ] →[a ]
reverse xs
=
reverse′ xs [ ]
For example, we have:

13.6.
MAKING APPEND VANISH
173
reverse [1, 2, 3]
=
{ applying reverse }
reverse′ [1, 2, 3] [ ]
=
{ applying reverse′ }
reverse′ [2, 3] (1 : [ ])
=
{ applying reverse′ }
reverse′ [3] (2 : (1 : [ ]))
=
{ applying reverse′ }
reverse′ [ ] (3 : (2 : (1 : [ ])))
=
{ applying reverse′ }
3 : (2 : (1 : [ ]))
That is, the list is reversed by using an extra argument to accumulate the
ﬁnal result.
The new deﬁnition for reverse is perhaps less clear than the
original version, but it is much more eﬃcient. In particular, the number of
reduction steps required to evaluate reverse xs for a list of length n using the
new deﬁnition is simply n + 2, and hence reverse now takes linear time in
the length of its argument. For example, reversing a list with ten thousand
elements will now take approximately ten thousand steps, in contrast to some
ﬁfty million with the original deﬁnition — quite an improvement!
Note that we have already seen the use of accumulation to improve the
eﬃciency of functions, in the context of the higher-order library function foldl
in chapters 7 and 12. For example, the accumulator version of reverse can also
be obtained simply by deﬁning reverse = foldl (:) [ ]. However, it is instructive
to see how the same kind of behaviour can be obtained using induction.
As another example of the elimination of append, which also illustrates
the use of induction on trees-like types, consider the following type of binary
trees, together with a function that ﬂattens such trees to a list:
data Tree
=
Leaf Int | Node Tree Tree
ﬂatten
::
Tree →[Int ]
ﬂatten (Leaf n)
=
[n ]
ﬂatten (Node l r)
=
ﬂatten l ++ ﬂatten r
Because of the use of append, the function ﬂatten is ineﬃcient. Let us now
construct a more eﬃcient version, by using the same trick as for reverse.
That is, we seek to deﬁne a more general function, ﬂatten′, that combines the
behaviours of the functions ﬂatten and ++:
ﬂatten′ t ns
=
ﬂatten t ++ ns
In order to prove that some property holds for all trees, the induction prin-
ciple for the type Tree states that it is suﬃcient to show that it holds for all
trees of the form Leaf n, and that if the property holds for any trees l and r
then it also holds for Node l r. Using this principle, we construct a deﬁnition
for ﬂatten′ that satisﬁes the above equation as follows.
Base case:

174
CHAPTER 13. REASONING ABOUT PROGRAMS
ﬂatten′ (Leaf n) ns
=
{ speciﬁcation of ﬂatten′ }
ﬂatten (Leaf n) ++ ns
=
{ applying ﬂatten }
[n ] ++ ns
=
{ applying ++ }
n : ns
Inductive case:
ﬂatten′ (Node l r) ns
=
{ speciﬁcation of ﬂatten′ }
(ﬂatten l ++ ﬂatten r) ++ ns
=
{ associativity of ++ }
ﬂatten l ++ (ﬂatten r ++ ns)
=
{ induction hypothesis for l }
ﬂatten′ l (ﬂatten r ++ ns)
=
{ induction hypothesis for r }
ﬂatten′ l (ﬂatten′ r ns)
⊓⊔
We conclude that the deﬁnition
ﬂatten′
::
Tree →[Int ] →[Int ]
ﬂatten′ (Leaf n) ns
=
n : ns
ﬂatten′ (Node l r) ns
=
ﬂatten′ l (ﬂatten′ r ns)
satisﬁes the speciﬁcation for ﬂatten′, and hence that the original function
ﬂatten can now be redeﬁned as follows:
ﬂatten
::
Tree →[Int ]
ﬂatten t
=
ﬂatten′ t [ ]
Once again, the new deﬁnition for ﬂatten is perhaps less clear than the original
version, but is much more eﬃcient, by using an extra argument to accumulate
the ﬁnal result, rather than using append.
13.7
Compiler correctness
We conclude this chapter with an extended example. Recall that in chapter 10
we deﬁned a type of arithmetic expressions built up from integers using an
addition operator, together with a function (here called eval) that evaluates
an expression directly to an integer value:
data Expr
=
Val Int | Add Expr Expr
eval
::
Expr →Int
eval (Val n)
=
n
eval (Add x y)
=
eval x + eval y

13.7.
COMPILER CORRECTNESS
175
Such expressions can also be evaluated indirectly, by means of code that ex-
ecutes using a stack. In this context, a stack is simply a list of integers, and
code comprises a list of push and add operations on the stack:
type Stack
=
[Int ]
type Code
=
[Op]
data Op
=
PUSH Int | ADD
The meaning of such code is given by deﬁning a function that executes a
piece of code using an initial stack to give a ﬁnal stack:
exec
::
Code →Stack →Stack
exec [ ] s
=
s
exec (PUSH n : c) s
=
exec c (n : s)
exec (ADD : c) (m : n : s)
=
exec c (n + m : s)
That is, the push operation places a new integer on the top of the stack, while
add replaces the top two integers by their sum. Using these operations, it
is now straightforward to deﬁne a function that compiles an expression into
code. An integer value is compiled by simply pushing that value, while an
addition is compiled by ﬁrst compiling the two argument expressions x and y,
and then adding the resulting two integers on the stack:
comp
::
Expr →Code
comp (Val n)
=
[PUSH n ]
comp (Add x y)
=
comp x ++ comp y ++ [ADD ]
Note that when an add operation is performed, the value of expression y will
be the top of the stack, and the value of x will be the second top, hence the
swapping of these two values in the deﬁnition of exec.
To illustrate the behaviour of the three functions deﬁned above, if e ::Expr
represents to the expression (2 + 3) + 4, then we have:
> eval e
9
> comp e
[PUSH 2, PUSH 3, ADD, PUSH 4, ADD ]
> exec (comp e) [ ]
[9]
Generalising from this example, the correctness of our compiler for expres-
sions can be expressed by the following equation:
exec (comp e) [ ]
=
[eval e ]

176
CHAPTER 13. REASONING ABOUT PROGRAMS
That is, compiling an expression and then executing the resulting code using an
empty initial stack gives the same ﬁnal stack as evaluating the expression and
then converting the resulting integer into a singleton stack. For the purposes
of proving this result, however, we will see that it is necessary to generalise
from the empty initial stack to an arbitrary initial stack:
exec (comp e) s
=
eval e : s
Using induction for the type Expr, which is the same as induction for the type
Tree in the previous section except that the names of the constructors are
diﬀerent, the compiler correctness equation can be veriﬁed as follows.
Base case:
exec (comp (Val n)) s
=
{ applying comp }
exec [PUSH n ] s
=
{ applying exec }
n : s
=
{ unapplying eval }
eval (Val n) : s
Inductive case:
exec (comp (Add x y)) s
=
{ applying comp }
exec (comp x ++ comp y ++ [ADD ]) s
=
{ associativity of ++ }
exec (comp x ++ (comp y ++ [ADD ])) s
=
{ distributivity - see below }
exec (comp y ++ [ADD ]) (exec (comp x) s)
=
{ induction hypothesis for x }
exec (comp y ++ [ADD ]) (eval x : s)
=
{ distributivity again }
exec [ADD ] (exec (comp y) (eval x : s))
=
{ induction hypothesis for y }
exec [ADD ] (eval y : eval x : s)
=
{ applying exec }
(eval x + eval y) : s
=
{ unapplying eval }
eval (Add x y) : s
⊓⊔
Note that without having generalised the result to an arbitrary stack, the
second induction hypothesis step would not be applicable, because the stack
becomes non-empty at this point.
The distributivity property used in the

13.7.
COMPILER CORRECTNESS
177
inductive case states that executing two pieces of code appended together
gives the same result as executing the two pieces of code in sequence:
exec (c ++ d) s
=
exec d (exec c s)
The proof of this property proceeds by induction on the code c, with the in-
ductive case being split into two separate cases, depending upon whether the
ﬁrst operation in the code is a push or an addition.
Base case:
exec ([ ] ++ d) s
=
{ applying ++ }
exec d s
=
{ unapplying exec }
exec d (exec [ ] s)
Inductive case:
exec ((PUSH n : c) ++ d) s
=
{ applying ++ }
exec (PUSH n : (c ++ d)) s
=
{ applying exec }
exec (c ++ d) (n : s)
=
{ induction hypothesis }
exec d (exec c (n : s))
=
{ unapplying exec }
exec d (exec (PUSH n : c) s)
Inductive case:
exec ((ADD : c) ++ d) s
=
{ applying ++ }
exec (ADD : (c ++ d)) s
=
{ assume s of the form m : n : s′ }
exec (ADD : (c ++ d)) (m : n : s′)
=
{ applying exec }
exec (c ++ d) (n + m : s′)
=
{ induction hypothesis }
exec d (exec c (n + m : s′))
=
{ unapplying exec }
exec ys (exec (ADD : c) (m : n : s′))
⊓⊔
The stack not having the assumed form in the second inductive case corre-
sponds to a stack underﬂow error. In practice, this will never arise, because
the structure of the compiler ensures that the stack will always contain at least
two integers when an add operation is performed.

178
CHAPTER 13. REASONING ABOUT PROGRAMS
In fact, however, both the distributivity property and its consequent under-
ﬂow issue can be avoided altogether by applying the technique of the previous
section to eliminate the use of append.
In particular, we seek to deﬁne a
generalised function comp′ with the following property:
comp′ e c
=
comp e ++ c
By induction on e, we can construct the deﬁnition
comp′
::
Expr →Code →Code
comp′ (Val n) c
=
PUSH n : c
comp′ (Add x y) c
=
comp′ x (comp′ y (ADD : c))
from which it follows that we can recover our original deﬁnition by comp e =
comp′ e [ ]. In turn, the correctness of the new version of the compiler with
respect to our semantics can now be stated as follows:
exec (comp′ e c) s
=
exec c (eval e : s)
That is, compiling an expression and then executing the resulting code to-
gether with arbitrary additional code gives the same result as executing the
additional code with the value of the expression on top of the original stack.
The proof of this result is by induction on the expression e.
Base case:
exec (comp′ (Val n) c) s
=
{ applying comp′ }
exec (PUSH n : c) s
=
{ applying exec }
exec c (n : s)
=
{ unapplying eval }
exec c (eval (Val n) : s)
Inductive case:
exec (comp′ (Add x y) c) s
=
{ applying comp′ }
exec (comp′ x (comp′ y (ADD : c))) s
=
{ induction hypothesis for x }
exec (comp′ y (ADD : c)) (eval x : s)
=
{ induction hypothesis for y }
exec (ADD : c) (eval y : eval x : s)
=
{ applying exec }
exec c ((eval x + eval y) : s)
=
{ unapplying eval }
exec c (eval (Add x y) : s)

13.8.
CHAPTER REMARKS
179
⊓⊔
Note that with s = c = [ ], this new result simpliﬁes to exec (comp e) [ ] =
[eval e ], our original statement of correctness. In addition to avoiding the
problem of stack underﬂow in the correctness proof, the accumulator version
of the compiler has two further beneﬁts. First of all, it avoids the use of ++,
and is hence more eﬃcient. And secondly, the new proof is less than half the
combined length of our previous two proofs. As is often the case in formal
reasoning, generalising a result in the appropriate manner can considerably
simplify its proof. Mathematics is an excellent tool for guiding the develop-
ment of eﬃcient programs with simple proofs!
13.8
Chapter remarks
Reasoning about functional programs is a subject for a book in its own right,
and we have only touched the surface here. Topics for further reading include
reasoning about partial and inﬁnite structures [5, 8], relational and point-free
approaches [1], automated testing of properties [4], reasoning about eﬀects [25],
and techniques that avoid induction [15]. The compiler example is adapted
from [19], and the phrase "making append vanish" is inspired by [31].
13.9
Exercises
1. Give an example of a function from the standard library in appendix A
that is deﬁned using overlapping patterns.
2. Show that add n (Succ m) = Succ (add n m), by induction on n.
3. Using this property, together with add n Zero = n, show that addition
is commutative, add n m = add m n, by induction on n.
4. Using the following deﬁnition for the library function that decides if all
elements of a list satisfy a predicate
all p [ ]
=
True
all p (x : xs)
=
p x ∧all p xs
complete the proof of the correctness of replicate by showing that it
produces a list with identical elements, all (== x) (replicate n x), by
induction on n ⩾0. Hint: show that the property is always True.
5. Using the deﬁnition
[ ] ++ ys
=
ys
(x : xs) ++ ys
=
x : (xs ++ ys)
verify the following two properties, by induction on xs:
xs ++ [ ]
=
xs
xs ++ (ys ++ zs)
=
(xs ++ ys) ++ zs

180
CHAPTER 13. REASONING ABOUT PROGRAMS
Hint: the proofs are similar to those for the add function.
6. The equation reverse (reverse xs) = xs can also be proved using a single
auxiliary result, reverse (xs ++ [x ]) = x : reverse xs, which can itself be
veriﬁed by induction on xs. Why might the proof using three auxiliary
results as in this chapter be viewed as preferable?
7. Using the deﬁnitions
map f [ ]
=
[ ]
map f (x : xs)
=
f x : map f xs
(f ◦g) x
=
f (g x)
show that map f (map g xs) = map (f ◦g) xs, by induction on xs.
8. Using the deﬁnition for ++ given above, together with
take 0
=
[ ]
take (n + 1) [ ]
=
[ ]
take (n + 1) (x : xs)
=
x : take n xs
drop 0 xs
=
xs
drop (n + 1) [ ]
=
[ ]
drop (n + 1) ( : xs)
=
drop n xs
show that take n xs ++drop n xs = xs, by simultaneous induction on the
integer n ⩾0 and the list xs. Hint: there are three cases, one for each
pattern of arguments in the deﬁnitions of take and drop.
9. Given the type declaration
data Tree
=
Leaf Int | Node Tree Tree
show that the number of leaves in a such a tree is always one greater
than the number of nodes, by induction on trees. Hint: start by deﬁning
functions that count the number of leaves and nodes in a tree.
10. Given the equation comp′ e c = comp e ++ c, show how to construct the
recursive deﬁnition for comp′, by induction on e.

Appendix A
Standard Prelude
In this appendix we present some of the most commonly used deﬁnitions from
the standard prelude. For clarity, a number of the deﬁnitions have been sim-
pliﬁed or modiﬁed from those given in the Haskell Report [26].
A.1
Classes
Equality types:
class Eq a where
(==), (̸=)
:: a →a →Bool
x ̸= y
= ¬ (x == y)
Ordered types:
class Eq a ⇒Ord a where
(<), (⩽), (>), (⩾)
:: a →a →Bool
min, max
:: a →a →a
min x y | x ⩽y
= x
| otherwise
= y
max x y | x ⩽y
= y
| otherwise
= x
Showable types:
class Show a where
show
:: a →String
Readable types:
class Read a where
read
:: String →a
Numeric types:
181

182
APPENDIX A. STANDARD PRELUDE
class (Eq a, Show a) ⇒Num a where
(+), (−), (∗)
:: a →a →a
negate, abs, signum
:: a →a
Integral types:
class Num a ⇒Integral a where
div, mod
:: a →a →a
Fractional types:
class Num a ⇒Fractional a where
(/)
:: a →a →a
recip
:: a →a
recip n
= 1 / n
Monadic types:
class Monad m where
return
:: a →m a
(>>=)
:: m a →(a →m b) →m b
A.2
Logical values
Type declaration:
data Bool
= False | True
deriving (Eq, Ord, Show, Read)
Logical conjunction:
(∧)
:: Bool →Bool →Bool
False ∧
= False
True ∧b
= b
Logical disjunction:
(∨)
:: Bool →Bool →Bool
False ∨b
= b
True ∨
= True
Logical negation:
¬
:: Bool →Bool
¬ False
= True
¬ True
= False
Guard that always succeeds:
otherwise
:: Bool
otherwise
= True

A.3. CHARACTERS AND STRINGS
183
A.3
Characters and strings
Type declarations:
data Char
= · · ·
deriving (Eq, Ord, Show, Read)
type String
= [Char ]
Decide if a character is a lower-case letter:
isLower
:: Char →Bool
isLower c
= c ⩾'a' ∧c ⩽'z'
Decide if a character is an upper-case letter:
isUpper
:: Char →Bool
isUpper c
= c ⩾'A' ∧c ⩽'Z'
Decide if a character is alphabetic:
isAlpha
:: Char →Bool
isAlpha c
= isLower c ∨isUpper c
Decide if a character is a digit:
isDigit
:: Char →Bool
isDigit c
= c ⩾'0' ∧c ⩽'9'
Decide if a character is alpha-numeric:
isAlphaNum
:: Char →Bool
isAlphaNum c
= isAlpha c ∨isDigit c
Decide if a character is spacing:
isSpace
:: Char →Bool
isSpace c
= elem c "␣\t\n"
Convert a character to a Unicode number:
ord
:: Char →Int
ord c
= · · ·
Convert a Unicode number to a character:
chr
:: Int →Char
chr n
= · · ·
Convert a digit to an integer:

184
APPENDIX A. STANDARD PRELUDE
digitToInt
:: Char →Int
digitToInt c | isDigit c
= ord c −ord '0'
Convert an integer to a digit:
intToDigit
:: Int →Char
intToDigit n
| n ⩾0 ∧n ⩽9
= chr (ord '0' + n)
Convert a letter to lower-case:
toLower
:: Char →Char
toLower c | isUpper c
= chr (ord c −ord 'A' + ord 'a')
| otherwise
= c
Convert a letter to upper-case:
toUpper
:: Char →Char
toUpper c | isLower c
= chr (ord c −ord 'a' + ord 'A')
| otherwise
= c
A.4
Numbers
Type declarations:
data Int
= · · ·
deriving (Eq, Ord, Show, Read,
Num, Integral)
data Integer
= · · ·
deriving (Eq, Ord, Show, Read,
Num, Integral)
data Float
= · · ·
deriving (Eq, Ord, Show, Read,
Num, Fractional)
Decide if an integer is even:
even
:: Integral a ⇒a →Bool
even n
= n 'mod' 2 == 0
Decide if an integer is odd:
odd
:: Integral a ⇒a →Bool
odd
= ¬ ◦even
Exponentiation:
(↑)
:: (Num a, Integral b) ⇒a →b →a
↑0
= 1
x ↑(n + 1)
= x ∗(x ↑n)

A.5. TUPLES
185
A.5
Tuples
Type declarations:
data ()
= · · ·
deriving (Eq, Ord, Show, Read)
data (a, b)
= · · ·
deriving (Eq, Ord, Show, Read)
data (a, b, c)
= · · ·
deriving (Eq, Ord, Show, Read)
...
Select the ﬁrst component of a pair:
fst
:: (a, b) →a
fst (x, )
= x
Select the second component of a pair:
snd
:: (a, b) →b
snd ( , y)
= y
A.6
Maybe
Type declaration:
data Maybe a
= Nothing | Just a
deriving (Eq, Ord, Show, Read)
A.7
Lists
Type declaration:
data [a ]
= [ ] | a : [a ]
deriving (Eq, Ord, Show, Read)
Decide if a list is empty:
null
:: [a ] →Bool
null [ ]
= True
null ( : )
= False
Decide if a value is an element of a list:
elem
:: Eq a ⇒a →[a ] →Bool
elem x xs
= any (== x) xs
Decide if all logical values in a list are True:

186
APPENDIX A. STANDARD PRELUDE
and
:: [Bool ] →Bool
and
= foldr (∧) True
Decide if any logical value in a list is False:
or
:: [Bool ] →Bool
or
= foldr (∨) False
Decide if all elements of a list satisfy a predicate:
all
:: (a →Bool) →[a ] →Bool
all p
= and ◦map p
Decide if any element of a list satisﬁes a predicate:
any
:: (a →Bool) →[a ] →Bool
any p
= or ◦map p
Select the ﬁrst element of a non-empty list:
head
:: [a ] →a
head (x : )
= x
Select the last element of a non-empty list:
last
:: [a ] →a
last [x ]
= x
last ( : xs)
= last xs
Select the nth element of a non-empty list:
(!!)
:: [a ] →Int →a
(x : ) !! 0
= x
( : xs) !! (n + 1)
= xs !! n
Select the ﬁrst n elements of a list:
take
:: Int →[a ] →[a ]
take 0
= [ ]
take (n + 1) [ ]
= [ ]
take (n + 1) (x : xs)
= x : take n xs
Select all elements of a list that satisfy a predicate:
ﬁlter
:: (a →Bool) →[a ] →[a ]
ﬁlter p xs
= [x | x ←xs, p x ]
Select elements of a list while they satisfy a predicate:
takeWhile
:: (a →Bool) →[a ] →[a ]
takeWhile
[ ]
= [ ]
takeWhile p (x : xs)
| p x
= x : takeWhile p xs
| otherwise
= [ ]

A.7. LISTS
187
Remove the ﬁrst element from a non-empty list:
tail
:: [a ] →[a ]
tail ( : xs)
= xs
Remove the last element from a non-empty list:
init
:: [a ] →[a ]
init [ ]
= [ ]
init (x : xs)
= x : init xs
Remove the ﬁrst n elements from a list:
drop
:: Int →[a ] →[a ]
drop 0 xs
= xs
drop (n + 1) [ ]
= [ ]
drop (n + 1) ( : xs)
= drop n xs
Remove elements from a list while they satisfy a predicate:
dropWhile
:: (a →Bool) →[a ] →[a ]
dropWhile
[ ]
= [ ]
dropWhile p (x : xs)
| p x
= dropWhile p xs
| otherwise
= x : xs
Split a list at the nth element:
splitAt
:: Int →[a ] →([a ], [a ])
splitAt n xs
= (take n xs, drop n xs)
Split a list using a predicate:
span
:: (a →Bool) →[a ] →([a ], [a ])
span p xs
= (takeWhile p xs, dropWhile p xs)
Process a list using an operator that associates to the right:
foldr
:: (a →b →b) →b →[a ] →b
foldr
v [ ]
= v
foldr f v (x : xs)
= f x (foldr f v xs)
Process a non-empty list using an operator that associates to the right:
foldr1
:: (a →a →a) →[a ] →a
foldr1
[x ]
= x
foldr1 f (x : xs)
= f x (foldr1 f xs)
Process a list using an operator that associates to the left:
foldl
:: (a →b →a) →a →[b] →a
foldl
v [ ]
= v
foldl f v (x : xs)
= foldl f (f v x) xs

188
APPENDIX A. STANDARD PRELUDE
Process a non-empty list using an operator that associates to the left:
foldl1
:: (a →a →a) →[a ] →a
foldl1 f (x : xs)
= foldl f x xs
Produce an inﬁnite list of identical elements:
repeat
:: a →[a ]
repeat x
= xs where xs = x : xs
Produce a list with n identical elements:
replicate
:: Int →a →[a ]
replicate n
= take n ◦repeat
Produce an inﬁnite list by iterating a function over a value:
iterate
:: (a →a) →a →[a ]
iterate f x
= x : iterate f (f x)
Produce a list of pairs from a pair of lists:
zip
:: [a ] →[b] →[(a, b)]
zip [ ]
= [ ]
zip
[ ]
= [ ]
zip (x : xs) (y : ys)
= (x, y) : zip xs ys
Calculate the length of a list:
length
:: [a ] →Int
length
= foldl (λn
→n + 1) 0
Calculate the sum of a list of numbers:
sum
:: Num a ⇒[a ] →a
sum
= foldl (+) 0
Calculate the product of a list of numbers:
product
:: Num a ⇒[a ] →a
product
= foldl (∗) 1
Calculate the minimum of a non-empty list:
minimum
:: Ord a ⇒[a ] →a
minimum
= foldl1 min
Calculate the maximum of a non-empty list:
maximum
:: Ord a ⇒[a ] →a
maximum
= foldl1 max
Append two lists:

A.8. FUNCTIONS
189
(++)
:: [a ] →[a ] →[a ]
[ ] ++ ys
= ys
(x : xs) ++ ys
= x : (xs ++ ys)
Concatenate a list of lists:
concat
:: [[a ]] →[a ]
concat
= foldr (++) [ ]
Reverse a list:
reverse
:: [a ] →[a ]
reverse
= foldl (λxs x →x : xs) [ ]
Apply a function to all elements of a list:
map
:: (a →b) →[a ] →[b]
map f xs
= [f x | x ←xs ]
A.8
Functions
Type declaration:
data a →b
= · · ·
Identity function:
id
:: a →a
id
= λx →x
Function composition:
(◦)
:: (b →c) →(a →b) →(a →c)
f ◦g
= λx →f (g x)
Constant functions:
const
:: a →(b →a)
const x
= λ
→x
Strict application:
($!)
:: (a →b) →a →b
f $! x
= · · ·
Convert a function on pairs to a curried function:
curry
:: ((a, b) →c) →(a →b →c)
curry f
= λx y →f (x, y)
Convert a curried function to a function on pairs:
uncurry
:: (a →b →c) →((a, b) →c)
uncurry f
= λ(x, y) →f x y

190
APPENDIX A. STANDARD PRELUDE
A.9
Input/Output
Type declaration:
data IO a
= · · ·
Read a character from the keyboard:
getChar
::
IO Char
getChar
=
· · ·
Read a string from the keyboard:
getLine
::
IO String
getLine
=
do x ←getChar
if x == '\n' then
return ""
else
do xs ←getLine
return (x : xs)
Read a value from the keyboard:
readLn
::
Read a ⇒IO a
readLn
=
do xs ←getLine
return (read xs)
Write a character to the screen:
putChar
::
Char →IO ()
putChar c
=
· · ·
Write a string to the screen:
putStr
::
String →IO ()
putStr ""
=
return ()
putStr (x : xs)
=
do putChar x
putStr xs
Write a string to the screen and move to a new line:
putStrLn
::
String →IO ()
putStrLn xs
=
do putStr xs
putChar '\n'
Write a value to the screen:
print
::
Show a ⇒a →IO ()
print
=
putStrLn ◦show
Display an error message and terminate the program:
error
::
String →a
error xs
=
· · ·

Appendix B
Symbol Table
In this appendix we present a table that summarises the meaning of each of
the special Haskell symbols that are used in this book, and shows how each of
the symbols is typed using a normal keyboard.
Symbol
Meaning
Typed
→
maps to
->
⇒
class constraint
=>
⩾
at least
>=
⩽
at most
<=
̸=
inequality
/=
∧
conjunction
&&
∨
disjunction
||
¬
negation
not
↑
exponentiation
^
◦
composition
.
λ
abstraction
\
++
append
++
←
drawn from
<-
>>=
sequencing
>>=
+++
choice
+++
191

192
APPENDIX B. SYMBOL TABLE

Bibliography
[1] Richard Bird and Oege de Moor. Algebra of Programming. Prentice Hall,
1997.
[2] Richard Bird and Shin-Cheng Mu. Countdown: A Case Study in Origami
Programming. University of Oxford, 2005.
[3] Richard Bird and Philip Wadler. An Introduction to Functional Program-
ming. Prentice Hall, 1988.
[4] Koen Claessen and John Hughes. QuickCheck: A Lightweight Tool for
Random Testing of Haskell Programs. In Proceedings of the Fifth ACM
SIGPLAN International Conference on Functional Programming, Mon-
treal, Canada, September 2000.
[5] Nils Anders Danielsson and Patrik Jansson. Chasing Bottoms: A Case
Study in Program Veriﬁcation in the Presense of Partial and Inﬁnite Val-
ues. In Proceedings of the 7th International Conference on Mathematics
of Program Construction, volume 3125 of Lecture Notes in Computer Sci-
ence, Stirling, Scotland, July 2004. Springer.
[6] Karl-Filip Fax´en. A Static Semantics for Haskell. In Graham Hutton, edi-
tor, Journal of Functional Programming, Special Double Issue on Haskell,
volume 12(4&5). Cambridge University Press, July 2002.
[7] Jeremy Gibbons and Oege de Moor, editors. The Fun of Programming.
Palgrave, March 2003.
[8] Jeremy Gibbons and Graham Hutton. Proof Methods for Corecursive
Programs. Fundamenta Informaticae Special Issue on Program Transfor-
mation, 66(4):353-366, April-May 2005.
[9] Andy Gill and Simon Marlow. Happy: A Parser Generator for Haskell.
Available on the web from: www.haskell.org/happy.
[10] Hugh Glaser, Pieter Hartel, and Paul Garratt. Programming by Numbers:
A Programming Method for Novices. The Computer Journal, 43(4), 2000.
[11] Paul Hudak. Conception, Evolution and Application of Functional Pro-
gramming Languages.
Communications of the ACM, 21(3):359-411,
September 1989.
193

194
BIBLIOGRAPHY
[12] Gerard Huet. The Zipper. Journal of Functional Programming, 7(5):549-
554, September 1997.
[13] John Hughes. Why Functional Programming Matters. The Computer
Journal, 32(2):98-107, 1989.
[14] Graham Hutton.
Programming in Haskell home page on the web:
www.cs.nott.ac.uk/~gmh/book.html.
[15] Graham Hutton. A Tutorial on the Universality and Expressiveness of
Fold. Journal of Functional Programming, 9(4):355-372, July 1999.
[16] Graham Hutton. The Countdown Problem. Journal of Functional Pro-
gramming, 12(6):609-616, November 2002.
[17] Graham Hutton and Erik Meijer. Monadic Parser Combinators. Technical
Report NOTTCS-TR-96-4, Department of Computer Science, University
of Nottingham, 1996.
[18] Graham Hutton and Erik Meijer. Monadic Parsing in Haskell. Journal
of Functional Programming, 8(4):437-444, July 1998.
[19] Graham Hutton and Joel Wright. Compiling Exceptions Correctly. In
Proceedings of the 7th International Conference on Mathematics of Pro-
gram Construction, volume 3125 of Lecture Notes in Computer Science,
Stirling, Scotland, July 2004. Springer.
[20] Graham Hutton and Joel Wright. Calculating an Exceptional Machine.
To appear in the Proceedings of the Fifth Symposium on Trends in Func-
tional Programming, Intellect, 2005.
[21] Mark P. Jones. Typing Haskell in Haskell. In Proceedings of the 1999
Haskell Workshop, Paris, France, October 1999.
[22] John Launchbury. A Natural Semantics for Lazy Evaluation. In Pro-
ceedings of the 20th ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages, pages 144-154, Charleston, South Carolina,
January 1993.
[23] Daan Leijen. Parsec: A Parsing Library for Haskell. Available on the
web from: www.haskell.org/parsec.
[24] Saunders MacLane. Categories for the Working Mathematician. Num-
ber 5 in Graduate Texts in Mathematics. Springer-Verlag, 1971.
[25] Simon Peyton Jones.
Tackling the Awkward Squad:
Monadic In-
put/Output, Concurrency, Exceptions, and Foreign-Language Calls in
Haskell. In Tony Hoare, Manfred Broy, and Ralf Steinbruggen, editors,
Engineering Theories of Software Construction, pages 47-96. IOS Press,
2001. Presented at the 2000 Marktoberdorf Summer School.

BIBLIOGRAPHY
195
[26] Simon Peyton Jones. Haskell 98 Language and Libraries: The Revised
Report. Cambridge University Press, 2003. Also available on the web
from www.haskell.org/definition.
[27] Simon Peyton Jones and David Lester. Implementing Functional Lan-
guages: A Tutorial. Prentice Hall, 1992.
[28] V.J. Rayward-Smith. A First Course in Formal Language Theory, volume
234 of Pitman Research Notes in Math. Blackwell Scientiﬁc Publications,
1983.
[29] John C. Reynolds. Theories of Programming Languages. Cambridge Uni-
versity Press, 1998.
[30] Simon Singh. The Code Book: The Secret History of Codes and Code
Breaking. Fourth Estate, 1999.
[31] Philip Wadler. The Concatenate Vanishes. University of Glasgow, 1989.
[32] Philip Wadler. Monads for Functional Programming. In Manfred Broy,
editor, Proceedings of the Marktoberdorf Summer School on Program De-
sign Calculi. Springer-Verlag, August 1992.

Index
(), 30, 98, 106, 185
[ ], 30, 92, 139, 185
$!, 158, 189
⇒, 34, 191
, 43, 52, 65, 73, 75
>>=, 94, 108, 134, 182, 191
⩾, 35, 181, 191
λ, 46, 85, 93, 150, 191
←, 51, 94, 108, 191
⩽, 35, 181, 191
∗, 19, 37, 181
+, 19, 37, 181
−, 19, 37, 181
/, 38, 57, 182
::, 27
:, 44, 185
<, 35, 181
>, 35, 181
◦, 85, 189, 191
↑, 19, 184, 191
==, 34, 181
∨, 182, 191
∧, 43, 182, 191
|, 42, 51, 120
¬, 43, 182, 191
̸=, 34, 181, 191
++, 21, 66, 83, 84, 188, 191
!!, 20, 186
→, 31, 189, 191
abs, 37, 42, 181
absolute value, see abs
accumulation, 10, 83, 159, 173
actions, 106
addition, see +, sum
all, 80, 186
and, 81, 84, 185
any, 80, 186
append, see ++
application, 9, 22, 27, 33, 158
partial, 32, 78, 81
strict, see $!
assignment, 11, 148
associativity, 20, 83, 164
for addition, 84, 99, 163, 168
for append, 171
for application, 33
for composition, 85
for cons, 45
for function types, 32
for multiplication, 99
binary trees, 124
Bool, 27, 28, 182
case, 93
category theory, 135
Char, 28, 183
characters, see Char
chr, 56, 183
class, 132
classes, 34, 132, 181
constraints, 34, 133
default deﬁnitions, 132
derived instances, 133
instances, 34, 132
methods, 34
clearing the screen, 109
comments, 25
commutativity, 143
for addition, 143, 179
for multiplication, 143, 163
composition, see ◦
comprehensions
list, 13, 51
set, 51, 60
196

INDEX
197
string, 55
concat, 52, 189
concatenation, see concat
conditions, 42
conjunction, see ∧, and
cons, see :
const, 46, 189
control characters, 28, 109
curry, 189
cursor, 109
dangling else, 42
data, 120
deriving, 133, 138
digitToInt, 183
disjunction, see ∨, or
distributivity, 163, 170, 176
div, 19, 23, 38, 88, 182
division, see div, /
do, 95, 108, 135
domain speciﬁc languages, 13, 78
domino eﬀect, 167
Dr Seuss, 92
drop, 21, 68, 72, 187
dropWhile, 80, 187
elem, 185
Eq, 34, 53, 181
equality, see ==
equational reasoning, 13, 163
error, 102, 190
error messages, 21, see error
evaluation, 19, 27, 102, 138, 147
call-by-name, 150, 151
call-by-value, 149, 151
innermost, 149
lazy, 13, 30, 43, 53, 87, 154
outermost, 150
top-level, 158
even, 41, 69, 184
examples
abstract machine, 130
base conversion, 86
Caesar cipher, 55
calculator, 110
chi-square, 58
compiler, 175
countdown, 137
expression parser, 99
factorial, 23, 63
fast reverse, 171
Fibonacci sequence, 68, 161
game of life, 113
insertion sort, 67
permutations, 139
prime numbers, 53, 157
quicksort, 16, 68
sieve of Eratosthenes, 157
string transmitter, 86
subsequences, 139
tautology checker, 125
exception handling, 116
exponentiation, see ↑
expressions, 9
arithmetic, 99, 130, 137, 174
conditional, see if
impure, 107
lambda, see λ
logical, 125
pure, 107
reducible, 149
False, 27, 28
ﬁle handling, 116
ﬁlter, 79, 186
Float, 29, 57, 184
foldl, 72, 84, 160, 187
foldl1, 188
foldr, 71, 81, 89, 187
foldr1, 187
FP, 14
Fractional, 38, 182
fromInt, 58
fst, 44, 185
functions, 9, 22, 31, 189
combinatorial, 139
composite, see ◦
constant, see const
constructor, 121
curried, 32, 46, 77, 150, 159
higher-order, 13, 78
identity, see id

198
INDEX
nameless, see λ
overloaded, 12, 34
polymorphic, 12, 33, 55, 78
recursive, 15, 63
strict, 150, 158
total, 31
generators, see ←
getCh, 108
getChar, 107, 108, 190
getLine, 108, 190
GHC, 19, 141
grammars, 99
ambiguous, 101
guards, 13, 42, 52, 74
head, 20, 45, 186
Hugs, 19, 22
commands, 23
id, 85, 189
identiﬁers, 24, 98
identities, 143
for addition, 15
for append, 172
for composition, 85
for division, 143
for multiplication, 64, 71, 143
if, 28, 42
indentation, 12, see layout rule
induction, 14, 166
hypothesis, 167
on expressions, 176
on lists, 169
on numbers, 166, 169
on trees, 173
inequality, see ̸=
inﬁnity, 151, 166
inﬁx notation, 23
init, 74, 187
input/output, see IO
instance, 132
Int, 29, 184
Integer, 29, 161, 184
Integral, 38, 73, 182
intToDigit, 184
IO, 106, 190
isAlpha, 96, 183
isAlphaNum, 96, 183
isDigit, 41, 96, 183
isLower, 96, 183
isSpace, 98, 183
isUpper, 96, 183
ISWIM, 14
iterate, 87, 188
keywords, 12, 24
lambda calculus, 14, 48
layout rule, 24, 95
length, 21, 52, 65, 82, 84, 188
lexicographic ordering, 36
Lisp, 14
lists, 13, 15, 20, 30, 51, 185
elements, 30, 44
empty, see [ ]
indexing, see !!
inﬁnite, 13, 30, 87, 154
length, 30
singleton, 30, 92, 139
sorted, 16, 54, 66, 68, 76
logical
operators, see ∧, ∨, ¬
propositions, 125
tautologies, 125
values, see Bool
lookup tables, 53, 120
map, 78, 189
max, 35, 181
maximum, 188
Maybe, 122, 185
min, 35, 181
minimum, 188
Miranda, 14
ML, 14
mod, 38, 52, 56, 88, 157, 182
Monad, 134, 182
monads, 13, see Monad
moving the cursor, 109
multiplication, see ∗, product
naming requirements, 24, 119, 120

INDEX
199
negate, 37, 181
negation, see ¬, negate
null, 45, 74, 185
Num, 15, 34, 37, 71, 181
numbers, 184
binary, 86
decimal, 86
ﬂoating-point, see Float
integer, see Int, Integer
natural, 98, 99, 122, 166
perfect, 60
prime, 53, 157
Unicode, 56, 88, 183
odd, 69, 85, 184
operators, 19, 47, 80, 83, 138
or, 81, 84, 186
Ord, 17, 35, 54, 66, 181
ord, 56, 183
otherwise, 42, 182
overloading, 34
parse trees, 100
parsers, 91
pattern matching, 13, 43, 71, 165
patterns, 43
disjoint, 165
integer, see n + k
list, 44, 65
n + k, 45, 63, 73
tuple, 44
wildcard, see
polymorphism, 33
predecessor, 45, 63, 69
predicates, 79, 96
print, 190
priorities, 20, 22, 99
product, 21, 65, 70, 81, 84, 188
programming
batch, 105
functional, 10
imperative, 11, 148
interactive, 19, 105
modular, 13, 156
putChar, 107, 190
putStr, 108, 190
putStrLn, 108, 190
Read, 36, 181
read, 36, 181
readLn, 190
recip, 38, 41, 182
reciprocation, 47, see recip
recursion, 13, 63
multiple, 68
mutual, 69, 97, 131
redex, 149
reduction, 148
under lambdas, 151
remainder, see mod
repeat, 88, 188
replicate, 169, 188
reserved words, 24
return, 92, 107, 134, 182
reverse, 21, 65, 82, 84, 170, 171, 189
rounding errors, 29
scalar product, 60
scripts, 22
sections, 47, 81
sequencing, see >>=
sharing, 153
Show, 36, 138, 181
show, 36, 181
side eﬀects, 13, 105
sign, see signum
signum, 37, 42, 43, 181
snd, 44, 185
sorting
insertion sort, 67
merge sort, 76
quicksort, 16, 68
sounding a beep, 109
spacing, 98
span, 187
splitAt, 41, 187
stacks, 175
control, 130
underﬂow, 177
standard prelude, 19, 181
state of the world, 106
String, 29, 183

200
INDEX
strings, see String
subtraction, see −
successor, 47, 122, 151
sum, 15, 21, 81, 83, 84, 188
symbol table, 191
tail, 20, 45, 186, 187
take, 20, 156, 186
takeWhile, 80, 186
termination, 10, 13, 151, 154
tokens, 98
toLower, 184
toUpper, 184
True, 27, 28
truth tables, 126
tuples, 30, 185
arity, 30, 44
components, 30, 44
empty, see ()
pairs, 30, 51, 54, 185
triples, 31, 185
type
constructors, 120
declarations, 119, 120
errors, 28
inference, 12, 15, 27
parameters, 120, 122
safety, 28
variables, 33
type, 119
types, 12, 15, 27
basic, 28
equality, see Eq
fractional, see Fractional
function, 31
integral, see Integral
list, 30, 123, 185
maybe, see Maybe
monadic, see Monad
numeric, see Num
ordered, see Ord
overloaded, 34
parameterised, 120, 122
polymorphic, 33
readable, see Read
recursive, 122
showable, see Show
tree, 124, 162, 173
tuple, 30
uncurry, 189
unfold, 90
where, 24
zip, 54, 67, 188
zipper, 135

