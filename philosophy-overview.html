<h3
id="a-participatory-universe-in-the-realist-mode">A-Participatory-Universe-in-the-Realist-Mode</h3>
<p>Title: A Participatory Universe in the Realist Mode: On the
Separation of Observational and Agentive Perspectives in Classical and
Quantum Mechanics</p>
<p>The paper by Jenann Ismael discusses the concept of interference,
suggesting that it plays a crucial role in understanding the differences
between classical and quantum mechanics. Interference is defined as the
unavoidable presence of one’s own actions influencing the very phenomena
they are trying to observe or measure. This influence creates problems
in stabilizing certain features of the world as objects of knowledge,
making it impossible to treat them independently from the act of
observation or measurement.</p>
<ol type="1">
<li><p>Interference in Classical Mechanics: In classical mechanics, the
separation between the observer and the observed is possible due to
effective control over disturbances. This allows for a clear delineation
between subject (observer) and object (system being investigated).
However, interference still exists; it’s simply channeled into the
future. For instance, predictions of political outcomes may influence
voting behavior, or stock predictions can affect stock prices. These are
instances where one’s actions as an agent interfere with what is
observed or measured.</p></li>
<li><p>Interference in Quantum Mechanics: In quantum mechanics,
interference is endemic and pervasive, making the separation of observer
and observed difficult to maintain. The standard textbook formulation of
quantum mechanics has issues with defining measurements accurately,
leading to what’s known as the measurement problem. This problem arises
because, according to quantum mechanics, superpositions (linear
combinations) of possible states are also valid states. When a
measurement is attempted on a system in such a superposition, Born’s
rule predicts a definite result with specific probabilities. However,
this conflicts with the assumption that unmeasured quantities have
definite values and that measurements reveal pre-existing properties of
systems.</p>
<p>No-go theorems (such as Kochen-Specker and Bell’s) demonstrate that
attempts to maintain these assumptions lead to inconsistencies.
Decoherence, which describes the transition from quantum superpositions
to classical states, suggests that measurement results do not reveal
pre-existing values but are instead probabilistically dependent on the
act of measurement itself.</p></li>
<li><p>Observer-Participancy and Realism: Ismael proposes that
understanding quantum mechanics through the lens of interference
demystifies its weirdness. She aligns this perspective with John
Wheeler’s idea of observer-participancy but incorporates it into a
realist account of material processes. In Wheeler’s formulation,
observer participation is seen as the general case, while the ability to
separate observation from participation is a special case.</p>
<p>The paper argues that quantum measurements should be understood as
choices rather than knowledge-gathering activities and suggests treating
quantum mechanics strategically instead of epistemically. This means
recognizing that in quantum mechanics, “measurement” interactions lack
the logic of measurement and don’t reveal properties that are already
there or would be there regardless of observation.</p></li>
<li><p>Conclusion: The author concludes by emphasizing the
inseparability of subject and object at a fundamental level. Quantum
mechanics reveals an underlying structure to reality that belies the
impression of stability, challenging our conventional notions of self,
world, and knowledge. Ismael’s perspective underscores the importance of
considering interference as a fundamental aspect of our understanding of
both classical and quantum mechanics, highlighting its role in shaping
how we represent and interact with the world around us.</p></li>
</ol>
<h3
id="addendum-to-how-to-combine-chance-and-determinism">Addendum-to-How-to-Combine-Chance-and-Determinism</h3>
<p>Peter Lewis’ paper, “Uncertainty and Probability for Branching
Selves,” was discussed at an APA session in 2005 by another author (name
not provided). The responding author begins by praising Lewis’ work,
acknowledging that it made them reconsider their own views on
uncertainty in a branching universe.</p>
<p>The main point of contention lies in the interpretation of
probability and uncertainty within an Everett Universe, which posits
that every quantum event causes the universe to split into multiple
branches, each representing a different outcome.</p>
<ol type="1">
<li><p><strong>Pre-measurement Uncertainty</strong>: The responding
author initially asserted there is genuine uncertainty about future
events in an Everett universe, but after reading Lewis’ paper, they
concede that this isn’t the case. In a literal branching world, there’s
no uncertainty because there’s nothing uncertain to begin with; every
outcome occurs in some branch. Instead, the author suggests interpreting
“uncertainty” as facts about one’s present state that can’t be
determined based on complete knowledge of past events and physical
laws.</p></li>
<li><p><strong>Interpretation of Born Probabilities</strong>: The
responding author outlines their project, which is to provide a physical
interpretation for the Born probabilities in an Everett universe. They
propose interpreting these probabilities as degrees of surprise from a
situated post-measurement perspective. This interpretation states that
the Born probability of an up-result in a spin measurement isn’t about
predicting future events but rather reflects how typical one’s situation
is among counterparts sharing the same pre-measurement history.</p></li>
<li><p><strong>Empirical Coherence</strong>: Lewis argues that without a
physical interpretation for Born probabilities, an Everett universe is
empirically incoherent because it lacks a means to connect its
mathematical predictions with observed frequencies of measurement
results. The responding author counters this by asserting their
interpretation does just that: long-term frequencies of measurement
results approach the distribution across all branches due to symmetries
in the universe, allowing for empirical confirmation.</p></li>
<li><p><strong>Predictions and Empiricism</strong>: A significant
disagreement arises around what constitutes a “prediction” in a theory.
Lewis requires that probabilities must be assignable before measurements
to confirm the theory, while the responding author argues that any
theory with testable empirical consequences is confirmable through
gathered evidence. The responding author questions why this temporal
requirement should apply to theories with historical subjects (like
continental drift or evolution), suggesting there might be a
misunderstanding here.</p></li>
<li><p><strong>Probability Interpretation</strong>: Finally, the author
challenges Lewis’ distinction between ‘ontic chances’ (outcomes of
indeterministic processes) and other forms of probability. They argue
that this distinction isn’t necessary and that Born probabilities,
interpreted as degrees of retrospective surprise, can still be
considered genuine probabilities.</p></li>
</ol>
<p>In conclusion, while the responding author agrees with Lewis’
correction regarding pre-measurement uncertainty, they dispute his
empirical incoherence claim and offer an alternative interpretation of
Born probabilities. They also question certain aspects of Lewis’
requirement for predictions to be made before measurements, suggesting
this might not apply universally across all scientific theories.</p>
<h3
id="could-statistical-mechanical-probabilities-have-a-quantum-mechanical-grounding">Could-statistical-mechanical-probabilities-have-a-quantum-mechanical-grounding</h3>
<p>The text discusses the foundations of statistical mechanics and the
role of probability in explaining thermodynamic phenomena. It critiques
David Albert’s approach to the Past Hypothesis (PH) and argues that a
global version of PH, which posits a uniform probability distribution
over all possible microstates at the beginning of the universe, is not
empirically intelligible or mechanically explanatory.</p>
<p>The author suggests that a local interpretation of PH, focusing on
individual systems like a gas in a container or ice cubes in water, can
provide a more plausible explanation for thermodynamic behavior. In this
context, the PH can be understood as expressing partial information
about the initial conditions of these specific systems.</p>
<p>The author argues that to be empirically intelligible and
mechanically explanatory, a probability distribution over worlds (i.e.,
possible universes) must either be an extrapolation from a distribution
over local subsystems obtained by mixing or dynamical symmetries, or
logically tied to observed regularities in the actual world. A purely
independent hypothesis presented as an explanatory primitive lacks
empirical content.</p>
<p>The author criticizes Albert’s global PH for not providing a
mechanical explanation of thermodynamic behavior and points out that its
epistemic interpretation cannot do any work in explaining the phenomena,
as the initial conditions about which it encodes information are what
ultimately explains thermodynamic behavior.</p>
<p>The text also touches on the distinction between statistical and
epistemic probabilities, with the former interpreted by a connection to
frequencies and the latter by a connection to belief. The author argues
that while a purely statistical interpretation of PH might be possible
at the local level, it becomes illusory when applied globally, as its
content becomes mostly extrinsic to the actual world.</p>
<p>In summary, the text critiques David Albert’s approach to the Past
Hypothesis in statistical mechanics and argues for a more local
interpretation that focuses on individual systems, providing a more
plausible explanation for thermodynamic behavior while maintaining
empirical intelligibility and mechanical explanatory power. The author
also discusses the distinction between statistical and epistemic
probabilities and the importance of connecting probability distributions
to observed regularities in the actual world for empirical
intelligibility.</p>
<h3 id="curies-principle">Curies-Principle</h3>
<p>The article by Jenann Ismael discusses Curie’s Principle, a statement
made by Pierre Curie in 1894 stating that the symmetry of a cause is
always preserved in its effects. Despite its straightforward nature, the
principle has been subject to criticism and misunderstanding over the
years, often dismissed as irrelevant or false.</p>
<p>Ismael aims to rehabilitate Curie’s Principle by presenting it under
a specific interpretation. She begins by defining key terms: ‘cause’ and
‘effect’ are understood as ‘Curie-causes’ and ‘Curie-effects,’ where a
Curie-cause is a set of mutually exclusive and jointly exhaustive event
types that, according to physical laws, uniquely determine another
set—the Curie-effect.</p>
<p>The principle, then, asserts that all characteristic symmetries
(symmetries common to all specifications) of a Curie-cause are also
characteristic symmetries of its effect. In other words, if an asymmetry
is found in the specification of an effect, it must also be present in
some specification of the cause.</p>
<p>Ismael presents a proof for this principle using deterministic
physical laws as examples. She argues that any transformation acting on
a Curie-cause and its effect will preserve the symmetries due to the
determinism of the underlying laws. If an asymmetry were to appear in
the effect but not in the cause, it would contradict the deterministic
nature of the laws.</p>
<p>The author also discusses the interpretation and significance of
Curie’s Principle. She emphasizes the importance of understanding
symmetries in a physically meaningful way, distinguishing between
‘relevant’ (characteristic) and ‘irrelevant’ permutations of parameters.
This distinction helps clarify how geometric transformations can be
understood as relevant permutations of irrelevant parameters, thus
aligning non-geometric and geometric asymmetries under the same
framework.</p>
<p>Ismael also addresses criticisms of Curie’s Principle, such as its
alleged contradiction with empirical evidence (like spontaneous symmetry
breaking) or its perceived uselessness in indeterministic contexts. She
argues that these criticisms often stem from misunderstandings about the
nature of cause and effect or the definition of symmetry itself.</p>
<p>Finally, Ismael explores the applicability of Curie’s Principle in
indeterministic contexts. Even in quantum mechanics, where laws map
state descriptions to probability functions rather than deterministic
outcomes, the principle can still apply. Here, asymmetries are defined
in terms of the resulting probability distributions over possible states
or outcomes.</p>
<p>In summary, Ismael’s interpretation of Curie’s Principle highlights
its logical consistency and broad applicability across both
deterministic and probabilistic physical theories. By focusing on the
nature of symmetry and carefully defining cause-effect relationships,
she argues that this principle provides valuable insights into the
structure and behavior of physical systems.</p>
<p>The provided text discusses Curie’s Principle, a concept in physics
that relates to symmetries of physical states and their transformations.
The principle was formulated by Pierre Curie and is concerned with how
symmetries of causes correspond to symmetries of effects in natural
phenomena.</p>
<ol type="1">
<li><p><strong>Curie’s Principle</strong>: This principle states that if
a cause A results in an effect B, then the characteristic symmetries of
A must also be present in B. In other words, any transformation that
leaves the cause invariant (i.e., its symmetry) must also leave the
effect invariant.</p></li>
<li><p><strong>Asymmetry and Symmetry</strong>: The text explores the
idea that any apparent asymmetry in a system’s behavior might be
concealing deeper, hidden symmetries. Curie’s Principle helps uncover
these by revealing how symmetries of causes correspond to those of
effects.</p></li>
<li><p><strong>Application in Deterministic and Indeterministic
Contexts</strong>: The principle applies equally well to deterministic
and indeterministic systems. In the former, the cause directly
determines the effect, while in the latter, probability distributions
come into play. Here, Curie’s Principle helps separate chancy aspects
(the unpredictable elements) from law-governed ones by defining coarse
and fine states.</p></li>
<li><p><strong>Spontaneous Symmetry Breaking</strong>: The text argues
against the concept of spontaneous symmetry breaking, suggesting that
apparent violations are actually due to non-linear dynamics and external
perturbations. It claims that such phenomena don’t violate Curie’s
Principle, as there are no truly symmetric causes in real physical
systems due to factors like experimental error, fluctuations, and the
impossibility of perfect isolation from surroundings.</p></li>
<li><p><strong>Hidden Variables</strong>: The principle is also
connected with hidden variables – properties of a system that aren’t
directly observable but influence its behavior. If A is the cause
(Curie-cause) of B, then any characteristic asymmetry in B must be
matched by a corresponding hidden asymmetry in A.</p></li>
<li><p><strong>Exegetical Support</strong>: The author provides
exegetical arguments to show that their interpretation of Curie’s
Principle aligns with what Pierre Curie likely intended, based on his
examples and applications in the original paper.</p></li>
<li><p><strong>Non-triviality</strong>: Despite appearing simple or even
obvious, the principle is argued not to be trivial. Its value lies in
its application to uncover hidden symmetries and causal relationships
that might not be apparent through observation alone.</p></li>
</ol>
<p>In summary, Curie’s Principle is a powerful tool for understanding
symmetries and causal relationships in physical phenomena. It suggests
that any apparent asymmetry in the behavior of a system (its effect)
must be mirrored by a hidden symmetry in its cause, providing a method
to uncover deeper, underlying structures governing natural
processes.</p>
<p>The text discusses Curie’s Principle, a philosophical principle in
physics and the philosophy of science proposed by Pierre Curie. The
principle essentially states that if a transformation (T) is not a
symmetry of the fundamental laws governing a physical system, it cannot
be a symmetry of the set of possible initial states for that system.</p>
<p>To illustrate, let’s consider two states A and B at different times.
If T is an asymmetry of the laws, there can’t be two physically possible
trajectories (A?, B) and T(A?, B), where Bi ≠ TBi, without also having
A? ≠ TAi. This principle is crucial because it asserts that a
transformation cannot simultaneously preserve and disturb the dynamics
of a system governed by those laws.</p>
<p>The author uses an example of an isolated Newtonian system (a ball on
a frictionless surface) to demonstrate how coordinate transformations
can affect our perception of symmetry. When observed from a coordinate
system moving non-inertially, the same physical situation can appear
asymmetric due to the change in coordinates. This shows that the
traditional coordinate-dependent formulation of laws isn’t covariant
under all transformations and thus hides dynamical relevance.</p>
<p>To address this issue, the author advocates for a generally covariant
or coordinate-independent representation of physical laws. In such
representations, laws explicitly relate dynamical behavior to intrinsic
structures of manifolds, making them covariant with respect to all
transformations between manifolds. This ensures that if T is a geometric
asymmetry of the laws, there’s a parameter in the equations not
invariant under T.</p>
<p>The author also discusses how this principle applies to various
interpretations of quantum mechanics and other indeterministic physical
theories. It suggests that when we postulate hidden variables
(parameters not directly observable) to explain observed asymmetries,
we’re essentially applying Curie’s Principle on a cosmic scale. We
derive intrinsic asymmetries of the underlying physical structure from
observable asymmetries.</p>
<p>Key points: 1. Curie’s Principle asserts that if a transformation
isn’t a symmetry of the laws, it can’t be one for possible initial
states. 2. Coordinate transformations can alter our perception of
symmetry in physical systems. 3. The principle highlights limitations in
traditional coordinate-dependent formulations of laws and advocates for
generally covariant representations to account for all dynamical
relevance. 4. Curie’s Principle is relevant in various interpretations
of quantum mechanics, where it helps explain the relationship between
observable asymmetries and underlying physical structures.</p>
<h3
id="how-to-combine-chance-and-determinism">How-to-Combine-Chance-and-Determinism</h3>
<p>Title: How to Combine Chance and Determinism: Thinking about the
Future in an Everett Universe Author: Jenann Ismael Publication:
Philosophy of Science, Vol. 70, No. 4 (October 2003)</p>
<p>In this paper, philosopher Jenann Ismael explores how to reconcile
chance and determinism within the context of Everett interpretations of
quantum mechanics, also known as Many-Worlds Theory. This theory
suggests that every quantum event causes the universe to split into
multiple parallel universes, each representing a different outcome.</p>
<p>Ismael aims to address three key problems when trying to understand
probability in an Everett universe: (1) finding a canonical method for
extracting a tree-like structure of histories from the universal wave
function without using a preferred basis; (2) showing how chance can
arise within deterministic dynamics; and (3) defending Born’s rule as
the quantitative method for calculating probabilities.</p>
<p>The main argument focuses on the second problem – how to reconcile
determinism with chancy events in an Everett universe where all possible
outcomes occur simultaneously, each in a separate branch of reality.
Ismael proposes that we can think of Born probabilities as the
probability that the next event in a pre-measurement history of a
specified kind is a spin-up-result-observing event.</p>
<p>In essence, the proposal suggests treating each post-measurement
observer as using Born’s rule to compute the probability of their
specific measurement outcome based on their pre-measurement history. The
probabilities tell them how surprised they should be by what they
observe in their individual branches of reality. This approach doesn’t
require any non-physical elements, such as humunculi or consciousnesses
traveling unique paths through the universe’s branches.</p>
<p>Ismael highlights two challenges with this interpretation:
indexicality and world-locality. Indexicality refers to the linguistic
difficulty in referring to specific events pre-measurement due to
symmetries between post-measurement branches, while world-locality is
about assigning probabilities without uniquely identifying individual
measurement results across branches.</p>
<p>Ismael concludes that the proposed interpretation acknowledges the
intuitive suspense one feels when awaiting a quantum measurement’s
outcome in an Everett universe – uncertainty in a deterministic context
– without appealing to non-physical entities. This interpretation aligns
with the broader metaphysical tendency of thinking about oneself as a
transcendent entity, distinct from the physical body, by showing that
such intuitions can be satisfied within a purely physical framework.</p>
<p>The paper also discusses an alternative way of interpreting
probabilities in Everett universes: treating branching metaphorically
rather than literally and relating it to van Fraassen’s modal frequency
interpretation or acknowledging the plurality of branches with unique
physically possible outcomes for each measurement. However, Ismael
argues these interpretations don’t capture the essential intuition that
there is genuine uncertainty in a deterministic context.</p>
<p>In summary, Jenann Ismael presents an argument for understanding
chance and determinism in Everett universes by treating Born
probabilities as referring to events within individual post-measurement
observers’ perspectives based on their pre-measurement histories. This
interpretation respects the determinism of global evolution while
allowing for local chanciness of measurement results without invoking
non-physical entities.</p>
<h3 id="quantum-holism">Quantum-Holism</h3>
<p>The paper discusses the concept of a common ground explanation for
quantum entanglement within the context of holism, which is the idea
that entities can be interconnected or interdependent in such a way that
they form an integrated whole. The authors extend the notion of common
cause explanations to include common ground explanations, where the
focus is on the underlying unity rather than a specific cause.</p>
<p>The paper proposes two holistic interpretations of quantum mechanics
as examples: Spacetime State Realism Streamlined and Wave Function
Realism. Both interpretations treat the components of entangled systems
as joint manifestations of a common ground, rather than independent
entities.</p>
<ol type="1">
<li><p>Spacetime State Realism Streamlined: This interpretation posits
that the fundamental ontology consists solely of the whole spacetime
bearing a density operator. From this universal density operator, one
can recover the many derivative subsystems (like Alice and Bob) through
partial trace operations. This approach avoids redundancy by not
assigning additional density operators to any subsystems beyond the
whole universe.</p></li>
<li><p>Wave Function Realism: In this view, the fundamental ontology
includes the wave function in a high-dimensional conﬁguration space (and
possibly a world-particle as well). The shape of the wave function
explains the coordinated behavior of Alice and Bob from a common source.
Although the wave function has multiple degrees of freedom, these are
not metaphysically distinct due to global constraints on its squared
amplitudes and potential entanglement aspects.</p></li>
</ol>
<p>The paper argues that both interpretations offer plausible common
ground explanations for quantum entanglement by treating manifest events
as non-distinct entities grounded in a common whole, thereby reconciling
entanglement with Humean principles of causation and necessity. This
contrasts with an alternative proposal to address entanglement by
positing new fundamental relations among existing parts, which the
authors view as less plausible due to lack of empirical evidence and
conceptual grounds connecting spatial separation with metaphysical
distinctness.</p>
<p>Einstein’s Inference – that spatially separated entities are distinct
existences – is discussed as a principle potentially at odds with
holism. However, the paper shows how this inference becomes ambiguous or
implausible in light of quantum mechanics and the proposed
interpretations. Ultimately, the authors suggest that any discomfort
with holistic interpretations stems from an atomistic picture of
fundamental entities as independent bits within familiar 3-dimensional
space, which quantum mechanics challenges.</p>
<p>In summary, the paper presents common ground explanations for quantum
entanglement by proposing Spacetime State Realism Streamlined and Wave
Function Realism as holistic interpretations that treat manifest events
as non-distinct entities grounded in a unified whole, thereby
reconciling entanglement with Humean principles of causation and
necessity.</p>
<h3 id="realism-without-reification">Realism-without-Reification</h3>
<p>The text discusses the philosophical and scientific exploration of
temporal experience—how humans perceive and understand time. It
primarily revolves around two contrasting conceptions of time:
Heraclitian (time as an absolute, irreversible process) and Parmenidean
(time as a fixed four-dimensional block).</p>
<ol type="1">
<li><p><strong>Heraclitian Conception</strong>: This perspective views
the universe undergoing a continuous process of becoming. It emphasizes
change, flux, and the dynamic nature of reality.</p></li>
<li><p><strong>Parmenidean Conception</strong>: Here, time is seen as a
static four-dimensional block consisting of all events. Everything that
exists happens simultaneously within this block.</p></li>
</ol>
<p>The text delves into the elements of temporal experience:</p>
<ul>
<li><strong>Asymmetry</strong>: The distinction between past and future;
past events are irreversible while future events remain open to
change.</li>
<li><strong>Flow</strong>: The sense of constant movement or change in
our perception at any given moment.</li>
<li><strong>Passage</strong>: The feeling that time moves forward, with
the past being settled and the future uncertain.</li>
</ul>
<p>Rudolf Carnap, a philosopher of science, argued that while physics
can describe the objective sequence of events (temporal sequence in
physics), our subjective experience of time—its asymmetry, flow, and
passage—falls into the realm of psychology to explain.</p>
<p>The text introduces two key concepts:</p>
<ol type="1">
<li><p><strong>Temporally Embedded Momentary Perspective
(TEMP)</strong>: This represents a snapshot of experiences at any given
moment, acknowledging that perceptual experience has a limited temporal
breadth compared to memory’s broader scope. Different types of
memory—episodic and autobiographical—are mentioned as part of this
perspective.</p></li>
<li><p><strong>Temporally Evolving Point of View (TEvPoV)</strong>: This
encompasses the entire history of a person’s temporal experiences,
represented as an evolving sequence of TEMPs. It includes not just past
and present but also future representations, even in
perception.</p></li>
</ol>
<p>The construction of such a system involves integrating perceptual
input into representational states with a temporal dimension, allowing
for recursive memory storage and organization into autobiographical
history. Decisions and judgments are considered mental performances that
influence the future while past beliefs remain unchanged by them
(FAPP).</p>
<p>The flow of information is described as a directed process involving
perceptual input, memory, and decision-making, shaping our understanding
of temporal relationships in the world.</p>
<p>Key features of this model include: finite temporal scope of
perceptual states, abundant structuring along the timeline, and a
unidirectional internal flow of information. The Heraclitian
properties—flow, passage, and openness—are seen as arising from changes
in perspective relative to an absolute background time.</p>
<p>The text concludes by reconciling these perspectives, suggesting they
may not be mutually exclusive but different ways of viewing the same
underlying reality. It also discusses the implications for physics,
particularly in quantum gravity discussions where the nature of time
remains a contentious issue. The model proposed here might provide
insights into how temporal experience could emerge from fundamental
physical processes.</p>
<p>In essence, this text presents a sophisticated philosophical
framework for understanding human temporal experience, integrating
elements of physics and psychology, and suggesting potential links to
ongoing debates in the foundations of physics.</p>
<h3
id="review-of-the-blind-spot-nature-physics">Review-of-the-Blind-Spot-Nature-Physics</h3>
<p>“The Blind Spot: Why Science Cannot Ignore Human Experience” is a
book authored by Adam Frank, Marcelo Gleiser, and Evan Thompson,
published by MIT Press in 2024. The book delves into the philosophical
implications of science’s historical tendency to abstract away human
experience, arguing that this oversight has led to several scientific,
social, and spiritual issues.</p>
<p>The central argument of the book is encapsulated in its title—the
“Blind Spot” refers to the scientific community’s tendency to ignore or
marginalize lived human experience when formulating our understanding of
the universe. The authors contend that this blind spot arises from
science’s historical progression, which has been characterized by an
increasing process of articulation and abstraction—moving beyond
immediate sensory perceptions towards more abstract, universal
concepts.</p>
<p>This process, while yielding significant scientific advancements,
also distanced us from our direct, subjective experiences. The book
suggests that this displacement of experience is problematic,
contributing to issues in understanding fundamental aspects like time,
life, the cosmos, consciousness, and quantum mechanics within science.
It’s further argued that this rift between experience and the objective
world has societal and spiritual repercussions, including an
objectification of nature and a subsequent crisis of meaning, which may
manifest in our willingness to exploit the environment for human
gain.</p>
<p>The authors do not propose a wholesale revision of scientific
theories but rather advocate for a philosophical re-evaluation. They
critique the dominant materialist view that equates the scientific
worldview with absolute completeness and autonomy. Instead, they argue
for restoring human experience to its central place in our conception of
reality, connecting science to the lived world without reducing or
eliminating experiential content.</p>
<p>The book uses the concept of time as a case study. Relativity theory
teaches us that the universe is a four-dimensional manifold where time
appears as one dimension. However, the authors argue against equating
this formal structure with ‘time itself.’ They caution against confusing
mathematical representations with the phenomena they describe—the map
(mathematical model) with the territory (lived experience).</p>
<p>The book does not attempt to integrate experiential data into
physical theories as new quantifiable entities. Rather, it calls for a
reevaluation of how we conceptualize reality to accommodate human
experience more effectively. The authors suggest returning to a
worldview where existence and experience are synonymous—a pre-fissure
state—to understand how abstract scientific concepts originate from this
foundational experiential basis.</p>
<p>In essence, “The Blind Spot” is a critique of the modern scientific
worldview’s tendency towards abstraction at the expense of human
experience. It argues that science cannot fully grasp existence without
acknowledging and incorporating our lived experiences, challenging the
notion that objective, third-person perspectives can capture the
fullness of reality. The book is a thought-provoking exploration of the
philosophical underpinnings of scientific endeavors and their
implications for our understanding of self, world, and existence.</p>
<h3
id="simplicity-as-guide-to-scientific-metaphysics">Simplicity-as-Guide-to-Scientific-Metaphysics</h3>
<p>The text discusses the concept of simplicity in theoretical physics
and its role in model-building. It emphasizes that simplicity is not
just about compactness or convenience but also about capturing the
underlying compositional structure of the world. The author argues for a
specific type of simplicity, measured by the number of degrees of
freedom in a theory’s phase space, as a crucial factor in choosing
models.</p>
<p>The text begins by presenting simple kinematical examples to
illustrate the intuitive justification favoring simpler models. It then
broadens this concept to apply to complex dynamical systems, emphasizing
that simplicity helps avoid unnecessary complexity and redundancy in
theories. The author argues that a simpler model does a better job of
clearly, non-redundantly, and without overreaching the evidence
reflecting the degrees of freedom implicated in producing macroscopic
variation.</p>
<p>The text discusses several objections and queries:</p>
<ol type="1">
<li>Objection: The number of degrees of freedom is an abstract measure
that doesn’t distinguish quite different accounts of compositional
structure. Response: This is correct; the number of degrees of freedom
does not provide a sole criterion for model construction, and questions
about how they are divided into components remain difficult.</li>
<li>Objection: If staying close to the evidence is the goal, why not use
a simple description neutral about underlying structure? Response: The
primary goal is forming powerful and accurate inductive hypotheses,
which requires understanding compositional structure. While simpler
models may be more conservative, they provide a basis for prediction and
intervention.</li>
<li>Objection: This approach doesn’t fit quantum mechanics, as it
presents a classical ontology. Response: The author argues that the
issue lies with quantum mechanics’ lack of a clear, unambiguous ontology
due to non-dynamical constraints on joint states of complex
systems.</li>
<li>Objection: If simplicity is based on epistemological conservatism,
what warrants its use as an extra-empirical criterion for model
construction? Response: The author suggests that simplicity’s role stems
from the method’s success in uncovering underlying order and guiding
interventions, making it a practical choice even if not fully
justified.</li>
</ol>
<p>The text concludes by emphasizing the importance of understanding
this type of simplicity in theoretical physics, as it unifies various
theoretical practices and explanatory principles. It acknowledges that
this is not the only type of simplicity but a significant one in
capturing compositional structure up to discernible macroscopic
effects.</p>
<h3
id="space-quantum-mechanics-and-bohms-fishtank">Space-Quantum-Mechanics-and-Bohms-Fishtank</h3>
<p>Jenann Ismael’s chapter, “Space, Quantum Mechanics, and Bohm’s Fish
Tank,” explores the possibility that space might not be a fundamental
structure in physics, drawing parallels with quantum phenomena. She
presents two main arguments using low-dimensional examples: Bohm’s Fish
Tank and Complementarity.</p>
<ol type="1">
<li><p><strong>Bohm’s Fish Tank</strong>: This example involves a 3D
fish tank where cameras project side-by-side images onto a 2D screen,
creating an ‘image space’. A viewer confined to the 2D screen would
observe correlated movements between images without any apparent causal
connection or signal passing through the 2D space. These correlations
are due to redundancy in the image space, which is a lower-dimensional
projection of the 3D reality. This mirrors quantum entanglement, where
particles’ properties become correlated despite no apparent causal
interaction between them in 3D space.</p></li>
<li><p><strong>Complementarity</strong>: In this section, Ismael
discusses how certain aspects of a 3D object (like a fish) are mutually
exclusive or partially occluded when viewed from different angles in the
image space. This is analogous to quantum complementarity, where
different observables (like position and momentum) cannot be
simultaneously measured with arbitrary precision due to their
non-commutativity.</p></li>
</ol>
<p>Ismael argues that these examples suggest space might not be
fundamental because:</p>
<ul>
<li>Correlations in both scenarios are the result of redundancy, not
direct causal connections within the observed space.</li>
<li>The challenges in understanding quantum phenomena (like
entanglement) may stem from trying to interpret them as happening within
a 3D space when they could be projections of a higher-dimensional
reality.</li>
</ul>
<p>She also discusses two kinds of causal notions and spaces:</p>
<ul>
<li><p><strong>Causal Notions</strong>: Directed, acyclic graphs (DAGs)
representing interventionist counterfactuals and causal processes as
chains of events involving conserved quantities. She suggests that
quantum mechanics’ challenges arise from the lack of these familiar
causal structures in 3D space-time.</p></li>
<li><p><strong>Notions of Space</strong>: Our-space (manifest, everyday
sense) vs Ur-space (hypothetical underlying space housing fundamental
objects). Ismael proposes that if Our-space is an ‘image space’ (like
the 2D projection in Bohm’s example), it might explain quantum
phenomena’s peculiarities without requiring a non-local, mysterious
causal structure.</p></li>
</ul>
<p>In conclusion, Ismael argues for a shift in our ontological stance
regarding space: instead of assuming a 3D world with hidden variables
explaining quantum effects, we should consider Our-space as potentially
derivative or emergent. This view aligns with certain interpretations of
quantum mechanics and cosmology/quantum gravity, where space is often
treated as non-fundamental due to high-level theoretical concerns. The
chapter aims to provide a clearer articulation of this impetus from
quantum phenomena for an emergent spatial ontology.</p>
<h3
id="symmetry-as-a-guide-to-superfluous-theoretical-structure">Symmetry-as-a-Guide-to-Superfluous-Theoretical-Structure</h3>
<p>Title: Symmetry as a Guide to Superfluous Theoretical Structure
Authors: Jenann Ismael and Bas C. van Fraassen</p>
<p>In this article, the authors explore how symmetries can serve as
indicators of superfluous structure within physical theories. They argue
that identifying such redundancy is essential for a more accurate
representation of nature, adhering to the principle of formal simplicity
in modern physics. Here’s a detailed summary and explanation:</p>
<ol type="1">
<li>Superfluous Structure:
<ul>
<li>The concept of superfluous structure refers to elements or relations
within a system (concrete or abstract) that are dispensable for its
intended purpose but might still be relevant from other perspectives,
like aesthetics or historical value. In the context of physical
theories, it indicates multiple representations for the same physical
situation.</li>
</ul></li>
<li>Theoretical Ontology and Laws:
<ul>
<li>A theory consists of two primary components: (1) theoretical
ontology, which specifies its initial metaphysical possibility space;
and (2) a set of laws that selects physical possibilities from this
broader space. The authors propose representing theories as structured
sets of possibilities, which aligns with familiar spaces used by
physicists like phase or configuration spaces.</li>
</ul></li>
<li>Empirical Content:
<ul>
<li>To interpret a theory correctly, it must be linked to observable
phenomena through an external relation (theory-phenomena relation). This
connection is achieved via qualitative aspects of physical situations,
which correspond to parameters directly accessible to observers through
perception.</li>
</ul></li>
<li>Symmetries:
<ul>
<li>The authors define symmetries in terms of structure preservation
within a theory’s initial possibility space:
<ol type="1">
<li>World symmetries: Transformations that map worlds onto themselves
(i.e., automorphisms).</li>
<li>Theory symmetries: Transformations preserving the satisfaction and
non-satisfaction of laws, without necessarily preserving specific
features of physical possibilities.</li>
</ol></li>
</ul></li>
<li>Signs of Superfluous Structure:
<ul>
<li>Symmetries of a theory that also preserve qualitative structure
indicate superfluous theoretical structure. These symmetries can be
interpreted as trivial, permuting physically insignificant features
while leaving empirical content unaffected. This interpretation allows
us to identify structures distinguishing related representations as
superfluous without altering the empirical content of the theory.</li>
</ul></li>
<li>Critique and Counterexamples:
<ul>
<li>The authors critique other accounts that fail to consider distinct
classes of symmetries, like those preserving qualitative structure but
not being symmetries of the laws or symmetries that do preserve
qualitative structure without being trivial. They also provide
counterexamples (e.g., a simple theory with only qualitatively
distinguishable models) to highlight the importance of these
distinctions.</li>
</ul></li>
<li>The Principle of Sufficient Reason (PSR):
<ul>
<li>PSR is often invoked in discussions about identifying superfluous
structure; however, it primarily prohibits recognizing invisible,
dynamically irrelevant differences rather than mandating the
identification of qualitatively identical possibilities. The authors
argue against a broad interpretation of PSR that would discard
combinatorial structure from spaces of possible worlds.</li>
</ul></li>
<li>Conclusion:
<ul>
<li>Symmetries of the laws serve as critical guides for identifying
superfluous theoretical structures, promoting formal simplicity in
physical theories and aligning with modern physics’ historical trend
toward eliminating redundant concepts. By focusing on
qualitative-structure-preserving symmetries, physicists can streamline
their representations without sacrificing empirical content.</li>
</ul></li>
</ol>
<h3
id="symmetry_and_superfluous_structure">Symmetry_and_superfluous_structure</h3>
<p>The text discusses the philosophical method used in physics,
particularly in space-time and non-space-time theories, to identify and
eliminate superfluous structure in a formalism. This method involves
using symmetries of laws to guide the identification of physically
insignificant structure that does not contribute to observable
dynamics.</p>
<ol type="1">
<li><p><strong>Historical Context</strong>: Pre-scientific metaphysics
relied on imagination to understand reality, but as complexity increased
and data became more abundant, mathematics emerged as a crucial tool for
recognizing hidden patterns. Mathematical representation allows us to
compactly represent vast amounts of data and uncover underlying
regularities.</p></li>
<li><p><strong>Mathematical Insight in Discovery</strong>: The ability
to see patterns requires focusing on the right quantities. For example,
Galileo noticed the consistent period of a swinging lamp’s motion by
measuring weight, radius, angular displacement, and time per swing
instead of considering irrelevant factors like the medium’s resistance
(as Aristotelian science would).</p></li>
<li><p><strong>Mathematical Representation</strong>: Mathematics helps
in uncovering hidden patterns within data by offering compact ways to
represent information and reveal regularities that are not visually
apparent. It also aids in identifying higher-order invariant
relationships between measurable quantities, which are essential for
scientific laws.</p></li>
<li><p><strong>Symmetries as Guides</strong>: Symmetries play an
important role in identifying superfluous structure by highlighting
physically insignificant aspects of the formalism or object being
studied. This method is used to simplify ontology (the nature of what
exists) and reduce degrees of freedom in a system without losing
essential dynamical information.</p></li>
<li><p><strong>Space-Time Physics</strong>: The history of space-time
physics exemplifies this method. Starting with Newtonian mechanics in
absolute space and time, scientists progressively eliminated unnecessary
structure using symmetries as guides:</p>
<ul>
<li>Galilean transformations identified excess structure (identity of
points over time), leading to Galilean space-time.</li>
<li>Poincare transformations were used for Special Relativity,
eliminating additional geometric structure not invariant under these
transformations, resulting in Minkowski space-time.</li>
</ul></li>
<li><p><strong>Non-Space-Time Theories</strong>: In non-space-time
theories like electromagnetism and quantum mechanics, internal
symmetries (transformations altering internal degrees of freedom) are
examined. This can lead to conflicts with common sense or analytic
metaphysics, as seen in gauge theories.</p></li>
<li><p><strong>Challenges and Limitations</strong>: Applying this method
is not straightforward due to complexities in distinguishing physically
significant from insignificant structure. It requires careful judgment,
new formalisms, and often results in difficult interpretations.
Moreover, identifying redundant structure lacks a purely formal way,
necessitating external criteria for distinction.</p></li>
<li><p><strong>Justification</strong>: The method’s justification is
rooted in its historical success in guiding fruitful lines of
development in physics. Its authority lies in leading to simpler
theories that better explain observations. However, there are ongoing
debates regarding its application, particularly concerning gauge
theories and the interpretation of frame-dependent quantities.</p></li>
</ol>
<p>The core idea is that by identifying symmetries within laws and
exploiting empirical indistinguishability, physicists can eliminate
redundant structure from their formalisms without losing essential
dynamical information. This approach has significantly shaped our
understanding of space-time and non-space-time theories while
challenging traditional views on ontology.</p>
<h3
id="tls-the-impossible-man-by-patchen-barss-_-book-review-">TLS-The-Impossible-Man-by-Patchen-Barss-_-Book-review-</h3>
<p>The review is about “The Impossible Man” by Patchen Barss, a
biography of renowned mathematician and physicist Roger Penrose. The
book delves into Penrose’s life, focusing on his personal relationships
rather than the intellectual aspects of his work.</p>
<p>Penrose, known for his contributions to black hole theory and Penrose
tilings, is portrayed as an ordinary man with an extraordinary
intellect. He was driven by a need for his father’s approval, which he
found in mathematics. His marital life is detailed, including his
initial marriage to a woman who showed him attention and later, his
intense relationship with Judith, a younger woman whom he pursued
romantically over several years.</p>
<p>The biography emphasizes the stark contrast between Penrose’s humble
personality and the vastness of his ideas. Barss uses vivid descriptions
to illustrate this, such as a light signal traveling billions of years
from distant stars to contribute to young Penrose’s thoughts while
crossing the road.</p>
<p>The book’s subtitle, “Roger Penrose and the cost of genius,” raises
questions about whether the price of intellectual brilliance is
isolation and diminishment. As Penrose grows older, his ideas fail to
achieve the same acclaim as earlier work, and he becomes isolated from
family, living alone in a darkened flat surrounded by puzzles.</p>
<p>Critics argue that while the personal aspects are interesting, they
don’t fully capture Penrose’s professional standing, such as his
reverence among students at Oxford and respect in scientific circles.
The book also touches on Penrose’s controversial views about
consciousness, suggesting it can’t be computed due to Gödel’s
incompleteness results. His proposals for where this revolution will
come from (quantum mechanics) have been met with skepticism by
physicists and logicians.</p>
<p>The reviewer, Jenann Ismael, finds the biography incomplete,
comparing it to a boxing biography that ignores in-ring action. She
appreciates Barss’s writing style but feels the book lacks depth into
Penrose’s professional impact and his ongoing work on consciousness,
which she believes holds promise. Overall, while the personal narrative
is engaging, Ismael suggests it leaves out crucial aspects of Penrose’s
life as a brilliant scientist.</p>
