Laplace meets Godel: How Self reference Foils Prediction

Santa Fe Institute

1,486 views  May 19, 2025
Jenann Ismael, Johns Hopkins University


A common assumption holds that perfect prediction is theoretically possible in a deterministic universe. However, I use puzzles of counterprediction and self-reference to highlight a source of unpredictability that is independent of ignorance or indeterminism. I argue that this form of unpredictability emerges for any system that represents the world from within, revealing a crack in the edifice of determinism  that life and cognition actively exploit. Crucially, representational activity must be understood as an intrinsic part of the world's fabric.

So thanks so much for having me here. I'm really, really happy to be here. It's kind of a magical place, even more than I imagined.
So the invitation asks for talk that would give you a sense of what I do. So I'm a philosopher of physics, so I think about lots of things like space, time, quantum mechanics, natural laws, the kinds of things that fall under the fold of philosophy of physics.
But I also think, as Marina said, about the big, squishy questions, the kinds of questions that all of the systematic philosophers of the past thought about.
So questions like, who are we? How do we fit into the architecture of the universe? What is life? What is mind? Is there free will?
These are questions that science confronts in its own way, and that often take a sharp and really kind of illuminating form in the setting of a mathematically articulated physical theory.
So what I'm going to do today, though, is I'm going to raise a really simple little puzzle and then talk my way through it that can cast some light on those kinds of big, squishy questions.
I'm going to warn you, though, that there are no equations, no numbers, and no data or experiments in my talk.
So don't throw any tomatoes at me. You invited me.
But I'm hoping that you'll see that the value of a little simple point can really change the way you think about things that you think already that you understand really well.
I'm happy to have you interrupt me if there's something that you don't understand, but I'll also tell you that I think you'll get the best out of me if you let me get it all out, kind of get the big picture out, because that will also help you decide which details matter.
And also because philosophers are words people, the kind of the words are chosen carefully, I will absolutely stop hard at 40 minutes.
So there will be lots of time for questions. But if there's something you don't understand, please feel free to stop me.
So there's a kind of big picture image of the universe that had a lot of currency in the 20th century, universe of particles obeying deterministic laws.
People now, of course, make concessions to our de facto ignorance and quantum mechanics, of course, has shaken this picture at the very foundation.
But the idea persists, I think, that at least in this kind of ideal setting, perfect prediction is in principle possible.
So Laplace gave us that sort of unshakable image of a demon that knows the positions and momenta of all of the particles of which universe is composed at the beginning of time.
And as he says, embraces in a single formula everything that will ever happen through the history of the universe.
So this big picture image of the universe, sorry, I would say that sort of image, of course, is really upsetting for our common sense conviction that if some demon came up to you and told you that you would, I don't know, raise your hand in a second from now, you could just flip them off.
Right. But you're supposed to just suck it up and say, OK, so we're wrong.
We've been wrong about plenty of things in the past.
I want to take this very simple deterministic setting and use it to bring into focus a kind of unpredictability that has nothing to do with determinism or ignorance and a lot to do with your ability to kind of flip off a demon.
If he tells you he knows what you will do.
So here's the puzzle that started me thinking about all of this.
So we have a theory, Newtonian mechanics, that says that a being that knew the initial conditions of the universe would be able to predict everything that happens.
Same theory lets us construct a device that would let us that would be designed to undermine any revealed prediction of what it would do.
So it wouldn't be hard to construct such a device.
We're imagining here a simple input output machine.
Maybe it has a light, a green light on top and a red light on top.
It takes predictions of its output in a particular form in a specified format and then does the opposite of what it's predicted.
So green light, if it's predicted, it will flash red and the opposite.
OK.
Now, if there could be a demon of the kind that Laplace describes, we could chain it together with this kind of device.
We give the demon access to all physically accessible information.
We let it make its calculation of the device's output.
We feed it into the device.
Now, what would happen here?
At least, what does classical mechanics say would happen here?
We don't have to fight about whether the device understands predictions.
We're just going to assume that the predictor understands predictions.
We'll let him use his language and fix the format of predictions and we'll design the device.
OK.
So all we have to suppose is that there's a fixed fact about what would count as a prediction being correct.
And then we'll construct the device.
So when it takes a prediction, what it will do in that form, it does the opposite.
If this is something that worries you, keep it in mind.
Prediction is a representational act.
So this puzzle only gets off ground if you're willing to naturalize representational activity and accept that there are at least beings in the world that represent and have semantic content to their utterances.
Now, in the early version of this puzzle, which comes out of a 1965 paper by Michael Scriven, what you have is a predictor and a counter predictive device, but they're not actually communicating with one another.
So they're each performing their own calculation.
A lot of people write papers.
There's all of this discussion about who out calculates who.
Then in a 2010 paper by Kuypers and Ruhmens, someone has this idea, what if we force the predictor to give its prediction to the counter predictive device?
And that sort of changes everything.
It's a really interesting move because it makes a good deal of the preceding discussion entirely irrelevant.
We don't have to talk about who calculates faster.
We don't even have to talk about how much information the device could have.
Calculation is irrelevant.
The counter predictive device just waits for the predictor to finish her calculation and then does the opposite.
She doesn't even need to know anything else.
So at this stage, it should be obvious, though, to the demon that the thing is rigged against him.
He can predict that any prediction he will make will be used to override his prediction.
Calculating isn't going to do him any good because his calculation will generate a piece of information that needs to be taken into account and that will override the result of his existing calculation and so on.
So the demon is trying to make a prediction, but the prediction is connected to what happens in such a way that when he tries to do the computation, he's coming up against the fact that his prediction is going to affect what he predicts.
So if you think of what the predictor is trying to do, he's effectively running a simulation of the evolution of the counter predictive device in his head.
So he's performing calculation or evolving forward a mental model.
He knows the output of his simulation is going to feed into the device and prompt a counter predictive response.
So as soon as he finishes the simulation, he needs to run the simulation with the new output, prompting a new simulation, a different output, and so on.
So his simulation has to include the result of his simulation.
And in that sense, he's never going to get ahead of himself.
So if he thinks about it hard enough, the predictor knows in advance that he's not going to get ahead.
Trying to generate an accurate prediction of what the device is doing is chasing his own shadow.
So you would encounter the same problem if you wanted to write a deterministic computer program that takes a prediction of its output and does the opposite.
Again, you wrote the thing, so there's no missing information and there's no indeterminism.
And still, if you trust the program, there's nothing you could learn, no information that you could have that's going to help.
You shouldn't put any money on predicting the output.
So what's going on here?
So if you think about this in physical terms, it's at least a prima facie of puzzling.
If the demon knows the initial conditions and the laws, he should be able to use those to generate a prediction with certainty.
Deductively, it should follow.
And yet he's faced with a situation where he knows that any prediction he makes is going to be used against him.
It's a losing game for him, and he can see that in advance.
So you might be looking here for ways to diffuse the problem by arguing, look, there are physical, there are practical bordering on in principle reasons that a calculation like this wouldn't be physically implementable.
So, for example, you might think it's impossible to know the initial conditions with perfect precision, impossible to carry out the computation in practical time, and so on.
But if all of those loopholes were closed, if you think about it, this is just like a closed causal loop.
And we can make the analogy explicit by realizing that advanced predictions of a Laplacian predictor that is an infallible predictor would be effectively proxies for the events themselves.
Since the demon predicts an event, if and only if it occurs, having an advanced prediction is just as good as having the event itself in its own past.
So you can rig up something that has the same form as a closed causal loop.
So here, closed causal loop takes E onto not E.
Here, you just have an advanced prediction with certainty connected to the thing that it's supposed to predict, and then leading causally to the thing, to the opposite of the thing.
So now, the analogy, once you have this analogy in mind, it makes it really tempting to reason this way.
Look, so long as the demon has done his calculations correctly, the counter-predictive device is going to have to end up doing what he predicts.
And that, of course, is the conclusion that many people have drawn from determinism.
They imagine that if there were a demon that knew enough about the past, and used it to predict what you would do, that you would, for example, raise your arm in five seconds, you might think that if he told you about it, you could refuse.
But unless he miscalculates, you're going to end up doing what he predicts.
It'll be like death in Damascus.
You'll try to avoid the fate that you're told you're going to encounter, and then your very efforts will somehow end up affirming the prediction.
An intelligence that knew enough about the past could use the loss to predict the future with certainty.
We're simply not going to succeed at doing anything other than what a demon like that predicts.
That's the only consistent solution, you might think.
And it's a familiar response to the grandfather paradoxes in the case of closed causal loops.
But then you think about this for a little while, and you realize there's a perfectly general argument, independently of the physics.
I'm going to call it the master argument, like obnoxiously, that that can't be right.
There could never have been a demon of the type that we're imagining, not in classical mechanics, not in any theory.
And probably some of you are already seeing it, looking at it sort of this way is going to turn the tables on the usual understanding of determinism.
I'm going to suggest and bring into focus what I said before, a source of unpredictability that has nothing to do with ignorance or indeterminism.
So here's the master argument.
So forget about demons for now.
Suppose we just want to program a computer to be our grand overarching database or repository of information, factual information about the physical world.
So we set about programming it with as much factual information as we have.
We program it with the laws of physics, all of the scientific knowledge we've amassed, facts we know about the history of the Earth, the monkeys of Costa Rica, and so on.
The goal is to be able to put to it any question of physical fact, any yes-no question of physical fact, and an answer will appear in the output channel.
Not hard to find a question, a physical fact that it can't answer.
Just ask, is the answer that's about to appear in the output channel? No.
So however it answers, it's going to be doing the opposite of what it says.
By saying things, right, so let me back up.
Think about this in physical terms.
So the computer is a physical system, right?
The question of what appears in its output channel is a question of physical fact, and yet it cannot answer truthfully.
Notice that the problem here, again, is not a lack of information, nor is it indeterminism.
And it's not just that you can't program the thing to answer correctly with certainty what it will do.
The system can't even accidentally guess the correct answer to this question.
And if you think about it in mechanical terms, it's very clear what's going on.
There's no paradox here.
What's going on is by saying things, the computer is doing things, and we can get a kind of interference between what it says, that is to say, the semantic content of the utterance, and what it does.
The act it performs in making that utterance, and in general, if one is dealing with a physical system that's in the business of representing the world, so it's making statements or forming beliefs about the world, and it falls under its own scope,
everything that it does, everything that it does is going to cast a shadow or register at the level of representation, at the semantic level, and every representational act is going to be connected in the domain that it's representing.
It's going to be part of the causal order, and there are going to be these kinds of interaction effects.
And what we've set things up here in the self-referential situation is that we've just set things up so that they're interfering negatively with one another.
So in the case we're describing, the computer can't stabilize the fact that it's meant to describe the word that appears on screen independently of giving the answer, the description that it gives,
and the thing is set up so that no matter what answer it gives, it's going to be doing the opposite.
The answer is going to conflict with what it says. That's what I mean by negative interference.
That's also what's going on with paradoxes of self-reference, and indeed with most semantic paradoxes.
So again, there's no actual paradox here. There are perfectly consistent ways the world can be.
The system can answer yes, it can answer no, it doesn't have to answer at all.
Those are all perfectly physically consistent ways the world can be.
It's just that whatever way it answers, it won't be speaking truly.
So the right response, right reaction to the puzzle here is not inconsistency in the world, it's incompleteness in representation.
So the thing has to maintain a kind of incompleteness in its representation on pain of inconsistency, not logical inconsistency, but inconsistency with fact.
Because it's going to be producing a fact that disagrees with what it's saying.
Interference, what I'm calling interference is just forcing into the open the fact that representational activity is part of the world,
and self-reference is going to arise naturally and inevitably for any system that's representing the world from the inside.
This is really what was behind the initial puzzle that I started with.
It was the self-reference that the demon encountered when he tried to perform his calculation that sent him into that paralyzing loop.
He goes to calculate the output of the counter predictive device, but he knows that the output of his calculation is going to feed into the device and prompt a counter response.
So as soon as he finishes the calculation, he needs to run it again without output, prompting a new calculation, and so on.
So it was the self-reference that was implicit in the calculation that he was trying to run that was getting him fouled up in the negative interference that was arranged between what he was trying to predict and the prediction.
Now, the fact that you're going to run into interaction effects of your system in the world representing it is something that gets pushed out of view in most day-to-day physics.
Because in most day-to-day physics, one is modeling other systems, pendula, planets, gases.
We maintain a kind of provisional separation of subject, the thing doing the experiment, and the object, or investigator and the system being investigated.
Even when we're modeling ourselves, we're typically not modeling our own current representational activity.
But the people that have unavoidably encountered it, interestingly, are people that are, for example, trying to program an artificial general intelligence in a robot, so an embedded agent.
So they want to program a system with general knowledge and the ability to model the world, and they're coming up against the fact that there are going to be problems of self-reference.
Self-reference is usually, in that context, thought of as a pathology.
So you want to get as close to minimizing any disturbances that the computer or the agent's own activity has on the truth values of sentences in the field that it's representing.
But let me just point out that actually this is a familiar phenomenon.
So negative interference can arise in other ways.
So our government is trying to guess where a foreign army will attack, but they're tracking communications, and whatever we predict, they won't do.
Google Maps predicts traffic congestion in the east part of the city at lunchtime, and people avoid the area.
Positive interference arises as well.
So positive interference is a self-fulfilling prophecy.
Man's insecurity about keeping his commitment.
Shy lover drives her away.
More hilariously, I hope you've all seen these XKCDs.
Okay.
So any system that is keeping his commitment shot, sorry, any system that's acting in the domain that it's representing is going to encounter these kinds of interaction effects.
And they can interfere in complicated ways with peer knowledge acquisition.
If the system's own activity is part of the domain it's representing, there just are going to be interactions between what it says and what it does.
You can try to quarantine these effects.
But in any highly connected domain, it's going to be impossible.
There are going to be less direct effects because of the way that the system's behavior is connected in the wider domain.
So just consider, for example, the computer we were talking to.
Okay.
We can say, okay, so just don't answer questions about yourself and your own representational activity.
But what about questions like, will someone who looks at the answer to this question see the word no?
If the computer has a database that records its answers, will the database tomorrow or a year after show that the answer had been no?
If there's an internal counter that counts negative answers, triggers the launch of a rocket that knocks an asteroid off its course when it reaches a certain number, when will the rocket launch, right?
So it's going to be harder than you think to quarantine the effects here.
If there are causal connections between events in the domain, so that if the computer can transform an answer to one question into answers to others, there's going to be no simple way to contain the effects.
So this is mostly a kind of philosophical point, but philosophers often think about knowledge in this sort of detached way.
There are the way things are on the one hand, and there are representations of the way things are on the other, and truth is a kind of abstract, atemporal relation between your representations and the way things are.
What we forget is that knowledge is part of the world, and it makes a difference to what happens.
So interference is, I'm going to come back to that point in a minute, but interference is a familiar problem in some domains.
So an influential analyst predicts a fall in the value of the stock, prompting a sell-off, polls in an election made public, prompts strategic voting, and affect the outcome.
Anytime you have a prediction feeding back into the domain and affecting what it predicts, you have interference, and it's the paradox of predictability, that puzzle I started with, just on a larger scale.
When you see it this way, there's nothing confusing about it.
When you really naturalize representational activity, when you absorb it, that is to say, into the causal fabric of the universe, so you see that it plays a role in what happens, you recognize the possibility of these kinds of effects was there the whole time.
It was always going to be a delicate question, how your own representational activity was going to affect what you were trying to represent.
So there's a bunch of things that we can learn from this.
The first is that it brings into focus what I said before, a kind of unpredictability that isn't simply ignorant, so it's not remediated by having more information, and has nothing to do with indeterminism.
It has connections to the halting problem and to other puzzles of self-reference.
So if you think about the predictor, counter-predictor device, with the halting problem in mind, suppose you can solve the halting problem, then you can construct a machine that halts if and only if it doesn't halt.
Suppose there are a Laplacian predictor in the world, then you can construct a system that flashes a green light if and only if it's predicted that it flashes a green light.
Same form of the problem.
The second thing that you can learn is that it corrects a misunderstanding of the implications of determinism.
So this idea that has wide currency, certainly in philosophy and in the public imagination, that it's just our ignorance that makes us think that the future is open, that a direct confrontation with the predictor without our mundane implications would just dispel the illusion that the future has that kind of openness.
I think what this does is it sort of flips the script.
Prediction is hostage to interference.
Laplace was right.
What he said was a demon outside the universe with access to its total state could predict the future with certainty, but that's because its predictions aren't going to interfere with what happens.
It's not going to encounter these problems.
But for any system in the world, interference is going to, it will encounter interference, and interference is going to be an absolute limiting factor on what it can predict.
It's just like, as I said, if you try to write a deterministic computer program that takes a prediction of what it's going to do and does the opposite.
The fact that you know that's going to happen, that you can predict the failure of your own prediction, doesn't help predict correctly.
The fact that you have to keep your prediction secret to preserve its accuracy makes the point that interference defeats prediction.
Okay.
So there's a good physics question here about why, for example, classical mechanics doesn't furnish the in-principle possibility of an embedded demon.
Happy to talk about that if you want to in question and answer.
We know from the self-referential version of the argument that no theory tells you that there could be an embedded demon that can correctly answer all yes, no questions of fact about the world.
Quite generally, the way that you should think about this is if you take any set of consistent laws that allows the emergence of systems that use information to guide behavior and that represent the world from inside,
the laws will tell you where a particular system that is generating predictions and interacting with the environment, where it's going to encounter interference.
But what I want to do for the rest of the time, and I promised I would stop with lots of time for questions, is I want to emphasize two very different types of lessons.
One is I want to suggest that interference is the crack in the edifice of determinism that life and cognition exploit.
And then I want to sort of just point out that we, as systems that represent the world and use it to guide our behavior, we live in the regime of interference.
Our own experience of the world is organized around it.
So on the first point, what interference really does is it just brings into focus the fact that representational activity, gathering information, modeling the world, generating predictions is tangled up in the causal fabric of the world, and it makes a difference to what happens.
So that doesn't just mean that any system in the world that is doing these things will encounter interference as a kind of regrettable artifact of its embeddedness.
This is what representational activity is for.
In philosophy, as I said, we kind of talk about representation in that detached way, as though the goal of representation is truth, which is this timeless relation between the way things are and our representations.
As soon as you embed representational activity in the world, you realize that your mind isn't there to passively represent.
Representation is embodied activity, embedded creatures.
Its natural purpose is not truth, but interference.
The representational machinery in your head is guiding action in a way that works and is designed to work to offset predictions you don't like,
to counteract, support, obstruct, and otherwise get in the way of your own predictions, if you don't like them, and promote the ones that you do.
So think about these three different types of systems.
A rock rolling down a hill, magnetotactic bacteria.
These are bacteria that have organelles that contain magnetic crystals that keep them oriented towards magnetic north,
sort of guiding them towards nutrient-rich environments.
Or a frog that snaps out its tongue at a passing fly.
Or a person making a decision.
So look at, in the case of the rock, there's nothing of special interest that's kind of going on inside.
In the case of the frog snapping out its tongue, or the bacteria, these are evolved systems.
The internal machinery is using information to produce motor responses that allow the system to access free energy
and do what it needs to offset the entropic tendencies of the environment that would otherwise lead to the system's dissolution.
The logic of anticipating the future and then selecting responses that counteract or offset disfavored results
is kind of implicit in those cases in the system's design.
By the time you get to a person making a decision, the logic of anticipation and selecting responses to offset things that you don't like
is explicit as a computation that the system is carrying out in real time.
So we're running an internal simulation that assesses the impact of different behaviors
and uses the outputs of the simulation to guide behavior in a preferred direction.
And it's crucial to this arrangement, that the inner gears are engaging the outer machinery of the world
in a way that's designed to create counter-predictive interference.
So go back to the kind of the demon and the device.
So in that case, we had the predictor and the responder,
and the connection and the relationship between them was adversarial.
The predictor's goal was prediction.
The counter-predictive goal was FOIL prediction.
But if you ask yourself, what is the human mind?
It's effectively a system that generates prediction chained together with a counter-predictive device.
But here we replace prediction with the more general expectations.
So predictions take the form of a probability distribution,
where before we had two adversarial systems, one to predict and one to FOIL a prediction.
What if they work together?
And the job of the whole system, not unlike the Poulter or the analyst,
is not to achieve accuracy in its predictions, but rather a kind of selective inaccuracy.
The job of the responder is to curb predictions it doesn't like and to promote ones that it does.
So you can think of the system as a whole here as using what it knows and what it anticipates
to guide responses in a way strategically designed to shift the downstream probabilities
in a direction that it favors.
So how does this work?
Predictor uses information from the past to generate probability distribution over futures compatible with it.
Responder takes a distribution, conditionalizes on different choices,
and then makes the choices that maximizes expected utility or whatever your favorite decision rule is.
But what's going on here?
So I'm saying all of this just to show you that this actually has the form of the counter-predictive interference.
The responder is effectively using interference to sculpt the future by getting in the way of predictions it doesn't like
and behind ones that it does.
So our own experience of the world is organized around paradox of predictability type interference.
Paradox of predictability is just the name for that puzzle I started with.
So if you are representing the world from within, and what you do is guided by what you expect to happen,
you live in the regime of interference.
Your expectations are meant to get, sorry, in their own way.
That's what they're for.
So the native position of the embedded agent is rife with interference.
I'm looking into my future in a way that's centered on the here and now,
and I'm in the regime of the sculptor, not of the predictor.
Okay, so I'll close just by highlighting the little sort of gestalt shifts that all of this can induce
when thinking about the role of intelligence in nature.
So one was this idea that the natural purpose of representation isn't truth but interference.
Another is really leaning into this idea that life and cognition aren't incidental byproducts
of the mindless crunching of physical law.
Not a way that you tend to think around here, but in the circles that I move in, it is.
But rather that life and cognition are exploiting laws of physics to guide the flow of energy to their own ends.
And finally, this is a little bit too cute, but the third has to do with that old familiar lesson about free will.
So the idea still really has wide currency that determinism is supposed to reveal,
that your sense of agency is illusory.
So if you were faced with a demon that knew enough about your past,
it could predict what you would do, and you would be powerless to do otherwise.
So that's that death in Damascus division that you would do your best efforts to avoid what it predicted,
and your efforts would themselves inevitably lead to your doing the thing.
So what I've been arguing is that the opposite is truth.
An aspiring demon is going to have to keep his prediction secret
if the prediction is about you and your voluntary behavior,
or you can use it against him.
So the real lesson is not that avoidance is futile because prediction is possible,
but that prediction is futile where avoidance is possible.
Thank you.
