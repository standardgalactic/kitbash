Philosophical Explorations
An International Journal for the Philosophy of Mind and Action
ISSN: 1386-9795 (Print) 1741-5918 (Online) Journal homepage: www.tandfonline.com/journals/rpex20
Cognitive access and cognitive phenomenology:
conceptual and empirical issues
Miguel Ángel Sebastián
To cite this article: Miguel Ángel Sebastián (2016) Cognitive access and cognitive
phenomenology: conceptual and empirical issues, Philosophical Explorations, 19:2, 188-204,
DOI: 10.1080/13869795.2016.1176235
To link to this article:  https://doi.org/10.1080/13869795.2016.1176235
Published online: 11 Aug 2016.
Submit your article to this journal 
Article views: 359
View related articles 
View Crossmark data
Citing articles: 1 View citing articles 
Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=rpex20

This paper is part of the special issue "Conscious Thinking and Cognitive Phenomenology"
guest edited by Marta Jorba and Dermot Moran
Cognitive access and cognitive phenomenology: conceptual and
empirical issues
Miguel A´ ngel Sebastia´n∗
Instituto de Investigaciones Filoso´ﬁcas, UNAM, Mexico City, Mexico
(Received 5 April 2016; ﬁnal version received 5 April 2016)
The
well-known
distinction
between
access
consciousness
and
phenomenal
consciousness has moved away from the conceptual domain into the empirical one,
and the debate now is focused on whether the neural mechanisms of cognitive access
are constitutive of the neural correlate of phenomenal consciousness. In this paper, I
want to analyze the consequences that a negative reply to this question has for the
cognitive phenomenology thesis - roughly the claim that there is a "proprietary"
phenomenology of thoughts. If the mechanisms responsible for cognitive access can
be disentangled from the mechanisms that give rise to phenomenology in the case of
perception and emotion, then the same disentanglement is to be expected in the case
of thoughts. This, in turn, presents, as I argue, a challenge to the cognitive
phenomenology thesis: either there are thoughts with cognitive phenomenology we
lack cognitive access to or there are good reasons to doubt that there is such a thing
as cognitive phenomenology. I discuss and explore the conceptual and empirical
problems for assessing this disjunction, and conclude that defenders of the cognitive
phenomenology thesis have nothing to fear from this distinction. I ﬁnish by
speculating on how it might, in turn, speak in favor of the cognitive phenomenology
thesis.
Keywords: consciousness; cognitive phenomenology; cognitive access; dual system
theories; dreams; global workspace
There is a well-known conceptual distinction, introduced by Block (1995-2002a),
between access consciousness and phenomenal consciousness. A mental state is access-
conscious if and only if, roughly, its content is available for belief formation and rational
control of action, whereas a mental state is phenomenally conscious if and only if there is
something it is like to be in that state. The debate over whether this conceptual distinction
picks up different properties has recently moved away from the conceptual domain into
the empirical one, and it has focused on the possibility of phenomenology without cog-
nitive access; that is, on whether the neural basis of phenomenal consciousness can be
disentangled "from the neural machinery of the cognitive access that underlies reports
of phenomenal consciousness" (Block 2007a, 481). This paper attempts to explore the
consequences of a positive answer to the previous question for the debate about cognitive
phenomenology.
Consider the proposition that it rains in Mexico in August. Call this proposition "p". p is
a proposition toward which one can have different attitudes. One can believe that p, desire
# 2016 Informa UK Limited, trading as Taylor & Francis Group
∗Email: msebastian@gmail.com
Philosophical Explorations, 2016
Vol. 19, No. 2, 188-204, http://dx.doi.org/10.1080/13869795.2016.1176235

that p, hope that p, doubt that p, etc. These different attitudes correspond to different mental
states. I will use the term "thought" to refer to them.1
It is uncontroversial that there are thoughts we have cognitive access to: we can report
the content of (some of) our thoughts. I can let you know that I desire to ﬁnish this paper,
that I believe that the coffee is getting cold and that I hope that Angelica ﬁnishes her
dissertation. Controversyarises when we consider the phenomenology of thoughts.Although
some authors have maintained that thoughts are example of states for which there is not some-
thing it is like to be in them (Braddon-Mitchell and Jackson 2006), few authors would agree
with the claim that all thoughts lack phenomenology. One of the most interesting questions in
current controversy around the phenomenology of thought is whether there are thoughts
whose phenomenology outstrips sensory phenomenology broadly understood as to include
images, moods, and the feelings associated with emotions; whether there is a "proprietary"
phenomenology of thoughts (Bayne and Montague 2011). I will refer, as is typically done,
to this kind of phenomenology as cognitive phenomenology.
Cognitive Phenomenology Some thoughts are phenomenally conscious and (and at least
some of them) have a proprietary phenomenology.
The main problem in evaluating this thesis is that the debate rests highly upon phenom-
enological observation. Participants in the debate tend to disagree on the details of their
experiences and we lack a criterion to decide who is introspecting better - or even to
decide whether they just happen to have different experiences. I do not mean that we
should study the alleged phenomenology of thoughts without introspection, but rather
that we should additionally look for empirical results that help tilt the scales in favor of
one position or the other. There is little work in this direction and looking for the empirical
commitments of an hypothesis seems to be the right way to go in order to assess it. This
paper attempts to advance the discussion in this direction.
I will start by presenting a challenge to the cognitive phenomenology thesis. The core
idea of this challenge is that, if the mechanisms responsible for cognitive access can be dis-
entangled from the mechanisms of phenomenology in the case of perception and emotion,
the same disentanglement is to be expected in the case of thoughts. I will argue that if, on the
contrary, there is no distinction between thoughts to which we have cognitive access and
phenomenally conscious thoughts, then the cognitive phenomenology thesis is jeopardized.
This problem is presented in Section 2 after I have properly introduced and motivated the
distinction between phenomenology and cognitive access in Section 1. In Section 3, I
discuss the problems for assessing whether there are phenomenally conscious thoughts
we cannot access at the empirical and conceptual levels. On the conceptual side, there
seems to be no room in our current taxonomies, based on report and deployment in reason-
ing, for the required category. However, I will argue that the empirical evidence derived
from studies in unconscious reasoning favors a broader taxonomy consistent with the
requirements of the cognitive phenomenology thesis. Finally, I will discuss the problems
for empirically assessing the reality of phenomenally conscious thoughts we lack cognitive
access to. I conclude by speculating about how the distinction between cognitive access and
phenomenology might, in turn, speak in favor of the cognitive phenomenology thesis.
1.
Phenomenology and cognitive access
There is a conceptual distinction between two of the senses in which the term "conscious-
ness" is deployed. They have been labeled "access" and "phenomenal consciousness" (or
simply phenomenology) (Block 2002b). However, it remains controversial whether the
neural mechanisms in virtue of which a state is access conscious differ from those in
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 189

virtue of which a state becomes phenomenally conscious. In other words, even if we grant
the conceptual distinction, it is unclear whether there are states whose content is available
for belief formation and rational control of action but lack phenomenology, or states that
have phenomenology but are not available for belief formation and rational control of
action.
Granting the conceptual distinction, the question seems to be an empirical one. Accord-
ingly, the debate has recently moved away from the conceptual domain into the empirical
one focusing on the possibility of phenomenology without access. For this purpose, the
notion of access-consciousness has been reﬁned to that of cognitive access, and the question
turned into whether the neural basis of phenomenal consciousness can be disentangled from
the neural machinery of the cognitive access on which reports of phenomenal consciousness
depend (Block 2007a, 481). The underlying idea is that the neural machinery of cognitive
access on which the corresponding reports depend is the same neural machinery on which
belief formation and rational control of action depend. Defenders of what I will call "access
theories" of phenomenal consciousness maintain, whereas non-access theories of phenom-
enal consciousness deny, that the neural mechanisms on which cognitive access depends are
constitutive of phenomenal consciousness.2
The most widely accepted theory of cognitive access is the Global Workspace Theory
(Baars 1988; Dehaene 2009).3 According to this theory, the mental states we can report on
- the metal states we have cognitive access to - are those encoded in the global workspace
(GWS). States encoded in the GWS are those that win the competition to activate reverbera-
tory activity in the GWS, thereby maintaining their peripheral sensory excitation until a new
coalition wins out (Dehaene 2009). The information encoded there is made available to all
kind of processes like those responsible for report, the formation of beliefs or the rational
control of action. If we assume that the GWS is the right theory of cognitive access, then
access theories maintain, and non-access theories deny, that being encoded in the GWS
is a necessary condition for a mental state to have phenomenology.
This paper assumes the truth of a non-cognitive theory of phenomenal consciousness to
show its consequences for the cognitive phenomenology debate. However, for those who
are not familiar with this position, I would like to motivate the view by quickly reviewing
the empirical debate.
Based on the results of partial report experiments, like those in Sperling (1960) and
some more recent results (Landman, Spekreijse, and Lamme 2003; Sligte, Scholte, and
Lamme 2008), Block (2007a, 2011) has argued that the capacity of the memory buffer in
which the content of phenomenally conscious states is encoded is greater than that of the
memory system on which cognitive access depends, in favor of non-access theories. He
argues that the empirical evidence suggests that the capacity of the visual phenomenal
system is greater than that of the working memory buffer on which reportability
depends; and hence, that the content of experience overﬂows what we can cognitively
access: there is more to phenomenology than what we can tell.
In reply, some authors (such as Brown 2012; Brown and Lau forthcoming; Kouider
et al. 2010; Rosenthal 2007) have maintained that the content of phenomenology might
not be as rich as some might have thought and that we suffer from some kind of "refriger-
ator light" illusion: it seems to us that there is a rich phenomenology because whenever we
attend to a particular location we ﬁnd a consciously represented element and we thereby
mistakenly assume that it was already conscious before attending. Some proponents of
this line of response have claimed, for example, that there is a generic representation of
a matrix of alphanumeric characters in Sperling's experiment before the cue, but no speciﬁc
190
Miguel A´ngel Sebastia´n

representation as of any particular character (for discussion, see Block 2011; Kouider,
Sackur, and de Gardelle 2012; Stazicker 2011).
The conclusions to be derived from partial reports experiments remain controversial.
However, alternative approaches have been suggested to settle the discussion. Elsewhere
(Sebastia´n 2014), I have presented further support in favor of the claim that cognitive
access is not required for phenomenology, which is not subject to the controversy surround-
ing partial report experiments (see also Block Block 2014), by relating the neural correlates
of cognitive access to empirical research into the neurophysiology of dreams.
There is plenty of empirical evidence suggesting that cognitive access essentially
depends on the activity of the dorsolateral prefrontal cortex (see, e.g., Fuster 2008;
Goldman-Rakic 1988; Oliveri et al. 2001; Turatto, Sandrini, and Miniussi 2004); and,
indeed, the very proponents of the GWS rely on the activity of the dorso lateral prefrontal
cortex (dlPFC) in their neuronal model (Dehaene and Naccache 2001). Especially, illumi-
nating is the result obtained by Lau and Passingham (2006). In their experiment, subjects
are presented with two possible stimuli (a square or a diamond). A mask that shares a
contour with the stimuli leading to a reduction in perceived brightness and to degraded per-
ception of the spatial shape of the target (metacontrast mask) is presented after a short vari-
able period of time called the "stimulus onset asynchrony" (SOA). After the presentation of
the target and the mask, subjects have two tasks: (i) decide whether the target stimulus was a
diamond or a square and (ii) indicate whether they actually saw the target or were simply
guessing in the previous task. The ﬁrst question attempts to measure the objective perform-
ance capacity of the subjects: how good they are at identifying the target stimulus. The
second question is intended to measure their level of conﬁdence in the identiﬁcation task
they just performed: how conﬁdent they are of having seen the stimulus. The performance
(measured by (i)) and the conﬁdence (measured by (ii)) change as a function of the SOA.
Interestingly, we can ﬁnd two conditions (different SOA) in which the subjects perform
equally well, but such that, in one they tend to say that they have seen the stimuli,
whereas in the other, they tend to say that they were just guessing when answering the
ﬁrst question. This result clearly suggests a difference in the cognitive access subjects
have to the content of their states between the two conditions. After observing this
result, Lau and Passingham performed functional magnetic resonance imaging (fMRI) on
the subjects of the experiment. The study revealed, as expected, that the condition where
subjects tend to report having seen the stimulus - the condition in which subjects tend
to have cognitive access to the perceptual information - is associated with a signiﬁcant
increase in dlPFC activity (Brodmann' s area 46), indicating that this area is responsible
for cognitive access. However, fMRI and positron emission tomography studies have
shown that the dlPFC is selectively deactivated during sleep (Braun et al. 1997; Maquet
et al. 1996, 2005; Muzur, Pace-Schott, and Hobson 2002); a period in which, common
sense and independent evidence show (Horikawa et al. 2013; LaBerge 1988; Leclair-Vison-
neau et al. 2010), we entertain conscious experiences: dreams. This suggests that the mech-
anisms on which cognitive access relies are not constitutive of the neural correlates of our
conscious experience; and so, that the two mechanisms can be disentangled in favor of a
non-access theory of phenomenal consciousness.
Even if one thinks that the evidence in favor of non-access theories is not decisive, I
think it sufﬁces to make it an alternative worth considering. And it would be a very bad
starting point if the cognitive phenomenology hypothesis were to depend upon its falsity.
So, in the rest of the paper I will simply assume its truth - cognitive access is not consti-
tutive of phenomenology - and explore its consequences for the cognitive phenomenology
thesis.
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 191

2.
The challenge
If we accept the truth of non-access theories of consciousness, then a mental state does not
become phenomenally conscious by virtue of the cognitive access we have to it:4 phenom-
enology is a feature of mental states that does not depend upon the mechanisms on which
reportability, in turn, depends. For illustration, consider the GWS theory. According to it,
states encoded in the GWS are thereby made available for report, as well as for belief for-
mation and rational control of action: mental states we have cognitive access to are those
encoded in the GWS. The information encoded there is made available to all kind of pro-
cesses such as reporting, formation of beliefs or rational control of action.
However, if the neural mechanisms of phenomenology are independent of those of cog-
nitive access, then phenomenology is not something that arises in the process of being
encoded in the GWS. States are phenomenally conscious without any need of being
encoded in the GWS, as illustrated by those states encoded in the iconic memory5 in
partial report experiments or those we undergo during dreams.
If the GWS theory is the right theory of cognitive access - as I am considering for pur-
poses of illustration - then thoughts are like any other processes competing to activate
reverberatory activity in the GWS (Dehaene 2009). Thoughts encoded in the GWS are
those on which we can report. If the belief that it is raining in Mexico is encoded in the
GWS then I can, non-inferentially, form the belief that I believe that it is raining in
Mexico, I can consider whether I prefer to wear an umbrella or getting wet, and I can
report that I believe that it is raining in Mexico.
According to the cognitive phenomenology thesis, some thoughts have proprietary phe-
nomenology. My presentation of the cognitive phenomenology thesis is neutral on whether
the alleged proprietary phenomenology is due to the content of the thought or to the prop-
ositional attitude; that is, it is neutral on whether there is a common proprietary phenomen-
ology between my belief that it rains in Mexico and my desire that it rains in Mexico, or
between the latter thought and my desire that there is a political change in the next elections.
In any case, when those thoughts are encoded in the GWS, I can report on them. However, if
the mechanisms of phenomenology can be disentangled from the mechanisms on which
cognitive access depends, thoughts would hardly get their phenomenology by virtue of
being encoded in the GWS.6
We are then faced with a dilemma: either there are thoughts with cognitive phenomen-
ology we lack cognitive access to (phenomenally conscious thoughts that are not encoded
in the GWS) or there are good reasons to doubt that there is such a thing as cognitive phe-
nomenology, because the mechanisms of cognitive access are not likely to give them their
phenomenology. In the next section, I will make explicit and face the problems, both at a
conceptual and at an empirical level, for assessing this dilemma.
3.
Assessing the reply to the challenge
Defenders of the cognitive phenomenology thesis are committed to embracing the ﬁrst horn
of the dilemma; that is, they are committed to the claim that there are phenomenally con-
scious thoughts we lack cognitive access to - phenomenally conscious thoughts on which
we cannot report. In order to evaluate this alternative, we are ﬁrst faced with a prima facie
conceptual problem: Can we make sense of this possibility? In the next subsection, I will
approach this question by looking into current taxonomies of thoughts. I will show that
although they hardly make room for the required kind of thoughts, it is a consistent possi-
bility to widen our taxonomies to do so. Once we show that the position is not conceptually
192
Miguel A´ngel Sebastia´n

inconsistent, the question whether there are phenomenally conscious thoughts we lack cog-
nitive access to becomes an empirical one. In Section 3.2, I argue on the basis of empirical
evidence in favor of an afﬁrmative answer to this question and conclude by hypothesizing a
way in which this possibility might favor the cognitive phenomenology thesis.
3.1.
Conceptual problems
We are working on the hypothesis that states we have cognitive access to are made available
to a bunch of processes including those responsible for rational control of action, belief for-
mation and report. Paradigmatically, reportability is the mark of the states we have cogni-
tive access to. Most would agree that they can tell what they are consciously thinking. This
is because when we talk about conscious thought, we typically refer to thoughts we have
cognitive access to (I will refer to this kind of thoughts as "a-conscious thoughts"). The
same point is reﬂected in scientiﬁc research. For example, Baumeister, Masicampo, and
DeWall (2011) point out that "Conscious thought enables people to talk to others and
thereby enables small groups to resolve differences." Independent of whether (a-)conscious
thoughts have such a social role, which seems plausible, the quote perfectly illustrates the
idea that we presuppose reportability when we talk about conscious thoughts.
Beyond the distinction between a-conscious and non-a-conscious thoughts, there is a
widely accepted distinction between occurrent and dispositional thoughts. If we focus
on beliefs, as a particular kind of thoughts, there is a huge amount of things we believe.
For example, I believe that Madrid is the capital of Spain, that Paris is the capital of
France, . . . , that two plus two equals four, that two plus three equals ﬁve, . . . , that
orchids are beautiful, etc. I do constantly believe that two plus two equals four or that
orchids are beautiful, but those thoughts only rarely come to the forefront of my mind.
When they do, I possesses the beliefs occurrently and the rest of the time only disposition-
ally. Whereas dispositional thoughts endure, occurrents thoughts do not. The traditional
representationalist model of our memory system easily accounts for the difference
between occurrent and dispositional thoughts. Schwitzgebel (2014) proposes that:
A subject S dispositionally believes P if a representation with the content P is stored in S's
memory or "belief box", 7and S occurrently believes P when that representation is retrieved
from memory for active deployment in reasoning or planning - as soon as S moves to a differ-
ent topic, the occurrent belief ceases.
These two distinctions have to be carefully differentiated. On the one hand, active deploy-
ment in reasoning is the criterion for distinguishing occurrent and dispositional thoughts.
On the other hand, reportability is the criterion for distinguishing thoughts we have cogni-
tive access to from thoughts we lack cognitive access to. Now, one might suspect that if
certain content is retrieved from memory for active deployment in reasoning, then it is
reportable and we have cognitive access to its content. This would make the class of a-con-
scious thoughts equivalent to the class of the occurrent thoughts. However, there are theor-
etical and empirical reasons for resisting this move.
A very popular view in psychology holds that there are two systems for reasoning - or
at least two types of systems for reasoning (for a review and discussion, see Evans 2008):
System 1 and System 2.8 Despite the differences between dual-system proposals, they all
have in common the distinction between cognitive processes that are fast, automatic and
unconscious (System 1) and processes that are slow, deliberative and conscious (System
2). Very importantly for current purposes, the notion of consciousness in this distinction
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 193

is that related to cognitive access. As Evans remarks in his review of dual-system theories:
"An operational deﬁnition of consciousness that seems to have appeared (often implicitly)
in dual-process theories is that System 2 thinking requires access to a central working
memory9 system of limited capacity, whereas System 1 does not." And more explicitly
when he notes that "Consciousness is also closely associated with working memory in
'global workspace theory' - see Baars & Franklin 2003" (Evans 2008, 8-9).
System 1 and System 2 are supposed to make use, respectively, of non a-conscious and
a-conscious thoughts. Now, if the distinction between occurrent and dispositional thoughts
is made in terms of active deployment in reasoning, we can conclude that although a-con-
scious thoughts are occurrent, not all occurrent thoughts are a-conscious. In particular, those
that take part in System 1 processes are occurrent, because they are deployed in reasoning,
but not a-conscious. Dispositional thoughts naturally correspond to unconscious (phenom-
enally and otherwise) ones. Therefore, the interesting question is whether (at least) some
occurrent but non a-conscious thoughts qualify for having phenomenology - as the defen-
der of the cognitive phenomenology thesis is committed to maintain modulo the truth of a
non-access theory of consciousness.
To understand the relevance of this question, let me introduce a third distinction, close
to the ones already presented, between implicit and explicit thoughts.10 The distinction is
better understood by means of a clear example. I have one sibling and I believe so. I
also believe that the number of siblings I have is fewer than two, and fewer than three,
. . . , and fewer than ﬁve hundred, . . . It does not seem plausible that I have all these
beliefs stored individually in representational format in my mind. Those beliefs are said
to be implicit. Following Schwitzgebel (2014) , we can say that:
One believes P explicitly if a representation with that content is actually present in the mind in
the right sort of way - for example, if a sentence with that content is inscribed in the "belief
box". One believes P implicitly (or tacitly) if one believes P, but the mind does not possess, in a
belief-like way, a representation with that content.
This distinction is relevant because implicit thoughts are not suitable for having phenom-
enology. Phenomenology is an occurrent property of an occurrent mental state (Burge
1997; Kriegel 2005), but implicit beliefs do not qualify as such - as Schwitzgebel notes,
many philosophers have the distinction between explicit and implicit thoughts in mind
when they talk about occurrent and dispositional ones. In having an implicit belief that
p, there is no occurrent representation that p toward which I bear the propositional attitude
of belief. So, in that sense, it is not a thought I really entertain, and hence not a candidate for
being a phenomenally conscious state.11 But, it follows straightforwardly from the deﬁ-
nitions above that nothing prevents explicit thoughts being either dispositional or occurrent.
Thoughts involved in System 2 processes are explicit ones, because a-conscious thoughts
are always explicit. But defenders of the cognitive phenomenology thesis require that
(some) non-a-conscious thoughts are explicit. If System 1 thoughts were all implicit,
their position would be jeopardized. One might observe that deploying a thought in reason-
ing requires explicitly tokening a representation of it. Therefore, if as defenders of dual-
process theories maintain, System 1 thoughts are deployed in reasoning then they have
to be explicit. However, it is unclear what would justify the claim that affecting reasoning
requires explicit tokening of a representation, and more importantly, doubtful that all dual-
processes theorist would endorse it.
Consider, for example, Frankish's (2004) theory. He defends a dual-process theory on
which System 2 - what he calls "supermind" - processes are a-conscious, linguistically
194
Miguel A´ngel Sebastia´n

articulated and semantically valuable states of mind, whereas System 1 operates on the
basis of non-a-conscious mental states that seem to involve little more than an encoding
of information in a way poised to guide action (Toribio 2007). This kind of mental states
can be understood as implicit thoughts or, as Frankish prefers, as a completely different
natural kind. Either way, one might be reasonably suspicious that this kind of dual-
process theory makes room for non-a-conscious explicit and occurrent thoughts that
have phenomenology.
One might reach a similar conclusion by reviewing the empirical literature about the
roles of System 1 and System 2. For example, Lieberman et al. (2002) have argued on
theoretical grounds that full-ﬂedged logical reasoning is limited to System 2 - what
they call the "C" or reﬂective system. In favor of this hypothesis, DeWall, Baumeister,
and Masicampo (2008) found that hampering System 1 with suppressed thoughts failed
to impair reasoning, while DeNeys (2006) showed that occupying System 2 through
high cognitive load caused decrements in logical reasoning. The relevant detail lies in
the manipulation employed by DeNeys and colleagues for overloading system 1 -
which follows the one developed by Wegner and Gold (1995) - based on Wegner
(1994) ironic processing theory. According to it, thought suppression has two parts,
one in which a non- (a-) conscious process scans the environment looking for cues that
might evoke the forbidden idea, and a conscious suppression of such thoughts. Nonethe-
less, the unconscious process continues vigilantly scanning for unwelcome cues even after
the conscious mind turns its attention elsewhere. Wegner and Gold had participants think
of a past close relation that either was or was not still desired (hot vs. cold old ﬂame) as
their skin conductance level was measured, and then they instructed participants to stop
thinking about him or her; that is, to suppress the related thoughts. This procedure
frees up System 2 to solve logic problems (as in DeNeys et al.'s experiment) while the
nonconscious system is still (somewhat) busy thinking about the old ﬂame. After ﬁnishing
the logic problem, an interview showed that the thought of the old ﬂame remained highly
accessible, which would indicate that the ironic processing had continued its work all
along. In particular, those who still desired the relation experienced an increase in
emotional arousal (emotional rebound) indicated by the increase in the skin conductance
levels, whereas those who did not desire the relation anymore experienced a cognitive
rebound, a rebound of thoughts related to the old ﬂame, as indicated by their reports of
their stream of consciousness. Once this is made clear, it is far from obvious that the
alleged thoughts that have to explain the scanning processes that ironic theory postulates,
and the emotional and cognitive rebound, require explicit representation of the old ﬂame
while the subject is solving the logical problems.
Summarizing, if non-access theories are true, as I am assuming in this paper, defenders
of the cognitive phenomenology thesis are committed to the claim that there are phenom-
enally conscious states we lack cognitive access to. This, in turn, commits them to the exist-
ence of non-a-conscious explicit occurrent thoughts, for only explicit occurrent thoughts are
candidates to be phenomenally conscious. The idea that there are occurrent thoughts that we
lack cognitive access to is vindicated by dual-process theories. In particular, thoughts
deployed in System 1 satisfy this desideratum. However, it is unclear whether thoughts
deployed in System 1 processes have to be explicit, and also unclear if the mental states
deployed in these processes are of right kind - the kind of mental states that can have phe-
nomenology. We are faced with an empirical question: Are there non-a-conscious explicit
occurrent thoughts? How can this question be studied? Answering this question is the
purpose of next section.
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 195

3.2.
Empirical problems
There is a prima facie problem if we want to investigate whether there are explicit occurrent
thoughts to which we lack cognitive access. The reason is that if the subject lacks cognitive
access to the thought, we cannot ask her about what she is thinking about, and we have to
infer the kind of thought she might be undergoing from its behavior. But then, one can raise
reasonable doubts about whether the thoughts that would account for such behavior require
an explicit representation toward which the subject bears any attitude. In this section, I want
to suggest that there is nonetheless empirical evidence that favors the claim that there are
explicit occurrent thoughts we lack cognitive access to.
The ﬁrst piece of evidence has been provided by Mandelbaum (2015) on the basis of
implicit bias. ("Implicit" here is to be understood in the sense in which it is used in psychol-
ogy; that is, as a synonym of non-a-conscious - see note 10. In order to avoid unnecessary
confusion, I will keep using the terms "implicit" and "explicit" in the sense presented in the
previous section and introduce the terms "implicit*" and "explicit*" for the typical use in
psychology). Mandelbaum argues that, on the more than plausible assumption that
implicit* bias is caused by implicit* attitudes, then such implicit* attitudes are non-a-con-
scious occurrent (because they are deployed in reasoning) explicit (propositionally struc-
tured representations) beliefs. The reason is that, if implicit* biases are implicitly
represented, rather than explicitly, then we would expect them to be caused by some sort
of association rather than by inference because inference requires explicit representation.
This assumption is used by Mandelbaum to argue on an empirical basis that implicit*
biases are explicitly represented. The basic idea is that if implicit* biases were implicitly
represented, then they should be modulated by extinction or counterconditioning but not
by rational argumentation - which relies on inference. However, the empirical evidence
points in the opposite direction, showing that rational argumentation inﬂuences implicit*
biases. For instance - just to advance a couple of examples from the collection presented
by Mandelbaum - Brinol, Petty, and McCaslin (2008) showed that implicit* biases are sen-
sitive to the strength of the arguments, and Sechrist and Stengor (2001) have showed that
implicit* biases can be adjusted depending on what one's peers think of the topic at hand. If
Mandelbaum's reasoning is correct, then implicit* biases depend on non-a-conscious occur-
rent, explicit thoughts.
I want to present a second piece of evidence coming from neuroscience following a
similar strategy as the one I used in Sebastia´n (2014). Cognitive access to our conscious
experience seems to essentially depend on sustained activity in the dlPFC (Dehaene and
Naccache 2001; Fuster 2008; Lau and Passingham 2006). Although most of the evidence
in favor of the claim that the dlPFC plays an essential role in cognitive access has been col-
lected making use of visual tasks, few would doubt that this area is fundamental for having
cognitive access to our thoughts. In particular, those who have researched the neural mech-
anism underlying a-conscious thoughts do not. Lieberman (2003) and Lieberman, Jarcho,
and Satpute (2004) have identiﬁed two neurological mechanisms described as X- and C-
systems, corresponding to System 1 and System 2. The X-system is composed of the amyg-
dala, basal ganglia and lateral temporal cortex brain areas. On the other hand, the C-system
involves the anterior cingulate cortex, the medial-temporal lobe (including hippocampus)
and the prefrontal cortexincluding the dlPFC, for, as Lieberman, Jarcho, and Satpute
(2004) note, System 2 "relies on symbolic representations, which are organized into prop-
ositions and processed serially in working memory" ( 422, my emphasis).
Now, as we have already seen, dlPFC is one of the most deprived areas during sleep
(Braun et al. 1997; Maquet et al. 1996; Schwarz and Maquet 2002). But, do we undergo
196
Miguel A´ngel Sebastia´n

explicit occurrent thoughts during sleep? Reports of the subject upon awakening suggest
that we do. When individuals are woken during NREM sleep they report dreams only
5-10% of the time, in comparison with 80% of the time when waken during REM
sleep. However, when subjects are asked about what was passing through their mind
rather than about what they were dreaming, they describe mental activity about 50% of
the time, and such mental activity tends to be similar to everyday thinking (Foulkes and
Vogel 1965). Here is an example of such a report provided by Hobson (2005, 7):
I kept thinking about my upcoming exam and about the subject matter it will contain. I didn't
sleep well because I kept waking up and was inevitably pulled back to the same rumination
about my exam.
Although there is also an emotional component, reports recollected after waking subjects
during NREM sleep, as this example illustrates, focus on thought, and support the claim
that dreams in this period tend to be thought-like (Tononi 2009, 96).
If this is the case, then it seems reasonable to maintain that those are thoughts that
involve fully propositional representation. It is on this basis that we report them upon awa-
kening although they are not reportable (set aside muscular inhibition which is irrelevant for
the notion of reportability that deﬁnes cognitive access), at the moment we entertain the
thought - the reason being that we lack cognitive access to them, as suggested by the deac-
tivation of dlPFC. This demands, as Windt (2015) notes, an explanation. Reports upon awa-
kening cannot depend on the cognitive access we have to our thoughts at the moment we
entertain them, but rather on other kind of memory system like long-term memory.
However, this does not seem especially problematic. The only empirical commitment of
my argument is that information can be encoded in long-term memory without going
ﬁrst through working memory. So that, upon awakening, information can be brought
back from long-term memory to working memory thereby making the report possible.
In reply, one might attempt to resist the claim that subjects really undergo those epi-
sodes, alleging that they might be cases of false memories or confabulation (Dennett
1976; Malcolm 1959). However, it seems to me that this skeptical view about the reports
of subjects upon awakening is left unsupported once we consider the evidence (reviewed
in Sebastia´n 2014, see especially Horikawa et al. 2013), in support of the claim that subjects
really undergo the episodes they claim in the case of visual experiences. Although one
might coherently accept reports concerning visual experience but still be reluctant to
accept reports regarding thoughts, this evidence provide prima facie support for taking
the reports at face value.
One might also argue on a priori grounds against the idea of entertaining thoughts in
dreams. Ichikawa (2009), for example, has argued that dreams do not involve beliefs. He
contends that the episodes we undergo during sleep do not have the same functional role
as ordinary beliefs because they lack connection with perceptual experience and fail to
motivate actions. He argues that interpretationalist or dispositional accounts of belief
speak against the view that the episodes we undergo during sleep, and on which basis
we report upon awakening, are beliefs. I have two things to say in reply. In the ﬁrst
place, it has to be noted that, if propositional attitudes are mere dispositions, then the cog-
nitive phenomenology thesis does not get off the ground, because there is no occurrent state
in the mind to which phenomenology is attributed - see note 11. Second, once we assume a
representationalist framework, Ichikawa's reasoning poses no threat to mine. Even if the
episodes we undergo during dreams are not beliefs, they would still entail explicit represen-
tations toward which we bear an attitude (which might not be that of believing). This is
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 197

enough to show that there are non-a-conscious occurrent explicit thoughts, as the defender
of cognitive phenomenology requires.
I want to ﬁnish by brieﬂy speculating that the truth of a non-access theory of conscious-
ness might, in turn, provide some support for the cognitive phenomenology thesis.12 Let me
start by noting that we cannot retrospectively report thoughts that take part in System 1 pro-
cesses - like, for example, the thoughts underlying the ironic processing described at the
end of Section 3.1. One possible explanation thereof is that thoughts that take part in
System 1 processes are merely implicit thoughts. Now, if Mandelbaum is right, this
cannot be the right explanation. The reason is that implicit* attitudes are occurrent explicit
thoughts and the processes that operate on their basis are of the System 1 type, for we lack
cognitive access to them and they are fast and automatic.13 Although sometimes we might
infer and tell that an implicit* attitude was underlying our behavior, we fail to have retro-
spective cognitive access to them: we cannot, non-inferentially, report implicit* attitudes,
neither at the moment that it is deployed in reasoning nor later on. Things are different
in the case of dreams. Despite our lack of cognitive access to the thoughts we undergo
in dreams, we can report on them upon awakening. As we have seen, if during dreams
we undergo explicit occurrent thoughts we lack cognitive access to, then - considering
that we can report on them upon awakening - they have to be encoded in long-term
memory without going through the working memory. This difference demands an expla-
nation. I would like to make two suggestions in search for an answer, the second being
more speculative than the ﬁrst:
1 Thoughts we undergo during sleep are of the same kind as the thoughts that partici-
pate in System 2 processes: cognitive access is not constitutive of them.
2 Phenomenology is what distinguishes the thoughts that participate in System 2 pro-
cesses from those that participate in System 1 processes.
System 2 processes are reﬂective and deliberative and we have cognitive access to those
processes. This does not require that the thoughts that take part in System 2 processes are
constitutively thoughts we have cognitive access to, only that we have cognitive access to
them when System 2 processes take place. In fact, the brain areas tagged by Lieberman and
colleagues as responsible for System 2 processes remain active during sleep with the excep-
tion of those in the prefrontal cortex associated with working memory and executive pro-
cesses. Now, as there are good reasons for doubting that those processes take place in (non-
lucid) dream, there is no prima facie reason for doubting the truth of i. One can appeal to a
difference in kind to explain why we can retrospectively and non-inferentially report the
thoughts we have in dreams but not our implicit* biases despite the fact that both are
non-a-conscious. However, if both are occurrent and explicit more needs to be said in
order to provide a characterization of their difference in kind.
Defenders of the cognitive phenomenology thesis have a response ready at hand:
System 2 thoughts are, and System 1 are not, phenomenally conscious. An analogy with
the case of sensory states might help to back up this claim. If a non-access theory of con-
sciousness is true, then we can distinguish sensory states we have and sensory state we lack
cognitive access to. However, contrary to fully unconscious states, we sometimes can retro-
spectively and non-inferentially report on them, as the visual experiences we undergo
during dreams illustrate. The difference between those we can report on and those we
cannot is that the former but not the latter are phenomenally conscious. Despite the fact
that both might be stored in long-term memory, only those with phenomenology can be
retrieved for report - phenomenology would be a necessary yet not sufﬁcient condition
198
Miguel A´ngel Sebastia´n

for reportability (retrospective or otherwise). Surely, in order to take this speculative sug-
gestion into more serious consideration, further work is required connecting phenomenol-
ogy and retrospective reports. One possible way forward for it might be found if
phenomenology is built into episodic memory,14 on which basis we seem to report the epi-
sodes we were undergoing during sleep. Although the goal of fully establishing this con-
nection - beyond intuition - lies beyond the scope of this paper, one can point to the
fact that episodic memory is said to entail an intimate, direct and immediate sense that
"I" experienced the event (Moscovitch 1995; Vandekerckhove 2009; Wheeler, Stuss, and
Tulving 1997; Zahavi 2005). This autonoetic consciousness is arguably grounded in the
subjective character of experience or pre-reﬂective self-consciousness (Prebble, Addis,
and Tippett 2013; Zahavi 2005); in the fact that experiences are "characterized by a
quality of mineness or for-me-ness, the fact that it is I who am having these experiences"
(Gallagher 2000).15 In this case, if autonoesis is constitutive of the episodic memory and
pre-reﬂective self-consciousness constitutive of phenomenology (Sebastia´n 2012; Galla-
gher and Zahavi 2006; Zahavi 2005), the link would be settled.
If this suggestion is sound, the same might be true in the case of thoughts. System 1
thoughts are fully unconscious. Thus, episodic memories are not formed on its basis and
they cannot be retrieved back into working memory for report: we cannot remember our-
selves as undergoing those thoughts. System 2 thoughts, on the other hand, would have
phenomenology and we can form episodic memories on their basis.16 Hence, although
we might lack cognitive access to them, as the case of dreams illustrate, they can be
retrieved into working memory upon awakening - when the corresponding mechanisms
are reactivated - making report possible: subjects can remember themselves as undergoing
those thoughts during sleep.
4.
Conclusion
If the mechanisms on which cognitive access depend are not constitutive of phenomenol-
ogy, then a mental state does not become phenomenally conscious in virtue of being poised
for report, belief forming and rational control of action. If encoding in the GWS is the cat-
egorical basis of this dispositional property - being poised for report - then we can say that
mental states do not become phenomenally conscious by virtue of being encoded in the
GWS. This is true for sensory states but also for any other kind of mental state suitable
to have phenomenology, including thoughts. This seems to jeopardize the cognitive phe-
nomenology thesis because it is not clear that the notion of a phenomenally conscious
thought we lack cognitive access to is coherent.
In this paper, I have argued that it is perfectly consistent in two steps. First, I have
showed that the notion of occurrent thought, a thought currently deployed in reasoning,
is independent of the cognitive access we have to the mental state, as dual-process theories
defend. However, one can reasonably doubt that such thoughts are suitable states to have
phenomenology, for they might be merely implicit thoughts. To address this worry, I
have discussed empirical evidence that suggests that there are explicit thoughts we lack cog-
nitive access to, as the defender of cognitive phenomenology thesis is committed to hold.
Of course, this does not show that the thesis is true but shows that its defender has nothing
to fear from the distinction between cognitive access and phenomenology, as it prima facie
seemed. Moreover, as suggested in the last section, the fact that we can report on thoughts
we lacked cognitive access to at the moment we entertained them - as allegedly happens in
NREM episodes - points to phenomenology as a plausible candidate for explaining this
fact in favor of the cognitive phenomenology thesis.
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 199

Acknowledgements
I am grateful to Marc Artiga, Ned Block, Eric Mandelbaum, James Stazicker and Pepa Toribio for
discussion of the ideas in this paper. Previous versions of this paper were presented at the International
Conference on Phenomenology of Cognitive Experiences at University College Dublin, the Conference
of the Association for the Scientiﬁc Study of Consciousness in Paris and the 1er Encuentro IIFs-PUCP in
Lima. I am grateful to the participants in those events, especially to Tim Bayne, David Chalmers, Ce´sar
Escajadillo, Jonathan Farrell, Marta Jorba, David Miguel Gray and Agustin Vicente. I would also like to
thank two anonymous referees of this journal for their thoughtful comments.
Disclosure statement
No potential conﬂict of interest was reported by the authors.
Funding
Financial support for this work was provided by the PAPIIT projects [IA400615], [IN4013015], the
project [FFI2014-51811-P] and the Newton Mobility Grant [NG150209].
Notes
1.
Sometimes the word "thought" is used to refer to cases in which we merely entertain the prop-
osition without bearing any further attitude toward it. If this were possible (see Mandelbaum
2013 for an argument to the effect that there are no such cases, and that whenever we entertain
a proposition we believe it), then thinking a proposition (merely entertaining a proposition)
would be a particular case of thought, in the sense in which I am using the term in this paper.
2.
The distinction between access and non-access theories corresponds to what I have called, fol-
lowing Fahrenfort and Lamme (2012), "cognitive" and "non-cognitive theories of phenomenal
consciousness" (Sebastia´n 2014). All things considered, I ﬁnd the term "access theories" to be
more appropriate; moreover, in the present context it avoids unnecessary confusion, as we are
dealing with cognitive phenomenology.
3.
Proponents of GWS often intend it as a theory of phenomenal consciousness denying the dis-
tinction between cognitive access and phenomenology (Baars 1988).
4.
One might think that it would be more precise to say that by virtue of the mechanisms under-
lying the cognitive access we have to its content. In order to avoid unnecessary complication in
the exposition, I will keep using the expression "having cognitive access to a state", rather than "
. . . to its content". I intend this expression to be neutral on whether we have cognitive access to
something beyond the content. For example, we can come to know whether we perceive that
there is a cup on the table rather that believe or hope that there is a cup on the table; if those
states have the same content, then we would have cognitive access to something beyond the
content. Nothing in my argument (phenomenology aside) hinges on these details.
5.
More precisely, those encoded in the very fragile short-term memory that roughly correspond to
the iconic memory once the contribution of retinal persistence is eliminated (Block 2011).
6.
One might worry, as a referee has suggested, that different kinds of mental states might acquire
phenomenology through different mechanisms. For example, it might be that certain visual
states become phenomenally conscious through, say, certain visual-cortical mechanisms,
while encoding in the GWS is what produces the distinctive phenomenology of thoughts.
The problem is that some perceptual states are also encoded in the GWS and they would
thereby have the kind of phenomenology that encoding in the GWS allegedly provides. As a
result, the cognitive phenomenology thesis would turn out to be false, because the phenomen-
ology of thoughts would not be proprietary. Alternatively, one might claim that thoughts get
their phenomenology in virtue of being encoded in the GWS but not so perceptual states. In
the absence of independent motivation or empirical support, this alternative seems completely
wanting.
7.
A subject is said to have a representation of the proposition P stored in the "belief box", when it
is apt to be deployed in ways we regard as a characteristic of belief; for example in theoretical
inferences toward which it is relevant.
200
Miguel A´ngel Sebastia´n

8.
See, for example, Evans (2006), Epstein (1994), Fodor (1983, 2001), Lieberman et al. (2002),
Lieberman (2003), Stanovich (1999, 2004) and Wilson (2002). For discussion on the relation
between dual system theories and an alternative view like the massive modularity hypothesis,
see Eran˜a (2012).
9.
For a discussion of the relation between GWS and working memory, see Shanahan and Baars
(2007), Block (2007b) and Sebastia´n (2014).
10.
In psychology, the terms "explicit" and "implicit thoughts" often correspond to that between
what I have called a-conscious and non-a-conscious thoughts, where implicit thoughts are
those we do not recognize ourselves as having. See, for example, Evans and Over (1996).
11.
In this discussion, I am assuming, as it is typically done in the literature, a representationalist
theory of beliefs in particular and thoughts in general. It is worth stressing that, for the
reasons just mentioned, if a dispositionalist or interpretationalist theory of belief - and other
propositional attitudes - were true (see Schwitzgebel 2014 for a review), then the cognitive phe-
nomenology thesis hardly gets off the ground.
12.
For an independent argument in favor of the cognitive phenomenology thesis based on the dis-
tinction between phenomenology and cognitive access, see Jorba and Vicente (2014).
13.
Mandelbaum (2015) criticizes the idea that bands together System 1 processes and association.
In my introduction of System 1 processes, I have carefully left out this feature for as Evans
(2008) also notes: "while the notion that System 2 is in some sense 'rule-based' is compatible
with the proposals of most dual-process theorists, the characterization of System 1 as associative
is not." (13)
14.
I am grateful to an anonymous referee for this suggestion.
15.
For further discussion on the relation between pre-reﬂective self-consciousness and autonoesis
see, for example, Vandekerckhove, Bulnes, and Panksepp (2014).
16.
Note that this thesis can be, in principle, accepted by those who reject the cognitive phenomen-
ology thesis; for they can appeal to non-cognitive phenomenology to explain this fact. However,
although there is an emotional component in the episodes we undergo during NREM sleep, this
seems to be insufﬁcient for grounding the memories on which basis we report upon awakening.
Opponents of the cognitive phenomenology thesis can also appeal to other sensory phenomen-
ology. It is unclear to me that this is consistent with the patterns of neural activation in NREM,
but a complete assessment of such a reply will depend on its details.
Notes on contributor
Miguel A´ ngel Sebastia´n is Associate Research Fellow at the Instituto de Investigaciones Filoso´ﬁcas at
Universidad Nacional Auto´noma de Me´xico (UNAM). His research focuses on the philosophy of
mind and cognitive sciences with deep interest in consciousness studies.
References
Baars, B. J. 1988. A Cognitive Theory of Consciousness. Cambridge: Cambridge University Press.
Baumeister, R. F., E. J. Masicampo, and C. N. DeWall. 2011. "Arguing, Reasoning, and the
Interpersonal (Cultural) Functions of Human Consciousness." Behavioral and Brain Sciences
34: 74.
Bayne, T., and M. Montague. 2011. "Cognitive phenomenology: An introduction." In Cognitive
Phenomenology, edited by T. Bayne and M. Montague, 1-34. Oxford: Oxford University Press.
Block, N. 1995-2002a. "On a Confusion about the Function of Consciousness." In Consciousness,
Function, and Representation: Collected Papers, edited by N. Block, 159-214. Vol. 1. Cambridge:
Bradford Books.
Block, N. 2002b. "Some Concepts of Consciousness." In Philosophy of Mind: Classical and
Contemporary Readings, edited by D. Chalmers, 206-218. New York: Oxford University Press.
Block, N. 2007a. "Consciousness, Accessibility, and the Mesh between Psychology and
Neuroscience." Behavioral and Brain Sciences 30: 481-548.
Block, N. 2007b. "Overﬂow, Access, and Attention." Behavioral and Brain Sciences 30: 530-542.
Block, N. 2011. "Perceptual Consciousness Overﬂows Cognitive Access." Trends in Cognitive
Sciences 12: 567-575.
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 201

Block, N. 2014. "Rich Conscious Perception Outside Focal Attention." Trends in Cognitive Sciences
18 (9): 445-447.
Braddon-Mitchell, D., and F. Jackson. 2006. Philosophy of Mind and Cognition: An Introduction. 2nd
ed. Oxford: Wiley-Blackwell.
Braun, A., T. J. Balkin, N. J. Wesenten, R. Carson, M. Varga, P. Baldwin, S. Selbie, G. Belenky, and P.
Herscovitch. 1997. "Regional Cerebral Blood Flow Throughout the Sleep Wake Cycle. An
h2(15)o PET Study." Brain 120: 1173-1197.
Brinol, P., R. Petty, and M. McCaslin. 2008. "Changing Attitudes on Implicit Versus Explicit
Measures: What is the Difference?" In Attitudes: Insights from the New Implicit Measures,
edited by R. F. R. Petty and P. Brinol, 236-285. New York: Psychology Press.
Brown, R. 2012. "The Myth of Phenomenological Overﬂow." Consciousness and Cognition 21 (2):
599-604.
Brown, R., and H. Lau. Forthcoming. "The Emperor's New Phenomenology? The Empirical Case for
Conscious Experience without First-order Representations." In Themes from Block, edited by
Adam Pautz and Daniel Stoljar. MIT Press.
Burge, T. 1997. "Two Kinds of Consciousness." In The Nature of Consciousness: Philosophical
Debates, edited by O. F. Ned Block and G. Guzeldere, 427-434. Cambridge: MIT Press.
Dehaene, S. 2009. "Neural Global Workspace." In The Oxford Companion to Consciousness, edited
by A. C. Tim Bayne and P. Wilken, 466-469. Oxford: Oxford University Press.
Dehaene, S., and L. Naccache. 2001. "Towards a Cognitive Neuroscience of Consciousness: Basic
Evidence and a Workspace Framework." Cognition 79: 1-37.
DeNeys, W. 2006. "Dual Processing in Reasoning: Two Systems but One Reasoner." Psychological
Science17: 428-433.
Dennett, D. 1976. "Are Dreams Experiences?" Philosophical Review 73: 151-171.
DeWall, C. N., R. F. Baumeister, and E. J. Masicampo. 2008. "Evidence that Logical Reasoning
Depends on Conscious Processing." Consciousness and Cognition 17: 628-645.
Epstein, S. 1994. "Integration of the Cognitive and Psychodynamic Unconscious." American
Psychologist 49: 709-724.
Eran˜a, A. 2012. "Dual Process Theories versus Massive Modularity Hypotheses." Philosophical
Psychology 25 (6): 855-872.
Evans, J. 2006. "The Heuristic-analytic Theory of Reasoning: Extension and Evaluation."
Psychonomic Bulletin and Review 13 (3): 378-379.
Evans, J. 2008. "Dual-processing Accounts of Reasoning, Judgment, and Social Cognition." Annual
Review of Psychology 59: 255-278.
Evans, J., and D. Over. 1996. Rationality and Reasoning. Hove: Psychology Press.
Fahrenfort, J. J., and V. A. Lamme. 2012. "A True Science of Consciousness Explains
Phenomenology: Comment on Cohen and Dennett." Trends in Cognitive Sciences 16 (3):
138-139.
Fodor, J. 1983. The Modularity of Mind. Scranton, PA: Crowell.
Fodor, J. 2001. The Mind Doesn't Work that Way. Cambridge, MA: MIT Press.
Foulkes, D., and G. Vogel. 1965. "Mental Activity at Sleep Onset." Journal of Abnormal Psychology
70 (4): 231-243.
Frankish, K. 2004. Mind and Supermind. Cambridge: Cambridge University Press.
Fuster, J. 2008. The Prefrontal Cortex. 4th ed. London: Academic Press.
Gallagher, S. 2000. "Self-reference and Schizophrenia: A Cognitive Model of Immunity to Error
through Misidentiﬁcation." In Exploring the Self: Philosophical and Psychopathological
Perspectives on Self-Experience, edited by D. Zahavi, 203-242. Amsterdam: John Benjamins.
Gallagher, S., and D. Zahavi. 2006. "Phenomenological Approaches to Self-consciousness." http://
plato.stanford.edu/entries/self-consciousness-phenomenological/
Goldman-Rakic, P. S. 1988. "Topography of Cognition: Parallel Distributed Networks in Primate
Association Cortex." Annual Review of Neuroscience 11: 137-156.
Hobson, A. 2005. Dreaming: A Very Short Introduction. Oxford: Oxford University Press.
Horikawa, T., M. Tamaki, Y. Miyawaki, and Y. Kamitani. 2013. "Neural Decoding of Visual Imagery
during Sleep." Science 340 (6136): 639-642.
Ichikawa, J. 2009. "Dreaming and Imagination." Mind and Language 24 (1): 103-121.
Jorba, M., and A. Vicente. 2014. "Cognitive Phenomenology, Access to Contents, and Inner Speech."
Journal of Consciousness Studies 21 (9-10): 74-99.
202
Miguel A´ngel Sebastia´n

Kouider, S., V. de Gardelle, J. Sackur, and E. Dupoux. 2010. "How Rich is Consciousness? The
Partial Awareness Hypothesis." Trends in Cognitive Sciences 14: 301-307.
Kouider, S., J. Sackur, and V. de Gardelle. 2012. "Do We Still Need Phenomenal Consciousness?
Comment on Block." Trends in Cognitive Sciences 16 (3): 140-141.
Kriegel, U. 2005. "Naturalizing Subjective Character." Philosophy and Phenomenological Research
71 (1): 23-57.
LaBerge, S. 1988. "Lucid Dreaming in Western Literature." In Conscious Mind, Sleeping Brain.
Perspectives on Lucid Dreaming, edited by Jayne Gackenbach and Stephen LaBerge, 11-26.
Stanford: Plenum Press.
Landman, R., H. Spekreijse, and V. A. F. Lamme. 2003. "Large Capacity Storage of Integrated
Objects before Change Blindness." Vision Research 43 (2): 149-164. PMID: 12536137. http://
www.ncbi.nlm.nih.gov/pubmed/12536137
Lau, H., and R. Passingham. 2006. "Relative Blindsight in Normal Observers and the Neural
Correlate of Visual Consciousness." Proceedings of the National Academy of Science
103 (49): 18763-18768.
Leclair-Visonneau, L., D. Oudiette, B. Gaymard, S. Leu-Semenescu, and I. Arnulf. 2010. "Do the
Eyes Scan Dream Images during Rapid Eye Movement Sleep? Evidence from the Rapid Eye
Movement Sleep Behaviour Disorder Model." Brain: A journal of Neurology 133: 1737-1746.
Lieberman, M. D. 2003. "Reﬂective and Reﬂexive Judgment Processes: A Social Cognitive
Neuroscience Approach." In Social judgments: Implicit and Explicit Processes, edited by
Joseph P. Forgas, Kipling D. Williams, and William von Hippel, 44-67. New York:
Cambridge University Press.
Lieberman, M. D., R. Gaunt, D. T. Gilbert, and Y. Trope. 2002. "Reﬂection and Reﬂexion: A Social
Cognitive Neuroscience Approach to Attributional Inference." Advances in Experimental Social
Psychology 34: 199-149.
Lieberman, M. D., J. M. Jarcho, and A. Satpute. 2004. "Evidence-based and Intuition-based Self-
knowledge: An FMRI Study." Journal of Personality and Social Psychology 87: 421-435.
Malcolm, N. 1959. Dreaming. Camden: Routledge and Kegan Paul.
Mandelbaum, E. 2013. "Thinking is Believing." Inquiry 57 (1): 55-96.
Mandelbaum, E. 2015. "Attitude, Inference, Association: On the Propositional Structure of Implicit
Bias." Nous. doi:10.1111/nous.12089.
Maquet, P., J. Peters, J. Aerts, G. Delﬁore, C. Degueldre, A. Luxen, and G. Franck. 1996. "Functional
Neuroanatomy of Human Rapid-eye-movement Sleep and Dreaming." Nature 383: 163-166.
Maquet, P., P. Ruby, A. Maudoux, G. Albouy, V. Sterpenich, T. Dang-Vu, and S. Laureys. 2005.
"Human Cognition during Rem Sleep and the Activity Proﬁle within Frontal and Parietal
Cortices: A Reappraisal of Functional Neuroimaging Data." Progress in Brain Research 150:
219-227.
Moscovitch, M. 1995. "Recovered Consciousness: A Hypothesis Concerning Modularity and
Episodic Memory." Journal of Clinical and Experimental Neuropsychology 17: 276-290.
Muzur, A., E. F. Pace-Schott, and J. A. Hobson. 2002. "The Prefrontal Cortex in Sleep." Trends in
Cognitive Sciences 6: 475-481.
Oliveri, M., P. Turriziani, G. A. Carlesimo, G. Koch, F. Tomaiuolo, and M. Panella. 2001. "Parieto-
frontal Interactions in Visual-object and Visual-spatial Working Memory: Evidence from
Transcranial Magnetic Stimulation." Cerebral Cortex 11 (8): 606-618.
Prebble, S. C., D. R. Addis, and L. Tippett. 2013. "Autobiographical Memory and Sense of Self."
Psychological Bulletin 139 (4): 815-840.
Rosenthal, D. M. 2007. "Phenomenological Overﬂow and Cognitive Access." Behavioral and Brain
Sciences30: 521-522.
Schwarz, S., and P. Maquet. 2002. "Sleep Imaging and Neuropsychological Assessment of Dreams."
Trends in Cognitive Sciences 6: 23-30.
Schwitzgebel, E. 2014. "Belief." In The Stanford Encyclopedia of Philosophy. http://plato.stanford.
edu/archives/spr2014/entries/belief/
Sebastia´n, M. A´ . 2012. "Experiential Awareness: Do you Prefer "It" to "Me"?." Philosophical Topics
40 (2): 155-177.
Sebastia´n, M. A´ . 2014. "Dreams: An Empirical Way to Settle the Discussion Between Cognitive and
Non-cognitive Theories of Consciousness." Synthese 191 (2): 263-285.
Sechrist, G., and C. Stengor. 2001. "Perceived Consensus Inﬂuences Intergroup Behavior and
Stereotype Accessibility." Journal of Personality and Social Psychology 4: 645-654.
Cognitive Access and Cognitive Phenomenology: Conceptual and Empirical Issues 203

Shanahan, M., and B. Baars. 2007. "Global Workspace Theory Emerges Unscathed." Behavioral and
Brain Sciences 30: 524-525.
Sligte, I. G., H. S. Scholte, and V. A. F. Lamme. 2008. "Are There Multiple Visual Short-term
Memory Stores?" Plos One 3: 1-9.
Sperling, G. 1960. "The Information Available in Brief Visual Presentation." Psychological
Monographs: General and Applied 74 (11): 1-29.
Stanovich, K. 1999. Who is Rational? Studies of Individual Differences in Reasoning. Mahway, NJ:
Lawrence Erlbaum Associates.
Stanovich, K. 2004. The Robot's Rebellion: Finding Meaning the Age of Darwin. Chicago: Chicago
University Press.
Stazicker, J. 2011. "Attention, Visual Consciousness and Indeterminacy." Mind and Language 26:
156-184.
Tononi, G. 2009. "Sleep and dreaming." In The Neurology of Consciousness: Cognitive Neuroscience
and Neuropathology, edited by S. Laurey and G. Tononi, 89-107. London: Elsevier.
Toribio, J. 2007. "Mind and Supermind, Keith Frankish." Philosophical Quarterly 57 (226): 139-
142.
Turatto, M., M. Sandrini, and C. Miniussi. 2004. "The Role of the Right Dorsolateral Prefrontal
Cortex in Visual Change Awareness." Neuroreport 15 (16): 2549-2552.
Vandekerckhove, M. 2009. "Memory, Autonoetic Consciousness and the Self: Consciousness as a
Continuum of Stages." Self and Identity 8: 4-23.
Vandekerckhove, M., L. C. Bulnes, and J. Panksepp. 2014. "The Emergence of Primary Anoetic
Consciousness in Episodic Memory." Frontiers in Behavorial Neuroscience 7: 210.
Wegner, D. M. 1994. "Ironic Processes of Mental Control." Psychological Review 101: 34-52.
Wegner, D., and D. Gold. 1995. "Fanning Old Flames: Emotional and Cognitive Effects of
Suppressing Thoughts of a Past Relationship." Journal of Personality and Social Psychology
68 (5): 782-792.
Wheeler, M. A., D. T. Stuss, and E. Tulving. 1997. "Toward a Theory of Episodic Memory: The
Frontal Lobes and Autonoetic Consciousness." Psychological Bulletin 121: 331-354.
Wilson, T. 2002. Strangers to Ourselves. Cambridge: Harvard University Press.
Windt, J. 2015. "Dreams and Dreaming." In The Stanford Encyclopedia of Philosophy, edited by
Edward N. Zalta. http://plato.stanford.edu/archives/sum2015/entries/dreams-dreaming/
Zahavi, D. 2005. Subjectivity and Selfhood: Investigating the First-Person Perspective. Cambridge:
MIT Press.
204
Miguel A´ngel Sebastia´n

