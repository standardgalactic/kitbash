Fake Barns. You are driving through the countryside, look out of the window of your car, see a barn in the field and form a belief that you are looking at a barn. Your belief is true as the structure you are looking at actually is a barn. Unbeknownst to you, however, it is one of the few real barns in an area otherwise peppered with mere façades that are so cleverly constructed as to be indistinguishable from real barns from your position on the road (Goldman 1976).
Fake Diamonds. You are a diamond expert and are currently handed a bag of fake diamonds that, thanks to a new technology, are so carefully crafted that they cannot be distinguished from real diamonds except by elaborate laboratory procedures. By some accident, one real diamond found its way into the bunch. You pick a stone at random, which happens to be the real thing, and check it for authenticity using a method that allows you to decisively discriminate real diamonds from all kinds of fakes except the ones produced by the new technology. Since the inventors of the new technology have been careful to keep its existence a secret, you do not know about it. You form a belief that you are looking at a real diamond.
Visiting Twin. You have a new colleague who has started working with you only last week. Unbeknownst to you, your colleague has an identical twin brother who still lives in the faraway country the two brothers grew up in. Today the twin brother has come for the first time to visit his brother in his new town. You are passing by a café, see your colleague bending over the table writing something down and form the belief that your colleague is sitting at that table. What you don't know is that your colleague's twin is also at the café and the only reason why you are seeing your colleague and not his twin is that the twin just went to the bathroom. Had the twin been not been to the bathroom, your colleague would not have bent over to write something down. Rather, he would have reclined in the chair and as a result would have been hidden from view by a curtain. At the same time, the twin would have been in plain view in the window instead.

Most epistemologists agree—and, accordingly I take it to be agreed— that, in all of these cases, the beliefs you form do not qualify as knowledge.4 Moreover, the cases also display the two characteristic features of Gettier cases: you suffer from two strokes of luck, one bad: there are many fakes barns/diamonds/an identical twin around, the other good: you are looking at one of the few real barns/the only real diamond/your actual colleague. It is pure luck that you arrive at a true belief here.
At the same time, there is an important structural difference between these cases (which, in recognition of the original case, I will henceforth refer to as fake barn cases) and standard Gettier cases like Stopped Clock: in the fake barns case your move in inquiry is not tarnished.5 Unlike in Stopped Clock, where you take a reading from a stopped clock, in fake barn cases, you do not, for instance, mistake a fake barn for a real barn. Of course, you might so easily have looked at a fake instead in which case your move in inquiry would have been tarnished in much the same way as your belief in Stopped Clock. However, as a matter of fact, you do not look at a fake. What is going on in fake barn cases, then, is that your move in inquiry is untarnished but might so easily have been tarnished. This suggests that Gettier cases need not be cases of success despite a tarnished move. Rather, cases in which the agent's successful move is untarnished but might easily have been tarnished will do as well.
Unfortunately, this means trouble for VR. VR takes knowledge to be the epistemic incarnation of apt move. As a result, VR will be able to accommodate the intuition of ignorance across the full range of Gettier cases only if all Gettier cases are cases of successful and competent but inapt epistemic move. Now I argued that successful and competent but inapt moves are tarnished moves. If so, VR will be able to accommodate the intuition of ignorance across the full range of Gettier cases only if all Gettier cases are cases of tarnished moves. However, it turns out that this is not the case. There are Gettier cases, notably fake barn cases, in which the agent's move is not tarnished. There is thus reason to believe that VR will not be able to accommodate the intuition of ignorance in all Gettier cases.
In fact, things are worse than that. There is excellent evidence that agents who succeed via competent moves that are not tarnished attain aptness, even when their moves might easily have been tarnished. Just think of an archery case in which you produce a successful shot at a normal target when shooting at the only unsabotaged target at a shooting range otherwise full of sabotaged targets, think of a case in which you successfully prepare a tasty omelette but happened to take the only salt shaker in which the salt wasn't replaced by sugar, or think of a case in which you successfully produce a beautiful monochrome after having taken the only can in which the colour wasn't replaced by acid. In all of these cases, you produce successful and competent moves that are untarnished but might easily have been tarnished. There can be little doubt that, in all of these cases, your moves rise to the level of achievement and so qualify as apt. Given that, in general, agents who succeed via competent moves that are not tarnished attain aptness, we may expect the same to hold for the particular case of moves in inquiry. Given that fake barn cases fit the bill, we may expect that the agents' beliefs in these cases are apt and so, by VR, qualify as knowledge. As a result, there is not only reason to believe that VR will be unable to accommodate the intuition of ignorance in all Gettier cases, but also that it will make the wrong predictions in fake barn cases. In other words, there is reason to believe that VR succumbs to Gettier-style counterexample after all.
Unsurprisingly, champions of VR are aware of this problem. In fact, solving it has been one of their major occupations. An interesting fact about the proposals in the literature is that they tend to venture to accommodate the intuition of ignorance by adding, incorporating or otherwise exploiting a safety or safety-like condition on knowledge. The core idea of safety is that in order to know one must be safe from error, and that is to say that one must avoid error not only at the actual world but also across a subset of nearby possible worlds.
As I am about to argue, there is reason to believe that this kind of response remains ultimately unsatisfactory. My general strategy is to show that solutions to the problem of fake barn cases that exploit a safety-like condition are bound run into trouble elsewhere. The reason for this is that safety-like conditions that will do the trick in fake barn cases are arguably too strong to be necessary for knowledge. There are a number of cases that have been claimed to drive this point home, including the following:

Halloween Party. "There is a Halloween party at Andy's house, and I am invited. Andy's house is very difficult to find, so he hires Judy to stand at a crossroads and direct people towards the house (Judy's job is to tell people that the party is at the house down the left road). Unbeknownst to me, Andy doesn't want Michael to go to the party, so he also tells Judy that if she sees Michael she should tell him the same thing she tells else (that the party is at the house down the left road), but she should immediately phone Andy so that the party can be moved to Adam's house, which is down the right road. I seriously consider disguising myself as Michael, but at the last moment I don't. When I get to the crossroads, I ask Judy where the party is, and she tells me that it is down the left road." (Comesaña 2005: 397)
Lucky Drink. "I am drinking a glass of water which I have just poured from the bottle. Standing next to me is a happy person who has just won the lottery. Had this person lost the lottery, she would have maliciously polluted my water with a tasteless, odorless, colorless toxin. But since she won the lottery, she does no such thing. Nonetheless, she almost lost the lottery. Now, I drink the pure, unadulterated water and judge, truly and knowingly, that I am drinking pure, unadulterated water. But the toxin would not have flavored the water, and so had the toxin gone in, I would still have believed falsely that I was drinking pure, unadulterated water" (Neta & Rohrbaugh 2004: 399-400).
Atomic Clock. "[T]he world's most accurate clock hangs in Smith's office at a cereal factory, and Smith knows this. The clock's accuracy is due to a clever radiation sensor, which keeps time by detecting the transition between two energy levels in cesium-133 atoms. This radiation sensor is very sensitive, however, and could easily malfunction if a radioactive isotope were to decay in the vicinity (a very unlikely event, given that Smith works in a cereal factory). This morning, against the odds, someone did in fact leave a small amount of a radioactive isotope near the world's most accurate clock in Smith's office. This alien isotope has a relatively short half-life, but—quite improbably—it has not yet decayed at all. It is 8:20 am. The alien isotope will decay at any moment, but it is indeterminate when exactly it will decay. Whenever it does, it will disrupt the clock's sensor, and freeze the clock on the reading '8:22.' (Don't ask why; it's complicated.) Therefore, though it is currently functioning properly, the clock's sensor is not safe. The clock is in danger of stopping at any moment, even while it currently continues to be the world's most accurate clock" (Bogardus 2013: 300).

In all of these cases, the agents are said to know, whilst their beliefs are not safe. As a result, any of them will do to run the argument I am about to offer.6 That said, I will here focus on my own preferred counterexample to safety, which can aptly be described as an epistemic Frankfurt case. This is in recognition of the fact that the inspiration for this kind of case is due to Frankfurt's famous (1969) counterexamples to the principle of alternative possibilities. The reason I am mentioning the other cases is just to highlight that the success of my argument does not hinge on the particular case that will guide my subsequent discussion. To repeat, any of the above cases would serve just as well. Here goes:

Frankfurt Clock. Your arch-nemesis, a powerful demon, has an interest that you form a belief that it's 8:22 when you come down the stairs this morning. In order to achieve this, your arch-nemesis has resolved to set the grandfather clock in your hallway (from which you habitually take a reading every morning) to 8:22 unless you come down the stairs at 8:22 of your own accord. Suppose, as it so happens, you do come down the stairs at 8:22. Your arch-nemesis remains inactive. You form a belief that it's 8:22. It is 8:22. The grandfather clock is working reliably as always.

In this case, you know that it is 8:22. After all, you have the ability to read the clock and form a belief via an exercise of this ability. Moreover, the clock is actually functioning properly and the reading is accurate. At the same time, your belief is not safe from error. After all, you might very easily have come down the stairs a minute earlier or later in which case your arch-nemesis would have intervened with the result that you would have taken a reading from an inaccurate clock and ended up with a false belief that it is 8:22. Since, in this case, your belief is at high risk of error, accounts of knowledge that feature a safety or safety-like condition will incorrectly predict the absence of knowledge here.7
The upshot of my argument is that champions of VR encounter another dilemma: this one has fake barn cases on one horn and Frankfurt cases on the other. And while champions of VR can avoid the creditworthiness dilemma, this one is a harder nut to crack. Or so I contend.
A Worry
Before moving on, I'd briefly like to consider the following worry: Aren't Frankfurt cases and fake barn cases structurally identical? And if so, isn't that reason to think that the at least one of the intuitions is mistaken and hence ought to be rejected?
My response is that I do not think that the two kinds of case are structurally identical. Here is one difference: in fake barn cases the relevant error possibilities are realised in the environment in a way in which they aren't in Frankfurt cases. For instance, in Fake Barns the error possibilities take the shape of the actual presence of fake barns in the environment. In contrast, in Frankfurt Clock, no similar relevant error possibilities are realised in the environment. For instance, there are no stopped clocks around. As a result, the relevant error possibilities in fake barn cases are live in a way in the error possibilities in Frankfurt cases aren't. By way of further evidence for this, note that, in fake barn cases, other agents actually fall prey to this error possibility, or so we may suppose. The same is not true of Frankfurt cases. It is not as if we can just assume that other agents in the same environment actually fall prey to the error possibility of forming a false belief by taking a reading from a stopped clock. After all, stopped clocks are simply nowhere to be found in the environment. Even if it is the case that if the two kinds of case are structurally identical, they should be treated alike, there is reason to think that they are not structurally identical.8
It may also be worth noting that while there is the structural difference between these cases, this difference cannot be detected by safety or safety-like conditions. Here is why. Even though the error possibility is not realised in the environment of a Frankfurt case, it might ever so easily have been realised. Moreover, Frankfurt cases are set up such that the closest worlds at which the error possibility is realised in the environment is also one at which the agent is fooled by it. As a result, in a Frankfurt case, the agent might ever so easily have ended up with a false belief. In contrast, in fake barn cases, the error possibility is realised at the actual world, but the closest world at which the agent is fooled by it is not the world at which it is realised (i.e. the actual world). Even so, the agent might ever so easily have been fooled by it. As a result, in a fake barns case, too, the agent might ever so easily have ended up with a false belief. Now, safety and safety-like conditions require absence of error at nearby (or perhaps very close nearby) possible worlds. Since the two cases do not differ on this front, the structural difference between the two cases is not one that can be detected by safety conditions. That's why accounts of the absence of knowledge in fake barn cases in terms of a safety or safety-like condition encounter the above dilemma. And that's why they remain ultimately unsatisfactory.
Lottery Cases
Let's start by considering the following case:

Lottery Loser. I have recently bought a ticket in a fair lottery, l, with one million tickets and exactly one winner. In view of the unfavourable odds, you are pessimistic about my prospects of becoming rich soon. In particular, you believe that the ticket I bought—say it's ticket 1— won't win l. And you turn out to be right. My ticket does indeed not win.

Although the probabilistic evidence supporting your belief that my ticket won't win (call this proposition <loser>) is excellent and the belief is true, you do not know <loser>.
Can VR accommodate this datum? Unfortunately, there is reason to think that it can't. To see this, let's ask whether your belief is apt. It is not hard to see that the answer to this question is yes. After all, your belief is very plausibly produced an ability to form true beliefs about lottery outcomes. Your way of belief formation, which takes the probabilistic evidence as input and outputs belief about lottery outcomes, disposes you to form true beliefs about lottery outcomes across a wide range of conditions. Across a wide range of SH and SI, the trigger-manifestation conditional—were you use this way of belief formation to form a belief about the lottery outcome, you would likely enough form a true belief— holds. Moreover, we may assume that your way of belief formation has been shaped through interaction with the environment or else that you know that it is a highly reliable way of forming true beliefs about lottery outcomes. As a result it satisfies the grounding condition on abilities and so qualifies as an ability to form true beliefs about lottery outcomes. If so, provided you are also in suitable SH, your belief will qualify as being produced by an epistemic ability. Moreover, the target propositions, <loser> is a proposition about lottery outcomes and so will count as being in the range of the ability. Your belief will be competent. Notice, furthermore, that your belief is also true. After all, <loser> is ex hypothesi true. If, finally, you are in suitable SI, your belief will qualify as apt as well.
The questions that remains to be answered is whether the SI you find yourself in are suitable. Recall that to investigate this question, we needed to ask whether in your SI the relevant trigger-manifestation conditional is true. And, again, the answer here is clearly yes. In your current SI (fair lottery, etc.), it is undeniably the case that were you to use the relevant way of belief formation to form a belief in <loser>, your belief in <loser> would likely be true. As a result, there is reason to believe that your belief in <loser> is apt. In consequence, VR-K* rules that it qualifies as knowledge. There is thus reason to believe that my favourite traditionalist version of VR does not succeed in explaining the absence of knowledge in lottery cases.
But perhaps this is just a difficulty my particular account faces. Perhaps other accounts do better. Before looking into this, let's briefly survey the theoretical options for explaining the absence of knowledge in cases like Lottery Loser. Recall that your belief in this case is ex hypothesi true. This means that there are three options of dealing with such cases available to champions of VR. They can either say that your belief falls short of knowledge because (i) it is not competent, (ii) it is (true and) competent but not apt, or (iii) they can simply deny that we do not have knowledge of lottery propositions and offer an error theory for those who think otherwise. In what follows, I will look at each of these three options, starting with the last one.
Knowledge
Accepting that we can know lottery propositions is perhaps the initially least promising line to pursue. As I am about to argue there is good reason for resisting it. To see this, consider first the following principle:

Minimal Coherence (MCH). If one knows that one is not in a position to know the conclusion of an argument one knows to be valid, then there is some premise of the argument that one is not in a position to know either.

This principle is eminently plausible. Suppose you were to believe the premises of an argument you know to be valid, whilst knowing that you are not in a position to know its conclusion. Belief in the premises rationally commits you to the truth of the propositions you believe. Knowing the argument to be valid rationally commits you to the truth of its conclusion. If you simultaneously know that you are not in a position to know its conclusion, you are in the unfortunate situation of being rationally committed to the truth of a proposition that you know you are not in a position to know. Your doxastic state is incoherent in a manner reminiscent of a Moorean paradox. MCH captures the plausible thought that such incoherences must be avoided.
With MCH in play, consider the following variation of Lottery Loser:

No Winners. I have recently bought a ticket in a fair lottery, l′, with one million tickets. While there may be a winner, there is no guarantee that there will be. In fact, there is a small chance that no ticket will win l′. In view of the unfavourable odds, you are pessimistic about my prospects of becoming rich soon. In particular, you believe that the ticket I bought—say it's ticket 1—won't win l′. And you turn out to be right. My ticket does indeed not win. As a matter of fact, on this particular occasion, the small chance of there being no winner materialises. All tickets lose.

As a first observation, you know that there is a valid argument from {ticket 1 will lose l′, . . . , ticket n will lose l′} to {All tickets will lose l′}. However, you know that you are not in a position to know that proposition. After all, the probability that it is true is vanishingly small. By MCH, it follows that there is some member of {ticket 1 will lose l′, . . . , ticket n will lose l′} such that you are not in a position to know it.
Crucially, if there is some member of Γ = {ticket 1 will lose l′, . . . , ticket n will lose l′}, such that you are not in a position to know it, then you are not in a position to know any member of it. Here is why. First, in this particular case, all members of the set are true. Second, whether you are in a position to know a proposition supervenes on your epistemic position towards it and its truth value. Hence, you will be in a position to know some member, i ∈ Γ without being in a position to know some other member j ∈ Γ if and only if your epistemic position towards i is not the same as your epistemic position towards j. However, third, you are in exactly the same epistemic position towards each member of Γ.
It follows that you are not in a position to know any member of Γ. But since one knows a proposition only if one is in a position to know it, you do not know any member of Γ. We will do best, then, to avoid trying to resist the received view which grants that lottery propositions cannot be known. Accordingly, we had better try and look for an account that explains why we don't know lottery propositions.
Inaptness
Once the idea that we know lottery propositions is abandoned, we are left with two alternative options. We can either argue that the agents' epistemic performances in lottery cases are not even competent—and, by VR-JB, not justified—or that they are successful and competent—true and justified—but not apt. Given that there is such strong reason to think that lottery propositions such as <loser> are true, at first glance it would seem as though the latter approach is more promising. As I am about to argue, however, there is reason to think that appearances are misleading here. To see why, consider first Kyburg's (1961, 1970) famous lottery paradox:

The Sufficiency Thesis (ST). If the probability of p on one's evidence is very high, then p is justifiably believable for one.
Conjunction Closure (CC). If p is justifiably believable for one and q is justifiably believable for one, then their conjunction, p and q, is justifiably believable for one.
No Contradictions (NC). No proposition one knows to be a contradiction is justifiably believable for one.

While individually plausible, it turns out that ST, CC and NC are jointly inconsistent. To see this, notice that no matter how high we set the standards for satisfaction of the predicate 'very likely', there will be some fair lottery with exactly one winner such that it is very likely on my evidence that each ticket will lose. So suppose that a ticket will very likely lose if the chance that it will lose is at least (n − 1)/n and let l be a fair lottery I know to have n tickets and exactly one winner. By ST, for each ticket i ∈ l, it is justifiably believable for me that i will lose. By CC, it is justifiably believable for me that all tickets in l will lose. Since I also know that l has exactly one winner, by a further application of CC, it is justifiably believable for me that all tickets in l will lose and that exactly one ticket in l will win. However, I know that this is a contradiction and so, by NC, it is not justifiably believable for me.
One of ST, CC and NC has to go. But which one? It is widely agreed that the least promising candidate is NC. After all, it is reasonable to think that NC is a basic principle of justified believability.
In fact, there is independent reason to think that NC is not at the fault in the lottery paradox since the paradox can be generated without invoking NC. To see this, consider the following plausible thesis:

No Moore Paradoxes (NMP). Propositions of the form 'φ but I don't know that φ' (henceforth also 'Moorean propositions') are not justifiably believable for one.9

Now consider No Winner once more. In this case, there is no guarantee that the lottery in question will have a winner. Accordingly, I do not know that there will be a winner. Instead, all I know is that there might be a winner, and hence that I do not know that all tickets will lose. It is not hard to see that the lottery paradox can be generated with ST, CC and NMP only. By ST and CC, it is justifiably believable for me that all tickets will lose. Since I know that I do not know that all tickets will lose, it is justifiably believable for me that I do not know that all tickets will lose. By another application of CC, it is justifiably believable for me that all tickets will lose but I do not know that all tickets will lose. By NMP this is not justifiably believable for me. We thus have a version of the lottery paradox that does not rely on NC.10
Denying CC is perhaps initially the most attractive option. After all, one might think that even if we have to give up CC, it might be possible to rescue at least a restricted version of CC. Thus, consider:

CC′. If p is justifiably believable for one and q is justifiably believable for one, then their conjunction, p and q, is justifiably believable for one, unless it is a contradiction.

Another noteworthy consequence of the Moore paradoxical version of the lottery paradox is that this way of restricting CC won't do the trick either. The reason for this is that the Moore paradoxical version of the lottery paradox shows that no contradiction is needed to generate the paradox. After all, the proposition that all tickets will lose but I do not know that all tickets will lose is not contradictory. Replacing CC by CC′ won't do the trick.
Of course, one could add to the list of riders. Thus, consider:

CC″. If p is justifiably believable for one and q is justifiably believable for one, then their conjunction, p and q, is justifiably believable for one, unless it is either a contradiction or a Moorean proposition.

Now, CC″ smacks of ad hocness. What would be needed to remove the air of ad hocness is some unifying and independently plausible account of why CC″ should feature these riders. I cannot help but suspect that the only plausible candidate appeals to the notion of justified believability. The reason why CC″ makes exceptions for contradictions and Moorean propositions is that they are not justifiably believable. But that, of course, won't do at all since holding that the conjunction of two justifiably believable propositions is justifiably believable unless it isn't renders the principle trivial. All we would have done is replace ad hocness by triviality.
Fortunately, the most common reason for rejecting CC is different. Here is the rough idea: We are fallible cognitive agents in the sense that, for a wide range of propositions, there will always be a small risk that, when we come to believe them, we make a mistake. At the same time, we are capable of justified belief in the sense that justified belief is attainable for a wide range of propositions, including a subset of propositions in the aforementioned range. Given that this is so, justified believability is compatible with a small risk of error. The aggregation of justifiably believable propositions involves an aggregation of small risks of error. Small risks of error accumulate to larger risks of error. Crucially, while justified believability is compatible with a small risk of error, it is not compatible with too large a risk of error. The problem with CC is that aggregation of justifiably believable propositions may lead to a risk of error that is simply too large. In that case, even though each member of the aggregate is justifiably believable, the aggregate as a whole is not. CC is bound to fail (e.g. Foley 1979; Kyburg 1997 an ancestor of the idea can be found as early as Ramsey 1990/1929).
These considerations would seem to provide a more promising diagnosis of the lottery paradox. After all, for any fair lottery with n tickets and exactly one winner, and any subset of m tickets, the risk that all its members won't lose is m/n. When n is sufficiently large and m sufficiently small, this risk will be very small, small enough, in fact, to allow that the proposition that all members of the subset will lose is justifiably believable for one. At the same time, when m is large enough, the risk of error will be too large to allow the proposition that all members of the subset will lose to be justifiably believable for one. If this is right, CC is bound to fail in the lottery case.
This diagnosis predicts that one cannot justifiably believe of all tickets in a fair lottery that they will lose. When the lottery is large enough, one cannot even justifiably believe of nearly all or even most tickets that they will lose. One would run too great a risk of error in so doing. This looks like a welcome result. After all, it appears independently plausible. In a lottery with one million tickets and one winner, one cannot justifiably believe that all one million tickets will lose. One also cannot justifiably believe that the first 999,567 or the first 500,000 tickets will lose either. One is too likely to be in error here. These results add to the attractiveness of the present proposal.
I do not want to deny that this diagnosis is attractive at first glance. However, I will argue that, despite its initial appeal, in the final analysis it remains unsatisfactory. The reason for this is that the paradox can once again be generated in a way that bypasses the relevant principle, in this case CC. The principle is a variation of a principle we already encountered in the previous subsection, to wit, MCH. Here goes:

Minimal Coherence, Justification (MCH-J). If one knows that the conclusion of an argument one knows to be valid is not justifiably believable for one, then some premise of the argument is not justifiably believable for one either.

MCH-J can be motivated in much the same way as MCH earlier. Suppose you were to believe the premises of an argument you know to be valid, whilst knowing that you cannot justifiably believe its conclusion. Belief in the premises rationally commits you to the truth of the propositions you believe. Knowing the argument to be valid rationally commits you to the truth of its conclusion. If you simultaneously know that you cannot justifiably believe its conclusion, you are in the unfortunate situation of being rationally committed to the truth of a proposition that you know you cannot justifiably believe. Your doxastic state is incoherent in a manner reminiscent of a Moorean paradox. MCH-J captures the plausible thought that such incoherences must be avoided.
MCH-J is inconsistent with ST. There are several ways of arguing this. Here is one. Note that, by NC, one class of propositions that are not justifiably believable for one are propositions one knows to be contradictory. As a result, MCH-J serves to motivate the following principle:

Minimal Consistency (MCN). If one knows that the conclusion of an argument one knows to be valid is a contradiction, then some premise of the argument is not justifiably believable for one.11

To see that MCN is inconsistent with ST, let, S1 be an agent who knows that there is a valid argument from the premise set {ticket 1 will lose l,. . . , ticket n will lose l, l has n tickets, l has one winner} to the conclusion ⊥. By MCN, some member of the premise set is not justifiably believable for S1. At the same time, each member of the premise set is very likely to be true on S1's evidence. By ST, each member of the premise set is justifiably believable for S1.
While I take this argument to provide strong reason to believe that ST is false, it does not serve to show that the above mentioned diagnosis in terms of accumulation of small risks is bound to remain unsatisfactory. Fortunately, there is another way of arguing that MCH-J is inconsistent with ST, which does the trick. Recall that, by NMP, no proposition of the form 'φ but I don't know that φ' is justifiably believable for one. Let S2 be an agent who knows:

P1. that there is a valid argument from the premise set {ticket i will lose l, I don't know that ticket i will lose l} to the conclusion ticket i will lose l but I don't know that ticket i will lose l, for each i ∈ l,
P2. that any such conclusion is Moore paradoxical and thus is not justifiably believable for him,
P3. that he does not know that ticket i will lose, for each i ∈ l.

Since S2 knows P1 and P2, by MCH-J, he cannot justifiably believe at least one of the argument's premises. That means that either ticket i will lose l or I don't know that ticket i will lose l is not justifiably believable for S2. Since, by P3, S2 knows the latter premise to be true for each i ∈ l, it follows that ticket i will lose l is not justifiably believable for S2, for each i ∈ l. At the same time, ticket i will lose l is highly probably on his evidence and so, by ST, justifiably believable for S2.
Crucially, the fact that small risks of error accumulate to larger risks of error does little to block the present argument. After all, we are aggregating justified believability for only two propositions. And while the risk of error associated with each proposition may be small enough to be compatible with justified believability and yet too large to be so compatible when aggregated, it need not be. Given that the probability of I don't know that ticket i will lose l surpasses the threshold at issue in ST, we can set up l such that the odds against winning are high enough that the probability of ticket i will lose l but I don't know that ticket i will lose l is still above the threshold at issue in ST. It comes to light that, on ST, Moore paradoxical propositions come out as justifiably believable. Since this cannot be the case, ST must be false.
Of course, if the culprit in the lottery paradox is ST, then, by the same token, there is reason to believe that we cannot even justifiably believe lottery propositions. Since we have now seen that there is independent theoretical reason to believe that ST is false, this means that there is independent theoretical reason to believe that we cannot justifiably believe lottery propositions.
But given that this is so, we can now see why the present strategy of accounting for why we lack knowledge of lottery propositions is bound to fail. Just recall that this account aims to show that beliefs in lottery propositions are not true because competent. In other words, it grants that such beliefs are successful and competent, and ventures to establish that they fall short of aptness. Even if they can get all the cases right, given that the lesson the lottery paradox teaches is that lottery propositions aren't even justifiably believable, this means that their account is bound to remain unsatisfactory. After all, knowledge entails justified believability, and so the absence of knowledge is already explained in terms of the absence of justified believability. Their account will be doomed to redundancy.
Incompetence
There is thus reason to believe that lottery propositions are not justifiably believable. This means that the right approach to lottery cases for virtue reliabilists is the remaining one, according to which beliefs in lottery propositions fall short of being competent. The question is how champions of VR can secure this result. One way to achieve this is to argue that we don't have the epistemic abilities required for competent belief. Unfortunately, as we have already seen, the prospects for this strategy are rather dim as it is very plausible that beliefs in lottery propositions are frequently produced by abilities to form true beliefs about lottery outcomes.12
Another approach may be to exploit the fact that justification can be defeated. If so, even if the lottery paradox leads us to reject ST, we may still be able to hold on to the following qualified version of ST:

ST′. If the probability of p on one's evidence is very high, then p is justifiably believable for one unless one's justification for believing p is defeated.

