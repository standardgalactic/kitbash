
NEURONAL DYNAMICS
What happens in our brain when we make a decision? What triggers a neuron to send out
a signal? What is the neural code?
This textbook for advanced undergraduate and beginning graduate students provides a
thorough and up-to-date introduction to the ﬁelds of computational and theoretical neuro-
science. It covers classical topics, including the Hodgkin-Huxley equations and Hopﬁeld
model, as well as modern developments in the ﬁeld such as Generalized Linear Models and
decision theory. Concepts are introduced using clear step-by-step explanations suitable for
readers with only a basic knowledge of differential equations and probabilities, and richly
illustrated by ﬁgures and worked-out examples.
End-of-chapter summaries and classroom-tested exercises make the book ideal for
courses or for self-study. The authors also give pointers to the literature and an extensive
bibliography, which will prove invaluable to readers interested in further study.
Wulfram Gerstner is Director of the Laboratory of Computational Neuroscience and a
Professor of Life Sciences and Computer Science at the ´Ecole Polytechnique F´ed´erale de
Lausanne (EPFL) in Switzerland. He studied physics in T¨ubingen and Munich and holds a
PhD from the Technical University of Munich. His research in computational neuroscience
concentrates on models of spiking neurons and synaptic plasticity. He teaches computa-
tional neuroscience to physicists, computer scientists, mathematicians, and life scientists.
He is co-author of Spiking Neuron Models (Cambridge University Press, 2002).
Werner M. Kistler received a Master's and PhD in physics from the Technical Univer-
sity of Munich. He previously worked as Assistant Professor in Rotterdam for computa-
tional neuroscience and he is co-author of Spiking Neuron Models. He is now working
in Munich as a patent attorney. His scientiﬁc contributions are related to spiking neuron
models, synaptic plasticity, and network models of the cerebellum and the inferior olive.
Richard Naud holds a PhD in computational neuroscience from the EPFL in Switzerland
and a Bachelor's degree in Physics from McGill University, Canada. He has published
several scientiﬁc articles and book chapters on the dynamics of neurons. He is now a post-
doctoral researcher.
Liam Paninski is a Professor in the statistics department at Columbia University and co-
director of the Grossman Center for the Statistics of Mind. He is also a member of the
Center for Theoretical Neuroscience, the Kavli Institute for Brain Science and the doctoral
program in neurobiology and behavior. He holds a PhD in neuroscience from New York
University and a Bachelor's from Brown University. His work focuses on neuron models,
estimation methods, neural coding and neural decoding. He teaches courses on computa-
tional statistics, inference, and statistical analysis of neural data.


NEURONAL DYNAMICS
From Single Neurons to Networks and Models of Cognition
WULFRAM GERSTNER
WERNER M. KISTLER
RICHARD NAUD
LIAM PANINSKI

University Printing House, Cambridge CB2 8BS, United Kingdom
Cambridge University Press is part of the University of Cambridge.
It furthers the University's mission by disseminating knowledge in the pursuit of
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781107060838
© Cambridge University Press 2014
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2014
Printed in the United Kingdom by TJ International Ltd. Padstow Cornwall
A catalogue record for this publication is available from the British Library
Library of Congress Cataloging-in-Publication Data
Gerstner, Wulfram.
Neuronal dynamics : from single neurons to networks and models of cognition / Wulfram Gerstner,
Werner M. Kistler, Richard Naud, Liam Paninski.
pages
cm
ISBN 978-1-107-06083-8 (Hardback : alk. paper)
ISBN 978-1-107-63519-7 (Paperback : alk. paper)
1. Neurobiology.
2. Neural networks (Neurobiology).
3. Cognitive neuroscience.
I. Kistler, Werner M., 1969-
II. Naud, Richard.
III. Paninski, Liam.
IV. Title.
QP363.G474 2014
612.8-dc23
2013047693
ISBN 978-1-107-06083-8 Hardback
ISBN 978-1-107-63519-7 Paperback
Additional resources for this publication at www.cambridge.org/gerstner
Cambridge University Press has no responsibility for the persistence or accuracy of
URLs for external or third-party internet websites referred to in this publication,
and does not guarantee that any content on such websites is, or will remain,
accurate or appropriate.

Contents
Preface
page ix
PART ONE
FOUNDATIONS OF NEURONAL DYNAMICS
1
1
Introduction: neurons and mathematics
3
1.1
Elements of neuronal systems
3
1.2
Elements of neuronal dynamics
7
1.3
Integrate-and-ﬁre models
10
1.4
Limitations of the leaky integrate-and-ﬁre model
19
1.5
What can we expect from integrate-and-ﬁre models?
23
1.6
Summary
25
2
Ion channels and the Hodgkin-Huxley model
28
2.1
Equilibrium potential
28
2.2
Hodgkin-Huxley model
31
2.3
The zoo of ion channels
42
2.4
Summary
56
3
Dendrites and synapses
58
3.1
Synapses
58
3.2
Spatial structure: the dendritic tree
64
3.3
Spatial structure: axons
72
3.4
Compartmental models
75
3.5
Summary
79
4
Dimensionality reduction and phase plane analysis
81
4.1
Threshold effects
81
4.2
Reduction to two dimensions
84
4.3
Phase plane analysis
91
4.4
Type I and type II neuron models
96
4.5
Threshold and excitability
103
4.6
Separation of time scales and reduction to one dimension
108
4.7
Summary
111

vi
Contents
PART TWO
GENERALIZED INTEGRATE-AND-FIRE NEURONS
115
5
Nonlinear integrate-and-ﬁre models
119
5.1
Thresholds in a nonlinear integrate-and-ﬁre model
120
5.2
Exponential integrate-and-ﬁre model
124
5.3
Quadratic integrate and ﬁre
129
5.4
Summary
132
6
Adaptation and ﬁring patterns
136
6.1
Adaptive exponential integrate-and-ﬁre
136
6.2
Firing patterns
140
6.3
Biophysical origin of adaptation
149
6.4
Spike Response Model (SRM)
154
6.5
Summary
165
7
Variability of spike trains and neural codes
168
7.1
Spike-train variability
169
7.2
Mean ﬁring rate
172
7.3
Interval distribution and coefﬁcient of variation
178
7.4
Autocorrelation function and noise spectrum
179
7.5
Renewal statistics
181
7.6
The problem of neural coding
190
7.7
Summary
199
8
Noisy input models: barrage of spike arrivals
202
8.1
Noise input
202
8.2
Stochastic spike arrival
207
8.3
Subthreshold vs. superthreshold regime
212
8.4
Diffusion limit and Fokker-Planck equation (*)
215
8.5
Summary
221
9
Noisy output: escape rate and soft threshold
224
9.1
Escape noise
224
9.2
Likelihood of a spike train
229
9.3
Renewal approximation of the Spike Response Model
232
9.4
From noisy inputs to escape noise
235
9.5
Summary
241
10
Estimating parameters of probabilistic neuron models
243
10.1
Parameter optimization in linear and nonlinear models
244
10.2
Statistical formulation of encoding models
249
10.3
Evaluating goodness-of-ﬁt
255
10.4
Closed-loop stimulus design
263
10.5
Summary
264

Contents
vii
11
Encoding and decoding with stochastic neuron models
267
11.1
Encoding models for intracellular recordings
268
11.2
Encoding models in systems neuroscience
273
11.3
Decoding
278
11.4
Summary
285
PART THREE
NETWORKS OF NEURONS AND
POPULATION ACTIVITY
287
12
Neuronal populations
291
12.1
Columnar organization
293
12.2
Identical neurons: a mathematical abstraction
297
12.3
Connectivity schemes
300
12.4
From microscopic to macroscopic
309
12.5
Summary
322
13
Continuity equation and the Fokker-Planck approach
325
13.1
Continuity equation
326
13.2
Stochastic spike arrival
328
13.3
Fokker-Planck equation
332
13.4
Networks of leaky integrate-and-ﬁre neurons
335
13.5
Networks of nonlinear integrate-and-ﬁre neurons
341
13.6
Neuronal adaptation and synaptic conductance
347
13.7
Summary
353
14
Quasi-renewal theory and the integral-equation approach
357
14.1
Population activity equations
358
14.2
Recurrent networks and interacting populations
367
14.3
Linear response to time-dependent input
375
14.4
Density equations vs. integral equations
381
14.5
Adaptation in population equations
386
14.6
Heterogeneity and ﬁnite size
390
14.7
Summary
392
15
Fast transients and rate models
395
15.1
How fast are population responses?
397
15.2
Fast transients vs. slow transients in models
399
15.3
Rate models
408
15.4
Summary
414

viii
Contents
PART FOUR
DYNAMICS OF COGNITION
417
16
Competing populations and decision making
421
16.1
Perceptual decision making
422
16.2
Competition through common inhibition
426
16.3
Dynamics of decision making
428
16.4
Alternative decision models
433
16.5
Human decisions, determinism, and free will
436
16.6
Summary
439
17
Memory and attractor dynamics
442
17.1
Associations and memory
442
17.2
Hopﬁeld model
446
17.3
Memory networks with spiking neurons
458
17.4
Summary
464
18
Cortical ﬁeld models for perception
467
18.1
Spatial continuum model
468
18.2
Input-driven regime and sensory cortex models
472
18.3
Bump attractors and spontaneous pattern formation
484
18.4
Summary
488
19
Synaptic plasticity and learning
491
19.1
Hebb rule and experiments
492
19.2
Models of Hebbian learning
495
19.3
Unsupervised learning
505
19.4
Reward-based learning
516
19.5
Summary
519
20
Outlook: dynamics in plastic networks
524
20.1
Reservoir computing
524
20.2
Oscillations: good or bad?
529
20.3
Helping patients
541
20.4
Summary
544
References
547
Index
573

Preface
This textbook for advanced undergraduate and beginning graduate students provides a
systematic introduction into the ﬁelds of neuron modeling, neuronal dynamics, neural cod-
ing, and neural networks. It can be used as a text for introductory courses on Computa-
tional and Theoretical Neuroscience or as main text for a more focused course on Neural
Dynamics and Neural Modeling at the graduate level. The book is also a useful resource for
researchers and students who want to learn how different models of neurons and descrip-
tions of neural activity are related to each other.
All mathematical concepts are introduced the pedestrian way: step by step. All chapters
are richly illustrated by ﬁgures and worked examples. Each chapter closes with a short
summary and a series of mathematical Exercises. On the authors' webpage Python source
code is provided for numerical simulations that illustrate the main ideas and models of the
chapter (http://lcn.epﬂ.ch/∼gerstner/NeuronalDynamics.html).
The book is organized into four parts with a total of 20 chapters. Part I provides a general
introduction to the foundations of computational neuroscience and its mathematical tools.
It covers classic material such as the Hodgkin-Huxley model, ion channels and dendrites,
or phase plane analysis of two-dimensional systems of differential equations. A special
focus is put on the ﬁring threshold for the generation of action potentials, in the Hodgkin-
Huxley models, as well as in reduced two-dimensional neuron models such as the Morris-
Lecar model.
Part II focuses on simpliﬁed models for the dynamics of a single neuron. It covers
nonlinear integrate-and-ﬁre models with and without adaptation, in particular the quadratic
and exponential integrate-and-ﬁre model, as well as the Izhikevich model and adaptive
exponential integrate-and-ﬁre model. The question of noise in the neural dynamics is posed
and two classic descriptions of noise are presented. First, stochasticity arising from random
spike arrival: this approach leads to a noise term in the differential equation of the voltage,
and can be formulated as a Langevin equation. Second, intrinsic stochasticity of neurons
leading to an "escape" across the ﬁring threshold even when the neuron is in the sub-
threshold regime: this approach leads to the framework of a Generalized Linear Model
which is systematically introduced and discussed in applications of neuronal coding and
decoding. The relation between the neuron models of Part II and biological data is
highlighted and systematic parameter optimization algorithms are presented.

x
Preface
Part III takes the simpliﬁed models derived in Part II and builds networks out of these.
The collective properties of the network dynamics are described in terms of equations for
the population activity also called the population ﬁring rate. The conditions under which
population activity can be described by a standard rate model are identiﬁed.
Part IV makes the link from dynamics to cognition. The population activity equations
are used for an analysis of famous paradigms of computational and cognitive neuroscience,
such as the neural activity during decision making or memory retrieval. In Part IV we also
sketch the theory of learning in relation to synaptic plasticity. The book closes with a
fascinating application of the principles of neuronal dynamics to help patients suffering
from Parkinson's disease.
A small fraction of the text of the present book is based on Spiking Neuron Models
(Cambridge University Press) which was ﬁrst published in 2002 and has been reprinted
several times since then. In the meantime, the ﬁeld has changed and we felt that a simple
update of Spiking Neuron Models for a second edition would not be enough to give credit
to the developments that have occurred.
Scientiﬁcally, the scope of Spiking Neuron Models was limited in several respects. First,
it mainly focused on linear integrate-and-ﬁre models, and mentioned their nonlinear coun-
terparts only in passing. In the present book, nonlinear integrate-and-ﬁre models are treated
in a full chapter. Second, adaptation was neglected in the treatment 10 years ago - mainly
because population equations for adaptive neurons were not yet available. In the present
book, adaptive integrate-and-ﬁre models are covered at length in a separate chapter and
the population activity equations for adaptive neurons are derived. Third, while the Spike
Response Model with escape noise has always contained all the features of a Generalized
Linear Model (GLM), by the year 2002 the theory of GLMs had not yet found its way into
the ﬁeld of neuroscience and was therefore simply absent from the original book. Given
the phenomenal rise of GLMs in neuroscience, the theory of GLMs for ﬁtting neuronal
data is given a prominent role in this book. Finally, during teaching we always felt the
need to show famous applications of the principles of neuronal dynamics, such as retrieval
of contents from associative memories or decision dynamics and the neuroscience of free
will. The present book covers these topics.
On a more general level, we felt that it would be useful to have a book that is, from the
beginning, designed as a textbook rather than a monograph. Therefore, the present book
makes the link to experimental data more visible, has more explanatory text, and, last but
not least, provides a series of exercises that have already been tested in the classroom over
several years.
We hope that this book will be useful for students and researchers alike.
Wulfram Gerstner, Werner Kistler, Richard Naud, Liam Paninski

Preface
xi
Advice to the reader
Each chapter starts with a speciﬁc question and gives ﬁrst intuitive answers in the ﬁrst
section. As the chapter proceeds, the material gets more advanced, and the presentation
becomes more technical. For a ﬁrst reading of the book, it is possible to read only the ﬁrst
section, or ﬁrst two sections, of each chapter and just glance at the subsequent sections.
More speciﬁc advice depends on the background. For example, readers who are new to
the ﬁeld of computational neuroscience are advised to spend enough time with the classic
material of Part I, before they move on to Parts II and IV. The expert reader may skip Part I
completely and start directly with Part II.
In Part III, the main ideas are exposed in Chapters 12 and 15, which present the founda-
tions for the rate models in Part IV. The more technical chapters and sections of Part III can
be skipped at a ﬁrst reading, but are necessary for a thorough understanding of the current
developments in the ﬁeld of computational neuroscience.
Part IV contains applications of neuronal dynamics to questions of cognition and can be
read in any arbitrary order.
Sections marked by an asterisk (∗) are mathematically more advanced and can be omit-
ted during a ﬁrst reading of the book.
Acknowledgements
We would like to thank our students, visitors, exchange students, and postdocs who care-
fully read and commented on at least two chapters each, some many more: Dane Corneil,
Andrea De Antoni, Mortiz Deger, Mohammad Faraji, Nicolas Fr´emaux, Felipe Gerhard,
Laureline Logiaco, Skander Mensi, Alexandre Payeur, Christian Pozzorini, Kerstin
Preuschoff, Tilo Schwalger, Alex Seeholzer, Hesam Setareh, Carlos Stein, Tim Vogels,
Friedemann Zenke, Lorric Ziegler.
The writing of the text was a joint work of the four authors. Werner Kistler and Wulfram
Gerstner were the authors of Spiking Neuron Models from which several sections sur-
vived. Liam Paninski was mainly involved in writing Chapters 9-11 of the present book
and gave valuable input to other chapters of Part II. Richard Naud contributed to writing
Chapters 1-11 and 14 with a leading role in some of these, made valuable comments and
suggestions for all other chapters, and was responsible for all the ﬁgures. Wulfram Gerstner
wrote the ﬁrst drafts of Parts III and IV and contributed text to all other chapters.
Wulfram Gerstner, Werner Kistler, Richard Naud, Liam Paninski


PART ONE
FOUNDATIONS OF NEURONAL DYNAMICS


1
Introduction: neurons and mathematics
The primary aim of this chapter is to introduce several elementary notions of neuroscience,
in particular the concepts of action potentials, postsynaptic potentials, ﬁring thresholds,
refractoriness, and adaptation. Based on these notions a preliminary model of neuronal
dynamics is built and this simple model (the leaky integrate-and-ﬁre model) will be used
as a starting point and reference for the generalized integrate-and-ﬁre models, which are
the main topic of the book, to be discussed in Parts II and III. Since the mathematics used
for the simple model is essentially that of a one-dimensional linear differential equation,
we take this ﬁrst chapter as an opportunity to introduce some of the mathematical notation
that will be used throughout the rest of the book.
Owing to the limitations of space, we cannot - and do not want to - give a comprehensive
introduction to such a complex ﬁeld as neurobiology. The presentation of the biological
background in this chapter is therefore highly selective and focuses on those aspects needed
to appreciate the biological background of the theoretical work presented in this book. For
an in-depth discussion of neurobiology we refer the reader to the literature mentioned at
the end of this chapter.
After the review of neuronal properties in Sections 1.1 and 1.2 we will turn, in Sec-
tion 1.3, to our ﬁrst mathematical neuron model. The last two sections are devoted to a
discussion of the strengths and limitations of simpliﬁed models.
1.1 Elements of neuronal systems
Over the past hundred years, biological research has accumulated an enormous amount of
detailed knowledge about the structure and function of the brain. The elementary process-
ing units in the central nervous system are neurons, which are connected to each other in an
intricate pattern. A tiny portion of such a network of neurons is sketched in Fig. 1.1, which
shows a drawing by Ram´on y Cajal, one of the pioneers of neuroscience around 1900. We
can distinguish several neurons with triangular or circular cell bodies and long wire-like
extensions. This picture can only give a glimpse of the network of neurons in the cortex. In
reality, cortical neurons and their connections are packed into a dense network with more
than 104 cell bodies and several kilometers of "wires" per cubic millimeter. Across areas of

4
Introduction
Fig. 1.1 This reproduction of a drawing of Ram´on y Cajal shows a few neurons in the mammalian
cortex that he observed under the microscope. Only a small portion of the neurons contained in the
sample of cortical tissue have been made visible by the staining procedure; the density of neurons is
in reality much higher. Cell b is a typical example of a pyramidal cell with a triangularly shaped cell
body. Dendrites, which leave the cell laterally and upwards, can be recognized by their rough surface.
The axons are recognizable as thin, smooth lines which extend downwards with a few branches to
the left and right. From Ram`on y Cajal (1909).
the brain the wiring pattern may look different. In all areas, however, neurons of different
sizes and shapes form the basic elements.
Still, the cortex does not consist exclusively of neurons. Beside the various types of
neuron, there are a large number of "supporter" cells, so-called glia cells, that are required
for energy supply and structural stabilization of brain tissue. Since glia cells are not directly
involved in information processing, we will not discuss them any further. We will also
neglect a few rare subtypes of neuron, such as non-spiking neurons in the mammalian
retina. Throughout this book we concentrate on spiking neurons only.
1.1.1 The ideal spiking neuron
A typical neuron can be divided into three functionally distinct parts, called dendrites, the
soma, and the axon; see Fig. 1.2. Roughly speaking, the dendrites play the role of the "input
device" that collects signals from other neurons and transmits them to the soma. The soma
is the "central processing unit" that performs an important nonlinear processing step: if
the total input arriving at the soma exceeds a certain threshold, then an output signal is
generated. The output signal is taken over by the "output device," the axon, which delivers
the signal to other neurons.
The junction between two neurons is called a synapse. Let us suppose that a neuron sends
a signal across a synapse. It is common to refer to the sending neuron as the presynaptic
cell and to the receiving neuron as the postsynaptic cell. A single neuron in vertebrate

1.1 Elements of neuronal systems
5
1ms
10mV
Action
potential
Dendrites
Soma
(a)
Electrode
Axon
Dendrites
(b)
Axon
Synapse
j
i
Fig. 1.2 (a) Single neuron in a drawing by Ram´on y Cajal. Dendrites, soma, and axon can be clearly
distinguished. The inset shows an example of a neuronal action potential (schematic). The action
potential is a short voltage pulse of 1-2 ms duration and an amplitude of about 100 mV. (b) Signal
transmission from a presynaptic neuron j to a postsynaptic neuron i. The synapse is marked by the
dashed circle. The axons at the lower right end lead to other neurons. (Schematic ﬁgure.)
cortex often connects to more than 104 postsynaptic neurons. Many of its axonal branches
end in the direct neighborhood of the neuron, but the axon can also stretch over several
centimeters so as to reach neurons in other areas of the brain.
1.1.2 Spike trains
The neuronal signals consist of short electrical pulses and can be observed by placing a
ﬁne electrode either on the soma or close to the soma or axon of a neuron; see Fig. 1.2.
The pulses, so-called action potentials or spikes, have an amplitude of about 100 mV and
typically a duration of 1-2 ms. The form of the pulse does not change as the action potential
propagates along the axon. A chain of action potentials emitted by a single neuron is called
a spike train - a sequence of stereotyped events which occur at regular or irregular intervals;
see Fig. 1.3. Since isolated spikes of a given neuron look alike, the form of the action
potential does not carry any information. Rather, it is the number and the timing of spikes
which matter. The action potential is the elementary unit of signal transmission.
Action potentials in a spike train are usually well separated. Even with very strong input,
it is impossible to excite a second spike during or immediately after a ﬁrst one. The mini-
mal distance between two spikes deﬁnes the absolute refractory period of the neuron. The
absolute refractory period is followed by a phase of relative refractoriness where it is difﬁ-
cult, but not impossible, to excite an action potential.

6
Introduction
Fig. 1.3 Action potentials are stereotypical events. Membrane potential recordings aligned on the
time of maximum voltage show little variability of the action potential shape. Data is courtesy of
Maria Toledo-Rodriguez and Henry Markram (Toledo-Rodriguez et al., 2004).
1.1.3 Synapses
The site where the axon of a presynaptic neuron makes contact with the dendrite (or soma)
of a postsynaptic cell is the synapse. The most common type of synapse in the vertebrate
brain is a chemical synapse. At a chemical synapse, the axon terminal comes very close to
the postsynaptic neuron, leaving only a tiny gap between pre- and postsynaptic cell mem-
brane. This is called the synaptic cleft. When an action potential arrives at a synapse, it
triggers a complex chain of biochemical processing steps that lead to a release of neuro-
transmitter from the presynaptic terminal into the synaptic cleft. As soon as transmitter
molecules have reached the postsynaptic side, they will be detected by specialized recep-
tors in the postsynaptic cell membrane and lead (either directly or via a biochemical sig-
naling chain) to an opening of speciﬁc channels causing ions from the extracellular ﬂuid
to ﬂow into the cell. The ion inﬂux, in turn, changes the membrane potential at the post-
synaptic site so that, in the end, the chemical signal is translated into an electrical response.
The voltage response of the postsynaptic neuron to a presynaptic spike is called the post-
synaptic potential.
Apart from chemical synapses neurons can also be coupled by electrical synapses, some-
times called gap junctions. Specialized membrane proteins make a direct electrical con-
nection between the two neurons. Not much is known about the functional aspects of gap
junctions, but they are thought to be involved in the synchronization of neurons.
1.1.4 Neurons are part of a big system
Neurons are embedded in a network of billions of other neurons and glial cells that make up
the brain tissue. The brain is organized into different regions and areas. The cortex can be
thought of as a thin but extended sheet of neurons, folded over other brain structures. Some
cortical areas are mainly involved in processing sensory input, other areas are involved in
working memory or motor control.
Neurons in sensory cortices can be experimentally characterized by the stimuli to which
they exhibit a strong response. For example, neurons in the primary visual cortex respond

1.2 Elements of neuronal dynamics
7
V1
Electrode
Receptive
field
Fig. 1.4 Receptive ﬁelds in the visual cortex. An electrode probes the activity of a neuron while
light dots are presented on a gray screen. The neuron responds whenever the stimulus falls into its
receptive ﬁeld, schematically indicated as an oval.
to dots of lights only within a small region of the visual space. The limited zone where a
neuron is sensitive to stimuli is called the neuron's receptive ﬁeld (Fig. 1.4).
The receptive ﬁeld of so-called simple cells in the visual cortex is not homogeneous, but
has typically two or three elongated subﬁelds. When a light dot falls into one of the positive
subﬁelds, the neuron increases its activity, i.e., it emits more spikes than in the absence of a
stimulus. When a light dot falls into a negative subﬁeld, it decreases the activity compared
to its spontaneous activity in the presence of a gray screen. A spot of light is in fact not the
best stimulus. The neuron responds maximally to a moving light bar with an orientation
aligned with the elongation of the positive subﬁeld (Hubel and Wiesel, 1968).
A large body of the neuroscience literature consists in determining the receptive ﬁelds
of neurons in sensory cortices. While neurons in the visual cortex respond to appropriate
visual stimuli, neurons in the auditory cortex or somatosensory cortex respond to auditory
or tactile stimuli. The concept of receptive ﬁeld becomes less well deﬁned if one moves
away from the sensory cortex. For example, in the inferotemporal cortex, neurons respond
to objects independently of their size and location; in working memory tasks, frontal
cortex neurons are active during periods where no stimulus is present at all. In Parts II,
III, and IV of this book we touch on aspects of receptive ﬁelds and memory of neuronal
networks embedded in a big system. For the moment, we return to a simple, idealized
neuron.
1.2 Elements of neuronal dynamics
The effect of a spike on the postsynaptic neuron can be recorded with an intracellular
electrode which measures the potential difference u(t) between the interior of the cell and
its surroundings. This potential difference is called the membrane potential. Without any
input, the neuron is at rest corresponding to a constant membrane potential urest. After the

8
Introduction
arrival of a spike, the potential changes and ﬁnally decays back to the resting potential; see
Fig. 1.5a. If the change is positive, the synapse is said to be excitatory. If the change is
negative, the synapse is inhibitory.
At rest, the cell membrane has already a strongly negative polarization of about -65 mV.
An input at an excitatory synapse reduces the negative polarization of the membrane and
is therefore called depolarizing. An input that increases the negative polarization of the
membrane even further is called hyperpolarizing.
1.2.1 Postsynaptic potentials
Let us formalize the above observation. We study the time course ui(t) of the membrane
potential of neuron i. Before the input spike has arrived, we have ui(t) = urest. At t = 0
the presynaptic neuron j ﬁres its spike. For t > 0, we see at the electrode a response of
neuron i
ui(t)−urest =: εi j(t).
(1.1)
The right-hand side of Eq. (1.1) deﬁnes the postsynaptic potential (PSP). If the voltage
difference ui(t)−urest is positive (negative) we have an excitatory (inhibitory) postsynaptic
potential or short EPSP (IPSP). In Fig. 1.5a we have sketched the EPSP caused by the
arrival of a spike from neuron j at an excitatory synapse of neuron i.
1.2.2 Firing threshold and action potential
Consider two presynaptic neurons j = 1,2, which both send spikes to the postsynaptic neu-
ron i. Neuron j = 1 ﬁres spikes at t(1)
1 ,t(2)
1 ,..., similarly neuron j = 2 ﬁres at t(1)
2 ,t(2)
2 ,... .
Each spike evokes a postsynaptic potential εi1 or εi2, respectively. As long as there are
only few input spikes, the total change of the potential is approximately the sum of the
individual PSPs,
ui(t) = ∑
j ∑
f
εi j(t −t f
j )+urest ,
(1.2)
i.e., the membrane potential responds linearly to input spikes; see Fig. 1.5b.
On the other hand, linearity breaks down if too many input spikes arrive during a short
interval. As soon as the membrane potential reaches a critical value ϑ, its trajectory shows
a behavior that is quite different from a simple summation of PSPs: the membrane potential
exhibits a pulse-like excursion with an amplitude of about 100 mV. This short voltage pulse
will propagate along the axon of neuron i to the synapses with other neurons. After the
pulse the membrane potential does not directly return to the resting potential, but passes,
for many neuron types, through a phase of hyperpolarization below the resting value. This
hyperpolarization is called "spike-afterpotential."
Single EPSPs have amplitudes in the range of 1 mV. The critical value for spike initiation
is about 20 to 30 mV above the resting potential. In most neurons, four spikes - as shown

1.2 Elements of neuronal dynamics
9
j= 1
(a)
ui(t)
j = 2
j = 1
(b)
ui (t )
t
urest
u(t)
t 1
f
ei1
J
t
urest
t1
f
t2
f
u(t)
J
j = 2
j = 1
(c)
ui(t )
t
urest
u(t)
t 1
1
t 1
2
t 2
1
t 2
2
Fig. 1.5 A postsynaptic neuron i receives input from two presynaptic neurons j = 1,2. (a) Each
presynaptic spike evokes an excitatory postsynaptic potential (EPSP) that can be measured with an
electrode as a potential difference ui(t) −urest. The time course of the EPSP caused by the spike of
neuron j = 1 is εi1(t −t f
1 ). (b) An input spike from a second presynaptic neuron j = 2 that arrives
shortly after the spike from neuron j = 1 causes a second postsynaptic potential that adds to the
ﬁrst one. (c) If ui(t) reaches the threshold ϑ, an action potential is triggered. As a consequence,
the membrane potential starts a large positive pulse-like excursion (arrow). On the voltage scale
of the graph, the peak of the pulse is out of bounds. After the pulse the voltage returns to a value
below the resting potential urest.

10
Introduction
schematically in Fig. 1.5c - are thus not sufﬁcient to trigger an action potential. Instead,
about 20-50 presynaptic spikes have to arrive within a short time window to trigger a
postsynaptic action potential.
1.3 Integrate-and-ﬁre models
We have seen in the previous section that, to a ﬁrst and rough approximation, neuronal
dynamics can be conceived as a summation process (sometimes also called "integration"
process) combined with a mechanism that triggers action potentials above some critical
voltage. Indeed in experiments ﬁring times are often deﬁned as the moment when the
membrane potential reaches some threshold value from below. In order to build a phe-
nomenological model of neuronal dynamics, we describe the critical voltage for spike ini-
tiation by a formal threshold ϑ. If the voltage ui(t) (that contains the summed effect of all
inputs) reaches ϑ from below, we say that neuron i ﬁres a spike. The moment of threshold
crossing deﬁnes the ﬁring time t f
i .
The model makes use of the fact that neuronal action potentials of a given neuron always
have roughly the same form. If the shape of an action potential is always the same, then
the shape cannot be used to transmit information: rather information is contained in the
presence or absence of a spike. Therefore action potentials are reduced to "events" that
happen at a precise moment in time.
Neuron models where action potentials are described as events are called "integrate-and-
ﬁre" models. No attempt is made to describe the shape of an action potential. Integrate-and-
ﬁre models have two separate components that are both necessary to deﬁne their dynamics:
ﬁrst, an equation that describes the evolution of the membrane potential ui(t); and second,
a mechanism to generate spikes.
In the following we introduce the simplest model in the class of integrate-and-ﬁre mod-
els using the following two ingredients: (i) a linear differential equation to describe the
evolution of the membrane potential; (ii) a threshold for spike ﬁring. This model is called
the "leaky integrate-and-ﬁre" model. Generalized integrate-and-ﬁre models, which will be
discussed in Part II of the book, can be seen as variations of this basic model.
1.3.1 Integration of inputs
The variable ui describes the momentary value of the membrane potential of neuron i. In
the absence of any input, the potential is at its resting value urest. If an experimenter injects
a current I(t) into the neuron, or if the neuron receives synaptic input from other neurons,
the potential ui will be deﬂected from its resting value.
In order to arrive at an equation that links the momentary voltage ui(t)−urest to the input
current I(t), we use elementary laws from the theory of electricity. A neuron is surrounded
by a cell membrane, which is a rather good insulator. If a short current pulse I(t) is injected
into the neuron, the additional electrical charge q =
 I(t′)dt′ has to go somewhere: it will

1.3 Integrate-and-ﬁre models
11
+
-
+
+
+
+
+
+
+
+
+
+
-
-
-
-
-
-
-
-
-
-
C
R
urest
u(t)
I(t
(a)
)
I (t)
+
+
-
-
I (t)
(b)
u (t)
t
t
urest
Fig. 1.6 Electrical properties of
neurons: the passive membrane.
(a) A neuron, which is enclosed
by the cell membrane (big circle),
receives a (positive) input current
I(t) which increases the electri-
cal charge inside the cell. The cell
membrane acts like a capacitor in
parallel with a resistor which is in
line with a battery of potential urest
(zoomed inset). (b) The cell mem-
brane reacts to a step current (top)
with a smooth voltage trace (bot-
tom).
charge the cell membrane (Fig. 1.6a). The cell membrane therefore acts like a capacitor
of capacity C. Because the insulator is not perfect, the charge will, over time, slowly leak
through the cell membrane. The cell membrane can therefore be characterized by a ﬁnite
leak resistance R.
The basic electrical circuit representing a leaky integrate-and-ﬁre model consists of a
capacitor C in parallel with a resistor R driven by a current I(t); see Fig. 1.6. If the driving
current I(t) vanishes, the voltage across the capacitor is given by the battery voltage urest.
For a biological explanation of the battery we refer the reader to the next chapter. Here we
have simply inserted the battery "by hand" into the circuit so as to account for the resting
potential of the cell (Fig. 1.6a).
In order to analyze the circuit, we use the law of current conservation and split the
driving current into two components,
I(t) = IR +IC.
(1.3)
The ﬁrst component is the resistive current IR which passes through the linear resistor R. It
can be calculated from Ohm's law as IR = uR/R where uR = u−urest is the voltage across
the resistor. The second component IC charges the capacitor C. From the deﬁnition of the
capacity as C = q/u (where q is the charge and u the voltage), we ﬁnd a capacitive current
IC = dq/dt = Cdu/dt. Thus
I(t) = u(t)−urest
R
+C du
dt .
(1.4)
We multiply Eq. (1.4) by R and introduce the time constant τm = RC of the "leaky integra-
tor." This yields the standard form
τm
du
dt = −[u(t)−urest]+RI(t).
(1.5)
We refer to u as the membrane potential and to τm as the membrane time constant of the
neuron.

12
Introduction
I ( t)
t
t
q/C
Δ u(t)
0
0
Fig. 1.7 Short pulses and total charged delivered on the passive membrane. The amplitude of
the voltage response (bottom) of a leaky integrator driven by a short current pulse I(t) (top)
depends only on the total charge q =
 I(t)dt, not on the height of the current pulse.
From a mathematical point of view, Eq. (1.5) is a linear differential equation. From the
point of view of an electrical engineer, it is the equation of a leaky integrator or RC-circuit
where resistor R and capacitor C are arranged in parallel. From the point of view of the
neuroscientist, Eq. (1.5) is called the equation of a passive membrane.
What is the solution of Eq. (1.5)? We suppose that, for whatever reason, at time t = 0
the membrane potential takes a value urest + Δu. For t > 0 the input vanishes I(t) = 0.
Intuitively we expect that, if we wait long enough, the membrane potential relaxes to its
resting value urest. Indeed, the solution of the differential equation with initial condition
u(t0) = urest +Δu is
u(t)−urest = Δu exp

−t −t0
τm

for t > t0 .
(1.6)
Thus, in the absence of input, the membrane potential decays exponentially to its resting
value. The membrane time constant τm = RC is the characteristic time of the decay. For a
typical neuron it is in the range of 10 ms, and hence rather long compared with the duration
of a spike which is of the order of 1 ms.
The validity of the solution (1.6) can be checked by taking the derivative on both sides
of the equation. Since it is the solution in the absence of input, it is sometimes called the
"free" solution.
1.3.2 Pulse input
Before we continue with the deﬁnition of the integrate-and-ﬁre model and its variants, let
us study the dynamics of the passive membrane deﬁned by Eq. (1.5) in a simple example.
Suppose that the passive membrane is stimulated by a constant input current I(t) = I0
which starts at t = 0 and ends at time t = Δ. For the sake of simplicity we assume that the
membrane potential at time t = 0 is at its resting value u(0) = urest.

1.3 Integrate-and-ﬁre models
13
As a ﬁrst step, let us calculate the time course of the membrane potential. The trajec-
tory of the membrane potential can be found by integrating (1.5) with the initial condition
u(0) = urest. The solution for 0 < t < Δ is
u(t) = urest +RI0

1−exp

−t
τm

.
(1.7)
If the input current never stopped, the membrane potential (1.7) would approach for t →∞
the asymptotic value u(∞) = urest + RI0. We can understand this result by looking at the
electrical diagram of the RC-circuit in Fig. 1.6. Once a steady state is reached, the charge
on the capacitor no longer changes. All input current must then ﬂow through the resistor.
The steady-state voltage at the resistor is therefore RI0 so that the total membrane voltage
is urest +RI0.
Example: Short pulses and the Dirac δ-function
For short pulses the steady-state value is never reached. At the end of the pulse, the
value of the membrane potential is given according to Eq. (1.7) by u(Δ) = urest +
RI0

1−exp

−Δ
τm
	
. For pulse durations Δ ≪τm (where ≪means much smaller than)
we can expand the exponential term into a Taylor series: exp(x) = 1+x+x2/2+···. To
ﬁrst order in x = −Δ
τm we ﬁnd
u(Δ) = urest +RI0
Δ
τm
for Δ ≪τm.
(1.8)
Thus, the voltage deﬂection depends linearly on the amplitude and the duration of the
pulse (Fig. 1.7, thick line).
We now make the duration Δ of the pulse shorter and shorter while increasing the
amplitude of the current pulse to a value I0 = q/Δ, so that the integral
 I(t)dt = q
remains constant. In other words, the total charge q delivered by the current pulse is
always the same. Interestingly, the voltage deﬂection at the end of the pulse calcu-
lated from Eq. (1.8) remains unaltered, however short we make the pulse. Indeed, from
Eq. (1.8) we ﬁnd u(Δ) −urest = qR/τm = q/C where we have used τm = RC. Thus we
can consider the limit of an inﬁnitely short pulse
I(t) = qδ(t) = lim
Δ→0
q
Δ
for 0 < t < Δ,
and 0 otherwise.
(1.9)
δ(t) is called the Dirac δ-function. It is deﬁned by δ(x) = 0 for x ̸= 0 and
 ∞
−∞δ(x)dx = 1.
Obviously, the Dirac δ-function is a mathematical abstraction since it is practically
impossible to inject a current with an inﬁnitely short and inﬁnitely strong current pulse
into a neuron. Whenever we encounter a δ-function, we should remember that, as a
stand-alone object, it looks strange, but it becomes meaningful as soon as we integrate
over it. Indeed the input current deﬁned in Eq. (1.9) needs to be inserted into the
differential equation (1.5) and integrated. The mathematical abstraction of the Dirac
δ-function suddenly makes a lot of sense, because the voltage change induced by a
short current pulse is always the same, whenever the duration of the pulse Δ is much

14
Introduction
δ(t −ti
1)
u
ϑ
ur
t
ti
1
urest
Fig. 1.8 In formal models of spiking neurons the shape of an action potential (dashed line) is usually
replaced by a δ-pulse (vertical line). The negative overshoot (spike-afterpotential) after the pulse
is replaced by a "reset" of the membrane potential to the value ur. The pulse is triggered by the
threshold crossing at t1
i .
shorter than the time constant τm. Thus, the exact duration of the pulse is irrelevant, as
long as it is short enough.
With the help of the δ-function, we no longer have to worry about the time course
of the membrane potential during the application of the current pulse: the membrane
potential simply jumps at time t = 0 by an amount q/C. Thus, it is as if we added
instantaneously a charge q onto the capacitor of the RC circuit.
What happens for times t > Δ? The membrane potential evolves from its new initial
value urest +q/C in the absence of any further input. Thus we can use the "free" solution
from Eq. (1.6) with t0 = Δ and Δu = q/C.
We can summarize the considerations of this section by the following statement. The
solution of the linear differential equation with pulse input
τm
du
dt = −[u(t)−urest]+Rqδ(t)
(1.10)
is u(t) = urest for t ≤0 and given by
u(t)−urest = q R
τm
exp

−t
τm

for t > 0.
(1.11)
The right-hand side of the equation is called the impulse-response function or Green's
function of the linear differential equation.
1.3.3 The threshold for spike ﬁring
Throughout this book, the term "ﬁring time" refers to the moment when a given neuron
emits an action potential t f . The ﬁring time t f in the leaky integrate-and-ﬁre model is
deﬁned by a threshold criterion
t f :
u(t f ) = ϑ .
(1.12)

1.3 Integrate-and-ﬁre models
15
0
20
40
60
80
100
t [ms]
0.0
0.2
0.4
0.6
0.8
1.0
1.2
(a)
Δ u (t)/J
t1
t2
t3
t4t4
t5
0
20
40
60
80
100
t [ms]
0.0
0.2
0.4
0.6
0.8
1.0
1.2
(b)
t1
t2
t3
t4
Δ u (t)/J
Fig. 1.9 Integrate-and-ﬁre model. (a) Time course of the membrane potential of an integrate-and-ﬁre
neuron driven by constant input current I0 = 1.5. The voltage Δu(t) = u−urest is normalized by the
value of the threshold ϑ. Units of input current are chosen so that I0 = 1 corresponds to a trajectory
that reaches the threshold for t →∞. After a spike, the potential is reset to ur = urest. (b) Voltage
response to a time-dependent input current.
The form of the spike is not described explicitly. Rather, the ﬁring time is noted and imme-
diately after t f the potential is reset to a new value ur < ϑ,
lim
δ→0;δ>0u(t f +δ) = ur .
(1.13)
For t > t f the dynamics is again given by (1.5) until the next threshold crossing occurs. The
combination of leaky integration (1.5) and reset (1.13) deﬁnes the leaky integrate-and-ﬁre
model (Stein, 1967b). The voltage trajectory of a leaky integrate-and-ﬁre model driven by
a constant current I0 is shown in Fig. 1.9.
For the ﬁring times of neuron i we write t f
i where f = 1,2,... is the label of the spike.
Formally, we may denote the spike train of a neuron i as the sequence of ﬁring times
Si(t) = ∑
f
δ(t −t f
i )
(1.14)
where δ(x) is the Dirac δ-function introduced earlier, with δ(x) = 0 for x ̸= 0 and
 ∞
−∞δ(x)dx = 1. Spikes are thus reduced to points in time (Fig. 1.8). We remind the reader
that the δ-function is a mathematical object that needs to be inserted into an integral in
order to give meaningful results.
1.3.4 Time-dependent input (*)1
We study a leaky integrate-and-ﬁre model which is driven by an arbitrary time-dependent
input current I(t); see Fig. 1.9b. The ﬁring threshold has a value ϑ and after ﬁring the
potential is reset to a value ur < ϑ.
1Sections marked by an asterisk are mathematically more advanced and can be omitted during a ﬁrst reading of the book.

16
Introduction
In the absence of a threshold, the linear differential equation (1.5) has a solution
u(t) = urest + R
τm
 ∞
0 exp

−s
τm

I(t −s)ds,
(1.15)
where I(t) is an arbitrary input current and τm = RC is the membrane time constant. We as-
sume here that the input current is deﬁned for a long time back into the past: t →−∞so that
we do not have to worry about the initial condition. A sinusoidal current I(t) = I0 sin(ω t)
or a step current pulse I(t) = I0Θ(t), where Θ denotes the Heaviside step function with
Θ(t) = 0 for t ≤0 and Θ(t) = 1 for t > 0, are two examples of a time-dependent current,
but the solution, Eq. (1.15), is also valid for every other time-dependent input current.
So far our leaky integrator does not have a threshold. What happens to the solution
Eq. (1.15) if we add a threshold ϑ? Each time the membrane potential hits the threshold,
the variable u is reset from ϑ to ur. In the electrical circuit diagram, the reset of the poten-
tial corresponds to removing a charge qr = C(ϑ −ur) from the capacitor (Fig. 1.6) or,
equivalently, adding a negative charge −qr onto the capacitor. Therefore, the reset corre-
sponds to a short current pulse Ir = −qr δ(t −t f ) at the moment of the ﬁring t f . Indeed, it
is not unusual to say that a neuron "discharges" instead of "ﬁres." Since the reset happens
each time the neuron ﬁres, the reset current is
Ir = −qr ∑
f
δ(t −t f ) = −C(ϑ −ur)S(t),
(1.16)
where S(t) denotes the spike train, deﬁned in Eq. (1.14).
The short current pulse corresponding to the "discharging" is treated mathematically just
like any other time-dependent input current. The total current I(t)+Ir(t), consisting of the
stimulating current and the reset current, is inserted into the solution (1.15) to give the ﬁnal
result
u(t) = urest +∑
f
(ur −ϑ) exp

−t −t f
τm

+ R
τm
 ∞
0 exp

−s
τm

I(t −s)ds,
(1.17)
where the ﬁring times t f are deﬁned by the threshold condition
t f = {t|u(t) = ϑ} .
(1.18)
Note that with our deﬁnition of the Dirac δ-function in Eq. (1.9), the discharging reset
follows immediately after the threshold crossing, so that the natural sequence of events -
ﬁrst ﬁring, then reset - is respected.
Equation (1.17) looks rather complicated. It has, however, a simple explanation. In Sec-
tion 1.3.2 we have seen that a short input pulse at time t′ causes at time t a response of
the membrane proportional to exp[−(t −t′/τm)], sometimes called the impulse response
function or Green's function; see Eq. (1.11). The second term on the right-hand side of
Eq. (1.17) is the effect of the discharging current pulses at the moment of the reset.
In order to interpret the last term on the right-hand side, we think of a stimulating current
I(t) as consisting of a rapid sequence of discrete and short current pulses. In discrete time,

1.3 Integrate-and-ﬁre models
17
there would be a different current pulse in each time step. Because of the linearity of the
differential equation, the effect of all these short current pulses can be added. When we
return from discrete time to continuous time, the sum of the impulse response functions
turns into the integral on the right-hand side of Eq. (1.17).
1.3.5 Linear differential equation vs. linear ﬁlter: two equivalent pictures (*)
The leaky integrate-and-ﬁre model is deﬁned by the differential equation (1.5), i.e.,
τm
du
dt = −[u(t)−urest]+RI(t),
(1.19)
combined with the reset condition
lim
δ→0;δ>0u(t f +δ) = ur,
(1.20)
where t f are the ﬁring times
t f = {t|u(t) = ϑ}.
(1.21)
As we have seen in the previous section, the linear equation can be integrated and yields
the solution (1.17). It is convenient to rewrite the solution in the form
u(t) =
 ∞
0 η(s)S(t −s)ds+
 ∞
0 κ(s)I(t −s)ds,
(1.22)
where we have introduced ﬁlters η(s) = (ur −ϑ) exp

−s
τm
	
and κ(s) = 1
C exp

−s
τm
	
.
Interestingly, Eq. (1.22) is much more general than the leaky integrate-and-ﬁre model,
because the ﬁlters do not need to be exponentials but could have any arbitrary shape.
The ﬁlter η describes the reset of the membrane potential and, more generally, accounts
for neuronal refractoriness. The ﬁlter κ summarizes the linear electrical properties of the
membrane. Eq. (1.22) in combination with the threshold condition (1.21) is the basis of
the Spike Response Model and Generalized Linear Models, which will be discussed in
Part II.
1.3.6 Periodic drive and Fourier transform (*)
Formally, the complex Fourier transform of a real-valued function f(t) with argument t on
the real line is
ˆf(ω) =
 ∞
−∞f(t)e−iωtdt = | ˆf(ω)|eiφ f (ω),
(1.23)
where | ˆf(ω)| and φ f (ω) are called the amplitude and phase of the Fourier transform at
frequency ω. The mathematical condition for a well-deﬁned Fourier transform is that the
function f be Lebesgue integrable with integral
 ∞
−∞| f(t)|dt < ∞. If f is a function of
time, then ˆf(ω) is a function of frequency. An inverse Fourier transform leads back from
frequency-space to the original space, i.e., time.

18
Introduction
For a linear system, the above deﬁnition gives rise to several convenient rules for Fourier-
transformed equations. For example, let us consider the system
u(t) =
 ∞
−∞κ(s)I(t −s)ds,
(1.24)
where I(t) is a real-valued input (e.g., a current), u(t) the real-valued system output (e.g., a
voltage) and κ a linear response ﬁlter, or kernel, with κ(s) = 0 for s < 0 because of causal-
ity. The convolution on the right-hand side of Eq. (1.24) turns after Fourier transformation
into a simple multiplication, as shown by the following calculation steps:
ˆu(ω) =
 ∞
−∞
 ∞
−∞κ(s)I(t −s)ds

e−iωtdt
=
 ∞
−∞
 ∞
−∞κ(s)e−iωs I(t −s)e−iω(t−s)dsdt
= ˆκ(ω) ˆI(ω),
(1.25)
where we introduced in the last step the variable t′ = t −s and used the deﬁnition (1.23) of
the Fourier transform.
Similarly, the derivative du/dt of a function u(t) can be Fourier-transformed using the
product rule of integration. The Fourier transform of the derivative of u(t) is iω ˆu(ω).
While introduced here as a purely mathematical operation, it is often convenient to visu-
alize the Fourier transform in the context of a physical system driven by a periodic input.
Consider the linear system of Eq. (1.24) with an input
I(t) = I0 eiωt .
(1.26)
A short comment on the notation. If the input is a current, it should be real-valued, as
opposed to a complex number. We therefore take I0 as a real and positive number and
focus on the real part of the complex equation (1.26) as our physical input. When we
perform a calculation with complex numbers, we therefore implicitly assume that, at the
very end, we take only the real part of solution. However, the calculation with complex
numbers turns out to be convenient for the steps in between.
Inserting the periodic drive, Eq. (1.26), into Eq. (1.24) yields
u(t) =
 ∞
−∞κ(s)I0eiω(t−s) ds =
 ∞
−∞κ(s)e−iωs ds

I0eiωt .
(1.27)
Hence, if the input is periodic at frequency ω the output is too. The term in square brackets
is the Fourier transform of the linear ﬁlter. We write u(t) = u0 eiφκ(ω) eiωt. The ratio between
the amplitude of the output and that of the input is
u0
I0
= | ˆκ(ω)|.
(1.28)
The phase φκ(ω) of the Fourier-transformed linear ﬁlter κ corresponds to the phase shift
between input and output or, to say it differently, a delay Δ = φκ/ω = φκ T/2π where T is
the period of the oscillation. Fourier transforms will play a role in the discussion of signal

1.4 Limitations of the leaky integrate-and-ﬁre model
19
processing properties of connected networks of neurons in Part III of the book.
Example: Periodic drive of a passive membrane
We consider the differential equation of the passive membrane deﬁned in Eq. (1.5)
and choose voltage units such that urest = 0, i.e.,
τm
du
dt = −u(t)+RI(t).
(1.29)
The solution, given by Eq. (1.15), corresponds to the convolution of the input I(t) with
a causal linear ﬁlter κ(s) = (1/C)e(−s/τm) for s > 0. In order to determine the response
amplitude u0 to a periodic drive I(t) = I0 eiωt we need to calculate the Fourier transform
of κ:
| ˆκ(ω)| =

1
C
 ∞
0 e
−t
τm e−iωt dt
 = 1
C

τm
1+iωτm
 .
(1.30)
For ωτm ≫1 the right-hand side is proportional to ω−1. Therefore the amplitude of the
response to a periodic input decreases at high frequencies.
1.4 Limitations of the leaky integrate-and-ﬁre model
The leaky integrate-and-ﬁre model presented in Section 1.3 is highly simpliﬁed and neglects
many aspects of neuronal dynamics. In particular, input, which may arise from presynaptic
neurons or from current injection, is integrated linearly, independently of the state of the
postsynaptic neuron:
τm
du
dt = −[u(t)−urest]+RI(t),
(1.31)
where I(t) is the input current. Furthermore, after each output spike the membrane potential
is reset,
if u(t) = ϑ then
lim
δ→0;δ>0u(t +δ) = ur,
(1.32)
so that no memory of previous spikes is kept. Let us list the major limitations of the sim-
pliﬁed model discussed so far. All of these limitations will be addressed in the extension
of the leaky integrate-and-ﬁre model presented in Part II of the book.
1.4.1 Adaptation, bursting, and inhibitory rebound
To study neuronal dynamics experimentally, neurons can be isolated and stimulated by
current injection through an intracellular electrode. In a standard experimental protocol
we could, for example, impose a stimulating current that is switched at time t0 from a
value I1 to a new value I2. Let us suppose that I1 = 0 so that the neuron is quiescent for
t < t0. If the current I2 is sufﬁciently large, it will evoke spikes for t > t0. Most neurons
will respond to the current step with a spike train where intervals between spikes increase

20
Introduction
(a)
(b)
(d)
(c)
I= 0
I
I
2
2
I= 0
I= 0
I2
I1
I=0
t
t0
0
Fig. 1.10 Response to a current step. In (a)-(c), the current is switched on at t = t0 to a value
I2 > 0. Fast-spiking neurons (a) have short interspike intervals without adaptation while regular-
spiking neurons (c) exhibit adaptation, visible as an increase in the duration of interspike intervals.
An example of a stuttering neuron is shown in (b). Many neurons emit an inhibitory rebound spike
(d) after an inhibitory current I1 < 0 is switched off. Data is courtesy of Henry Markram and Maria
Toledo-Rodriguez (Markram et al., 2004; Toledo-Rodriguez et al., 2004).
successively until a steady state of periodic ﬁring is reached; see Fig. 1.10c. Neurons that
show this type of adaptation are called regularly ﬁring neurons (Connors and Gutnick,
1990). Adaptation is a slow process that builds up over several spikes. Since the standard
leaky integrate-and-ﬁre model resets the voltage after each spike to the same value and
restarts the integration process, no memory is kept beyond the most recent spike. Therefore,
the leaky integrate-and-ﬁre neuron cannot capture adaptation. Detailed neuron models,
which will be discussed in Chapter 2, explicitly describe the slow processes that lead to
adaptation. To mimic these processes in integrate-and-ﬁre neurons, we need to add up
the contributions to refractoriness of several spikes back in the past. As we shall see in
Chapter 6, this can be done in the "ﬁlter" framework of Eq. (1.22) by using a ﬁlter η for
refractoriness with a time constant much slower than that of the membrane potential, or
by combining the differential equation of the leaky integrate-and-ﬁre model with a second
differential equation describing the evolution of a slow variable; see Chapter 6.
A second class of neurons are fast-spiking neurons. These neurons show no adaptation
(see Fig. 1.10a) and can therefore be well approximated by non-adapting integrate-and-ﬁre
models. Many inhibitory neurons are fast-spiking neurons. Apart from regular-spiking and
fast-spiking neurons, there are also bursting and stuttering neurons which form a separate
group (Connors and Gutnick, 1990). These neurons respond to constant stimulation by a
sequence of spikes that is periodically (bursting) or aperiodically (stuttering) interrupted by
rather long intervals; see Fig. 1.10b. Again, a neuron model that has no memory beyond the
most recent spike cannot describe bursting, but the framework in Eq. (1.22) with arbitrary
"ﬁlters" is general enough to account for bursting as well.
Another frequently observed behavior is post-inhibitory rebound. Consider a step current
with I1 < 0 and I2 = 0, i.e., an inhibitory input that is switched off at time t0; see Fig. 1.10d.

1.4 Limitations of the leaky integrate-and-ﬁre model
21
Many neurons respond to such a change with one or more "rebound spikes"; even the
release of inhibition can trigger action potentials. We will return to inhibitory rebound in
Chapter 3.
1.4.2 Shunting inhibition and reversal potential
In the previous section we focused on an isolated neuron stimulated by an applied current.
In reality, neurons are embedded into a large network and receive input from many other
neurons. Suppose a spike from a presynaptic neuron j is sent at time t f
j towards the synapse
of a postsynaptic neuron i. When we introduced in Fig. 1.5 the postsynaptic potential that
is generated after the arrival of the spike at the synapse, its shape and amplitude did not
depend on the state of the postsynaptic neuron i. This is of course a simpliﬁcation and
reality is somewhat more complicated. In Chapter 3 we will discuss detailed neuron models
that describe synaptic input as a change of the membrane conductance. Here we simply
summarize the major phenomena.
In Fig. 1.11 we have sketched schematically an experiment where the neuron is driven
by a constant current I0. We assume that I0 is too weak to evoke ﬁring so that, after some
relaxation time, the membrane potential settles at a constant value u0. At t = t f one of the
presynaptic neurons emits a spike so that shortly afterwards the action potential arrives at
the synapse and provides additional stimulation of the postsynaptic neuron. More precisely,
the spike generates a current pulse at the postsynaptic neuron (postsynaptic current, PSC)
with amplitude
PSC ∝[u0 −Esyn]
(1.33)
where u0 is the membrane potential and Esyn is the "reversal potential" of the synapse.
Since the amplitude of the current input depends on u0, the response of the postsynaptic
potential does so as well. Reversal potentials are systematically introduced in Chapter 2;
models of synaptic input are discussed in Section 3.1.
Example: Shunting inhibition
The dependence of the postsynaptic response upon the momentary state of the neuron
is most pronounced for inhibitory synapses. The reversal potential of inhibitory synapses
Esyn is below, but usually close to the resting potential. Input spikes thus have hardly any
effect on the membrane potential if the neuron is at rest; see Fig. 1.11a. However, if the
membrane is depolarized, the very same input spikes evoke a larger inhibitory postsy-
naptic potential. If the membrane is already hyperpolarized, the input spike can even
produce a depolarizing effect. There is an intermediate value u0 = Esyn - the reversal
potential - where the response to inhibitory input "reverses" from hyperpolarizing to
depolarizing.
Though inhibitory input usually has only a small impact on the membrane potential,
the local conductivity of the cell membrane can be signiﬁcantly increased. Inhibitory

22
Introduction
u
(a)
urest
t f
u
(b)
urest
t f
Fig. 1.11 The shape of postsynaptic potentials depends on the momentary level of depolarization.
(a) A presynaptic spike that arrives at time t f at an inhibitory synapse has hardly any effect on the
membrane potential when the neuron is at rest, but a large effect if the membrane potential u is
above the resting potential. If the membrane is hyperpolarized below the reversal potential of the
inhibitory synapse, the response to the presynaptic input changes sign. (b) A spike at an excitatory
synapse evokes a postsynaptic potential with an amplitude that depends only slightly on the momen-
tary voltage u. For large depolarizations the amplitude saturates and becomes smaller. (Schematic
ﬁgure.)
synapses are often located on the soma or on the shaft of the dendritic tree. Owing to
their strategic position, a few inhibitory input spikes can "shunt" the whole input that is
gathered by the dendritic tree from hundreds of excitatory synapses. This phenomenon
is called "shunting inhibition."
The reversal potential for excitatory synapses is usually signiﬁcantly above the rest-
ing potential. If the membrane is depolarized u0 ≫urest the amplitude of an excitatory
postsynaptic potential is reduced, but the effect is not as pronounced as for inhibition.
For very high levels of depolarization a saturation of the EPSPs can be observed; see
Fig. 1.11b.
1.4.3 Conductance changes after a spike
The shape of the postsynaptic potentials depends not only on the level of depolarization but,
more generally, on the internal state of the neuron, e.g., on the timing relative to previous
action potentials.
Suppose that an action potential has occurred at time t f
i and that a presynaptic spike
arrives at a time t f
j > t f
i at the synapse j. The form of the postsynaptic potential depends
now on the time t f
j −t f
i ; see Fig. 1.12. If the presynaptic spike arrives during or shortly
after a postsynaptic action potential, it has little effect because some of the ion channels
that were involved in ﬁring the action potential are still open. If the input spike arrives
much later, it generates a postsynaptic potential of the usual size. We will return to this
effect in Chapter 2.
1.4.4 Spatial structure
The form of postsynaptic potentials also depends on the location of the synapse on the
dendritic tree. Synapses that are located far away from the soma are expected to evoke a

1.5 What can we expect from integrate-and-ﬁre models?
23
t i
f
t j
f
t j
f
urest
Fig. 1.12 The shape of postsynaptic potentials (dashed lines) depends on the time t −t f
i that has
passed since the last output spike of neuron i. The postsynaptic spike has been triggered at time t f
i .
A presynaptic spike that arrives at time t f
j shortly after the spike of the postsynaptic neuron has a
smaller effect than a spike that arrives much later. Data is courtesy of Thomas Berger (Berger et al.,
2009).
smaller postsynaptic response at the soma than a synapse that is located directly on the
soma; see Chapter 3. If several inputs occur on the same dendritic branch within a few
milliseconds, the ﬁrst input will cause local changes of the membrane potential that inﬂu-
ence the amplitude of the response to the input spikes that arrive slightly later. This may
lead to saturation or, in the case of so-called "active" currents, to an enhancement of the
response. Such nonlinear interactions between different presynaptic spikes are neglected
in the leaky integrate-and-ﬁre model. Whereas a purely linear dendrite can be incorporated
in the "ﬁlter" description of the model, as we shall see in Chapter 6, nonlinear interactions
cannot. Small regions on the dendrite where a strong nonlinear boosting of synpatic cur-
rents occurs are sometimes called dendritic "hot spots." The boosting can lead to dendritic
spikes which, in contrast to normal somatic action potentials last for tens of milliseconds
(Larkum and Nevian, 2008).
1.5 What can we expect from integrate-and-ﬁre models?
The leaky integrate-and-ﬁre model is an extremely simpliﬁed neuron model. As we have
seen in the previous section, it neglects many features that neuroscientists have observed
when they study neurons in the living brain or in slices of brain tissue. Therefore the
question arises: what should we expect from such a model? Clearly we cannot expect it
to explain the complete biochemistry and biophysics of neurons. Nor do we expect it to
account for highly nonlinear interactions that are caused by active currents in some "hot
spots" on the dendritic tree. However, the integrate-and-ﬁre model is surprisingly accu-
rate when it comes to generating spikes, i.e., precisely timed events in time. Thus, it could
potentially be a valid model of spike generation in neurons, or more precisely, in the soma.
It is reasonable to require from a model of spike generation that it should be able to pre-
dict the moments in time when a real neuron spikes. Let us look at the following schematic

24
Introduction
Neuron
Mathematical
neuron model 
Prediction
Model
optimization 
I (t )
Fig. 1.13 The challenge of spike time prediction. A current I(t) is experimentally injected into the
soma of a real neuron in vitro through an electrode. The response of the neuron is recorded and half
of the response is made available for model optimization while part of the response remains hidden.
The challenge is then to use the input I(t) to predict the spike times of the hidden response with a
mathematical neuron model.
set-up (Fig. 1.13). An experimenter injects a time-dependent input current I(t) into the
soma of a cortical neuron using a ﬁrst electrode. With an independent second electrode he
or she measures the voltage at the soma of the neuron. Not surprisingly, the voltage trajec-
tory contains from time to time sharp electrical pulses. These are the action potentials or
spikes.
A befriended mathematical neuroscientist now takes the time course I(t) of the input
current that was used by the experimenter together with the time course of the membrane
potential of the neuron and adjusts the parameters of a leaky integrate-and-ﬁre model
so that the model generates, for the very same input current, spikes at roughly the same
moments in time as the real neuron. This needs some parameter tuning, but seems feasible.
The relevant and much more difﬁcult question, however, is whether the neuron model can
now be used to predict the ﬁring times of the real neuron for a novel time-dependent input
current that was not used during parameter optimization (Fig. 1.13).
As discussed above, neurons not only show refractoriness after each spike but also
exhibit adaptation which builds up over hundreds of milliseconds. A simple leaky integrate-
and-ﬁre model does not perform well at predicting the spike times of a real neuron. How-
ever, if adaptation (and refractoriness) is added to the neuron model, the prediction works
surprisingly well. A straightforward way to add adaptation is to make the ﬁring threshold
of the neuron model dynamic: after each spike the threshold ϑ is increased by an amount
θ, while during a quiescent period the threshold approaches its stationary value ϑ0. We can

1.6 Summary
25
Missed
Extra
40
20
0
-20
-40
-60
-80
0
100
200
300
t [ms]
u [mV]
400
500
Fig. 1.14 Comparing a generalized integrate-and-ﬁre model with experimental traces. A voltage
trace (thick black trace) recorded in a real neuron driven by a ﬂuctuating current is superposed on
the voltage trace generated by a generalized integrate and ﬁre model (thin line) driven by the same
current. The subthreshold voltage ﬂuctuations are accurately predicted (inset) and the spike timings
are well predicted on average, apart from a few additional or missed spikes (arrows).
use the Dirac δ-function to express this idea
τadapt
d
dt ϑ(t) = −[ϑ(t)−ϑ0]+θ ∑
f
δ(t −t f )
(1.34)
where τadapt is the time constant of adaptation (a few hundred milliseconds) and t f =
t(1),t(2),t(3),... are the ﬁring times of the neuron.
The predictions of an integrate-and-ﬁre model with adaptive threshold agree nicely with
the voltage trajectory of a real neuron, as can be seen from Fig. 1.14. The problem of how
to construct practical, yet powerful, generalizations of the simple leaky integrate-and-ﬁre
model is the main topic of Part II of the book. Another question arising from this is how to
quantify the performance of such neuron models (see Chapter 11).
Once we have identiﬁed good candidate neuron models, we will ask in Part III whether
we can construct big populations of neurons with these models, and whether we can use
them to understand the dynamic and computational principles as well as potential neural
codes used by populations of neurons. Indeed, as we shall see, it is possible to make the
transition from plausible single-neuron models to large and structured populations. This
does not mean that we understand the full brain, but understanding the principles of large
populations of neurons from well-tested simpliﬁed neuron models is a ﬁrst and important
step in this direction.
1.6 Summary
The neuronal signal consists of short voltage pulses called action potentials or spikes.
These pulses travel along the axon and are distributed to several postsynaptic neurons
where they evoke postsynaptic potentials. If a postsynaptic neuron receives a sufﬁcient

26
Introduction
number of spikes from several presynaptic neurons within a short time window, its mem-
brane potential may reach a critical value and an action potential is triggered. We say that
the neuron has "ﬁred" a spike. This spike is the neuronal output signal which is, in turn,
transmitted to other neurons.
A particularly simple model of a spiking neuron is the leaky integrate-and-ﬁre model.
First, a linear differential equation describes how input currents are integrated and trans-
formed into a membrane voltage u(t). Here the input can be the input current injected
by an experimenter into an isolated neuron or synaptic input currents caused by spikes
arriving from other neurons in a large and highly connected network. Second, the model
neuron generates an output spike if the membrane voltage reaches the threshold ϑ. Finally,
after spike ﬁring, the integration of the linear differential equation resumes from a reset
value ur.
The simple leaky integrate-and-ﬁre model does not account for long-lasting refractori-
ness or adaptation. However, if the voltage dynamics of the leaky integrate-and-ﬁre model
is enhanced by mechanisms of adaptation, then it can be a powerful tool to accurately
predict spike times of cortical neurons. Such generalized integrate-and-ﬁre models are the
main topic of Part II.
Literature
An elementary, non-technical introduction to neurons and synapses can be found in the
book by Thompson (1993). At an intermediate level is the introductory textbook of
Purves et al. (2008) while the Principles of Neural Science by Kandel et al. (2000) can
be considered as a standard textbook on neuroscience covering a wealth of experimental
results.
The use of mathematics to explain neuronal activity has a long tradition in theoretical
neuroscience, over one hundred years. Phenomenological spiking neuron models similar
to the leaky integrate-and-ﬁre model were proposed in 1907 by Lapicque, who wanted to
predict the ﬁrst spike after stimulus onset (so that his model did not yet have the reset of
the membrane potential after ﬁring), and have been developed further in different variants
by others (Lapicque, 1907; Hill, 1936; McCulloch and Pitts, 1943; Stein, 1965; Geisler
and Goldberg, 1966; Weiss, 1966; Stein, 1967b). For the "ﬁlter" description of integrate-
and-ﬁre models see, for example, Gerstner et al. (1996b) and Pillow et al. (2008). The
elegance and simplicity of integrate-and-ﬁre models makes them a widely used tool to
describe principles of neural information processing in neural networks of a broad range
of sizes.
A different line of mathematical neuron models are biophysical models, ﬁrst devel-
oped by Hodgkin and Huxley (1952); these biophysical models are the topic of the next
chapter.

1.6 Summary
27
Exercises
1. Synaptic current pulse. Synaptic inputs can be approximated by an exponential current I(t) =
q 1
τs exp[−t−t f
τs ] for t > t f where t f is the moment when the spike arrives at the synapse.
(a) Use Eq. (1.5) to calculate the response of a passive membrane with time constant τm to an
input spike arriving at time t f .
(b) In the solution resulting from (a), take the limit τs →τm and show that in this limit the
response is proportional to ∝[t −t f ] exp[−t−t f
τs ]. A function of this form is sometimes called an
α-function.
(c) In the solution resulting from (a), take the limit τs →0. Can you relate your result to the
discussion of the Dirac-δ function?
2. Time-dependent solution. Show that Eq. (1.15) is a solution of the differential equation Eq. (1.5)
for time-dependent input I(t). To do so, start by changing the variable in the integral from s to
t′ = t −s. Then take the derivative of Eq. (1.15) and compare the terms to those on both sides of
the differential equation.
3. Chain of linear equations. Suppose that arrival of a spike at time t f releases neurotransmit-
ter into the synaptic cleft. The amount of available neurotransmitter at time t is τx dx
dt = −x +
δ(t −t f ). The neurotransmitter binds to the postsynaptic membrane and opens channels that
enable a synaptic current τs dI
dt = −I +I0 x(t). Finally, the current charges the postsynaptic mem-
brane according to τm du
dt = −u + RI(t). Write the voltage response to a single current pulse as
an integral.

2
Ion channels and the Hodgkin-Huxley model
From a biophysical point of view, action potentials are the result of currents that pass
through ion channels in the cell membrane. In an extensive series of experiments on the
giant axon of the squid, Hodgkin and Huxley succeeded in measuring these currents and
described their dynamics in terms of differential equations. Their paper published in 1952,
which presents beautiful experiments combined with an elegant mathematical theory
(Hodgkin and Huxley, 1952), was rapidly recognized as groundbreaking work and eventu-
ally led to the Nobel Prize for Hodgkin and Huxley in 1963. In this chapter, the Hodgkin-
Huxley model is reviewed and its behavior illustrated by several examples.
The Hodgkin-Huxley model in its original form describes only three types of ion chan-
nel. However, as we shall see in Section 2.3 it can be extended to include many other ion
channel types. The Hodgkin-Huxley equations are the basis for detailed neuron models
which account for different types of synapse, and the spatial geometry of an individ-
ual neuron. Synaptic dynamics and the spatial structure of dendrites are the topics of
Chapter 3. The Hodgkin-Huxley model is also the starting point for the derivation of sim-
pliﬁed neuron models in Chapter 4 and will serve as a reference throughout the discussion
of generalized integrate-and-ﬁre models in Part II of the book.
Before we can turn to the Hodgkin-Huxley equations, we need to give some additional
information on the equilibrium potential of ion channels.
2.1 Equilibrium potential
Neurons, just as other cells, are enclosed by a membrane which separates the interior of
the cell from the extracellular space. Inside the cell the concentration of ions is different
from that in the surrounding liquid. The difference in concentration generates an electrical
potential which plays an important role in neuronal dynamics. In this section, we pro-
vide some background information and give an intuitive explanation of the equilibrium
potential.

2.1 Equilibrium potential
29
Δ u
n1 (inside)
n2 (outside)
E = qu
(a)
(b)
Fig. 2.1 (a) At thermal equilibrium, positive ions in an electric ﬁeld will be distributed so that fewer
ions are in a state of high energy and more at low energy. Thus a voltage difference generates a gradi-
ent in concentration. (b) Similarly, a difference in ion concentration generates an electrical potential.
The concentration n2 inside the neuron is different from the concentration n1 of the surround. The
resulting potential is called the Nernst potential. The solid line indicates the cell membrane. Ions can
pass through the gap.
2.1.1 Nernst potential
From the theory of thermodynamics, it is known that the probability of a molecule taking
a state of energy E is proportional to the Boltzmann factor, p(E) ∝exp(−E/kT), where
k is the Boltzmann constant and T the temperature. Let us consider positive ions with
charge q in a static electrical ﬁeld. Their energy at location x is E(x) = qu(x) where u(x)
is the potential at x. The probability of ﬁnding an ion in the region around x is therefore
proportional to exp[−qu(x)/kT]. Since the number of ions is huge, we may interpret the
probability as an ion density. For ions with positive charge q > 0, the ion density is therefore
higher in regions with low potential u. Let us write n(x) for the ion density at point x. The
relation between the density at point x1 and point x2 is
n(x1)
n(x2) = exp

−qu(x1)−qu(x2)
kT

.
(2.1)
A difference in the electrical potential Δu = u(x1)−u(x2) generates therefore a difference
in ion density; see Fig. 2.1.
Since this is a statement about an equilibrium state, the reverse must also be true. A
difference in ion density generates a difference Δu in the electrical potential. We consider
two regions of ions with concentration n1 and n2, respectively; see Fig. 2.1b. Solving (2.1)
for Δu we ﬁnd that, at equilibrium, the concentration difference generates a voltage
Δu = kT
q lnn2
n1
(2.2)
which is called the Nernst potential (Hille, 2001).

30
The Hodgkin-Huxley Model
2.1.2 Reversal potential
The cell membrane consists of a thin bilayer of lipids and is a nearly perfect electrical
insulator. Embedded in the cell membrane are, however, speciﬁc proteins which act as ion
gates. A ﬁrst type of gate is the ion pumps, a second one is ion channels. Ion pumps actively
transport ions from one side to the other. As a result, ion concentrations in the intracellular
liquid differ from those of the surround. For example, the sodium concentration inside a
mammalian neuron (≈10 mM) is lower than that in the extracellular liquid (≈145 mM).
On the other hand, the potassium concentration inside is higher (≈140 mM) than in the
surround (≈5 mM) (Purves et al., 2008). For the giant axon of the squid which was studied
by Hodgkin and Huxley the numbers are slightly different, but the basic idea is the same:
there is more sodium outside the cell than inside, while the reverse is true for potassium.
Let us focus for the moment on sodium ions. At equilibrium the difference in concen-
tration causes a Nernst potential ENa of about +67 mV. That is, at equilibrium the interior
of the cell has a positive potential with respect to the surround. The interior of the cell
and the surrounding liquid are in contact through ion channels where Na+ ions can pass
from one side of the membrane to the other. If the voltage difference Δu is smaller than the
value of the Nernst potential ENa, more Na+ ions ﬂow into the cell so as to decrease the
concentration difference. If the voltage is larger than the Nernst potential ions would ﬂow
out the cell. Thus the direction of the current is reversed when the voltage Δu passes ENa.
For this reason, ENa is called the reversal potential.
Example: Reversal potential for potassium
As mentioned above, the ion concentration of potassium is higher inside the cell
(≈140 mM) than in the extracellular liquid (≈5 mM). Potassium ions have a single
positive charge q = 1.6 × 10−19 C. Application of the Nernst formula, (2.2), with the
Boltzmann constant k = 1.4×10−23 J/K yields EK ≈−83 mV at room temperature. The
reversal potential for K+ ions is therefore negative.
Example: Resting potential
So far we have considered the presence of either sodium or potassium. In real cells,
these and other ion types are simultaneously present and contribute to the voltage across
the membrane. It is found experimentally that the resting potential of the membrane is
about urest ≈65 mV. Since EK < urest < ENa, potassium ions, at the resting potential,
ﬂow out of the cell while sodium ions ﬂow into the cell. In the stationary state, the
active ion pumps balance this ﬂow and transport just as many ions back as pass through

2.2 Hodgkin-Huxley model
31
+
-
+
+
-
-
+
-
K+
Na+
Outside
Inside
R
C
I
EL
RNa
ENa
EK
RK
u
Fig. 2.2 Schematic diagram for the Hodgkin-Huxley model.
the channels. The value of urest is determined by the dynamic equilibrium between the
ion ﬂow through the channels (permeability of the membrane) and active ion transport
(efﬁciency of the ion pump in maintaining the concentration difference).
2.2 Hodgkin-Huxley model
Hodgkin and Huxley (1952) performed experiments on the giant axon of the squid and
found three different types of ion current, namely, sodium, potassium, and a leak current
that consists mainly of Cl−ions. Speciﬁc voltage-dependent ion channels, one for sodium
and another one for potassium, control the ﬂow of those ions through the cell membrane.
The leak current takes care of other channel types which are not described explicitly.
2.2.1 Deﬁnition of the model
The Hodgkin-Huxley model can be understood with the help of Fig. 2.2. The semiperme-
able cell membrane separates the interior of the cell from the extracellular liquid and acts
as a capacitor. If an input current I(t) is injected into the cell, it may add further charge on
the capacitor, or leak through the channels in the cell membrane. Each channel type is rep-
resented in Fig. 2.2 by a resistor. The unspeciﬁc channel has a leak resistance R, the sodium
channel a resistance RNa and the potassium channel a resistance RK. The diagonal arrow
across the diagram of the resistor indicates that the value of the resistance is not ﬁxed, but
changes depending on whether the ion channel is open or closed. Because of active ion
transport through the cell membrane, the ion concentration inside the cell is different from
that in the extracellular liquid. The Nernst potential generated by the difference in ion con-
centration is represented by a battery in Fig. 2.2. Since the Nernst potential is different for
each ion type, there are separate batteries for sodium, potassium, and the unspeciﬁc third
channel, with battery voltages ENa,EK and EL, respectively.
Let us now translate the above schema of an electrical circuit into mathematical equa-
tions. The conservation of electric charge on a piece of membrane implies that the applied
current I(t) may be split into a capacitive current IC which charges the capacitor C and

32
The Hodgkin-Huxley Model
(a)
(b)
Fig. 2.3 The Hodgkin-Huxley model. (a) The equilibrium functions for the three variables m,n,h
in the Hodgkin-Huxley model. (b) The voltage-dependent time constant. The resting potential is
at u = −65mV (arrow) and parameters are those given in Table 2.1.
further components Ik which pass through the ion channels. Thus
I(t) = IC(t)+∑
k
Ik(t),
(2.3)
where the sum runs over all ion channels. In the standard Hodgkin-Huxley model there
are only three types of channel: a sodium channel with index Na, a potassium channel
with index K and an unspeciﬁc leakage channel with resistance R; see Fig. 2.2. From the
deﬁnition of a capacity C = q/u where q is a charge and u the voltage across the capacitor,
we ﬁnd the charging current IC = Cdu/dt. Hence from (2.3)
Cdu
dt = −∑
k
Ik(t)+I(t).
(2.4)
In biological terms, u is the voltage across the membrane and ∑k Ik is the sum of the ionic
currents which pass through the cell membrane.
As mentioned above, the Hodgkin-Huxley model describes three types of channel. All
channels may be characterized by their resistance or, equivalently, by their conductance.
The leakage channel is described by a voltage-independent conductance gL = 1/R. Since u
is the total voltage across the cell membrane and EL the voltage of the battery, the voltage
at the leak resistor in Fig. 2.2 is u −EL. Using Ohm's law, we get a leak current IL =
gL (u−EL).
The mathematics of the other ion channels is analogous except that their conductance is
voltage- and time-dependent. If all channels are open, they transmit currents with a max-
imum conductance gNa or gK, respectively. Normally, however, some of the channels are
blocked. The breakthrough of Hodgkin and Huxley was that they succeeded in measur-
ing how the effective resistance of a channel changes as a function of time and voltage.
Moreover, they proposed a mathematical description of their observations. Speciﬁcally,
they introduced additional "gating" variables m,n and h to model the probability that a

2.2 Hodgkin-Huxley model
33
x
Ex [mV]
gx [mS/cm2]
Na
55
40
K
−77
35
L
−65
0.3
x
αx(u/mV)[ms−1]
βx(u/mV)[ms−1]
n
0.02(u−25)/[1−e−(u−25)/9]
−0.002(u−25)/[1−e(u−25)/9]
m
0.182(u+35)/[1−e−(u+35)/9]
−0.124(u+35)/[1−e(u+35)/9]
h
1/[1+e−(u+62)/6]
4e(u+90)/12 /[1+e−(u+62)/6]
Table 2.1 Parameters for the Hodgkin-Huxley equations ﬁtted on pyramidal neurons of
the cortex. The parameters for n and m were ﬁtted by Zach Mainen (Mainen et al., 1995)
on experiments reported by Huguenard et al. (1988) and the parameters for h by Richard
Naud on the experiments reported in Hamill et al. (1991). Voltage is measured in mV and
the membrane capacity is C = 1μF/cm2.
channel is open at a given moment in time. The combined action of m and h controls the
Na+ channels while the K+ gates are controlled by n. For example, the effective conduc-
tance of sodium channels is modeled as 1/RNa = gNa m3 h, where m describes the activation
(opening) of the channel and h its inactivation (blocking). The conductance of potassium
is 1/RK = gK n4, where n describes the activation of the channel.
In summary, Hodgkin and Huxley formulated the three ion currents on the right-hand-
side of (2.4) as
∑
k
Ik = gNa m3h(u−ENa)+gK n4 (u−EK)+gL (u−EL).
(2.5)
The parameters ENa, EK, and EL are the reversal potentials.
The three gating variables m, n, and h evolve according to differential equations of the
form
˙x = −
1
τx(u)[x−x0(u)],
(2.6)
with ˙x = dx/dt, and where x stands for m, n, or h. The interpretation of (2.6) is simple: for a
ﬁxed voltage u, the variable x approaches the target value x0(u) with a time constant τx(u).
The voltage dependence of the time constant and asymptotic value is illustrated in Fig. 2.3.
The form of the functions plotted in Fig. 2.3, as well as the maximum conductances
and reversal potentials in (2.5), were deduced by Hodgkin and Huxley from empirical
measurements.
Example: Voltage step
Experimenters can hold the voltage across the cell membrane at a desired value by
injecting an appropriate current into the cell. Suppose that the experimenter keeps the

34
The Hodgkin-Huxley Model
t [ms]
0
5
10
gKn4(t)
Fig.
2.4 Original
data
and
ﬁt
of
Hodgkin
and
Huxley
(1952).
The
measured time course of the potassium
conductance (circles) after application
of a voltage step of 25 mV and after
return to resting potential. The ﬁt (solid
line) is based on Eq. (2.8). Adapted
from Hodgkin and Huxley (1952).
cell at resting potential u0 = −65 mV for t < t0 and switches the voltage at t0 to a new
value u1. Integration of the differential equation (2.6) gives, for t > t0, the dynamics
m(t) = m0(u1)+[m0(u0)−m0(u1)]exp
−(t −t0)
τm(u1)

,
h(t) = h0(u1)+[h0(u0)−h0(u1)]exp
−(t −t0)
τh(u1)

,
(2.7)
so that, based on the model with given functions for m0(u), h0(u), τm(u), τh(u), we can
predict the sodium current INa(t) = gNa [m(t)3]h(t)(u1 −ENa) for t > t0 generated by the
voltage step at t = t0.
Similarly, the potassium current caused by a voltage step is IK(t) = gK [n(t)4](u1 −
EK) with
n(t) = n0(u1)+[n0(u0)−n0(u1)]exp
−(t −t0)
τn(u1)

.
(2.8)
Hodgkin and Huxley used Eqs. (2.7) and (2.8) to work the other way round. After
blocking the sodium channel with appropriate pharmacological agents, they applied
a voltage step and measured the time course of the potassium current. Dividing the
recorded current through the driving potential (u1 −EK) yields the time-dependent con-
ductance gK [n(t)4]; see Fig. 2.4. Using (2.8), Hodgkin and Huxley deduced the value
of n0(u1) and τn(u1) as well as the exponent of 4 in n4(t) for potassium. Repeating the
experiments for different values u1 gives the experimental curves for n0(u) and τn(u).
Example: Activation and de-inactivation
The variable m is called an activation variable. To understand this terminology, we
note from Fig. 2.3 that the value of m0(u) at the neuronal resting potential of u =
−65 mV is close to zero. Therefore, at rest, the sodium current INa = gNa m3h(u−ENa)
through the channel vanishes. In other words, the sodium channel is closed.
When the membrane potential increases signiﬁcantly above the resting potential, the
gating variable m increases to its new value m0(u). As long as h does not change, the

2.2 Hodgkin-Huxley model
35
-40
-140
3 pA
10 ms
Fig. 2.5 Stochastic channel activation. The current
ﬂowing through a small patch of membrane after
application of a voltage step (top row) shows step-
like changes and is different in each trial (subsequent
traces). Averaging over many trials yields the bottom
trace. Adapted from Patlak and Ortiz (1985) . ©1985
Rockefeller University Press. Originally published in
Journal of General Physiology, 86: 89-104.
sodium current increases and the gate opens. Therefore the variable m "activates" the
channel. If, after a return of the voltage to rest, m decays back to zero, it is said to be
"de-activating."
The terminology of the "inactivation" variable h is analogous. At rest, h has a large
positive value. If the voltage increases to a value above −40 mV, h approaches a new
value h0(u) which is close to rest. Therefore the channel "inactivates" (blocks) with a
time constant that is given by τh(u). If the voltage returns to zero, h increases so that the
channel undergoes "de-inactivation." This sounds like tricky vocabulary, but it turns out
to be useful to distinguish between a deactivated channel (m close to zero and h close to
1) and an inactivated channel (h close to zero).
2.2.2 Stochastic channel opening
The number of ion channels in a patch of membrane is ﬁnite, and individual ion channels
open and close stochastically. Thus, when an experimenter records the current ﬂowing
through a small patch of membrane, he does not ﬁnd a smooth and reliable evolution of the
measured variable over time but rather a highly ﬂuctuating current, which looks different
at each repetition of the experiment (Fig. 2.5).
The Hodgkin-Huxley equations, which describe the opening and closing of ion channels
with deterministic equations for the variables m, h, and n, correspond to the current density
through a hypothetical, extremely large patch of membrane containing an inﬁnite number
of channels or, alternatively, to the current through a small patch of membrane but averaged
over many repetitions of the same experiment (Fig. 2.5). The stochastic aspects can be
included by adding appropriate noise to the model.

36
The Hodgkin-Huxley Model
Example: Time constants, transition rates, and channel kinetics
As an alternative to the formulation of channel gating in Eq. (2.6), the activation and
inactivation dynamics of each channel type can also be described in terms of voltage-
dependent transition rates α and β,
˙m = αm(u)(1−m)−βm(u)m,
˙n = αn(u)(1−n)−βn(u)n,
(2.9)
˙h = αh(u)(1−h)−βh(u)h.
The two formulations Eqs. (2.6) and (2.9) are equivalent. The asymptotic value x0(u) and
the time constant τx(u) are given by the transformation x0(u) = αx(u)/[αx(u) + βx(u)]
and τx(u) = [αx(u) + βx(u)]−1. The various functions α and β, given in Table 2.1, are
empirical functions of u that produce the curves in Fig. 2.3.
Equations (2.9) are typical equations used in chemistry to describe the stochastic
dynamics of an activation process with rate constants α and β. We may interpret this pro-
cess as a molecular switch between two states with voltage-dependent transition rates.
For example, the activation variable n can be interpreted as the probability of ﬁnding
a single potassium channel open. Therefore in a patch with K channels, k ≈(1 −n)K
channels are expected to be closed. We may interpret αn(u)Δt as the probability that in a
short time interval Δt one of the momentarily closed channels switches to the open state.
2.2.3 Dynamics
In this section we study the dynamics of the Hodgkin-Huxley model for different types of
input. Pulse input, constant input, step current input, and time-dependent input are consid-
ered in turn. These input scenarios have been chosen so as to provide an intuitive under-
standing of the dynamics of the Hodgkin-Huxley model.
The most important property of the Hodgkin-Huxley model is its ability to generate
action potentials. In Fig. 2.6a an action potential has been initiated by a short current pulse
of 1 ms duration applied at t = 1 ms. The spike has an amplitude of nearly 100 mV and
a width at half maximum of about 2.5 ms. After the spike, the membrane potential falls
below the resting potential and returns only slowly back to its resting value of −65 mV.
Ion channel dynamics during spike generation
In order to understand the biophysics underlying the generation of an action potential we
return to Fig. 2.3a. We ﬁnd that m0 and n0 increase with u whereas h0 decreases. Thus,
if some external input causes the membrane voltage to rise, the conductance of sodium
channels increases due to increasing m. As a result, positive sodium ions ﬂow into the cell
and raise the membrane potential even further. If this positive feedback is large enough,
an action potential is initiated. The explosive increase comes to a natural halt when the
membrane potential approaches the reversal potential ENa of the sodium current.

2.2 Hodgkin-Huxley model
37
(a)
(b)
(c)
Fig. 2.6 (a) Action potential. The Hodgkin-Huxley model is stimulated by a short, but strong, cur-
rent pulse between t = 1 ms and t = 2 ms. The time course of the membrane potential u(t) for t > 2 ms
shows the action potential (positive peak) followed by a relative refractory period where the potential
is below the resting potential urest (dashed line). The right panel shows an expanded view of the
action potential between t = 2 ms and t = 5 ms. (b) The dynamics of gating variables m, h, n illustrate
how the action potential is mediated by sodium and potassium channels. (c) The sodium current INa
which depends on the variables m and h has a sharp peak during the upswing of an action potential.
The potassium current IK is controlled by the variable n and starts with a delay compared with INa.
At high values of u the sodium conductance is slowly shut off due to the factor h. As
indicated in Fig. 2.3b, the "time constant" τh is always larger than τm. Thus the variable h
which inactivates the channels reacts more slowly to the voltage increase than the variable
m which opens the channel. On a similar slow time scale, the potassium (K+) current
sets in Fig. 2.6c. Since it is a current in outward direction, it lowers the potential. The
overall effect of the sodium and potassium currents is a short action potential followed by

38
The Hodgkin-Huxley Model
(a)
0
-60
-40
-20
0
20
40
60
80 100
t [ms]
u [mV]
120 140
0
2
4
6
8
10
I0 [µA/cm2]
0
50
100
150
200
Firing frequency [Hz]
(b)
50
0
-50
0
20
40
60
80
100
t [ms]
u [mV]
(c)
100
50
 Firing frequency [Hz]
0
5
10
0
15
20
I0 [mA/cm2]
(d)
Fig. 2.7 (a) Spike train of the Hodgkin-Huxley model (with the parameters used in this book) for
constant input current I0. (b) Gain function. The mean ﬁring rate ν is plotted as a function of I0. The
gain function of the Hodgkin-Huxley model is of type II, because it exhibits a jump. (c) Same as (a),
but for the original parameters found by Hodgkin and Huxley to describe the ion currents in the giant
axon of the squid. (d) Gain function for the model in (c).
a negative overshoot; see Fig. 2.6a. The negative overshoot, called hyperpolarizing spike-
afterpotential, is due to the slow de-inactivation of the sodium channel, caused by the
h-variable.
Example: Mean ﬁring rates and gain function
The Hodgkin-Huxley equations (2.4)-(2.9) may also be studied for constant input
I(t) = I0 for t > 0. (The input is zero for t ≤0.) If the value I0 is larger than a critical
value Iθ ≈2.7μA/cm2, we observe regular spiking; see Fig. 2.7a. We may deﬁne a ﬁring
rate ν = 1/T where T is the interspike interval.
The ﬁring rate as a function of the constant input I0, often called the "frequency-
current" relation or "f-I plot," deﬁnes the gain function plotted in Fig. 2.7b. With the
parameters given in Table 2.1, the gain function exhibits a jump at Iθ. Gain functions
with a discontinuity are called "type II."

2.2 Hodgkin-Huxley model
39
(a)
(b)
Fig. 2.8
(a) Spike train of the Hodgkin-Huxley model driven by a time-dependent input cur-
rent. The action potentials occur irregularly. The ﬁgure shows the voltage u as a function of time.
(b) Threshold effect. A short current pulse of 1 ms is applied which leads to a excursion of the mem-
brane potential of a few millivolts (dashed line). A slight increase of the strength of the current pulse
leads to the generation of an action potential (solid line) with an amplitude of about 100 mV above
rest (out of bounds).
If we shift the curve of the inactivation variable h to more positive voltages, and
keep the same parameters otherwise, the modiﬁed Hodgkin-Huxley model exhibits a
smooth gain function; see Section 2.3.2 and Fig. 2.11. Neuron models or, more gener-
ally, "excitable membranes" are called "type I" or "class I" if they have a continuous
frequency-current relation. The distinction between the excitability of type I and II can
be traced back to Hodgkin (1948).
Example: Stimulation by time-dependent input
In order to explore a more realistic input scenario, we stimulate the Hodgkin-Huxley
model by a time-dependent input current I(t) that is generated by the following pro-
cedure. Every 2 ms, a random number is drawn from a Gaussian distribution with zero
mean and standard deviation σ = 34 μA/cm2. To get a continuous input current, a linear
interpolation was used between the target values. The resulting time-dependent input
current was then applied to the Hodgkin-Huxley model (2.4)-(2.6). The response to
the current is the voltage trace shown in Fig. 2.8a. Note that action potentials occur at
irregular intervals.
Example: Firing threshold
In Fig. 2.8b an action potential (solid line) has been initiated by a short current pulse
of 1 ms duration. If the amplitude of the stimulating current pulse is reduced below some

40
The Hodgkin-Huxley Model
critical value, the membrane potential (dashed line) returns to the rest value without a
large spike-like excursion; see Fig. 2.8b. Thus we have a threshold-type behavior.
If we increased the amplitude of the current by a factor of 2, but reduced the duration
of the current pulse to 0.5 ms, so that the current pulse delivers exactly the same electric
charge as before, the response curves in Fig. 2.8b would look exactly the same. Thus, the
threshold of spike initiation can not be deﬁned via the amplitude of the current pulse.
Rather, it is the charge delivered by the pulse or, equivalently, the membrane voltage
immediately after the pulse, which determines whether an action potential is triggered or
not. However, while the notion of a voltage threshold for ﬁring is useful for a qualitative
understanding of spike initiation in response to current pulses, it is in itself not sufﬁcient
to capture the dynamics of the Hodgkin-Huxley model; see the discussion in this and
the next two chapters.
Example: Refractoriness
In order to study neuronal refractoriness, we stimulate the Hodgkin-Huxley model by
a ﬁrst current pulse that is sufﬁciently strong to excite a spike. A second current pulse
of the same amplitude as the ﬁrst one is used to probe the responsiveness of the neuron
during the phase of hyperpolarization that follows the action potential. If the second
stimulus is not sufﬁcient to trigger another action potential, we have a clear signature
of neuronal refractoriness. In the simulation shown in Fig. 2.9, a second spike is not
emitted if the second stimulus is given less than 40 ms after the ﬁrst one. It would, of
course, be possible to trigger a second spike after a shorter interval, if a signiﬁcantly
stronger stimulation pulse was used; for classical experiments along those lines (see,
e.g., Fuortes and Mantegazzini 1962).
If we look more closely at the voltage trajectory of Fig. 2.9, we see that neuronal
refractoriness manifests itself in two different forms. First, owing to the hyperpolarizing
spike-afterpotential, the voltage is lower. More stimulation is therefore needed to reach
the ﬁring threshold. Second, since a large portion of channels are open immediately
after a spike, the resistance of the membrane is reduced compared with the situation
at rest. The depolarizing effect of a stimulating current pulse therefore decays faster
immediately after the spike than 10 ms later. An efﬁcient description of refractoriness
plays a major role in simpliﬁed neuron models discussed in Chapter 6.
Example: Damped oscillations and transient spiking
When stimulated with a small step-increase in current, the Hodgkin-Huxley model
with parameters as in Table 2.1 exhibits a damped oscillation with a maximum of about

2.2 Hodgkin-Huxley model
41
Fig. 2.9 Refractoriness of the Hodgkin-Huxley model. At t = 20 ms the model is stimulated by a
short current pulse (left arrow) so as to trigger an action potential. A second current pulse of the
same amplitude applied at t = 35,45, or 55 ms (subsequent arrows) is not sufﬁcient to trigger a
second action potential.
20 ms after the onset of the current step; see Fig. 2.10. If the step size is large enough,
but not sufﬁcient to cause sustained ﬁring, a single spike can be generated. Note that in
Fig. 2.10 the input current returns at 200 ms to the same value it had a hundred millisec-
onds before. While the neuron stays quiescent after the ﬁrst step, it ﬁres a transient spike
the second time not because the total input is stronger but because the step starts from a
strong negative value.
A spike which is elicited by a step current that starts from a strong negative value and
then switches back to zero would be called a rebound spike. In other words, a rebound
spike is triggered by release from inhibition. For example, the Hodgkin-Huxley model
with the original parameters for the giant axon of the squid exhibits rebound spikes
when a prolonged negative input current is stopped; the model with the set of parameters
adopted in this book, however, does not.
The transient spike in Fig. 2.10 occurs about 20 ms after the start of the step. A simple
explanation of the transient spike is that the peak of the membrane potential oscillation
after the step reaches the voltage threshold for spike initiation, so that a single action
potential is triggered. It is indeed the subthreshold oscillations that underly the transient
spiking illustrated in Fig. 2.10.
Damped oscillations result from subthreshold inactivation of the sodium current. At
rest the sodium currents are not activated (m ≈0) but only partially inactivated (h ≈0.6).
Responding to the step stimulus, the membrane potential increases, which activates
slightly and de-inactivates slowly the sodium channel. When the input is not strong
enough for an action potential to be initiated, the de-inactivation of INa reduces the effec-
tive drive and thus the membrane potential. The system then relaxes to an equilibrium.
If, on the other hand, the current was strong enough to elicit a spike, the equilibrium may
be reached only after the spike. A further increase in the step current drives sustained
ﬁring (Fig. 2.10).

42
The Hodgkin-Huxley Model
Fig.
2.10 Damped
oscilla-
tions and a transient spike.
Top. The voltage response to
a step current shows a damped
oscillation
(arrow),
a
sin-
gle rebound spike (asterisk)
or repetitive ﬁring. Bottom.
Time course of the stimulat-
ing current.
2.3 The zoo of ion channels
Hodgkin and Huxley used their equations to describe the electrophysiological properties
of the giant axon of the squid. These equations capture the essence of spike generation
by sodium and potassium ion channels. The basic mechanism of generating action poten-
tials is a short inﬂux of sodium ions that is followed by an efﬂux of potassium ions. This
mechanism of spike generation is essentially preserved in higher organisms, so that, with
the choice of parameters given in Table 2.1, we already have a ﬁrst approximate model of
neurons in vertebrates. With a further change of parameters we could adapt the model
equations to different temperatures to account for the fact that neurons at 37 degrees
Celsius behave differently than neurons in a lab preparation held at a room temperature
of 21 degrees Celsius.
However, in order to account for the rich biophysics observed in the neurons of the verte-
brate nervous system, two types of ion channel are not enough. Neurons come in different
types and exhibit different electrical properties which in turn correspond to a large variety
of ion channels. Today, about 200 ion channels are known and many of these have been
identiﬁed genetically (Ranjan et al., 2011). In experimental laboratories where the bio-
physics and functional role of ion channels are investigated, speciﬁc ion channel types can
be blocked through pharmacological manipulations. In order to make predictions of block-
ing results, it is important to develop models that incorporate multiple ion channels. As
we shall see below (Section 2.3.1), the mathematical framework of the Hodgkin-Huxley
model is well suited for such an endeavor.
For other scientiﬁc questions, we may be interested only in the ﬁring pattern of neurons
and not in the biophysical mechanisms that give rise to it. Later, in Part II of this book,

2.3 The zoo of ion channels
43
we will show that generalized integrate-and-ﬁre models can account for a large variety of
neuronal ﬁring patterns (Chapter 6) and predict spike timings of real neurons with high
precision (Chapter 11). Therefore, in Parts III and IV of the book, where we focus on large
networks of neurons, we mainly work with generalized integrate-and-ﬁre rather than bio-
physical models. Nevertheless, biophysical models, i.e., Hodgkin-Huxley equations with
multiple ion channels, serve as an important reference.
2.3.1 Framework for biophysical neuron models
The formalism of the Hodgkin-Huxley equation is extremely powerful, because it enables
researchers to incorporate known ion channel types into a given neuron model. Just as
before, the electrical properties of a patch of neuronal membrane are described by the
conservation of current
Cdu
dt = −∑
k
Ik(t)+I(t),
(2.10)
but in contrast to the simple Hodgkin-Huxley model discussed in the previous section, the
right-hand side now contains all types of ion current found in a given neuron. For each ion
channel type k, we introduce activation and inactivation variables
Ik(t) = gk([Ca++],...)mpk hqk (u−Ek),
(2.11)
where m and h describe activation and inactivation of the channel with equations analogous
to (2.6), pk and qk are empirical parameters, Ek is the reversal potential, and gk is the max-
imum conductance which may depend on secondary variables such as the concentration of
calcium, magnesium, dopamine or other substances. In principle, if the dynamics of each
channel type (i.e., all parameters that go into Eqs. (2.11) and (2.6)) are available, then one
needs only to know which channels are present in a given neuron in order to build a bio-
physical neuron model. Studying the composition of messenger RNA in a drop of liquid
extracted from a neuron gives a strong indication of which ion channels are present in a
neuron, and which are not (Toledo-Rodriguez et al., 2004). The relative importance of ion
channels is not ﬁxed, but depends on the age of neuron as well as other factors. Indeed,
a neuron can tune its spiking dynamics by regulating its ion channel composition via a
modiﬁcation of the gene expression proﬁle.
Ion channels are complex transmembrane proteins which exist in many different forms.
It is possible to classify an ion channel using (i) its genetic sequence; (ii) the ion type
(sodium, potassium, calcium, ...) that can pass through the open channel; (iii) its voltage
dependence; (iv) its sensitivity to second-messengers such as intracellular calcium; (v) its
presumed functional role; (vi) its response to pharmacological drugs or to neuromodulators
such as acetylcholine and dopamine.
Using a notation that mixes the classiﬁcation schemes (i)-(iii), geneticists have dis-
tinguished multiple families of voltage-gated ion channels on the basis of similarities in

44
The Hodgkin-Huxley Model
the amino acid sequences. The channels are labeled with the chemical symbol of the ion
of their selectivity, one or two letters denoting a distinct characteristic and a number to
determine the subfamily. For instance "Kv5" is the ﬁfth subfamily of the voltage-sensitive
potassium channel family "Kv". An additional number may be inserted to indicate the
channel isoforms, for instance "Nav1.1" is the ﬁrst isoform that was found within the ﬁrst
subfamily of voltage-dependent sodium channels. Sometimes a lower-case letter is used
to point to the splice variants (e.g., "Nav1.1a"). Strictly speaking, these names apply to a
single cloned gene which corresponds to a channel subunit, whereas the full ion channel
is composed of several subunits usually from a given family but possibly from different
subfamilies.
Traditionally, electrophysiologists have identiﬁed channels with subscripts that reﬂect a
combination of the classiﬁcation schemes (ii)-(vi). The index of the potassium "M-current"
IM points to its response to pharmacological stimulation of Muscarinic (M) acetylcholine
receptors. Another potassium current, IAHP, shapes the after-hyperpolarization (AHP) of
the membrane potential after a spike. Thus the subscript corresponds to the presumed func-
tional role of the channel. Sometimes the functionally characterized current can be related
to the genetic classiﬁcation; for instance IAHP is a calcium-dependent potassium channel
associated with the small-conductance "SK" family, but in other cases the link between an
electrophysiologically characterized channel and its composition in terms of genetically
identiﬁed subunits is still uncertain. Linking genetic expression with a functionally char-
acterized ion current is a fast-expanding ﬁeld of study (Ranjan et al., 2011).
In this section we select a few examples from the zoo of ion channels and illustrate how
ion channels can modify the spiking dynamics. The aim is not to quantitatively specify
parameters of each ionic current as this depends heavily on the genetic expression of the
subunits, cell type, temperature and neurotransmitters. Rather, we would like to explore
qualitatively the inﬂuence of ion channel kinetics on neuronal properties. In other words,
let us bring the zoo of ion channels to the circus and explore the stunning acts that can be
achieved.
2.3.2 Sodium ion channels and the type-I regime
The parameters of the Hodgkin-Huxley model in Table 2.1 relate to only one type of
sodium and potassium ion channel. There are more than 10 different types of sodium chan-
nels, each with a slightly different activation and inactivation proﬁle. However, as we shall
see, even a small change in the ion channel kinetics can profoundly affect the spiking
characteristics of a neuron.
Let us consider a sodium ion channel which has its inactivation curve h0(u) (Fig. 2.3a)
shifted to depolarized voltages by 20 mV compared with the parameters in Table 2.1. With
maximal conductances gNa = 25 nS/cm2 and gK = 40 nS/cm2, the dynamics of a neuron
with this modiﬁed sodium channel (Fig. 2.11) is qualitatively different from that of a neu-
ron with the parameters as in Table 2.1 (Figs. 2.7 and 2.10).

2.3 The zoo of ion channels
45
(a)
(b)
Fig. 2.11 A modiﬁcation of sodium channel kinetics leads to different neuronal dynamics.
(a) Response of a model with modiﬁed sodium channel to current steps of different amplitudes.
(b) Delayed spike initiation. A short current pulse of 2 ms duration is applied at t = 8 ms. The action
potential that is elicited in response to the current pulse is shown for decreasing pulse amplitudes
(I = 6.25,5.90,5.88μA/cm2). Note that the action potential can occur more than 10 ms after the end
of the current pulse.
(a)
(b)
Fig. 2.12 Type-I regime with a modiﬁed sodium current. (a) Regular spiking response to constant
input. (b) Firing frequency as a function of the constant current.
First, the neuron with the modiﬁed sodium dynamics shows no damped oscillations in
response to a step input (Fig. 2.11a). Second, the neuron responds to a short current pulse
which is just slightly above the ﬁring threshold with a delayed action potential (Fig. 2.11b).
Third, during regular spiking the shape of the action potential is slightly different in the
model with the modiﬁed sodium channel (Fig. 2.12a). In particular, the membrane poten-
tial between the spikes exhibits an inﬂection point, unlike the spike train with the origi-
nal set of parameters (Fig. 2.7a). Finally, the gain function (frequency-current plot) has
no gap so that the neuron model can ﬁre at arbitrarily small frequencies (Fig. 2.12b). If
we compare this f-I plot with the gain function of the neuron with parameters from Table

46
The Hodgkin-Huxley Model
2.1, we can distinguish two types of excitability: type I has a continuous input-output
function (Fig. 2.12b), while type II has a discontinuity (Fig. 2.7b).
2.3.3 Adaptation and refractoriness
We have seen in Section 2.2 that the combination of sodium and potassium channels gen-
erates spikes followed by a relative refractory period. The refractoriness is caused by the
slow return of the sodium inactivation variable h and the potassium activation variable n to
their equilibrium values. The time scale of recovery in the Hodgkin-Huxley model, with
parameters as in Table 2.1, is 4 ms for the potassium channel activation and 20 ms for the
sodium channel inactivation. Other ion channel types, not present in the original Hodgkin-
Huxley model, can affect the recovery process on much longer time scales and lead to
spike-frequency adaptation: after stimulation with a step current, interspike intervals get
successively longer. The basic mechanism of adaptation is the same as that of refractori-
ness: either a hyperpolarizing current is activated during a spike (and slowly de-activates
thereafter) or a depolarizing current is inactivated during a spike and de-inactivates on a
much slower time scale.
Example: Slow inactivation of a hyperpolarizing current
Let us start with the muscarinic potassium channel IM, often called M-current. Genet-
ically, the channel is composed of subunits of the Kv7 family. Figure 2.13a,b show the
activation function as well as the voltage dependence of the time constant as charac-
terized by Yamada et al. (1989). The activation function (Fig. 2.13a) tells us that this
channel tends to be activated at voltages above 40 mV and is de-activated below 40 mV
with a very sharp transition between the two regimes. Since 40 mV is well above the
threshold of spike initiation, the membrane potential is never found above 40 mV except
during the 1-2 ms of a spike. Therefore the channel partially activates during a spike
and, after the end of the action potential, de-activates with a time constant of 40-60 ms
(Fig. 2.13b). The slow deactivation of this potassium channel affects the time course
of the membrane potential after a spike. Compared with the original Hodgkin-Huxley
model, which has only the two currents speciﬁed in Table 2.1, a model with an addi-
tional IM current exhibits a prolonged hyperpolarizing spike-afterpotential and therefore
a longer relative refractory period (Fig. 2.13c-e).
In the regular ﬁring regime, it is possible that the M-current caused by a previous
spike is still partially activated when the next spike is emitted. The partial activation
can therefore accumulate over successive spikes. By cumulating over spikes, the acti-
vation of IM gradually forces the membrane potential away from the threshold, increas-
ing the interspike interval. This results in a spiking response that appears to "adapt"
to a step input, hence the name "spike-frequency adaptation" or simply "adaptation"
(Fig. 2.13c-e).

2.3 The zoo of ion channels
47
(a)
(b)
(c)
(d)
(e)
Fig. 2.13 Spike-frequency adaptation with IM. (a) Voltage dependence of the stationary value
of the activation variable m and (b) its time constants for the muscarinic potassium current
IM = gM m(u−Ek) extracted from experimental observations (Yamada et al., 1989). (c) Voltage
response to the current shown in (d) of the original Hodgkin-Huxley model with parameters from
Table 2.1 (dashed line) and a model which also contains the IM channel. The model with IM exhibits
adaptation. (e) Progressive activation of the potassium current IM during the repetitive spiking period
shown in (c).

48
The Hodgkin-Huxley Model
Example: A-current
Another potassium ion channel with kinetics similar to IM is IA, but qualitatively dif-
ferent effects: IA makes the relative refractory period longer and stronger without causing
much adaptation. To see the distinction between IA and IM, we compare the activation
kinetics of both channels (Figs. 2.13b and 2.14b). The time constant τm of activation is
much faster for IA than for IM. This implies that the A-current increases rapidly during
the short time of the spike and decays quickly afterward. In other words, the effect of
IA is short and strong whereas the effect of IM is long and small. Because the effect of
IA does not last as long, it contributes to refractoriness, but only very little to spike fre-
quency adaptation (Fig. 2.14c-e). Even though an inactivation process, with variable h,
was reported for IA, its time constant τh is so long (>150 ms) that it does not play a role
in the above arguments.
Example: Slow extrusion of calcium
Multiple ion channel families contribute to spike-frequency adaptation. In contrast to
the direct action of IM, the calcium-dependent potassium channel IK[Ca] generates adapta-
tion indirectly via its dependence on the intracellular calcium concentration. During each
spike, calcium enters through the high-threshold calcium channel IHVA. As calcium accu-
mulates inside the cell, the calcium-dependent potassium channel IK[Ca] gradually opens,
lowers the membrane potential, and makes further spike generation more difﬁcult. Thus,
the level of adaptation can be read out from the intracellular calcium concentration.
In order to understand the accumulation of calcium, we need to discuss the high-
threshold calcium channel IHVA. Since it activates above −40 mV to −30 mV, the chan-
nel opens during a spike. Its dynamics is therefore similar to that of the sodium cur-
rent, but the direct effect of IHVA on the shape of the spike is small. Its main role is
to deliver a pulse of calcium ions into the neuron. The calcium ions have an important
role as second-messengers; they can trigger various cascades of biophysical processes.
Intracellular calcium is taken up by internal buffers, or slowly pumped out of the cell,
leading to an intricate dynamics dependent on the properties of calcium buffers and
calcium pumps. For small calcium transients, however, or when the calcium pump has
high calcium afﬁnity and slow extrusion rate, the intracellular calcium dynamics follow
(Helmchen et al., 2011)
d[Ca]
dt
= φCaICa +τ−1
Ca ([Ca]−[Ca]0),
(2.12)
where [Ca] denotes the intracellular calcium concentration, ICa is the sum of currents
coming from all calcium ion channels, φCa is a constant that scales the ionic current to
changes in ionic concentration, [Ca]0 is a baseline intracellular calcium concentration,

2.3 The zoo of ion channels
49
(a)
(b)
(c)
(d)
(e)
Fig. 2.14 IA and the refractory period. (a) Voltage dependence of the stationary values and (b) time
constants of the activation variable m and inactivation variable h for the A-type potassium current
IA = gA mh(u −EK) extracted from experimental observations in pyramidal neurons of the cortex
(Korngreen and Sakmann, 2000). (c) Voltage response to the current shown in (d), consisting of a
single pulse and a step. (e) Progressive activation (solid line) and inactivation (dashed line) of the
potassium current IA during the stimulation shown in (c) and (d).

50
The Hodgkin-Huxley Model
(a)
(b)
(c)
(d)
(e)
Fig. 2.15 Calcium-based spike-frequency adaptation with IK[Ca] and IHVA. (a) Voltage dependence of
the stationary values. (b) Time constants of the activation variable m and inactivation variable h of the
high-threshold calcium current IHVA = gL hm(u−ECa) extracted from experiments (Reuveni et al.,
1993). (c) Voltage response of a Hodgkin-Huxley model with the calcium current IHVA (dashed line)
and a model that also contains a calcium-dependent potassium current IK[Ca]. (d) External current
used for the simulation in (c) and (e). (e) Progressive accumulation of intracellular calcium in the
two models.

2.3 The zoo of ion channels
51
and τCa is the effective time constant of calcium extrusion. In our simple example the
sole source of incoming calcium ions is the high-threshold calcium channel hence ICa =
IHVA. Because of the short duration of the spike, each spike adds a ﬁxed amount of
intracellular calcium which afterward decays exponentially (Fig. 2.15e), as observed in
many cell types (Helmchen et al., 2011).
The calcium-dependent potassium channel IK[Ca] = gK[Ca] n(u−EK) is weakly sensi-
tive to the membrane potential but highly sensitive to intra cellular calcium concentra-
tion. The dynamics of activation can be modeled with a calcium-dependent time constant
(Destexhe et al., 1994a) of the activation variable n
τn([Ca]) =
k3
1+k2ek1[Ca]
(2.13)
and a stationary value (Destexhe et al., 1994a)
n0 =
k2ek1[Ca]
1+k2ek1[Ca]
(2.14)
where k1, k2, k3, and gK[Ca] are constants.
Figure 2.15 shows the effect of the combined action of calcium channel and IK[Ca]. A
single spike generates a transient increase in intracellular calcium which in turn causes
a transient increase in IK[Ca] activation which results in a hyperpolarization of the mem-
brane potential compared with a model without IK[Ca]. During sustained stimulation, cal-
cium accumulates over several spikes, so that the effect of IK[Ca] becomes successively
larger and interspike intervals increase. The time constant associated with adaptation is
a combination of the calcium extrusion time constant and the potassium activation and
de-activation time constant.
Example: Slow de-inactivation of a persistent sodium channel
The stationary values of activation and inactivation of the persistent sodium channel
INaP (Fig. 2.16a) are very similar to that of the normal sodium channel of the Hodgkin-
Huxley model. The main difference lies in the time constant. While activation of the
channel is quick, it inactivates on a much slower time scale. Hence the name: the current
"persists". The time constant of the inactivation variable h is of the order of a second.
During sustained stimulation, each spike contributes to the inactivation of the sodium
channel and therefore reduces the excitability of the neuron. This special type of refrac-
toriness is not visible in the spike-afterpotential, but can be illustrated as a relative
increase in the effective spiking threshold (Fig. 2.16b). Since, after a ﬁrst spike, the
sodium channel is partially inactivated, it becomes more difﬁcult to make the neuron
ﬁre a second time.

52
The Hodgkin-Huxley Model
(a)
(b)
Fig. 2.16 The persistent sodium channel INaP increases the ﬁring threshold. (a) Activation and inac-
tivation proﬁles for INaP = gNaP mh(u−ENa). Activation is fast (a few ms) whereas inactivation is of
the order of a second as measured in pyramidal neurons of the cortex (Aracri et al., 2006). (b) Slow
inactivation affects the effective threshold. In a Hodgkin-Huxley model with persistent sodium cur-
rent, subthreshold current pulses are injected at different moments (arrows). At t = 75 ms (asterisk)
only, a suprathreshold stimulation was applied. Tuning the strength of the other current pulses so that
they are just below spike initiation reveals an effective voltage threshold (dashed line) that is higher
immediately after the ﬁrst spike.
2.3.4 Subthreshold effects
Some ion channels have an activation proﬁle m0(u) which has a signiﬁcant slope well
below the spike initiation threshold. During subthreshold activation of the cell by back-
ground activity in vivo, or during injection of a ﬂuctuating current, these currents partially
activate and inactivate, following the time course of membrane potential ﬂuctuations and
shaping them in turn.
We describe two examples of subthreshold ion channel dynamics. The ﬁrst one illus-
trates adaptation to a depolarized membrane potential by inactivation of a depolarizing
current, which results in a subsequent reduction of the membrane potential. The second
example illustrates the opposite behavior: in response to a depolarized membrane poten-
tial, a depolarizing current is triggered which increases the membrane potential even fur-
ther. The two examples therefore correspond to subthreshold adaptation and subthreshold
facilitation, respectively.
Example: Subthreshold adaptation by Ih
Subthreshold adaptation through a hyperpolarization-activated current Ih is present in
many cell classes. As the name implies, the current is activated only at hyperpolarized
voltages as can be seen in Fig. 2.17a. Thus, the voltage dependence of the activation
variable is inverted compared with the normal case and has negative slope. Therefore, the
activation variable looks more like an inactivation variable and this is why we choose h
as the symbol for the variable. The channel is essentially closed for prolonged membrane

2.3 The zoo of ion channels
53
(a)
(b)
Fig. 2.17 Subthreshold adaptation with Ih. (a) Stationary values and (b) time constants of the vari-
able h controlling the hyperpolarization-activated mixed current Ih as measured in pyramidal neurons
of the hippocampus (Magee, 1998).
potential ﬂuctuations above −30 mV. The Ih current is a non-speciﬁc cation current,
meaning that sodium, potassium, and calcium can pass through the Ih channel when it
is open. The reversal potential of this ion channel is usually around −45 mV so that
the h-current Ih = gh h(u−Eh) is depolarizing at resting potential and over most of the
subthreshold regime.
The presence of Ih causes the response to step changes in input current to exhibit
damped oscillations. The interaction works as follows: suppose an external driving cur-
rent depolarizes the cell. In the absence of ion channels this would lead to an exponential
relaxation to a new value of the membrane potential of, say, −50 mV. Since Ih was mildly
activated at rest, the membrane potential increase causes the channel to de-activate. The
gradual closure of Ih removes the effective depolarizing drive and the membrane poten-
tial decreases, leading to a damped oscillation (as in Fig. 2.10). This principle can also
lead to a rebound spike as seen in Fig. 2.10. Subthreshold adaptation and damped oscil-
lations will be treated in more detail in Chapter 6.
Example: Subthreshold facilitation by INaS
The sodium ion channel INaS is slow to activate. Let us consider again stimulation with
a step current using a model which contains both the fast sodium current of the Hodgkin-
Huxley model and the slow sodium current INaS. If the strength of the current step is such
that it does not activate the fast sodium channel but is strong enough to activate INaS,
then the slow activation of this sodium current increases membrane potential gradually
with the time constant of activation of the slow sodium current (Fig. 2.18b). The slow
depolarization continues until the fast sodium current activates and an action potential

54
The Hodgkin-Huxley Model
(a)
(b)
(c)
(d)
(e)
Fig. 2.18
Subthreshold facilitation with INaS. (a) Stationary values and (b) time constants of the
activation variable m for the slow sodium current INaS similar to measurements done in pyramidal
neurons of the hippocampus (Hoehn et al., 1993). (c) Voltage response. (d) External current. (e) Slow
sodium current activation, leading to delayed spike initiation and ﬁring frequency facilitation.
is generated (Fig. 2.18c). Such delayed spike initiation has been observed in various
types of interneurons of the cortex. If the amplitude of the step current is sufﬁcient to
immediately activate the fast sodium channels, the gradual activation of INaS increases
the ﬁring frequency leading to spike-frequency facilitation.

2.3 The zoo of ion channels
55
2.3.5 Calcium spikes and postinhibitory rebound
Postinhibitory rebound means that a hyperpolarizing current which is suddenly switched
off results in an overshoot of the membrane potential or even in the triggering of one or
more action potentials. Through this mechanism, action potentials can be triggered by
inhibitory input. These action potentials, however, occur with a certain delay after the
arrival of the inhibitory input, i.e., after the end of the IPSP (Aizenman and Linden, 1999).
Inactivating currents with a voltage threshold below the resting potential, such as the
low-threshold calcium current, can give rise to a much stronger effect of inhibitory rebound
than the one seen in the standard Hodgkin-Huxley model. Compared with the sodium cur-
rent, the low-threshold calcium current IT has activation and inactivation curves that are
shifted signiﬁcantly toward a hyperpolarized membrane potential so that the channel is
-100
-80
-60
-40
-20
0
u [mV]
0
0.2
0.4
0.6
0.8
1
m   ,h
(a)
-100
-80
-60
-40
-20
0
u[mV]
0
1
2
3
4
tm ,0.01 th
tm
th
(b)
0
500
t [ms]
-60
-40
-20
0
u[mV]
(c)
0
500
t[ms]
0.0
0.2
0.4
0.6
0.8
1.0
m
0.0
0.02
0.04
0.06
0.08
0.1
h
(d)
Fig. 2.19 Postinhibitory rebound through de-inactivation. (a) Activation m0(u) and inactivation
h0(u) at equilibrium of the low-threshold calcium current IT. Small circles indicate the equilibrium
values of m and h at the resting potential. To de-inactivate the current, the membrane potential must
be below rest. (b) The time constants of activation and inactivation. Note that different vertical scales
have been used for τm and τh since the dynamics of the inactivation variable h is slower by a fac-
tor 10-100 than that of the activation variable m. Numerical values of parameters correspond to
a model of neurons in the deep cerebellar nuclei (Kistler and van Hemmen, 2000). (c) Membrane
potential as a function of time. Injection of a hyperpolarizing current pulse (100 pA during 200 ms
from t = 100 ms to t = 300 ms) results, at the end of current injection, in a low-threshold calcium
spike that in turn triggers two sodium action potentials. (d) Time course of activation (solid line, left
scale) and inactivation (dashed line, right scale) variables of the IT current that is responsible for this
phenomenon.

56
The Hodgkin-Huxley Model
completely inactivated (h ≈0) at the resting potential; see Fig. 2.19a and b. In order to
open the low-threshold calcium channels it is ﬁrst of all necessary to remove its inactiva-
tion by hyperpolarizing the membrane. The time constant of the inactivation variable h is
rather high and it thus takes a while until h has reached a value sufﬁciently above zero;
see Fig. 2.19b and d. But even if the channels have been successfully "de-inactivated" they
remain in a closed state, because the activation variable m is zero as long as the membrane
is hyperpolarized. However, the channels will be transiently opened if the membrane poten-
tial is rapidly relaxed from the hyperpolarized level to the resting potential, because acti-
vation is faster than inactivation and, thus, there is a short period when both m and h are
nonzero. The current that passes through the channels is terminated ("inactivated") as soon
as the inactivation variable h has dropped to zero again, but this takes a while because of
the relatively slow time scale of τh. The resulting current pulse is called a low-threshold
calcium spike and is much broader than a sodium spike.
The increase in the membrane potential caused by the low-threshold calcium spike may
be sufﬁcient to trigger ordinary sodium action potentials. These are the rebound spikes that
may occur after a prolonged inhibitory input. Figure 2.19c shows an example of (sodium)
rebound spikes that ride on the broad depolarization wave of the calcium spike; note that
the whole sequence is triggered at the end of an inhibitory current pulse. Thus release from
inhibition causes here a spike-doublet.
2.4 Summary
The Hodgkin-Huxley model describes the generation of action potentials on the level of
ion channels and ion current ﬂow. It is the starting point for detailed biophysical neu-
ron models which in general include more than the three types of currents considered by
Hodgkin and Huxley. Electrophysiologists have described an overwhelming richness of
different ion channels. The set of ion channels is different from one neuron to the next.
The precise channel conﬁguration in each individual neuron determines a good deal of its
overall electrical properties.
Literature
A nice review of the Hodgkin-Huxley model including some historical remarks can be
found in Nelson and Rinzel (1995). A comprehensive and readable introduction to the bio-
physics of single neurons is provided by the book of Christof (1999). Even more detailed
information on ion channels and nonlinear effects of the nervous membrane can be found
in B. Hille's book of Ionic Channels of Excitable Membranes (Hille, 2001). The rapidly
growing knowledge of the genetic description of ion channel families and associated phe-
notypes is condensed in Channelpedia (Ranjan et al., 2011).

2.4 Summary
57
Exercises
1. Nernst equation. Using the Nernst equation (Eq. 2.2) calculate the reversal potential of Ca2+
at room temperature (21 degrees Celsius), given an intracellular concentration of 10−4 mM and
an extracellular concentration of 1.5 mM.
2. Reversal potential and stationary current-voltage relation. An experimenter studies an
unknown ion channel by applying a constant voltage u while measuring the injected current I
needed to balance the membrane current that passes through the ion channel.
(a) Sketch the current-voltage relationship (I as a function of u) assuming that the current
follows Iion = gionmh (u −Erev) with gion = 1 nS and Erev = 0 mV where m = 0.1 and h = 1.0
are independent of the voltage.
(b) Sketch qualitatively the current-voltage relationship assuming that the current follows
Iion = gionmh (u −Erev) with gion = 1 nS and Erev = 0 mV where m0(u) and h0(u) have the
qualitative shape indicated in Fig. 2.15.
3. Activation time constant. An experimenter holds the channel from Fig. 2.15a and b at u =
−50 mV for two seconds and then suddenly switches to u = 0 mV. Sketch the current passing
through the ion channel as a function of time, assuming Iion = gionmh (u−Erev) with gion = 1 nS
and Erev = 0 mV.
4. The power of the exponent. An experimenter holds an unknown potassium ion channel with
activation variable n with voltage dependence n0(u) and time constant τn at u = −50 mV for two
seconds and then, at time t = 0, suddenly switches to u = 0 mV.
(a) Sketch the activation variable n, n2, n3 as a function of time for times smaller than τn.
(b) Show mathematically that for 0 < t < τn the time course of the activation variable can be
approximated n(t) = n0(−50mV)+[n0(0mV)−n0(−50mV)]t/τm.
(c) Do you agree with the statement that "the exponent p in the current formula Iion = gionnp (u−
Erev) determines the "delay" of activation"? Justify your answer.
5. Hodgkin-Huxley parameter estimation. Design a set of experiments to constrain all the param-
eters of the two ion channels of the Hodgkin-Huxley model. Assume that the neuron has only the
INa and IK currents and that you can use tetrodotoxin (TTX) to block the sodium ion channel and
tetraethylammonium (TEA) to block the potassium ion channel.
Hint: Use the results of the previous exercises.
6. Simpliﬁed expression of the activation function. Show that with the voltage-dependent param-
eters αm(u) = 1/[1 −e−(u+a)/b] and βm(u) = 1/[1 −e−(u+a)/b] (compare Table 2.1), the sta-
tionary value of the activation variable can be written as m0(u) = 0.5[1 + tanh[β (u −θact)]].
Determine the activation threshold θact and the activation slope β.
Hint: tanh(x) = [exp(x)−exp(−x)]/[exp(x)+exp(−x)].

3
Dendrites and synapses
Neurons have intricate morphologies: the central part of the cell is the soma, which con-
tains the genetic information and a large fraction of the molecular machinery. At the soma
originate long wire-like extensions which come in two different ﬂavors. First, the den-
drites form a multitude of smaller or larger branches on which synapses are located. The
synapses are the contact points where information from other neurons (i.e., "presynaptic"
cells) arrives. Second, also originating at the soma, is the axon, which the neuron uses
to send action potentials to its target neurons. Traditionally, the transition region between
soma and axon is thought to be the crucial region where the decision is taken whether a
spike is sent out or not.
The Hodgkin-Huxley model, at least in the form presented in the previous chapter, disre-
gards this spatial structure and reduces the neuron to a point-like spike generator - despite
the fact that the precise spatial layout of a neuron could potentially be important for signal
processing in the brain. In this chapter we will discuss how some of the spatial aspects can
be taken into account by neuron models. In particular we focus on the properties of the
synaptic contact points between neurons and on the electrical function of dendrites.
3.1 Synapses
In the previous chapter, we have encountered two classes of ion channels, namely voltage-
activated and calcium-activated ion channels. The third type of ion channel we have to
deal with are the transmitter-activated ion channels involved in synaptic transmission (see
Fig. 3.1) and generally activated from outside the cell. Activation of a presynaptic neuron
results in a release of neurotransmitters into the synaptic cleft. The transmitter molecules
diffuse to the other side of the cleft and activate receptors that are located in the post-
synaptic membrane. So-called ionotropic receptors have a direct inﬂuence on the state of
an associated ion channel. Metabotropic receptors control the state of an ion channel by
means of a biochemical cascade of G proteins and second-messengers. In both cases, the
activation of the receptor results in the opening of certain ion channels and, thus, in an
excitatory or inhibitory postsynaptic transmembrane current (EPSC or IPSC).
Instead of developing a mathematical model of the transmitter concentration in the
synaptic cleft, we keep things simple and describe transmitter-activated ion channels as

3.1 Synapses
59
an explicitly time-dependent conductivity gsyn(t) that will open whenever a presynaptic
spike arrives. The current that passes through a synaptic channel depends, as before, on
the difference between its reversal potential Esyn and the actual value of the membrane
potential,
Isyn(t) = gsyn(t)(u(t)−Esyn).
(3.1)
The parameter Esyn and the function gsyn(t) can be used to describe different types of
synapses. For inhibitory synapses Esyn is usually set to −75 mV, whereas for excitatory
synapses Esyn ≈0.
Typically, a superposition of exponentials is used for gsyn(t). A simple choice for the
time course of the synaptic conductance in Eq. (3.1) is an exponential decay
gsyn(t) = ∑
f
¯gsyn e−(t−t f )/τ Θ(t −t f ),
(3.2)
with a time constant of, e.g., τ = 5 ms and an amplitude of ¯gsyn = 40 pS. Here, t f denotes
the arrival time of a presynaptic action potential and Θ(x) is the Heaviside step function.
For some synapse types, a single exponential decay is not sufﬁcient. Rather, the post-
synaptic current is made up of two different components, a fast one with a decay time
constant of a few milliseconds, and a second one that is often ten times slower. If we also
take into account the smooth rise of the synaptic response, the postsynaptic conductance is
of the form
gsyn(t) =∑
f
¯gsyn [1−e−(t−t f )/τrise]

ae−(t−t f )/τfast +(1−a)e−(t−t f )/τslow

Θ(t −t f ), (3.3)
where a is the relative weight of the fast component. The time constant τrise characterizes
the rise time of the synaptic conductance.
Example: A more detailed synapse model
Instead of considering a synapse with a ﬁxed time course gsyn(t), we can also make
a model which has the ﬂavor of a Hodgkin-Huxley channel. We describe the synaptic
conductance gsyn(t) = gmax R(t), by its maximal conductance gmax and a gating variable
R, where R(t) is the fraction of open synaptic channels. Channels open when neurotrans-
mitter N binds to the synapse
dR
dt = α N (1−R)−β R,
(3.4)
where α is the binding constant, β the unbinding constant and (1 −R) the fraction
of closed channels where binding of neurotransmitter can occur. Neurotransmitter N
is released with each presynaptic spike so that the total amount of neurotransmitter at
synapse j is
N(t) =
 ∞
0 γ(s)S j(t −s)ds,
(3.5)

60
Dendrites and synapses
Transmitter 
release
Presynaptic
Postsynaptic
Transmitter-gated
ion channels
Glutamate
K    ion ﬂux
+
Na   ion ﬂux
+
Neuronal
membrane
}
(a)
(b)
Fig. 3.1 (a) Schema of synaptic transmission. Upon arrival of a presynaptic spike, neurotransmitter
spills into the synaptic cleft and is captured by postsynaptic receptors. (b) Schema of a postsynaptic
AMPA1 receptor of an excitatory synapse. When glutamate is bound to the receptor, sodium and
potassium ions can ﬂow through the membrane.
where Sj = ∑f δ(t −t f
j ) is the presynaptic spike train (a sequence of δ-functions, see
Chapter 1) and γ(s) is the time course of the neurotransmitter density as measured at
the site of the postsynaptic receptor. More advanced synaptic signaling schemes can be
designed along the same line of argument (Destexhe et al., 1994b).
3.1.1 Inhibitory synapses
The effect of fast inhibitory neurons in the central nervous system of higher vertebrates is
almost exclusively conveyed by a neurotransmitter called γ-aminobutyric acid, or GABA
for short. A characteristic feature of inhibitory synapses is that the reversal potential Esyn
is in the range of −70 to −75 mV. Thus, if the neuronal membrane potential is above
the reversal potential, presynaptic spike arrival leads to a hyperpolarization of the neu-
ron, making action potential generation less likely. However, the same presynaptic spike
would lead to a depolarization of the membrane if the neuron has its membrane potential at
−80 mV or below.
There are many different types of inhibitory interneurons (Markram et al., 2004; Klaus-
berger and Somogyi, 2008). Biologists distinguish between two major types of inhibitory
synapse, called GABAA and GABAB. Both synapse types use GABA as the neurotrans-
mitter. GABAA channels are ionotropic and open exclusively for chloride ions, whereas
GABAB synapses have metabotropic receptors that trigger a comparatively slow signal-
ing chain ultimately leading to the opening of K+ channels. Consequently the value of
the synaptic reversal potential Esyn depends for GABAA synapses on the concentration of
chloride ions inside and outside the cell, while that of GABAB synapses depends on the
potassium concentrations.
1AMPA is short for α-amino-3-hydroxy-5-methyl-4-isoxalone propionic acid.

3.1 Synapses
61
Example: GABAA synapse model
GABAA synapses have a fast time course that can be approximated by a single term
in Eq. (3.3) with a = 1, τrise ≈1 ms, and a time constant τfast ≈6 ms (Destexhe and Pare
(1999); Fig. 3.2), which has also been deemed 3 times larger. More complex models are
sometimes used (Destexhe et al., 1994b).
Example: GABAB synapse model
This is a slow inhibitory synapse working via a second-messenger chain. Common
models use Eq. (3.3) with a rise time of about 25-50 ms, a fast decay time in the range
of 100-300 ms and a slow decay time of 500-1000 ms. The fast component accounts
for about 80% of the amplitude of conductance (a = 0.8) (Destexhe et al., 1994b;
McCormick et al., 1993), illustrated in Fig. 3.2.
3.1.2 Excitatory synapses
Most excitatory synapses in the vertebrate central nervous system rely on glutamate as
their neurotransmitter. The postsynaptic receptors, however, can have very different phar-
macological properties and different types of glutamate receptor units can be present in
a single synapse. These receptors are classiﬁed using artiﬁcial drugs such as NMDA or
AMPA that act as selective agonists. NMDA (N-methyl-D-aspartate) binds to channels
with NMDA receptors, but not to other glutamate receptors. The most prominent among
those glutamate receptors that do not respond to NMDA are the AMPA-receptors. AMPA is
an artiﬁcial glutamate. Channels with AMPA-sensitive receptors are called "AMPA chan-
nels" because these channels react to AMPA, whereas channels with NMDA-sensitive
receptors do not open upon application of AMPA. However, both NMDA and AMPA
channels react to the natural form of glutamate that the nervous system uses as
neurotransmitter.
AMPA receptors consist of four subunits, each with a glutamate binding site. Most
AMPA receptors contain the subunit called GluR2. If an AMPA-receptor channel contain-
ing GluR2 is open, sodium and potassium ions can pass, but calcium ions cannot. Synaptic
channels with AMPA-receptors are characterized by a fast response to presynaptic spikes
and a quickly decaying postsynaptic current.
NMDA-receptor controlled channels are signiﬁcantly slower and have additional inter-
esting properties that are due to a voltage-dependent block by magnesium ions (Hille,
1992). In addition to sodium and potassium ions, also calcium ions can pass through open
NMDA-channels.

62
Dendrites and synapses
0
100
200
300
400
500
t [ms]
−300
−200
−100
0
100
200
300
400
−Isyn [pA]
AMPA
NMDA
GABAA
GABAB
Fig. 3.2 Dynamics of postsynaptic
current (3.1) after a single presynap-
tic spike at t = 0. GABAA, GABAB,
AMPA, and NMDA without magne-
sium block are shown for a postsynap-
tic neuron at rest (u = −65mV).
Example: Conductance of glutamate channels with AMPA-receptors
The time course of the postsynaptic conductivity caused by an activation of AMPA-
receptors at time t = t f is sometimes described by Eq. (3.2) with a decay time of about
2-5 ms (Gabbiani et al., 1994; Destexhe et al., 1994b).
Example: Conductance of glutamate channels with NMDA-receptors
NMDA-receptor controlled channels exhibit a rich repertoire of dynamic behavior
because their state is controlled not only by the presence or absence of glutamate, but
also by the membrane potential. At resting potential the NMDA channel is blocked by a
common extracellular ion, Mg2+, even if glutamate is present (Hille, 1992). Even in the
presence of glutamate, the channel remains closed at the resting potential. If the mem-
brane is depolarized beyond −50 mV, the Mg2+-block is removed, the channel opens
when glutamate binds to the receptor and, thereafter, stays open for 10-100 ms. A sim-
ple model of the voltage dependence of NMDA-receptor controlled channels is
gNMDA(t) = ¯gNMDA ·

1−e−(t−t f )/τrise

e−(t−t f )/τdecay g∞(u,[Mg2+]o)Θ(t −t f ),
with g∞(u,[Mg2+]o) =

1+β eα u [Mg2+]o
−1 ,
(3.6)
with τrise in the range of 3 ms to 15 ms, τdecay in the range of 40 ms to 100 ms,
¯gNMDA = 1.5 nS, α = −0.062mV−1, β = 1/(3.57mM), and an extracellular magnesium
concentration [Mg2+]o = 1.2 mM (McCormick et al., 1993; Gabbiani et al., 1994).
What is the potential functional role of NMDA receptors? First, their comparatively
long time constant keeps a trace of presynaptic events and acts as a low-pass ﬁlter. Sec-
ond, even though NMDA-receptor controlled ion channels are permeable to sodium and
potassium ions, their permeability to Ca2+ is ﬁve or ten times larger. Calcium ions are
known to play an important role in intracellular signalling and are probably involved in

3.1 Synapses
63
(a)
(b)
Fig. 3.3 Short-term plasticity. A synapse is activated by four presynaptic spikes and a ﬁfth spike 400
ms later. (a) At a facilitating synapse, the effect of the second and third spike is larger than that of
the ﬁrst spike. The effect of a spike after a pause of 400 ms is approximately that of the ﬁrst spike
(time constant τP = 200 ms). (b) At a depressing synapse, successive spikes in a periodic spike train
have less and less effect: 400 ms later, the synapse has partially recovered, but is still signiﬁcantly
depressed (τP = 500 ms).
long-term modiﬁcations of synaptic efﬁcacy. Calcium inﬂux through NMDA-controlled
ion channels can occur if presynaptic spike arrival (leading to glutamate release from
presynaptic sites) coincides with a depolarization of the postsynaptic membrane (lead-
ing to removal of the Mg2+-block). Hence, NMDA-receptors operate as molecular coin-
cidence detectors between pre- and postsynaptic events.
3.1.3 Rapid synaptic dynamics
Parameters of a synaptic contact point are not ﬁxed, but can change as a function of the
stimulation history. Some of these changes are long-lasting and are thought to represent the
neuronal correlate of learning and memory formation. The description of these learning-
related changes will be covered in Chapter 19. Here we concentrate on dynamic changes
of the synapse that do not persist but decay back to their normal values within hundreds of
milliseconds or a few seconds. These changes are called short-term synaptic plasticity.
Short-term synaptic plasticity can be measured if a presynaptic neuron is stimulated so
as to generate a sequence of spikes. Synaptic facilitation means that the apparent amplitude
of a postsynaptic current in response to the second spike is larger than that to the ﬁrst spike.
Synaptic depression is the opposite effect (Fig. 3.3).
As a simple model of synaptic facilitation and depression (Dayan and Abbott, 2001), we
assume that the maximal synaptic conductance ¯gsyn in Eq. (3.2) or (3.3) depends on the
fraction Prel of presynaptic sites releasing neurotransmitter. Facilitation and depression can
both be modeled as presynaptic processes that modify Prel. With each presynaptic spike,
the number of available presynaptic release sites changes. Between spikes the value of Prel

64
Dendrites and synapses
(a)
(b)
(c)
(d)
(e)
Fig. 3.4 Reconstructed morphology of various types of neurons. (a) Pyramidal neuron from a deep
cortical layer (Contreras et al., 1997). (b) Pyramidal neuron from the CA1 of the hippocampus
(Golding et al., 2005). (c) Purkinje cell from the cerebellum (Rapp et al., 1994). (d) Motoneuron
from the spinal cord (Cullheim et al., 1987). (e) Stellate neuron from the neocortex (Mainen and
Sejnowski, 1996). Reconstructed morphologies can be downloaded from http://NeuroMorpho.Org.
Scale bars represent 100μm.
returns exponentially to its resting value P0. Thus,
dPrel
dt
= −Prel −P0
τP
+ fF (1−Prel) ∑
f
δ(t −t f )
(3.7)
where τP is a time constant, fF controls the degree of facilitation, and t f denotes the times
of presynaptic spike arrivals.
The model of a depressing synapse is completely analogous. The amount of neurotrans-
mitter available for release develops according to the differential equation
dPrel
dt
= −Prel −P0
τP
−fD Prel ∑
f
δ(t −t f )
(3.8)
where τP is a time constant and the parameter fD with 0 < fD < 1 controls the amount of
depression per spike.
The total effect of presynaptic spikes depends on the available neurotransmitter as well
as the value g0 of postsynaptic conductance if all synaptic ion channels are open, so that,
for depressing or facilitating synapses, we can use Eq. (3.2) with a value ¯gsyn = Prel g0. This
procedure has been used to generate Fig. 3.3.
3.2 Spatial structure: the dendritic tree
Neurons in the cortex and other areas of the brain often exhibit highly developed dendritic
trees that may extend over several hundred microns (Fig. 3.4). Synaptic input to a neuron
is mostly located on its dendritic tree. Disregarding NMDA- or calcium-based electrogenic
"spikes," action potentials are generated at the soma near the axon hillock. Up to now we

3.2 Spatial structure: the dendritic tree
65
have discussed point neurons only, i.e., neurons without any spatial structure. What are the
consequences of the spatial separation of input and output?
The electrical properties of point neurons have been described as a capacitor that is
charged by synaptic currents and other transversal ion currents across the membrane.
A non-uniform distribution of the membrane potential on the dendritic tree and the soma
induces additional longitudinal current along the dendrite. We are now going to derive the
cable equation that describes the membrane potential along a dendrite as a function of time
and space. In Section 3.4 we shall see how geometric and electrophysiological properties
can be integrated in a comprehensive biophysical model.
3.2.1 Derivation of the cable equation
Consider a piece of dendrite decomposed into short cylindric segments of length dx each.
The schematic drawing in Fig. 3.5 shows the corresponding circuit diagram. Using Kirch-
hoff's laws we ﬁnd equations that relate the voltage u(x) across the membrane at location x
with longitudinal and transversal currents. First, a longitudinal current i(x) passing through
the dendrite causes a voltage drop across the longitudinal resistor RL according to Ohm's
law,
u(t,x+dx)−u(t,x) = RL i(t,x),
(3.9)
where u(t,x + dx) is the membrane potential at the neighboring point x + dx. Second, the
transversal current that passes through the RC-circuit is given by C∂u(t,x)/∂t + ∑ion Iion
where the sum runs over all ion channel types present in the dendrite. Kirchhoff's law
regarding the conservation of current at each node leads to
i(t,x+dx)−i(t,x) = C ∂
∂t u(t,x)+∑
ion
Iion −Iext(t,x).
(3.10)
The values of the longitudinal resistance RL, the capacity C, the ionic currents as well as the
externally applied current can be expressed in terms of speciﬁc quantities per unit length
rL, c, iion and iext, respectively, namely
RL = rL dx,
C = cdx,
Iext(t,x) = iext(t,x)dx,
Iion(t,x) = iion(t,x)dx.
(3.11)
These scaling relations express the fact that the longitudinal resistance and the capacity
increases with the length of the cylinder. Similarly, the total amount of transversal current
increases with the length dx simply because the surface through which the current can pass
is increasing. Substituting these expressions in Eqs. (3.9) and (3.10), dividing by dx, and
taking the limit dx →0 leads to
∂
∂x u(t,x) = rL i(t,x)
(3.12a)
∂
∂x i(t,x) = c ∂
∂t u(t,x)+∑
ion
iion(t,x)−iext(t,x).
(3.12b)

66
Dendrites and synapses
dx
RL
R T
C
u(x)
u(x+dx)
i(x)
i(x+dx)
Iext(x)
Fig. 3.5 Part of a dendrite and the corresponding circuit diagram. Longitudinal and transversal resis-
tors are denoted by RL and RT, respectively. The electrical capacity of each small piece of dendrite
is symbolized by capacitors C.
Taking the derivative of equation (3.12a) with respect to x and substituting the result into
(3.12b) yields
∂2
∂x2 u(t,x) = crL
∂
∂t u(t,x)+rL∑
ion
iion(t,x)−rL iext(t,x).
(3.13)
Equation (3.13) is called the general cable equation.
Example: Cable equation for passive dendrite
The ionic currents ∑ion iion(t,x) in Eq. (3.13) can in principle comprise many dif-
ferent types of ion channel, as discussed in Section 2.3. For simplicity, the dendrite is
sometimes considered as passive. This means that the current density follows Ohm's law
∑ion iion(t,x) = gl(u −El) where gl = 1/rT is the leak conductance per unit length and
El is the leak reversal potential.
We introduce the characteristic length scale λ 2 = rT/rL ("electrotonic length scale")
and the membrane time constant τ = rT c. If we multiply Eq. (3.13) by λ 2 we get
λ 2 ∂2
∂x2 u(t,x) = τ ∂
∂t u(t,x)+[u(t,x)−El]−rT iext(t,x).
(3.14)
After a transformation to unit-free coordinates,
x →ˆx = x/λ ,
t →ˆt = t/τ ,
(3.15)
and a rescaling of the current and voltage variables,
i →ˆi = √rT rL i,
iext →ˆiext = rT iext ,
u →ˆu = u−El,
(3.16)
we obtain the cable equation (where we have dropped the hats)
∂
∂t u(t,x) = ∂2
∂x2 u(t,x)−u(t,x)+iext(t,x),
(3.17)
in an elegant unit-free form.

3.2 Spatial structure: the dendritic tree
67
The cable equation can be easily interpreted. The change in time of the voltage at
location x is determined by three different contributions. The ﬁrst term on the right-hand
side of Eq. (3.17) is a diffusion term that is positive if the voltage is a convex function of
x. The voltage at x thus tends to increase, if the values of u are higher in a neighborhood
of x than at x itself. The second term on the right-hand side of Eq. (3.17) is a simple decay
term that causes the voltage to decay exponentially towards zero. The third term, ﬁnally,
is a source term that acts as an inhomogeneity in the otherwise autonomous differential
equation. This source can be due to an externally applied current or to synaptic input
arriving at location x.
Example: Stationary solutions of the cable equation
In order to get an intuitive understanding of the behavior of the cable equation of a
passive dendrite we look for stationary solutions of Eq. (3.17), i.e., for solutions with
∂u(t,x)/∂t = 0. In that case, the partial differential equation reduces to an ordinary
differential equation in x, namely
∂2
∂x2 u(t,x)−u(t,x) = −iext(t,x).
(3.18)
The general solution to the homogenous equation with iext(t,x) ≡0 is
u(t,x) = c1 sinh(x)+c2 cosh(x),
(3.19)
as can easily be checked by taking the second derivative with respect to x. Here, c1 and
c2 are constants that are determined by the boundary conditions.
Solutions for non-vanishing input current can be found by standard techniques. For
a stationary input current iext(t,x) = δ(x) localized at x = 0 and boundary conditions
u(±∞) = 0 we ﬁnd
u(t,x) = 1
2 e−|x|;
(3.20)
see Fig. 3.6. This solution is given in units of the intrinsic length scale λ = (rT/rL)1/2. If
we re-substitute the physical units, we see that λ is the length over which the stationary
membrane potential drops by a factor 1/e. In the literature λ is referred to as the electro-
tonic length scale (Rall, 1989). Typical values for the speciﬁc resistance of the intracellu-
lar medium and the cell membrane are 100 Ω cm and 30k Ω cm2, respectively. In a den-
drite with radius ρ = 1μm this amounts to a longitudinal and a transversal resistance of
rL = 100Ωcm/(πρ2) = 3×105 Ωμm−1 and rT = 30kΩcm2/(2πρ) = 5×1011 Ωμm.
The corresponding electrotonic length scale is λ = 1.2mm. Note that the electrotonic

68
Dendrites and synapses
−3
−2
−1
0
1
2
3
x
0.1
0.2
0.3
0.4
0.5
u
l
Fig. 3.6 Stationary solution of the cable
equation with a constant current of unit
strength
being
injected
at
x = 0,
i.e.,
iext(t,x) = δ(x). The electrotonic length scale
λ is the distance over which the membrane
potential drops to 1/e of its initial value.
length can be signiﬁcantly smaller if the transversal conductivity is increased, e.g., due
to open ion channels.
For arbitrary stationary input current iext(x) the solution of Eq. (3.17) can be found by
a superposition of translated fundamental solutions (3.20), namely
u(t,x) =

dx′ 1
2 e−|x−x′| iext(x′).
(3.21)
This is an example of the Green's function approach applied here to the stationary case.
The general time-dependent case will be treated in the next section.
3.2.2 Green's function of the passive cable
In the following we will concentrate on the equation for the voltage and start our analysis
by a discussion of the Green's function for a cable extending to inﬁnity in both directions.
The Green's function is deﬁned as the solution of a linear equation such as Eq. (3.17) with
a Dirac δ-pulse as its input. It can be seen as an elementary solution of the differential
equation because - due to linearity - the solution for any given input can be constructed as
a superposition of these Green's functions.
Suppose a short current pulse iext(t,x) is injected at time t = 0 at location x = 0. As we
will show below, the time course of the voltage at an arbitrary position x is given by
u(t,x) = Θ(t)
√
4π t exp

−t −x2
4t

≡G∞(t,x),
(3.22)
where G∞(t,x) is the Green's function. Knowing the Green's function, the general solution
for an inﬁnitely long cable is given by
u(t,x) =
 t
−∞dt′
 ∞
−∞dx′ G∞(t −t′,x−x′)iext(t′,x′).
(3.23)
The Green's function is therefore a particularly elegant and useful mathematical tool: once
you have solved the linear cable equation for a single short current pulse, you can write
down the full solution to arbitrary input as an integral over (hypothetical) pulse-inputs at
all places and all times.

3.2 Spatial structure: the dendritic tree
69
Checking the Green's property (*)
We can check the validity of Eq. (3.22) by substituting G∞(t,x) into Eq. (3.17). After a
short calculation we ﬁnd
 ∂
∂t −∂2
∂x2 +1

G∞(t,x) =
1
√
4π t exp

−t −x2
4t

δ(t),
(3.24)
where we have used ∂Θ(t)/∂t = δ(t). As long as t ̸= 0 the right-hand side of Eq. (3.24)
vanishes, as required by Eq. (3.28). For t →0 we ﬁnd
lim
t→0
1
√
4π t exp

−t −x2
4t

= δ(x),
(3.25)
which proves that the right-hand side of Eq. (3.24) is indeed equivalent to the right-hand
side of Eq. (3.28).
Having established that
 ∂
∂t −∂2
∂x2 +1

G∞(t,x) = δ(x)δ(t),
(3.26)
we can readily show that Eq. (3.23) is the general solution of the cable equation for arbi-
trary input currents iext(t0,x0). We substitute Eq. (3.23) into the cable equation, exchange
the order of integration and differentiation, and ﬁnd
 ∂
∂t −∂2
∂x2 +1

u(t,x)
=
 t
−∞dt′
 ∞
−∞dx′
 ∂
∂t −∂2
∂x2 +1

G∞(t −t′,x−x′)iext(t′,x′)
=
 t
−∞dt′
 ∞
−∞dx′ δ(x−x′)δ(t −t′)iext(t′,x′) = iext(t,x).
(3.27)
Derivation of the Green's function (*)
Previously, we have just "guessed" the Green's function and then shown that it is indeed a
solution of the cable equation. However, it is also possible to derive the Green's function
step by step. In order to ﬁnd the Green's function for the cable equation we thus have to
solve Eq. (3.17) with iext(t,x) replaced by a δ-impulse at x = 0 and t = 0
∂
∂t u(t,x)−∂2
∂x2 u(t,x)+u(t,x) = δ(t)δ(x).
(3.28)
Fourier transformation with respect to the spatial variable yields
∂
∂t u(t,k)+k2 u(t,k)+u(t,k) = δ(t)/
√
2π .
(3.29)
This is an ordinary differential equation in t and has a solution of the form
u(t,k) = exp

−

1+k2
t

/
√
2π Θ(t),
(3.30)

70
Dendrites and synapses
with Θ(t) denoting the Heaviside function. After an inverse Fourier transform we obtain
the desired Green's function G∞(t,x),
u(t,x) = Θ(t)
√
4π t exp

−t −x2
4t

≡G∞(t,x).
(3.31)
Example: Finite cable
Real cables do not extend from −∞to +∞and we have to take extra care to correctly
include boundary conditions at the ends. We consider a ﬁnite cable extending from x = 0
to x = L with sealed ends, i.e., i(t,x = 0) = i(t,x = L) = 0 or, equivalently,
∂
∂xu(t,x =
0) = ∂
∂xu(t,x = L) = 0.
The Green's function G0,L for a cable with sealed ends can be constructed from G∞
by applying a trick from electrostatics called "mirror charges" (Jackson, 1962). Similar
techniques can also be applied to treat branching points in a dendritic tree (Abbott,
1991). The cable equation is linear and, therefore, a superposition of two solutions is
also a solution. Consider a δ-current pulse at time t0 and position x0 somewhere along
the cable. The boundary condition ∂
∂xu(t,x = 0) = 0 can be satisﬁed if we add a second,
virtual current pulse at a position x = −x0 outside the interval [0,L]. Adding a current
pulse outside the interval [0,L] comes for free since the result is still a solution of the
cable equation on that interval. Similarly, we can fulﬁll the boundary condition at x = L
by adding a mirror pulse at x = 2L−x0. In order to account for both boundary conditions
simultaneously, we have to compensate for the mirror pulse at −x0 by adding another
mirror pulse at 2L+x0 and for the mirror pulse at x = 2L−x0 by adding a fourth pulse
at −2L+x0 and so forth. Altogether we have
G0,L(t0,x0;t,x) =
∞
∑
n=−∞
G∞(t −t0,x−2nL−x0)+G∞(t −t0,x−2nL+x0).
(3.32)
We emphasize that in the above Green's function we have to specify both (t0,x0) and
(t,x) because the setup is no longer translation invariant. The general solution on the
interval [0,L] is given by
u(t,x) =
 t
−∞dt0
 L
0 dx0 G0,L(t0,x0;t,x)iext(t0,x0).
(3.33)
An example for the spatial distribution of the membrane potential along the cable is
shown in Fig. 3.7a, where a current pulse has been injected at location x = 1. In addition
to Fig. 3.7a, Fig. 3.7b exhibits the time course of the membrane potential measured in
various distances from the point of injection. It is clearly visible that the peak of the
membrane potential measured at, say, x = 3 is more delayed than at, say, x = 2. Also the
amplitude of the membrane potential decreases signiﬁcantly with the distance from the
injection point. This is a well-known phenomenon that is also present in neurons. In the
absence of active ampliﬁcation mechanisms, synaptic input at distal dendrites produces

3.2 Spatial structure: the dendritic tree
71
0
1
2
3
4
5
x
0
0.2
0.4
0.6
0.8
(a)
u
0
0.5
1
1.5
2
2.5
3
t
0
0.1
0.2
0.3
0.4
u
(b)
Fig. 3.7 Spatial distribution (a) and temporal evolution (b) of the membrane potential along a
dendrite (L = 5) with sealed ends

∂
∂xu

x∈{0,L} = 0

after injection of a unit current pulse at x = 1
and t = 0. The various traces in (a) show snapshots for time t = 0.1, 0.2,..., 1.0, respectively (top to
bottom). The traces in (b) give the membrane potential as a function of time for different locations
x = 1.5, 2.0, 2.5,..., 5.0 (top to bottom) along the cable.
broader and weaker response at the soma as compared to synaptic input at proximal
dendrites.
3.2.3 Nonlinear extensions to the cable equation
In the context of a realistic modeling of "biological" neurons, two nonlinear extensions
of the cable equation have to be discussed. The obvious one is the inclusion of nonlinear
elements in the circuit diagram of Fig. 3.5 that account for specialized ion channels. As we
have seen in the Hodgkin-Huxley model, ion channels can exhibit a complex dynamics that
is in itself governed by a system of (ordinary) differential equations. The current through
one of these channels is thus not simply a (nonlinear) function of the actual value of the
membrane potential but may also depend on the time course of the membrane potential
in the past. Using the symbolic notation iion[u](t,x) for this functional dependence, the
extended cable equation takes the form
∂
∂t u(t,x) = ∂2
∂x2 u(t,x)−u(t,x)−iion[u](t,x)+iext(t,x).
(3.34)
A more subtle complication arises from the fact that a synapse cannot be treated as
an ideal current source. The effect of an incoming action potential is the opening of ion
channels. The resulting current is proportional to the difference of the membrane potential
and the corresponding ionic reversal potential. Hence, a time-dependent conductivity as in
Eq. (3.1) provides a more realistic description of synaptic input than an ideal current source
with a ﬁxed time course.
If we replace in Eq. (3.17) the external input current iext(t,x) by an appropriate synaptic
input current −isyn(t,x) = −gsyn(t,x)[u(t,x) −Esyn] with gsyn being the synaptic

72
Dendrites and synapses
conductivity and Esyn the corresponding reversal potential, we obtain2
∂
∂t u(t,x) = ∂2
∂x2 u(t,x)−u(t,x)−gsyn(t,x)[u(t,x)−Esyn].
(3.35)
This is still a linear differential equation but its coefﬁcients are now time-dependent. If
the time course of the synaptic conductivity can be written as a solution of a differential
equation, then the cable equation can be reformulated so that synaptic input reappears as
an inhomogeneity to an autonomous equation. For example, if the synaptic conductivity is
simply given by an exponential decay with time constant τsyn we have
∂
∂t u(t,x)−∂2
∂x2 u(t,x)+u(t,x)+gsyn(t,x)[u(t,x)−Esyn] = 0,
(3.36a)
∂
∂t gsyn(t,x)−τ−1
syn gsyn(t,x) = S(t,x).
(3.36b)
Here, S(t,x) is a sum of Dirac δ-functions which describe the presynaptic spike train that
arrives at a synapse located at position x. Note that this equation is nonlinear because it
contains a product of gsyn and u which are both unknown functions of the differential
equation. Consequently, the formalism based on Green's functions cannot be applied. We
have reached the limit of what we can do with analytical analysis alone. To study the
effect of ion channels distributed on the dendrites numerical approaches in compartmental
models become invaluable (Section 3.4).
3.3 Spatial structure: axons
Any given neuron has a single axon that leaves the soma to make synaptic contacts. Like
dendrites, axons have a range of different morphologies. Some axons project mainly to
neurons close by. This is the case for neurons in the layer 2-3 of cortex; their axons branch
out in all directions from the soma forming a star-shaped axonal arbor called a "daisy."
Other neurons such as pyramidal neurons situated deeper in the cortex have axons that
plunge in the white matter and may cross the whole brain to reach another brain area.
There are even longer axons that leave the central nervous system and travel down the
spinal cord to reach muscles at the tip of the foot.
In terms of propagation dynamics, we distinguish two types of axons: the myelinated
and the unmyelinated axons. We will see that myelin is useful to increase propagation
speed in far-reaching projections. This is the case for cortical projections passing through
the white matter, or for axons crossing the spinal cord. Short projections on the other hand
use axons devoid of myelin.
3.3.1 Unmyelinated axons
Mathematical description of the membrane potential in the axon is identical to that of
dendrites with active ion channels. Unmyelinated axons contain sodium and potassium
2We want outward currents to be positive, hence the change in the sign of iext and isyn.

3.3 Spatial structure: axons
73
channels uniformly distributed over their entire length. The classical example is the squid
giant axon investigated by Hodgkin and Huxley. The Hodgkin-Huxley model described in
Chapter 2 was developed for a small axon segment. The general equation for ion channels
imbedded on a passive membrane is
crL
∂
∂t u(t,x) = ∂2
∂x2 u(t,x)−rL(u(t,x)−El)−rLiion[u](t,x)
(3.37)
where we have reverted to a variable u in units of mV from the equation of active dendrites
seen in Section 3.2.3. For the giant squid axon, the ionic current are described by the
Hodgkin-Huxley model
iion[u](t,x) = gNa m3(t,x)h(t,x)(u(t,x)−ENa)+gK n4(t,x)(u(t,x)−EK).
(3.38)
In other systems, the axon may be covered with other types of sodium or potassium ion
channels.
When an action potential is ﬁred in the axon initial segment, the elevated membrane
potential will depolarize the adjacent axonal segments. Sodium channels farther down the
axon, which were previously closed, will start to open, thereby depolarizing the mem-
brane further. The action potential propagates by activating sodium channels along the
cable rather than by spreading the charges as in a passive dendrite. The properties of the
ion channels strongly inﬂuence conduction velocity. In the unmyelinated axons of the hip-
pocampus, the conduction velocity of the axons is 0.25 m/s.
The dynamics described by Eqs. (3.37)-(3.38) reproduces many properties of real axons.
In particular, two spikes traveling in opposite direction will collide and annihilate each
other. This is unlike waves propagating on water. Another property is reﬂection at branch
points. When the impedance mismatch at the point where a single axon splits into two is
signiﬁcant, the action potential can reﬂect and start traveling in the direction it came from.
The solution of Eq. (3.37) with sodium and postassium ion channels as in Eq. (3.38)
cannot be written in a closed form. Properties of axonal propagation are either studied
numerically (see Section 3.4) or with reduced models of ion channels.
Example: Speed of propagation with simpliﬁed action potential dynamics
For the sake of studying propagation properties, we can replace the active properties
of a small axonal segment by a bistable switch (FitzHugh, 1961; Nagumo et al., 1962) .
We can write the time- and space-dependent membrane potential as
crL
∂
∂t u(t,x) = ∂2
∂x2 u(t,x)−rLg
1−au(t,x)(u(t,x)−1)(u(t,x)−a),
(3.39)
where a < 1/2 and g are parameters. The membrane potential is scaled such that it rests
at zero but may be activated to u = 1. The reduced model can switch between u = 0 and
u = 1 if it is pushed above u = a, but does not reproduce the full upswing followed by
downswing of action potentials.

74
Dendrites and synapses
It turns out that Eq. (3.39) can also be interpreted as a model of ﬂame front propaga-
tion. The solution of this equation follows (Zeldovich and Frank-Kamenetskii, 1938)
u(x,t) =
1
1+exp

x−vt
√
2λ∗
	
(3.40)
with traveling speed
v =
c(1−2a)

2(1−a)rL/g
.
(3.41)
The propagation velocity depends on the capacitance per unit length c, the longitudinal
resistance per unit length rL, and the excitability parameters g and a.
How does the conduction velocity scale with axon size? Since rL, c and g themselves
depend on the diameter of the axon, we expect the velocity to reﬂect that relationship.
The parameters c and g scale with the circumference of the cellular membrane and
therefore scale linearly with the radius ρ. The cytoplasmic resistance per unit length,
however, scales with the cross-sectional area, rL ∝ρ2. With these relations in mind,
Eq. (3.41) shows that the conduction velocity is proportional to the square root of the
diameter v ∝√ρ. Therefore, increasing the diameter improves propagation velocity.
This is thought to be the reason why the unmyelinated axons that Hodgkin and Huxley
studied were so large (up to ρ = 500 μm).
3.3.2 Myelinated axons
Myelinated axons have sodium and potassium channels only in restricted segments called
nodes of Ranvier. These nodes form only 0.2% of the axonal length, the rest is considered
a passive membrane that is wrapped into a myelin sheath. Myelin mainly decreases the
membrane capacitance C and increase the resistance RT by a factor of up to 300 (Debanne
et al., 2011). Ions are trapped by myelin since it prevents them from either ﬂowing outside
the axon or accumulating on the membrane. Instead, ions ﬂow in and out of the nodes such
that an ion leaving a node of Ranvier forces another to enter the following node. Assuming
that the nodes are equally separated by a myelinated segment of length L, we can model the
evolution of the membrane potential at each node un. The dynamics of idealized myelinated
axons follow Kirchoff's equation with a resistance RL = LrL replacing the myelinated
segment
Cdun
dt =
1
LrL
(un+1(t)−2un(t)+un−1(t))−∑
ion
Iion,n(t)
(3.42)
where C is the total capacitance of the node. This equation was encountered in the deriva-
tion of the cable equation (Section 3.2.1). The conduction velocity is greatly increased by
myelin such that some nerves reach 70-80 m/s (Debanne et al., 2011).

3.4 Compartmental models
75
Example: Propagation speed with simpliﬁed action potential dynamics
Using the simpliﬁcation of the ion channel dynamics in Eq. (3.39) for each node
Cdun
dt =
1
LrL
(un+1(t)−2un(t)+un−1(t))−
g
1−aun(t)(un(t)−1)(un(t)−a)
(3.43)
where g and a < 1/2 are parameters regulating the excitability of the node. Unlike
Eq. (3.39), the parameter g has units of conductance per node since the nodes of Ran-
vier are discrete segments. An activated node may fail to excite the adjacent nodes if the
membrane potential does not reach u = a. In this model, the internodal distance must
satisfy (Erneux and Nicolis, 1993)
L < L∗= 1−a
4a2rLg
(3.44)
for propagation to be sustained. When the internodal distance L is smaller than L∗,
propagation will fail. When the internodal distance is larger, propagation will succeed.
The propagation velocity for small L∗−L follows (Binczak et al., 2001)
v ≈
πga
(1−a)C

L(L∗−L)
(3.45)
which is maximum at L = L∗/2. Since, in most myelinated axons, internodal distance
scales linearly with their radius (Waxman, 1980), the velocity of myelinated axons also
scales linearly with radius, v ∝L ∝ρ.
3.4 Compartmental models
We have seen that analytical solutions can be given for the voltage along a passive cable
with uniform geometrical and electrical properties. If we want to apply the above results in
order to describe the membrane potential along the dendritic tree of a neuron we face sev-
eral problems. Even if we neglect "active" conductances formed by nonlinear ion channels,
a dendritic tree is at most locally equivalent to a uniform cable. Numerous bifurcations and
variations in diameter and electrical properties along the dendrite render it difﬁcult to ﬁnd
a solution for the membrane potential analytically (Abbott et al., 1991).
Numerical treatment of partial differential equations such as the cable equation requires
a discretization of the spatial variable. Hence, all derivatives with respect to spatial vari-
ables are approximated by the corresponding quotient of differences. Essentially we are
led back to the discretized model of Fig. 3.5 that has been used as the starting point for the
derivation of the cable equation. After the discretization we have a large system of ordinary
differential equations for the membrane potential at the chosen discretization points as a
function of time. This system of ordinary differential equations can be treated by standard
numerical methods.

76
Dendrites and synapses
C m
RT
m
RL
1
2
RL
I
m
1
2
Fig. 3.8 Multi-compartment neuron model. Dendritic compartments with membrane capacitance Cμ
and transversal resistance Rμ
T are coupled by a longitudinal resistance rμν = (Rμ
L +Rν
L)/2. External
input to compartment μ is denoted by Iμ. Some or all compartments may also contain nonlinear ion
channels (variable resistor in leftmost compartment).
In order to solve for the membrane potential of a complex dendritic tree numerically,
compartmental models are used that are the result of the above mentioned discretiza-
tion. The dendritic tree is divided into small cylindric compartments with an approxima-
tively uniform membrane potential. Each compartment is characterized by its capacity and
transversal conductivity. Adjacent compartments are coupled by the longitudinal resistance
determined by their geometrical properties (see Fig. 3.8).
Once numerical methods are used to solve for the membrane potential along the den-
dritic tree, some or all compartments can be equipped with nonlinear ion channels as
well. In this way, effects of nonlinear integration of synaptic input can be studied. Apart
from practical problems that arise from a growing complexity of the underlying differen-
tial equations, conceptual problems are related to a drastically increasing number of free
parameters. To avoid these problems, all nonlinear ion channels responsible for generating
spikes are usually lumped together at the soma and the dendritic tree is treated as a pas-
sive cable. For a review of the compartmental approach we refer the reader to Bower and
Beeman (1995). In the following we illustrate the compartmental approach by a model of
a pyramidal cell.
Example: A multi-compartment model of a deep-layer pyramidal cell
Software tools such as NEURON (Carnevale and Hines, 2006) or GENESIS (Bower
and Beeman, 1995) enable researchers to construct detailed compartmental models of
any type of neuron. The morphology of such a detailed model is constrained by the
anatomical reconstruction of the corresponding "real" neuron. This is possible if length,

3.4 Compartmental models
77
2
1
1
1
2
1
1
1
2
2
2
1
2
2
2
Vm
(a)
(b)
(c)
(d)
(e)
Vm
Vm
Vm
Istim
50 mV
10 ms
4 nA
Istim
Istim
Istim
Fig. 3.9 Bursting in a computational model of a deep layer cortical neuron. (a) Reconstruction of the
complete morphology indicating the location of injection and measurement sites marked "1" at the
soma, and "2" at the dendrite. (b) A current is injected into the dendrite (lower trace, marked "2")
mimicking an excitatatory postsynaptic current (EPSC). The model responds to the current injection
in the dendrite with a voltage deﬂection at the dendrite (upper trace marked "2") but hardly any
deﬂection at the soma ("1"). (c). A current pulse in the soma (lower trace, marked "1") causes an
action potential at the soma (voltage trace marked "1") that back-propagates as a broader voltage
pulse ("2") into the dendrite. (d) Coincidence of somatic current pulse and dendritic EPSC activates
calcium currents in the dendrites and causes a burst of spikes in the soma. (e) A single, but large
EPSC-shaped dendritic current can also activate calcium currents and leads to a delayed burst of
spikes in the soma. Image modiﬁed from Hay et al. (2011).
size and orientation of each dendritic segment are measured under a microscope, after
the neuron has been ﬁlled with a suitable dye. Before the anatomical reconstruction,
the electrophysiological properties of the neuron can be characterized by stimulating
the neuron with a time-dependent electric current. The presence of speciﬁc ion channel
types can be inferred, with genetic methods, from the composition of the intracellular
liquid, extracted from the neuron (Toledo-Rodriguez et al., 2004). The distribution of ion

78
Dendrites and synapses
channels across the dendrite is probably the least constrained parameter. It is sometimes
inferred from another set of experiments on neurons belonging to the same class. All the
experimental knowledge about the neuron is then condensed in a computational neuron
model. A good example is the model of a deep-layer cortical neuron with active dendrites
as modeled by Hay et al. (2011).
The complete morphology is divided into 200 compartments, none exceeding 20 μm
in length. Each compartment has its speciﬁc dynamics deﬁned by intracellular ionic
concentration, transversal ion ﬂux through modeled ion channels, and longitudinal cur-
rent ﬂux to connected compartments. The membrane capacitance is set to 1 μF/cm2 for
the soma and axon and to 2 μF/cm2 in the dendrites to compensate for the presence of
dendritic spines. A cocktail of ionic currents is distributed across the different compart-
ments. These are:
• the fast inactivating sodium current INa (Section 2.2.1),
• the persistent sodium current INaP (Section 2.3.3),
• the non-speciﬁc cation current Ih (Section 2.3.4),
• the muscarinic potassium current IM (Section 2.3.3),
• the small conductance calcium-activated potassium current IK[Ca] (Section 2.3.4),
• the fast non-inactivating potassium current IKv3.1 (Rettig et al., 1992) which is very
similar to the model of potassium current of the Hodgkin-Huxley model in Table 2.1,
• the high-voltage activated calcium current IHVA (mentioned in Section 2.3.3),
• the low-voltage activated calcium current IL(Avery and Johnston, 1996; Randall and
Tsien, 1997) (similar to the HVA channel but different parameters),
• and a calcium pump (Section 2.3.3).
In addition, the model contains a slow and a fast inactivating potassium current IKp, IKt,
respectively (Korngreen and Sakmann, 2000).
In the dendrites all these currents are modeled as uniformly distributed except Ih, IHVA
and IL. The ﬁrst one of these, Ih, is exponentially distributed along the main dendrite that
ascends from the deep layers with low Ih concentration to the top layers with large Ih
concentration (Kole et al., 2006). The two calcium channels were distributed with a uni-
form distribution in all dendrites except for a single hotspot with a concentration 100 and
10 times higher for IL and IHVA, respectively. Finally, the strength of each ionic current
was scaled by choosing the maximal conductance gion that best ﬁt experimental data.
This detailed compartmental model can reproduce quantitatively some features of the
deep-layer pyramidal neurons (Fig. 3.9). For example, a small dendritic current injection
results in a transient increase of the dendritic voltage, but only a small effect in the
soma (Fig. 3.9b). A sufﬁciently large current pulse in the soma initiates not only a spike
at the soma but also a back-propagating action potential traveling into the dendrites
(Fig. 3.9c). Note that it is the presence of sodium and potassium currents throughout the
dendrites that support the back-propagation. In order to activate the dendritic calcium
channels at the hotspot, either a large dendritic injection or a coincidence between the

3.5 Summary
79
back-propagating action potential and a small dendritic injection is required (Fig. 3.9d,
e). The activation of calcium channels in the hotspot introduces a large and long (around
40 ms) depolarizing current that propagates forward to the soma where it eventually
causes a burst of action potentials.
3.5 Summary
"Real" neurons are complex biophysical and biochemical entities. Before designing a
model it is therefore necessary to develop an intuition for what is important and what
can be safely neglected. Synapses are usually modeled as speciﬁc ion channels that open
for a certain time after presynaptic spike arrival. The geometry of the neuron can play an
important role in the integration of incoming signals because the effect of synaptic input on
the somatic membrane potential depends on the location of the synapses on the dendritic
tree. Though some analytic results can be obtained for passive dendrites, it is usually nec-
essary to resort to numerical methods and multi-compartment models in order to account
for the complex geometry and presence of active ion channels on neuronal dendrites.
Literature
The book Dendrites (Stuart et al., 2007) offers a comprehensive review of the role and
importance of dendrites from multiple points of view. An extensive description of cable
theory as applied to neuronal dendrites can be found in the collected works of Wilfrid Rall
(Segev et al., 1994). NEURON (Carnevale and Hines, 2006) and GENESIS (Bower and
Beeman, 1995) are important tools to numerically solve the system of differential equations
of compartmental neuron models. There are useful repositories of neuronal morpholo-
gies (see http://NeuroMorpho.Org for instance) and of published models on ModelDB
(http://senselab.med.yale.edu/modeldb). The deep-layer cortical neuron discussed in
this chapter is described in Hay et al. (2011). Potential computational consequences of
nonlinear dendrites are described in Mel (1994).
Exercises
1. Biophysical synapse model and its relation to other models
(a) Consider Eq. (3.4) and discuss its relation to Eq. (3.2). Hint: (i) Assume that the time course
γ(t) can be described by a short pulse (duration of 1 ms) and that the unbinding is on a time scale
β −1 > 10ms. (ii) Assume that the interval between two presynaptic spike arrivals is much larger
than β −1.
(b) Discuss the relation of the depressive synapse model in Eq. (3.8) with the biophysically model
in Eq. (3.4). Hint: (i) Assume that the interval between two presynaptic spikes is of the same order
β −1. (ii) In Eq. (3.8) consider a variable x = Prel/P0.

80
Dendrites and synapses
2. Transmitter-gated ion channel
For each of the following statements state whether it is correct or wrong:
(a) AMPA channels are activated by glutamate.
(b) AMPA channels are activated by AMPA.
(c) If the AMPA channel is open, AMPA can pass through the channel.
(d) If the AMPA channel is open, glutamate can pass through the channel.
(e) If the AMPA channel is open, potassium can pass through the channel.
3. Cable equation
(a) Show that the passive cable equation for the current is
∂
∂t i(t,x) = ∂2
∂x2 i(t,x)−i(t,x)+ ∂
∂x iext(t,x).
(3.46)
(b) Set the external current to zero and ﬁnd the mapping to the heat equation
∂
∂t y(t,x) = ∂2
∂x2 y(t,x).
(3.47)
Hint: Try y(t,x) = f(t)i(t,x) with some function f.
(c) Find the solution to the current equation in (a) for the inﬁnite cable receiving a short current
pulse at time t = 0 and show that the corresponding equation for y satisﬁes the heat equation
in (b).
4. Non-leaky cable
(a) Redo the derivation of the cable equation for the case of an inﬁnite one-dimensional passive
dendrite without transversal leak and show that the solution to the equation is of the form
u(x,t) =
 t
−∞dt′
 ∞
−∞dx′ Gd(t −t′,x−x′)iext(t′,x′)
(3.48)
where Gd is a Gaussian of the form
Gd(x,t) =
1

2πσ(t)
exp−
x2
2σ2(t).
(3.49)
Determine σ(t) and discuss the result.
(b) Use the method of mirror charges to discuss how the solution changes if the cable is semi-
inﬁnite and extends from zero to inﬁnity.
(c) Take the integral over space of the elementary solution of the non-leaky cable equation and
show that the value of the integral does not change over time. Give an interpretation of this result.
(d) Take the integral over space of the elementary solution of the normal leaky cable equation of
a passive dendrite and derive an expression for its temporal evolution. Give an interpretation of
your result.
5. Conduction velocity in unmyelinated axons
(a) Using the simpliﬁed ion channel dynamics of Eq. (3.39), transform x and t to dimensionless
variables using effective time and electrotonic constants.
(b) A traveling pulse solution will have the form u(x,t) = ˜u(x −vt) where v is the conduction
velocity. Find the ordinary differential equation that rules ˜u.
(c) Show that ˜u(y) =
1
1+exp(y) with traveling speed v = 1−2a
√
2 is a solution.

4
Dimensionality reduction and phase plane analysis
The ﬁring of action potentials has been successfully described by the Hodgkin-Huxley
model, originally for the spikes in the giant axon of the squid but also, with appropriate
modiﬁcations of the model, for other neuron types. The Hodgkin-Huxley model is deﬁned
by four nonlinear differential equations. The behavior of high-dimensional systems of non-
linear differential equations is difﬁcult to visualize - and even more difﬁcult to analyze. For
an understanding of the ﬁring behavior of the Hodgkin-Huxley model, we therefore need
to turn to numerical simulations of the model. In Section 4.1 we show, as an example,
some simulation results in search of the ﬁring threshold of the Hodgkin-Huxley model.
However, it remains to show whether we can get some deeper insights into the observed
behavior of the model.
Four equations are in fact just two more than two: in Section 4.2 we exploit the temporal
properties of the gating variables of the Hodgkin-Huxley model so as to approximate the
four-dimensional differential equation by a two-dimensional one. Two-dimensional differ-
ential equations can be studied in a transparent manner by means of a technique known as
"phase plane analysis." Section 4.3 is devoted to the phase plane analysis of generic neuron
models consisting of two coupled differential equations, one for the membrane potential
and the other for an auxiliary variable.
The mathematical tools of dimension reduction and phase plane analysis that are pre-
sented in Sections 4.2 and 4.3 will be repeatedly used throughout this book, in particular
in Chapters 5, 6, 16 and 18. As a ﬁrst application of phase plane analysis, we study in
Section 4.4 the classiﬁcation of neurons into type I and type II according to their frequency-
current relation. As a second application of phase plane analysis, we return in Section 4.5
to some issues around the notion of a "ﬁring threshold," which will be sketched now.
4.1 Threshold effects
Many introductory textbooks of neuroscience state that neurons ﬁre an action potential
if the membrane potential reaches a threshold. Since the onset of an action potential is
characterized by a rapid rise of the voltage trace, the onset points can be detected in exper-

82
Dimensionality reduction and phase plane analysis
iment recordings (Fig. 4.1a). Intuitively, the onset of an action potential occurs when the
membrane potential crosses the ﬁring threshold.
The ﬁring threshold is not only a useful concept for experimental neuroscience, it is also
at the heart of most integrate-and-ﬁre models and therefore central to Parts II and III of this
book. But does a ﬁring threshold really exist?
Experimenters inject currents into a single neuron to probe its ﬁring characteristics.
There is a large choice of potential current wave forms, but only few of these are rou-
tinely used in many labs. In this section we use current pulses and steps in order to explore
the threshold behavior of the Hodgkin-Huxley model.
4.1.1 Pulse input
A Hodgkin-Huxley model is stimulated by a short current pulse of 1 ms duration. If the
stimulus is strong enough, it elicits a spike. In Fig. 4.1a,b the amplitude of the stimulating
current is only slightly increased between the ﬁrst and second current pulse. The membrane
potential returns directly to the resting potential after the stimulus, while the neuron ﬁres
a spike in response to the second pulse. This seems to suggest that the voltage threshold
for spike ﬁring is just above the maximum voltage that is reached after the ﬁrst current
injection (upper horizontal dashed line in Fig. 4.1b.
Unfortunately, however, such an interpretation is incorrect. If we use a longer current
pulse of 100 ms duration and apply the same argument as before, we would ﬁnd a different
voltage threshold, indicated by the lower horizontal dashed line in Fig. 4.1b.
Despite the fact that neuronal action potential ﬁring is often treated as a threshold-
like behavior, such a threshold is not well deﬁned mathematically (Rinzel and Ermen-
trout, 1998; Koch et al., 1995). For practical purposes, however, the transition can be
treated as a threshold effect. However, the threshold we ﬁnd depends on the stimulation
protocol.
For a mathematical discussion of the threshold phenomenon, it is helpful to reduce the
system of four differential equations to two equations; this is the topic of Section 4.2. We
will return to pulse currents in Section 4.5.
Example: Short current pulse as voltage step
The above argument excludes a voltage threshold, but could there be a current thresh-
old? Instead of injecting a current of 1 ms duration we can use a shorter pulse that lasts
only half as long. Numerically, we ﬁnd that the minimal current necessary to trigger
an action potential of the Hodgkin-Huxley model is now twice as large as before. We
conclude that, for short current pulses, it is not the amplitude of the current that sets
the effective ﬁring threshold, but rather the integral of the current pulse or the charge.
Indeed, the more charge we put on the membrane the higher the voltage, simply because
of the capacitance C of the membrane. For very short current pulses

4.1 Threshold effects
83
(a)
(b)
Fig. 4.1 Firing threshold. (a) Experimental recording of membrane voltage (top) during stimulation
with a time-dependent current (bottom). The onset of spikes, deﬁned as the moment when the voltage
starts its upswing, is marked by open circles. The lowest and highest onset voltage during a recording
of 20 s are marked by dotted horizontal lines. Inset: Histogram of onset voltages; adapted from Mensi
et al. (2013). (b) Stimulation of the Hodgkin-Huxley model with pulse and step current. Voltage (top)
in response to pulses and steps (bottom). The apparent voltage threshold is higher (dotted lines in top
panel) for a pulse than for a step current. The critical currents are 16.6 μA/cm2 for the 1 ms pulse and
3.31 μA/cm2 for the step. Parameters of the Hodgkin-Huxley model as in Table 2.1.
I(t) = qδ(t) = lim
Δ→0
q
Δ
for 0 < t < Δ
and 0 otherwise.
(4.1)
The voltage of the Hodgkin-Huxley model increases at the moment of current injection
by an amount Δu = q/C where q is the charge of the current pulse (see Section 1.3.2).
If the model was at rest for t < 0, the new voltage u = urest + Δu can be used as the
initial condition for the numerical integration of the Hodgkin-Huxley model for times

84
Dimensionality reduction and phase plane analysis
t > 0. Thus, a short current pulse amounts to a step-like increase of the voltage by a ﬁxed
amount.
4.1.2 Step current input
In Chapter 2 we have seen that a constant input current I0 > Iθ can generate regular ﬁring.
In this paragraph we study the response of the Hodgkin-Huxley model to a step current of
the form
I(t) = I1 +ΔI Θ(t).
(4.2)
Here Θ(t) denotes the Heaviside step function, i.e., Θ(t) = 0 for t ≤0 and Θ(t) = 1 for
t > 0. At t = 0 the input jumps from a ﬁxed value I1 to a new value I2 = I1 + ΔI; see
Fig. 4.2a. We may wonder whether spiking for t > 0 depends only on the ﬁnal value I2 or
also on the step size ΔI.
The answer to this question is given by Fig. 4.2d. A large step ΔI facilitates the spike
initiation. For example, a target value I2 = 2μA/cm2 elicits a spike, provided that the step
size is large enough, but does not cause a spike if the step is small. The letter S in Fig. 4.2d
denotes the regime where only a single spike is initiated. Repetitive ﬁring (regime R) is
possible for I2 > 2.6μA/cm2, but must be triggered by sufﬁciently large current steps.
We may conclude from Fig. 4.2d that, when probing with step currents, there is neither a
unique current threshold for spike initiation nor for repetitive ﬁring. The trigger mechanism
for action potentials depends not only on I2 but also on the size of the current step ΔI.
Biologically, the dependence upon the step size arises from the different time constants
of activation and inactivation of the ion channels. Mathematically, the stimulation with step
currents can be analyzed transparently in two dimensions (Sections 4.3 and 4.4).
4.2 Reduction to two dimensions
A system of four differential equations, such as the Hodgkin-Huxley model, is difﬁcult to
analyze, so that normally we are limited to numerical simulations. A mathematical analysis
is, however, possible for a system of two differential equations.
In this section we perform a systematic reduction of the four-dimensional Hodgkin-
Huxley model to two dimensions. To do so, we have to eliminate two of the four variables.
The essential ideas of the reduction can also be applied to detailed neuron models that may
contain many different ion channels. In these cases, more than two variables would have to
be eliminated, but the procedure would be completely analogous (Kepler et al., 1992).
4.2.1 General approach
We focus on the Hodgkin-Huxley model discussed in Chapter 2 and start with two quali-
tative observations. First, we see from Fig. 2.3b that the time scale of the dynamics of the

4.2 Reduction to two dimensions
85
0
50
100
−80
−60
−40
u (mV)
0
50
100
t (ms)
−80
−60
−40
−20
0
20
u (mV)
0
50
100
−80
−60
−40
−20
0
20
u (mV)
0
50
100
t (ms)
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
I2 [µA/cm2]
0
1
2
3
4
5
6
ΔI [mA/cm2]
Q
R
S
I2
I1
t (ms)
t (ms)
(a)
(c)
(d)
(e)
(b)
Fig. 4.2 Phase diagram for stimulation with a step current. (a) The input current I(t) changes at t = 0
from I1 to I2. (b), (c), (e). Sample responses of the Hodgkin-Huxley model to step current input. (d)
The outcome of the simulation experiment as a function of the ﬁnal current I2 and the step size
ΔI = I2 −I1. Three regimes denoted by S, R, and Q may be distinguished. In Q no action potential is
initiated (quiet regime). In S, a single spike is initiated by the current step (single spike regime). In R,
periodic spike trains are triggered by the current step (repetitive ﬁring). Examples of voltage traces
in the different regimes are presented in the smaller graphs (b, c, e) with stimulation parameters
indicated by the ﬁlled circles in (d). Note that for the same ﬁnal current I2 (e.g., (d) 2.0 μA/cm2), the
neuron model emits a spike if the current step ΔI is large enough (regime S), or no spike if the step is
too small. For a ﬁnal current I2 = 3 μA/cm2, the model exhibits bistability between repetitive ﬁring
and quiescence.
gating variable m is much faster than that of the variables n and h.Moreover, the time scale
of m is fast compared with the membrane time constant τ = C/gL of a passive membrane,
which characterizes the evolution of the voltage u when all channels are closed. The rela-
tively rapid time scale of m suggests that we may treat m as an instantaneous variable. The
variable m in the ion current equation (2.5) of the Hodgkin-Huxley model can therefore
be replaced by its steady-state value, m(t) →m0[u(t)]. This is what we call a quasi steady-
state approximation which is possible because of the "separation of time scales" between
fast and slow variables.
Second, we see from Fig. 2.3b that the time constants τn(u) and τh(u) have similar
dynamics over the voltage u. Moreover, the graphs of n0(u) and 1 −h0(u) in Fig. 2.3a
are also similar. This suggests that we may approximate the two variables n and (1 −h)
by a single effective variable w. To keep the formalism slightly more general we use a
linear approximation (b−h) ≈an with some constants a,b and set w = b−h = an. With
h = b−w, n = w/a, and m = m0(u), Eqs. (2.4)-(2.5) become
Cdu
dt = −gNa[m0(u)]3 (b−w)(u−ENa)−gK
w
a
	4
(u−EK)−gL (u−EL)+I ,
(4.3)

86
Dimensionality reduction and phase plane analysis
(a)
(b)
Fig. 4.3 Phase plane u,w of a Hodgkin-Huxley model reduced to two dimensions. (a) The reduction
of the Hodgkin-Huxley model leads to a system of two equations, τ du/dt = F(u,w) + RI and τw
dw/dt = G(u,w). The ensemble of points with F(u,w) = 0 and G(u,w) = 0 is shown as a function
of voltage u and recovery variable w, based on Eqs. (4.3), (4.20) and (4.21). (b) As in (a), but for the
Morris-Lecar model (see text for details).
(a)
(b)
Fig. 4.4 Close-up of Fig. 4.3a and b. Solid lines: the sets of points with F(u,w) = 0 and G(u,w) = 0
are determined in the absence of stimulation (I = 0). Dashed line: in the presence of a constant
current I = I0 > 0, the set of points with du/dt = 0 is given F(u,w) = −RI0. The curve G(u,w) = 0
characterizing the points with dw/dt = 0 starts (for u →−∞) nearly horizontally at w = 0 and does
not change under stimulation.
or
du
dt = 1
τ [F(u,w)+RI] ,
(4.4)
with R = g−1
L , τ = RC and some function F. We now turn to the three equations (2.9).
The m equation has disappeared since m is treated as instantaneous. Instead of the two
equations (2.9) for n and h, we are left with a single effective equation
dw
dt = 1
τw
G(u,w),
(4.5)
where τw is a parameter and G a function that interpolates between dn/dt and dh/dt (see

4.2 Reduction to two dimensions
87
Section 4.2.2). Equations (4.4) and (4.5) deﬁne a general two-dimensional neuron model.
If we start with the Hodgkin-Huxley model and implement the above reduction steps we
arrive at functions F(u,w) and G(u,w) which are illustrated in Figs. 4.3a and 4.4a. The
mathematical details of the reduction of the four-dimensional Hodgkin-Huxley model to
the two equations (4.4) and (4.5) are given below.
Before we go through the mathematical steps, we present two examples of
two-dimensional neuron dynamics which are not directly derived from the Hodgkin-Huxley
model, but are attractive because of their mathematical simplicity. We will return to these
examples repeatedly throughout this chapter.
Example: Morris-Lecar model
Morris and Lecar (1981) proposed a simpliﬁed two-dimensional description of neu-
ronal spike dynamics. A ﬁrst equation describes the evolution of the membrane potential
u, the second equation the evolution of a slow "recovery" variable ˆw. The Morris-Lecar
equations read
C du
dt = −g1 ˆm0(u)(u−V1)−g2 ˆw(u−V2)−gL (u−VL)+I ,
(4.6)
d ˆw
dt = −1
τ(u) [ ˆw−w0(u)] .
(4.7)
If we compare Eq. (4.6) with Eq. (4.3), we note that the ﬁrst current term on the right-
hand side of Eq. (4.3) has a factor (b −w) which closes the channel for high voltage
and which is absent in (4.6). Another difference is that neither ˆm0 nor ˆw in Eq. (4.6)
have exponents. To clarify the relation between the two models, we could set ˆm0(u) =
[m0(u)]3 and ˆw = (w/a)4. In the following we consider Eqs. (4.6) and (4.7) as a model
in its own right and drop the hats over m0 and w.
The equilibrium functions shown in Fig. 2.3a typically have a sigmoidal shape. It is
reasonable to approximate the voltage dependence by
m0(u) = 1
2

1+tanh
u−u1
u2

,
(4.8)
w0(u) = 1
2

1+tanh
u−u3
u4

,
(4.9)
with parameters u1,...,u4, and to approximate the time constant by
τ(u) =
τw
cosh

u−u3
2u4
	
(4.10)
with a further parameter τw. With the above assumptions, the zero-crossings of functions
F(u,w) and G(u,w) of the Morris-Lecar model have the shape illustrated in Fig. 4.3b.
The Morris-Lecar model (4.6)-(4.10) gives a phenomenological description of action

88
Dimensionality reduction and phase plane analysis
potentials. We shall see later on that the mathematical conditions for the ﬁring of action
potentials in the Morris-Lecar model can be discussed by phase plane analysis.
Example: FitzHugh-Nagumo model
FitzHugh and Nagumo where probably the ﬁrst to propose that, for a discussion of
action potential generation, the four equations of Hodgkin and Huxley can be replaced
by two, i.e., Eqs. (4.4) and (4.5). They obtained sharp pulse-like oscillations reminiscent
of trains of action potentials by deﬁning the functions F(u,w) and G(u,w) as
F(u,w) = u−1
3u3 −w,
G(u,w) = b0 +b1 u−w,
(4.11)
where u is the membrane voltage and w is a recovery variable (FitzHugh, 1961; Nagumo
et al., 1962). Note that both F and G are linear in w; the sole nonlinearity is the cubic
term in u. The FitzHugh-Nagumo model is one of the simplest models with non-trivial
behavior lending itself to a phase plane analysis, which will be discussed below in Sec-
tions 4.3-4.5.
4.2.2 Mathematical steps (*)
The reduction of the Hodgkin-Huxley model to Eqs. (4.4) and (4.5) presented in this sec-
tion is inspired by the geometrical treatment of Rinzel (1985); see also the slightly more
general method of Abbott and Kepler (1990) and Kepler et al. (1992).
The overall aim of the approach is to replace the variables n and h in the Hodgkin-
Huxley model by a single effective variable w. At each moment of time, the values
(n(t),h(t)) can be visualized as points in the two-dimensional plane spanned by n and
h; see Fig. 4.5b. We have argued above that the time course of the scaled variable an is
expected to be similar to that of b−h. If, at each time, an(t) were equal to b−h(t), then all
possible points (n,h) would lie on the straight line h = b−an which changes through (0,b)
and (1,b−a). It would be unreasonable to expect that all points (n(t),h(t)) that occur dur-
ing the temporal evolution of the Hodgkin-Huxley model fall exactly on that line. Indeed,
during an action potential (Fig. 4.5a), the variables n(t) and h(t) stay close to a straight line,
but are not perfectly on it (Fig. 4.5b). The reduction of the number of variables is achieved
by a projection of those points onto the line. The position along the line h = b−an gives
the new variable w; see Fig. 4.6. The projection is the essential approximation during the
reduction.
To perform the projection, we will proceed in three steps. A minimal condition for the
projection is that the approximation introduces no error while the neuron is at rest. As a ﬁrst
step, we therefore shift the origin of the coordinate system to the rest state and introduce

4.2 Reduction to two dimensions
89
(a)
(b)
Fig. 4.5 Similarity of gating variables h and n. (a). After stimulation of the Hodgkin-Huxley model
by a short current pulse, the membrane potential (solid line) exhibits an action potential. The time
course of the variables n (dashed line) mirrors that of the variable h (dot-dashed). (b). During and
after the action potential, the trajectory of the variables n(t) and h(t) (solid line) stays very close
to the straight line h = b −an (dashed) with slope a and offset b. The point (n0(urest),h0(urest)) is
indicated with a circle.
new variables
x = n−n0(urest),
(4.12)
y = h−h0(urest).
(4.13)
At rest, we have x = y = 0.
Second, we turn the coordinate system by an angle α which is determined as follows.
For a given constant voltage u, the dynamics of the gating variables n and h approaches
the equilibrium values (n0(u),h0(u)). The points (n0(u),h0(u)) as a function of u deﬁne a
curve in the two-dimensional plane. The slope of the curve at u = urest yields the rotation
angle α via
tanα =
dh0
du |urest
dn0
du |urest
.
(4.14)
Rotating the coordinate system by α turns the abscissa e1 of the new coordinate system in
a direction tangential to the curve. The coordinates (z1,z2) in the new system are
 z1
z2

=

cosα
sinα
−sinα
cosα
  x
y

.
(4.15)

90
Dimensionality reduction and phase plane analysis
h
1
e1
e2
n0(urest) 
h0(urest)
n
(n,h)
1
Fig. 4.6
Mathematical reduction: arbitrary
points (n,h) are projected onto the line in
direction of e1 and passing through the point
(n0(urest),h0(urest)). The dotted line gives
the curve (n0(u),h0(u)).
Third, we set z2 = 0 and retain only the coordinate z1 along e1. The inverse transform,
 x
y

=
 cosα
−sinα
sinα
cosα
  z1
z2

,
(4.16)
yields x = z1 cosα and y = z1 sinα since z2 = 0. Hence, after the projection, the new values
of the variables n and h are
n′ = n0(urest)+z1 cosα ,
(4.17)
h′ = h0(urest)+z1 sinα .
(4.18)
In principle, z1 can directly be used as the new effective variable. From (4.15) we ﬁnd
the differential equation
dz1
dt = cosα dn
dt +sinα dh
dt .
(4.19)
We use Eq. (2.6) and replace, on the right-hand side, n(t) and h(t) by (4.17) and (4.18).
The result is
dz1
dt = −cosα z1 cosα +n0(urest)−n0(u)
τn(u)
−sinα z1 sinα +h0(urest)−h0(u)
τh(u)
,
(4.20)
which is of the form dz1/dt = G(u,z1), as desired.
To see the relation to Eqs. (4.3) and (4.5), it is convenient to rescale z1 and deﬁne
w = −tanα n0(urest)−z1 sinα .
(4.21)
If we introduce a = −tanα and b = an0(urest) + h0(urest), we ﬁnd from Eq. (4.17) the
variable n′ = w/a and from Eq. (4.18) h′ = b −w, which are exactly the approximations
that we used in (4.3). The differential equation for the variable w is of the desired form
dw/dt = G(u,w) and can be found from Eqs. (4.20) and (4.21). The resulting function
G(u,w) of the two-dimensional model is illustrated in Fig. 4.3a.

4.3 Phase plane analysis
91
−2
−1
0
1
2
u
−1
−0.5
0
0.5
1
(a)
w
−2
−1
0
1
2
u
−1
−0.5
0
0.5
1
(b)
w
Fig. 4.7 (a) Phase portrait of the FitzHugh-Nagumo model. The u-nullcline (curved line) and the
w-nullcline (straight line) intersect at the three ﬁxed points. The direction of the arrows indicates
the ﬂow ( ˙u, ˙w)T . (b) Arrows on the u-nullcline point vertically upward or downward, while on the
w-nullcline arrows are horizontal. In the neighborhood of the ﬁxed points, arrows have a short length
indicating slow movement. At the ﬁxed point, the direction of the arrows change.
Example: Further simpliﬁcation
We may further approximate the time constants τn and τh by a common function τ(u)
so that the dynamics of w is
dw
dt = −1
τ(u) [w−w0(u)] ,
(4.22)
with a new equilibrium function w0(u) that is a linear combination of the functions h0
and n0. From Eqs. (4.20) and (4.21) we ﬁnd
w0(u) = −sinα [cosα n0(u)+sinα h0(u)−bsinα].
(4.23)
In practice, w0(u) and τ(u) can be ﬁtted by the expressions (4.9) and (4.10), respectively.
4.3 Phase plane analysis
In two-dimensional models, the temporal evolution of the variables (u,w)T can be visual-
ized in the so-called phase plane. From a starting point (u(t),w(t))T the system will move
in a time Δt to a new state (u(t +Δt),w(t +Δt))T which has to be determined by integra-
tion of the differential equations (4.4) and (4.5). For Δt sufﬁciently small, the displacement
(Δu,Δw)T is in the direction of the ﬂow ( ˙u, ˙w)T, i.e.,
Δu
Δw

=
 ˙u
˙w

Δt ,
(4.24)

92
Dimensionality reduction and phase plane analysis
w.>0
w. =0
w.<0
u.>0
u.<0
u.=0
u
w
(a) Stable (node)
u.< 0
u.> 0
w.> 0
w.< 0
u
w
w. =0
u.=0
(b) Stable or unstable
w. > 0
w. = 0
w. < 0
u. > 0
u. =0
u. <0
u
w
(c) Unstable (saddle)
u.> 0
u.< 0
w.< 0
w.> 0
u. =0
u
w
w. = 0
(d) Unstable (saddle)
Fig. 4.8 Four examples of phase portraits around a ﬁxed point. Case (a) is stable, cases (c) and (d)
are unstable. Stability in case (b) cannot be decided with the information available from the picture
alone. Cases (c) and (d) are saddle points.
which can be plotted as a vector ﬁeld in the phase plane. Here ˙u = du/dt is given by (4.4)
and ˙w = dw/dt by (4.5). The ﬂow ﬁeld is also called the phase portrait of the system. An
important tool in the construction of the phase portrait is the nullcline, which is introduced
now.
4.3.1 Nullclines
Let us consider the set of points with ˙u = 0, called the u-nullcline. The direction of ﬂow on
the u-nullcline is in the direction of (0, ˙w)T, since ˙u = 0. Hence arrows in the phase portrait
are vertical on the u-nullcline. Similarly, the w-nullcline is deﬁned by the condition ˙w = 0
and arrows are horizontal. The ﬁxed points of the system, deﬁned by ˙u = ˙w = 0 are given
by the intersection of the u-nullcline and the w-nullcline. In Fig. 4.7 we have three ﬁxed
points.
So far we have argued that arrows on the u-nullcline are vertical, but we do not know
yet whether they point up or down. To get the extra information needed, let us return
to the w-nullcline. By deﬁnition, it separates the region with ˙w > 0 from the area with
˙w < 0. Suppose we evaluate G(u,w) on the right-hand side of Eq. (4.5) at a single point,
e.g., at (0,−1). If G(0,−1) > 0, then the whole area on that side of the w-nullcline has
˙w > 0. Hence, all arrows along the u-nullcline that lie on the same side of the w-nullcline

4.3 Phase plane analysis
93
w. =0 
u.=0
u
w
Fig. 4.9 Bounding surface around an unstable ﬁxed point and the limit cycle (schematic ﬁgure).
as the point (0,−1) point upward. The direction of arrows normally1 changes where the
nullclines intersect; see Fig. 4.7b.
4.3.2 Stability of Fixed Points
In Fig. 4.7 there are three ﬁxed points, but which of these are stable? The local stability of
a ﬁxed point (uFP,wFP) is determined by linearization of the dynamics at the intersection.
With x = (u−uFP,w−wFP)T , we have after the linearization
d
dt x =
Fu
Fw
Gu
Gw

x,
(4.25)
where Fu = ∂F/∂u, Fw = ∂F/∂w, . . . , are evaluated at the ﬁxed point. To study the stability
we set x(t) = e exp(λt) and solve the resulting eigenvalue problem. There are two solutions
with eigenvalues λ+ and λ−and eigenvectors e+ and e−, respectively. Stability of the ﬁxed
point x = 0 in Eq. (4.25) requires that the real part of both eigenvalues be negative. The
solution of the eigenvalue problem yields λ+ +λ−= Fu +Gw and λ+ λ−= FuGw −FwGu.
The necessary and sufﬁcient condition for stability is therefore
Fu +Gw < 0
and
FuGw −FwGu > 0.
(4.26)
If FuGw −FwGu < 0, then the imaginary part of both eigenvalues vanishes. One of the
eigenvalues is positive, the other one negative. The ﬁxed point is then called a saddle point.
Eq. (4.25) is obtained by Taylor expansion of Eqs. (4.4) and (4.5) to ﬁrst order in x. If
the real part of one or both eigenvalues of the matrix in Eq. (4.25) vanishes, the complete
characterization of the stability properties of the ﬁxed point requires an extension of the
Taylor expansion to higher order.
1Exceptions are the rare cases where the function F or G is degenerate: for example, F(u,w) = w2.

94
Dimensionality reduction and phase plane analysis
Example: Linear model
Let us consider the linear dynamics
˙u = au−w,
˙w = ε (bu−w),
(4.27)
with positive constants b,ε > 0. The u-nullcline is w = au, the w-nullcline is w = bu.
For the moment we assume a < 0. The phase diagram is that of Fig. 4.8a. Note that by
decreasing the parameter ε, we may slow down the w-dynamics in Eq. (4.27) without
changing the nullclines.
Because Fu +Gw = a−ε < 0 for a < 0 and FuGw −FwGu = ε (b−a) > 0, it follows
from (4.26) that the ﬁxed point is stable. Note that the phase portrait around the left ﬁxed
point in Fig. 4.7 has locally the same structure as the portrait in Fig. 4.8a. We conclude
that the left ﬁxed point in Fig. 4.7 is stable.
Let us now keep the w-nullcline ﬁxed and turn the u-nullcline by increasing a to pos-
itive values; see Fig. 4.8b and c. Stability is lost if a > min{ε,b}. Stability of the ﬁxed
point in Fig. 4.8b can therefore not be decided without knowing the value of ε. On
the other hand, in Fig. 4.8c we have a > b and hence FuGw −FwGu = ε (b −a) < 0.
In this case one of the eigenvalues is positive (λ+ > 0) and the other one nega-
tive (λ−< 0), hence we have a saddle point. The imaginary parts of the eigenvalues
vanish. The eigenvectors e−and e+ are therefore real and can be visualized in the
phase space. A trajectory through the ﬁxed point in the direction of e−is attracted
toward the ﬁxed point. This is, however, the only direction by which a trajectory may
reach the ﬁxed point. Any small perturbation around the ﬁxed point which is not
strictly in the direction of e2 will grow exponentially. A saddle point as in Fig. 4.8c
plays an important role in so-called type I neuron models that will be introduced in
Section 4.4.1.
For the sake of completeness we also study the linear system
˙u = −au+w,
˙w = ε (bu−w), with 0 < a < b,
(4.28)
with positive constants a, b, and ε. This system is identical to Eq. (4.27) except that the
sign of the ﬁrst equation is ﬂipped. As before we have nullclines w = au and w = bu; see
Fig. 4.8d. Note that the nullclines are identical to those in Fig. 4.8b, only the direction
of the horizontal arrows on the w-nullcline has changed.
Since FuGw −FwGu = ε (a −b), the ﬁxed point is unstable if a < b. In this case, the
imaginary part of the eigenvalues vanish and one of the eigenvalues is positive (λ+ > 0)
while the other one is negative (λ−< 0). Thus the ﬁxed point can be classiﬁed as a
saddle point.
One of the attractive features of phase plane analysis is that there is a direct method
to show the existence of limit cycles. The theorem of Poincar´e-Bendixson (Hale and

4.3 Phase plane analysis
95
(a)
(b)
(c)
(d)
Fig. 4.10 (a) The nullclines of the FitzHugh-Nagumo model for zero input. The thin curved line
is the u-nullcline; the w-nullcline is the straight line, w = b0 + b1u, with b0 = 0.9,b1 = 1.0. The
thick line is a trajectory that starts at (−2,−0.5) (open square) and converges to the ﬁxed point at
(−1.1,−0.5). (b) Time course of the membrane potential of the trajectory shown in (a). (c) Same as
in (a) but with positive input I = 2 so that the ﬁxed point in (a) is replaced by a limit cycle (thick
line). (d) Voltage time course of the trajectory shown in (c). Trajectories are the result of numerical
integration of Eqs. (4.29) and (4.30) with ε = 1.25.
Koc¸ac, 1991) tells us that, if (i) we can construct a bounding surface around a ﬁxed
point so that all ﬂux arrows on the surface are pointing toward the interior, and (ii) the
ﬁxed point in the interior is repulsive (real part of both eigenvalues positive), then there
must exist a stable limit cycle around that ﬁxed point.
The proof follows from the uniqueness of solutions of differential equations, which
implies that trajectories cannot cross each other. If all trajectories are pushed away from
the ﬁxed point, but cannot leave the bounded surface, then they must ﬁnally settle on a
limit cycle; see Fig. 4.9. Note that this argument holds only in two dimensions.
In dimensionless variables the FitzHugh-Nagumo model is
du
dt = u−1
3u3 −w+I,
(4.29)
dw
dt = ε (b0 +b1 u−w).
(4.30)

96
Dimensionality reduction and phase plane analysis
ν
I
Iθ
(a)
ν
I
Iθ
(b)
Fig. 4.11 (a) Gain function for models of type I. The frequency ν during a limit cycle oscillation
is a continuous function of the applied current I. (b) The gain function of type II models has a
discontinuity.
Time is measured in units of τ, and ε = τ/τw is the ratio of the two time scales. The
u-nullcline is w = u −u3/3 + I with maxima at u = ±1. The maximal slope of the
u-nullcline is dw/du = 1 at u = 0; for I = 0 the u-nullcline has zeros at 0 and ±
√
3. For
I ̸= 0 the u-nullcline is shifted vertically. The w-nullcline is a straight line w = b0 + b1 u.
For b1 > 1, there is always exactly one intersection, for any I. The two nullclines are shown
in Fig. 4.10.
A comparison of Fig. 4.10a with the phase portrait of Fig. 4.8a, shows that the ﬁxed
point is stable for I = 0. If we increase I the intersection of the nullclines moves to the
right; see Fig. 4.10c. According to the calculation associated with Fig. 4.8b, the ﬁxed point
loses stability as soon as the slope of the u-nullcline becomes larger than ε. It is possible
to construct a bounding surface around the unstable ﬁxed point so that we know from the
Poincar´e-Bendixson theorem that a limit cycle must exist. Figures 4.10a and 4.10c show
two trajectories, one for I = 0 converging to the ﬁxed point and another one for I = 2
converging toward the limit cycle. The horizontal phases of the limit cycle correspond to
a rapid change of the voltage, which results in voltage pulses similar to a train of action
potentials; see Fig. 4.10d.
4.4 Type I and type II neuron models
We have already seen in Chapter 2 that neuron models fall into two classes: those with a
continuous frequency-current curve are called type I whereas those with a discontinuous
frequency-current curve are called type II. The characteristic curves for both model types
are illustrated in Fig. 4.11. The onset of repetitive ﬁring under constant current injection is
characterized by a minimal current Iθ, also called the rheobase current.
For two-dimensional neuron models, the ﬁring behavior of both neuron types can be
understood by phase plane analysis. To do so we need to observe the changes in structure
and stability of ﬁxed points when the current passes from a value below Iθ to a value just
above Iθ, where Iθ determines the onset of repetitive ﬁring. Mathematically speaking, the
point Iθ where the transition in the number or stability of ﬁxed points occurs is called a
bifurcation point and I is the bifurcation parameter.

4.4 Type I and type II neuron models
97
Fig. 4.12 Saddle-node bifurcation. The u-nullcline is represented as a parabola that moves upward
as the current is increased (from left to right). The saddle point is shown as an open circle and the
node as a ﬁlled circle. When the current is increased, the two ﬁxed points, which are initially far apart
(left), move closer together (middle) and ﬁnally annihilate (right).
Example: Number of ﬁxed points changes at bifurcation
Let us recall that the ﬁxed points of the system lie at the intersection of the u-nullcline
with the w-nullcline. Fig. 4.3 shows examples of two-dimensional neuron models where
the u-nullcline crosses the w-nullclines three times so that the models exhibit three ﬁxed
points. If the external driving current I is slowly increased, the u-nullcline shifts verti-
cally upward.2 If the driving current I becomes strong enough, the two left-most ﬁxed
points merge and disappear; see Fig. 4.4. The moment when the two ﬁxed points dis-
appear is the bifurcation point. At this point a qualitative change in the dynamics of the
neuron model is observed, e.g., the transition from the resting state to periodic ﬁring.
These changes are discussed in the following subsections.
4.4.1 Type I models and saddle-node-onto-limit-cycle bifurcation
Neuron models with a continuous gain function are called type I. Mathematically, a saddle-
node-onto-limit-cycle bifurcation generically gives rise to a type I behavior, as we will
explain now.
For zero input and weakly positive input, we suppose that our neuron model has three
ﬁxed points in a conﬁguration such as that in Fig. 4.13: a stable ﬁxed point (node) to the
left, a saddle point in the middle, and an unstable ﬁxed point to the right. If I is increased,
the u-nullcline moves upward and the stable ﬁxed point merges with the saddle and disap-
pears (Fig. 4.12). We are left with the unstable ﬁxed point around which there must be a
limit cycle provided the ﬂux is bounded. If the limit cycle passes through the region where
the saddle and node disappeared, the scenario is called a saddle-node-onto-limit-cycle
bifurcation.
Can we say anything about the frequency of the limit cycle? Just before the transition
point where the two ﬁxed points merge, the system exhibits a stable ﬁxed point which
(locally) attracts trajectories. As a trajectory gets close to the stable ﬁxed point, its velocity
1It may also undergo some changes in shape, but these are not relevant for the following discussion.

98
Dimensionality reduction and phase plane analysis
(a)
(b)
(c)
(d)
Fig. 4.13 (a) The nullclines of the Morris-Lecar model for zero input. The w-nullcline is ﬂat at low
u but increases monotonically above u = −20, the u-nullcline is the nonlinear curve crossing the w-
nullcline in three points. (a) Trajectory starting at (−65,−0.15) (open square) converges to the stable
ﬁxed point at (-59,0) (ﬁlled circle). (b) Time course of the membrane potential of the trajectory shown
in (a). (c) Same as in (a) but with positive input I = 45. The stable ﬁxed point in (a) has merged with
the saddle (open circle in (a)) and disappeared leaving a limit cycle around the third, unstable, ﬁxed
point. (d) Voltage time course of the trajectory shown in (c). Trajectories are the results of numerical
integration of Eqs. (4.6)-(4.10).
decreases until it ﬁnally stops at the ﬁxed point. Let us now consider the situation where
the driving current is a bit larger so that I = Iθ. This is the transition point, where the two
ﬁxed points merge and a new limit cycle appears. At the transition point the limit cycle has
zero frequency because it passes through the two merging ﬁxed points where the velocity
of the trajectory is zero. If I is increased a little, the limit cycle still "feels" the "ghost" of
the disappeared ﬁxed points in the sense that the velocity of the trajectory in that region is
very low. While the ﬁxed points have disappeared, the "ruins" of the ﬁxed points are still
present in the phase plane. Thus the onset of oscillation is continuous and occurs with zero
frequency. Models which fall into this class are therefore of type I; see Fig. 4.11.
From the above discussion it should be clear that, if we increase I, we encounter a
transition point where two ﬁxed points disappear, namely, the saddle and the stable ﬁxed
point (node). At the same time a limit cycle appears. If we come from the other side, we
have ﬁrst a limit cycle which disappears at the moment when the saddle-node pair shows
up. The transition is therefore called a saddle-node bifurcation on a limit cycle.

4.4 Type I and type II neuron models
99
(a)
(b)
(c)
(d)
Fig. 4.14 Reduced Hodgkin-Huxley model with nullclines and dynamics of a type I model. (a) For
weakly positive input, the u-nullcline has three intersections with the w-nullcline. (b) Zoom onto
the two left-most ﬁxed points. A trajectory (thick solid line) is attracted toward the left ﬁxed point.
(c) For input I > Iθ , the u-nullcline is shifted vertically and only one ﬁxed point remains which is
unstable. The trajectory starting from the same initial condition as in (a) turns into a limit cycle. (d)
Zoom onto the same region as in (b). The limit cycle passes through the region where the two ﬁxed
points have been before, but these ﬁxed points have now disappeared. The nearly vanishing length
of the arrows indicates that movement of the trajectory in this region is very slow giving rise to a
near-zero ﬁring frequency.
Example: Morris-Lecar model
Depending on the choice of parameters, the Morris-Lecar model is of either type I
or type II. We consider a parameter set where the Morris-Lecar model has three ﬁxed
points located such that two of them lie in the unstable region where the u-nullcline has
large positive slope as indicated schematically in Fig. 4.13. Comparison of the phase
portrait of Fig. 4.13 with that of see Fig. 4.8 shows that the left ﬁxed point is stable as in
Fig. 4.8a, the middle one is a saddle point as in Fig. 4.8c, and the right one is unstable
as in Fig. 4.8b provided that the slope of the u-nullcline is sufﬁciently positive. Thus
we have the sequence of three ﬁxed points necessary for a saddle-node-onto-limit-cycle
bifurcation.

100
Dimensionality reduction and phase plane analysis
Example: Hodgkin-Huxley model reduced to two dimensions
The reduced Hodgkin-Huxley model of Fig. 4.3a has three ﬁxed points. Stability
analysis of the ﬁxed points or comparison of the phase portrait of this model in Fig. 4.14a
with the standard cases in Fig. 4.8 shows that the left ﬁxed point is stable, the middle
one is a saddle, and the right one is unstable. If a step current I is applied, the u-nullcline
undergoes some minor changes in shape, but mainly shifts upward. If the step is big
enough, two of the ﬁxed points disappear. The resulting limit cycle passes through the
ruins of the ﬁxed point; see Figs. 4.14c and 4.14d.
4.4.2 Type II models and saddle-node-off-limit-cycle bifurcation
There is no fundamental reason why a limit cycle should appear at a saddle-node bifurca-
tion. Indeed, in one-dimensional differential equations, saddle-node bifurcations are pos-
sible, but never lead to a limit cycle. Moreover, if a limit cycle exists in a two-dimensional
system, there is no reason why it should appear directly at the bifurcation point - it can
also exist before the bifurcation point is reached. In this case, the limit cycle does not pass
through the ruins of the ﬁxed point and therefore has ﬁnite frequency. This gives rise to a
type II neuron model. The corresponding bifurcation can be classiﬁed as saddle-node-off-
limit-cycle.
Example: Hodgkin-Huxley model reduced to two dimensions
Fig. 4.15 shows the same neuron model as Fig. 4.14 except for one single change in
parameter: the time scale τw in Eq. (4.5) for the w-dynamics is slightly faster. While the
position and shape of the nullclines is unchanged, the dynamics are different.
To understand the difference we focus on Fig. 4.15d. The limit cycle triggered by a
current step does not touch the region where the ruins of the ﬁxed points lie, but passes
further to the right. Thus the bifurcation is of the type saddle-node-off-limit-cycle, the
limit cycle has ﬁnite frequency, and the neuron model is of type II.
Example: Saddle-node without limit cycle
Not all saddle-node bifurcations lead to a limit cycle. If the slope of the w-nullcline
of the FitzHugh-Nagumo model deﬁned in Eqs. (4.29) and (4.30) is smaller than 1, it
is possible to have three ﬁxed points, one of them unstable and the other two stable;
see Fig. 4.7. The system is therefore bistable. If a positive current I > 0 is applied the
u-nullcline moves upward. Eventually the left stable ﬁxed point and the saddle merge
and disappear via a (simple) saddle-node bifurcation. Since the right ﬁxed point remains
stable, no oscillation occurs.

4.4 Type I and type II neuron models
101
(a)
(b)
(c)
(d)
Fig. 4.15 Reduced Hodgkin-Huxley model with nullclines and dynamics of a type II model. (a) For
weakly positive input, the u-nullcline (solid line) has three intersections with the w-nullcline (dashed
line). (b) Zoom onto the two left-most ﬁxed points. A trajectory (thick solid line) is attracted toward
the left ﬁxed point. (c) For input I > Iθ, only one ﬁxed point remains which is unstable. The trajectory
starting from the same initial condition as in A turns into a limit cycle. (d) Zoom onto the same region
as in (b). The limit cycle passes to the right of the region where the two ﬁxed points have been in
(b). Arrows along the limit cycle indicate ﬁnite speed of the trajectory, so that the limit cycle has a
nonzero ﬁring frequency.
4.4.3 Type II models and Hopf bifurcation
The typical jump from zero to a ﬁnite ﬁring frequency, observed in the frequency-current
curve of type II models can arise by different bifurcation types. One important example is
a Hopf bifurcation.
Let us recall that the ﬁxed points of the system lie at the intersection of the u-nullcline
with the w-nullcline. In the FitzHugh-Nagumo model, with parameters as in Fig. 4.10,
there is always a single ﬁxed point whatever the (constant) driving current I. Nevertheless,
while I is slowly increased, the behavior of the system changes qualitatively from a stable
ﬁxed point to a limit cycle; see Fig. 4.10. The transition occurs when the ﬁxed point loses
its stability.
From the solution of the stability problem in Eq. (4.25) we know that the eigenval-
ues λ+/−form a complex conjugate pair with a real part γ and a imaginary part +/ −ω

102
Dimensionality reduction and phase plane analysis
Im(l)  
Re(l) 
a
Supercritical
Subcritical
w
w
g
t
t
w -1
Unstable fixed point (g > 0)
Stable fixed point (g <0)
g 
a
Re(l) 
Fig. 4.16
Hopf bifurcation. Top: Complex plane of eigenvalues. When the bifurcation parameter
increases, the real part of the complex eigenvalues λ+/−= γ ±iω passes at the bifurcation point from
a negative value (γ < 0) to a positive one. Associated stable and unstable oscillatory solutions are
shown in left and right insets, respectively. Bottom: Amplitude a of oscillatory solutions as a function
of γ. For γ < 0 the ﬁxed point (constant solution) is stable corresponding to an oscillation of zero
amplitude. At the bifurcation point, the constant solution loses its stability (dashed line) and a novel
oscillatory solution appears. The amplitude of the oscillatory solution increases continuously. For a
supercritical Hopf bifurcation the oscillatory solution is stable (solid line) whereas for a subcritical
Hopf bifurcation, it is unstable close to the bifurcation point. The linear bifurcation analysis is valid
only in the direct neighborhood of the bifurcation point (dashed box) and cannot predict the stable
limit cycle (solid line) of the subcritical Hopf bifurcation.
(Fig. 4.16). The ﬁxed point is stable if γ < 0. At the transition point, the real part vanishes
and the eigenvalues are
λ± = ±i

FuGw −GuFw .
(4.31)
These eigenvalues correspond to an oscillatory solution (of the linearized equation) with a
frequency given by ω = √FuGw −GuFw. The above scenario of stability loss in combina-
tion with an emerging oscillation is called a Hopf bifurcation.
Unfortunately, the discussion so far does not tell us anything about the stability of the
oscillatory solution. If the new oscillatory solution, which appears at the Hopf bifurcation,
is itself unstable (which is more difﬁcult to show), the scenario is called a subcritical Hopf
bifurcation (Fig. 4.16). This is the case in the FitzHugh-Nagumo model where, owing to
the instability of the oscillatory solution in the neighborhood of the Hopf bifurcation, the
system blows up and approaches another limit cycle of large amplitude; see Fig. 4.10.
The stable large-amplitude limit cycle solution exists, in fact, slightly before I reaches the

4.5 Threshold and excitability
103
critical value of the Hopf bifurcation. Thus there is a small regime of bistability between
the ﬁxed point and the limit cycle.
In a supercritical Hopf bifurcation, on the other hand, the new periodic solution is stable.
In this case, the limit cycle would have a small amplitude if I is just above the bifurcation
point. The amplitude of the oscillation grows with the stimulation I (Fig. 4.16). Such peri-
odic oscillations of small amplitude are not linked to neuronal ﬁring, but must rather be
interpreted as spontaneous subthreshold oscillations.
Whenever we have a Hopf bifurcation, be it subcritical or supercritical, the limit cycle
starts with ﬁnite frequency. Thus if we plot the frequency of the oscillation in the limit cycle
as a function of the (constant) input I, we ﬁnd a discontinuity at the bifurcation point. How-
ever, only models with a subcritical Hopf bifurcation give rise to large-amplitude oscilla-
tions close to the bifurcation point. We conclude that models where the onset of oscillations
occurs via a subcritical Hopf bifurcation exhibit a gain function of type II.
Example: FitzHugh-Nagumo model
The appearance of oscillations in the FitzHugh-Nagumo Model discussed above in
Fig. 4.10 is of type II. If the slope of the w-nullcline is larger than 1, there is only one
ﬁxed point, whatever I. With increasing current I, the ﬁxed point moves to the right.
Eventually it loses stability via a Hopf bifurcation.
4.5 Threshold and excitability
We have seen in Section 4.1 that the Hodgkin-Huxley model does not have a clear-cut ﬁr-
ing threshold. Nevertheless, there is a critical regime where the sensitivity to input current
pulses is so high that it can be fairly well approximated by a threshold. For weak stimuli,
the voltage trace returns more or less directly to the resting potentials. For stronger stimuli
it makes a large detour, that is, the model emits a spike; see Fig. 4.1b. This property is
characteristic for a large class of systems collectively termed excitable systems.
For two-dimensional models, excitability can be discussed in phase space in a trans-
parent manner. We pose the following questions. What are the conditions for a thresh-
old behavior? If there is no sharp threshold, what are the conditions for a regime of high
(threshold-like) sensitivity? As we have seen in Section 4.1, the search for a threshold
yields different results for step or pulsatile currents. We shall see now that, for stimula-
tion with a short current pulse of variable amplitude, models with saddle-node bifurcation
(on or off a limit cycle) indeed have a threshold, whereas models where ﬁring arises via a
Hopf bifurcation have not. On the other hand, even models with Hopf bifurcation can show
threshold-like behavior for current pulses if the dynamics of w are considerably slower than
that of u.
Throughout this section we use the following stimulation paradigm. We assume that
the neuron is at rest (or in a known state) and apply a short current pulse I(t) = qδ(t)

104
Dimensionality reduction and phase plane analysis
(a)
(b)
Fig. 4.17 Threshold in a type I model. (a) The stable manifold (thick dashed line) acts as a threshold.
Trajectories (thick solid lines) that start to the right of the stable manifold cannot return directly to
the stable ﬁxed point (ﬁlled circle) but have to take a detour around the repulsive ﬁxed point (circle at
(u,w) ≈(−1,0.2)). The result is a spike-like excursion of the u-variable. Thin lines are the nullclines.
(b) Blow-up of the rectangular region in (a). The starting points of the two sample trajectories are
marked by squares.
of amplitude q > 0. The input pulse inﬂuences the neuronal dynamics via Eq. (4.4). As a
consequence, the voltage u jumps at t = 0 by an amount Δu = qR/τ; see Eq. (4.4). With
τ = RC the voltage jump can be written Δu = q/C in agreement with the discussion in
Section 4.1.1.
Since the current pulse does not act directly on the recovery variable w (see Eq. (4.5)),
the time course of w(t) is continuous. In the phase plane, the current pulse therefore shifts
the value of state variables (u,w) of the system horizontally to a new value (u + Δu,w).
How does the system return to equilibrium? How does the behavior depend on the ampli-
tude q of the current pulse?
We will see that the behavior can depend on the charge q of the current pulse in two
qualitatively distinct ways. In type I models, the response to the input shows an "all-or-
nothing" behavior and consists of either a signiﬁcant pulse (that is, an action potential) or
a simple decay back to rest. To this effect, type I models exhibit a threshold behavior. If the
action potential occurs, it has always roughly the same amplitude, but occurs at different
delays depending on the strength q of the stimulating current pulse. In models with a Hopf
bifurcation, on the other hand, the amplitude of the response depends continuously on the
amplitude q. Therefore, models with a Hopf bifurcation do not have a sharp threshold.
Type II models with a saddle-node-off-limit-cycle bifurcation have a threshold behavior
for pulse injection similar to that of type I models.
Example: Single current pulses versus multiple pulses
The discussion so far has been focused on an isolated current pulse of charge q. Note,
however, that even in a model with threshold, a ﬁrst input pulse that lifts the state of the
system above the threshold can be counterbalanced by a second negative input which

4.5 Threshold and excitability
105
(a)
(b)
Fig. 4.18 Type I model and delayed spike initiation. (a) Trajectories in the phase starting with initial
conditions (u0,wrest) where u0 = −20,−17,−14,−10 are close to the threshold. (b) Projection of
the trajectories on the voltage axis. Close to the threshold, spike initiation starts with a delay, but the
amplitude of the action potential is always roughly the same.
pulls the state of the system back. Thus, even in models with a threshold, the threshold
is only "seen" for the speciﬁc input scenario considered here, namely, one isolated short
current pulse.
4.5.1 Type I models
As discussed above, type I models are characterized by a set of three ﬁxed points, a stable
one to the left, a saddle point in the middle, and an unstable one to the right. The linear
stability analysis at the saddle point reveals, by deﬁnition of a saddle, one positive and
one negative eigenvalue, λ+ and λ−, respectively. The imaginary parts of the eigenvalues
vanish. Associated with λ−is the (real) eigenvector e−. A trajectory which approaches the
saddle in the direction of e−from either side will eventually converge toward the ﬁxed
point. There are two of these trajectories. The ﬁrst one starts at inﬁnity and approaches
the saddle from below. In the case of a type I mode, the second one starts at the unsta-
ble ﬁxed point and approaches the saddle from above. The two together deﬁne the stable
manifold of the ﬁxed point (Hale and Koc¸ac, 1991). A perturbation around the ﬁxed point
that lies on the stable manifold returns to the ﬁxed point. All other perturbations will grow
exponentially.
The stable manifold plays an important role for the excitability of the system. Due to the
uniqueness of solutions of differential equations, trajectories cannot cross. This implies that
all trajectories with initial conditions to the right of the stable manifold must make a detour
around the unstable ﬁxed point before they can reach the stable ﬁxed point. Trajectories
with initial conditions to the left of the stable manifold return immediately toward the
stable ﬁxed point; see Fig. 4.17.
Let us now apply these considerations to neuron models driven by a short current pulse.
At rest, the neuron model is at the stable ﬁxed point. A short input current pulse moves the

106
Dimensionality reduction and phase plane analysis
f
f
J
0
fr
(b)
(a)
Fig. 4.19 Type I model as a phase model. (a) For I > 0, the system is on a limit cycle. The phase
velocity dφ/dt is positive everywhere. (b) For I < 0, the phase has a stable ﬁxed point at φ = φr and
an unstable ﬁxed point at φ = ϑ.
state of the system to the right. If the current pulse is small, the new state of the system is
to the left of the stable manifold. Hence the membrane potential u decays back to rest. If
the current pulse is sufﬁciently strong, it will shift the state of the system to the right of
the stable manifold. Since the resting point is the only stable ﬁxed point, the neuron model
will eventually return to the resting potential. To do so, it has, however, to take a large
detour which is seen as a pulse in the voltage variable u. The stable manifold thus acts as a
threshold for spike initiation, if the neuron model is probed with an isolated current pulse.
Example: Delayed spike initiation
We consider a sequence of current pulse of variable amplitude that cause a jump to
initial values (u0,wrest) where u0 is close to the ﬁring threshold identiﬁed above. As u0
approaches the ﬁring threshold from above, action potentials are elicited with increasing
delay; see Fig. 4.18b. The reason is that close to the ﬁring threshold (i.e., the stable
manifold of the saddle point) the trajectory is attracted toward the saddle point without
reaching it. At the saddle point, the velocity of the trajectory would be zero. Close to the
saddle point the velocity of the trajectory is nonzero, but extremely slow. The rapid rise
of the action potential only starts after the trajectory has gained a minimal distance from
the saddle point.
Example: Canonical type I model
We have seen in the previous example that, for various current amplitudes, the tra-
jectory always takes nearly the same path on its detour in the two-dimensional phase
plane. Let us therefore simplify further and just describe the position or "phase" on this
standard path.

4.5 Threshold and excitability
107
-3
-2
-1
0
1
2
3
u
-2
0
2
4
(a)
0
5
10
15
20
t
-3
-2
-1
0
1
2
3
u
(b)
Fig. 4.20 Threshold behavior in a model with Hopf bifurcation. (a) Trajectories in the phase starting
with initial conditions (u0,wrest) where u0 = −0.5,−0.25,−0.125,0,0.25. (b) Projection of the tra-
jectories on the voltage axis. For u0 ≤−0.25, the trajectories return rapidly to rest. The trajectories
with u0 ≥−0.125 start with positive slope. Parameters were b0 = 2, b1 = 1.5, ε = 0.1 with I = 0.
Consider the one-dimensional model
dφ
dt = q(1−cosφ)+I (1+cosφ)
(4.32)
where q > 0 is a parameter and I is the applied current, with 0 < |I| < q. The variable φ
is the phase along the limit cycle trajectory. Formally, a spike is said to occur whenever
φ = π.
For I < 0 on the right-hand side of Eq. (4.32), the phase equation dφ/dt has two ﬁxed
points. The resting state is at the stable ﬁxed point φ = φr. The unstable ﬁxed point at
φ = ϑ acts as a threshold; see Fig. 4.19b. Let us now assume initial conditions slightly
above threshold, namely, φ0 = ϑ + δφ. Since dφ/dt|φ0 > 0 the system starts to ﬁre an
action potential but for δφ ≪1 the phase velocity is still close to zero and the maximum
of the spike (corresponding to φ = π) is reached only after a long delay. This delay
depends critically on the initial condition.
For all currents I > 0, we have dφ/dt > 0, so that the system is circling along the limit
cycle; see Fig. 4.19a. The minimal velocity is dφ/dt = I for φ = 0. The period of the limit
cycle can be found by integration of (4.32) around a full cycle. Let us now reduce the
amplitude of the applied current I. For I →0, the velocity along the trajectory around
φ = 0 tends to zero. The period of one cycle T(I) therefore tends to inﬁnity. In other
words, for I →0, the frequency of the oscillation ν = 1/T(I) decreases (continuously)
to zero, the characteristic feature of type I models.
The model (4.32) is a canonical model in the sense that all type I neuron models close
to the point of a saddle-node-on-limit-cycle bifurcation can be mapped onto Eq. (4.32)
(Ermentrout, 1996).
4.5.2 Hopf bifurcations
In contrast to models with saddle-node bifurcation, a neuron model with a Hopf bifurcation
does not have a stable manifold and, hence, there is no "forbidden line" that acts as a

108
Dimensionality reduction and phase plane analysis
sharp threshold. Instead of the typical all-or-nothing behavior of type I models there is a
continuum of trajectories; see Fig. 4.20a.
Nevertheless, if the time scale of the u-dynamics is much faster than that of the
w-dynamics, then there is a critical regime where the sensitivity to the amplitude of the
input current pulse can be extremely high. If the amplitude of the input pulse is increased by
a tiny amount, the amplitude of the response increases a lot. In practice, the consequences
of the regime of high sensitivity are similar to that of a sharp threshold. There is, however,
a subtle difference in the timing of the response between type I models with saddle-node-
onto-limit-cycle bifurcation and type II models with Hopf bifurcation. In models with Hopf
bifurcation, the peak of the response is always reached with roughly the same delay, inde-
pendently of the size of the input pulse. It is the amplitude of the response that increases
rapidly but continuously; see Fig. 4.20b.
This is to be contrasted with the behavior of models with a saddle-node-onto-limit cycle
behavior. As discussed above, the amplitude of the response of type I models is rather
stereotyped: either there is an action potential or not. For input currents which are just
above threshold, the action potential occurs, however, with an extremely long delay.
4.6 Separation of time scales and reduction to one dimension
Consider the generic two-dimensional neuron model given by Eqs. (4.4) and (4.5). We
measure time in units of τ and take R = 1. Equations (4.4) and (4.5) are then
du
dt = F(u,w)+I,
(4.33)
dw
dt = ε G(u,w),
(4.34)
where ε = τ/τw. If τw ≫τ, then ε ≪1. In this situation the time scale that governs the evo-
lution of u is much faster than that of w. This observation can be exploited for the analysis
of the system. The general idea is that of a "separation of time scales;" in the mathematical
literature the limit of ε →0 is called "singular perturbation." Oscillatory behavior for small
ε is called a "relaxation oscillation."
What are the consequences of the large difference of time scales for the phase portrait
of the system? Recall that the ﬂow is in the direction of ( ˙u, ˙w). In the limit of ε →0,
all arrows in the ﬂow ﬁeld are therefore horizontal, except those in the neighborhood of
the u-nullcline. On the u-nullcline, ˙u = 0 and arrows are vertical as usual. Their length,
however, is only of order ε. Intuitively speaking, the horizontal arrows rapidly push the
trajectory toward the u-nullcline. Only close to the u-nullcline are directions of movement
other than horizontal possible. Therefore, trajectories slowly follow the u-nullcline, except
at the knees of the nullcline where they jump to a different branch.
Excitability can now be discussed with the help of Fig. 4.21. A current pulse shifts the
state of the system horizontally away from the stable ﬁxed point. If the current pulse is
small, the system returns immediately (i.e., on the fast time scale) to the stable ﬁxed point.
If the current pulse is large enough so as to put the system beyond the middle branch of

4.6 Separation of time scales and reduction to one dimension
109
u. = 0
w. = 0
u
w
Fig. 4.21 Excitability in a type II model with separated time scales. The u-dynamics are much
faster than the w-dynamics. The ﬂux is therefore close to horizontal, except in the neighborhood
of the u-nullcline (schematic ﬁgure). Initial conditions (circle) to the left of the middle branch of the
u-nullcline return directly to the stable ﬁxed point; a trajectory starting to the right of the middle
branch develops a voltage pulse.
the u-nullcline, then the trajectory is pushed toward the right branch of the u nullcline.
The trajectory follows the u-nullcline slowly upward until it jumps back (on the fast time
scale) to the left branch of the u-nullcline. The "jump" between the branches of the null-
cline corresponds to a rapid voltage change. In terms of neuronal modeling, the jump from
the right to the left branch corresponds to the downstroke of the action potential. The mid-
dle branch of the u-nullcline (where ˙u > 0) acts as a threshold for spike initiation; see
Fig. 4.22.
If we are not interested in the shape of an action potential, but only in the process of
spike initiation, we can exploit the separation of time scales for a further reduction of the
two-dimensional system of equations to a single variable. Without input, the neuron is at
rest with variables (urest,wrest)T . An input current I(t) acts on the voltage dynamics, but
has no direct inﬂuence on the variable w. Moreover, in the limit of ε ≪1, the inﬂuence of
the voltage u on the w-variable via Eq. (4.34) is negligible. Hence, we can set w = wrest
and summarize the voltage dynamics of spike initiation by a singe equation
du
dt = F(u,wrest)+I .
(4.35)
Equation (4.35) is the basis of the nonlinear integrate-and-ﬁre models that we will discuss
in Chapter 5.
In a two-dimensional neuron model with separation of time scales, the upswing of the
spike corresponds to a rapid horizontal movement of the trajectory in the phase plane. The
upswing is therefore correctly reproduced by Eq. (4.35). The recovery variable departs
from its resting value wrest only during the return of the system to rest, after the voltage has
(nearly) reached its maximum (Fig. 4.22a). In the one-dimensional system, the downswing
of the action potential is replaced by a simple reset of the voltage variable, as we shall see
in the next chapter.

110
Dimensionality reduction and phase plane analysis
-3.0
0.0
3.0
u
-2.0
0.0
2.0
w
w. =0
u.= 0
(a)
0.0
50.0
100.0
t
−2.0
−1.0
0.0
1.0
2.0
u
(b)
Fig. 4.22 FitzHugh-Nagumo model with separated time scales. All parameters are identical to those
of Fig. 4.20 except for ε in Eq. (4.34) which has been reduced by a factor of 10. (a) A trajectory
which starts to the left-hand side of the middle branch of the u-nullcline returns directly to the rest
state; all other trajectories develop a pulse. (b) Owing to slow w-dynamics, pulses are much broader
than in Fig. 4.20.
Example: Piecewise linear nullclines
Let us study the piecewise linear model shown in Fig. 4.23,
du
dt = f(u)−w+I,
(4.36)
dw
dt = ε (bu−w),
(4.37)
with f(u) = au for u < 0.5, f(u) = a(1−u) for 0.5 < u < 1.5 and f(u) = c0 +c1u for
u > 1.5 where a,c1 < 0 are parameters and c0 = −0.5a−1.5c1. Furthermore, b > 0 and
0 < ε ≪1.
The rest state is at u = w = 0. Suppose that the system is stimulated by a short current
pulse that shifts the state of the system horizontally. As long as u < 1, we have f(u) < 0.
According to (4.36), ˙u < 0 and u returns to the rest state. For u < 0.5 the relaxation to
rest is exponential with u(t) = exp(at) in the limit of ε →0. Thus, the return to rest after
a small perturbation is governed by the fast time scale.
If the current pulse moves u to a value larger than unity, we have ˙u = f(u) > 0. Hence
the voltage u increases and a pulse is emitted. That is to say, u = 1 acts as a threshold.
Hence, under the assumption of a strict separation of time scales, this neuron model does
have a threshold when stimulated with pulse input. The threshold sits on the horizontal
axis w = 0 at the point where ˙u = 0.
Let us now suppose that the neuron receives a weak and constant background current
during our threshold-search experiments. A constant current shifts the u-nullcline ver-
tically upward. Hence the point where ˙u = 0 shifts leftward and therefore the voltage

4.7 Summary
111
w. = 0
u.=0
w
u
ε
1
Fig. 4.23 Piecewise linear model with separation of
time scale. The inset shows the trajectory (arrows)
which follows the u-nullcline at a distance of order
ε where ε ≪1 is the ratio of the time scale of the
u-dynamics and that of the w-dynamics in unit-free
coordinates; see Eq. (4.37).
threshold for pulse stimulation sits now at a lower value. Again, we conclude that the
threshold value we ﬁnd depends on the stimulation protocol.
4.7 Summary
The four-dimensional model of Hodgkin-Huxley can be reduced to two dimensions under
the assumption that the m-dynamics are fast compared with u, h, and n, and that the latter
two evolve on the same time scale. Two-dimensional models can readily be visualized and
studied in the phase plane.
As a ﬁrst application of phase plane analysis, we asked whether neuron models have a
ﬁring threshold - and found that the answer is something like "No, but ... ." The answer
is "No," because the threshold value depends on the stimulation paradigm. The voltage
threshold derived with short current pulses is different from that found with constant cur-
rent or slow ramps. In type II models the onset of repetitive ﬁring at the rheobase cur-
rent value starts with nonzero frequency. Type I models exhibit onset of repetitive ﬁring
with zero frequency. The transition to repetitive ﬁring in type I models arises through a
saddle-node-onto-limit-cycle bifurcation whereas several bifurcation types can give rise to
a type II behavior.
The methods of phase plane analysis and dimension reduction are generic tools and
will also play a role in several chapters of Parts II and IV of this book. In particular, the
separation of time scales between the fast voltage variable and the slow recovery variable
enables a further reduction of neuronal dynamics to a one-dimensional nonlinear integrate-
and-ﬁre model, a fact which we will exploit in the next chapter.
Literature
An in-depth introduction to dynamical systems, stability of ﬁxed points, and (un)stable
manifolds can be found, for example, in the book of Hale and Koc¸ac (1991). The book
by Strogatz (1994) presents the theory of dynamical systems in the context of various
problems of physics, chemistry, biology, and engineering. A wealth of applications of
dynamical systems to various (mostly non-neuronal) biological systems can be found in
the comprehensive book by Murray (1993), which also contains a thorough discussion of

112
Dimensionality reduction and phase plane analysis
the FitzHugh-Nagumo model. Phase plane methods applied to neuronal dynamics are dis-
cussed in the clearly written review paper of Rinzel and Ermentrout (1998) and in the book
by Izhikevich (2007b).
The classiﬁcation of neuron models as type I and type II can be found in Rinzel and
Ermentrout (1998) and in Ermentrout (1996), and systematically in Izhikevich (2007b).
The steps of dimensionality reduction are presented in Kepler et al. (1992).
Exercises
1. Inhibitory rebound.
(a) Draw on the phase plane a schematic representation of the nullclines and ﬂow for the piece-
wise linear FitzHugh-Nagumo (Eqs. (4.36) and (4.37)) with parameters a = c1 = −1 and b = 2,
and mark the stable ﬁxed point.
(b) A hyperpolarizing current is introduced very slowly and increased up to a maximal value of
I = −2. Calculate the new value of the stable ﬁxed point. Draw the nullclines and ﬂow for I = −2
on a different phase plane.
(c) The hyperpolarizing current is suddenly removed. Use the phase planes in (a) and (b) to
ﬁnd out what will happen. Draw schematically the evolution of the neurons state as a membrane
potential time-series and as a trajectory in the phase plane. Use ε = 0.1.
Hint: The resting state from b is the initial value of the trajectory in c.
2. Separation of time scales and quasi-stationary assumption.
(a) Consider the following differential equation:
τ dx
dt = −x+c,
(4.38)
where c is a constant. Find the ﬁxed point of this equation. Determine the stability of the ﬁxed
point and the solution for any initial condition.
(b) Suppose that c is now piecewise constant:
c = c(t) =
⎧
⎪
⎨
⎪
⎩
0
fort < 0
c0
for0 ≤t ≤1
0
fort > 1.
(4.39)
Calculate the solution x(t) for the initial condition x(t = −10) = 0.
(c) Now consider the linear system:
du
dt = f(u)−m,
ε dm
dt −m+c(u).
(4.40)
Exploit the fact that ε << 1 to reduce the system to one equation. Note the similarity with the
equations in (a) and (b).
3. Separation of time scale and relaxation oscillators.
(a) Show that in the piecewise linear neuron model deﬁned in Eqs. (4.36) and (4.37) the trajectory
evolves parallel to the right branch of the u-nullcline, shifted upward by a distance of order ε
(Fig. 4.23) or parallel to the lifted branch of the u-nullcline, shifted downward by a distance of
order ε.
Hint: If the u-nullcline is given by the function f(u), set w(t) = f[u(t)] + ε x(t) where x(t) is
the momentary distance and study the evolution of du/dt and dw/dt according to the differential
equations of u and w. At the same time, under the assumption of parallel movement, x(t) is

4.7 Summary
113
a constant and the geometry of the problem in the two-dimensional phase space tells us that
dw/dt = (df/du)(du/dt). Show that this leads to a consistent solution for the distance x.
(b) What is the time course of the voltage u(t) while the trajectory follows the branch?


PART TWO
GENERALIZED INTEGRATE-AND-FIRE
NEURONS


117
RS
Part II
Part I
Ion channels
Ions
Dendrites
t
u(t)
Threshold
Biophysical
models 
Neurotransmitters
In Part II we exploit the mathematical and biophysical foundations that were laid in Part I in
order to reduce the complexity of neuron models. Part II is focused on simpliﬁed
phenomenological models in which spikes are generated by a threshold criterion, possi-
bly in combination with a stochastic process. We start in Chapter 5 with a determinstic
one-dimensional integrate-and-ﬁre model. It turns out that such a model is not powerful
enough to account for ﬁring properties of real neurons so that we add adaptation variables
(Chapter 6) and stochasticity (Chapters 7-9). These simpliﬁed neuron models, often called
generalized integrate-and-ﬁre models or generalized linear models, can be systematically
ﬁtted to experimental data (Chapter 10). Moreover they allow a transparent discussion of
neuronal encoding in (and decoding of) stochastic spike trains (Chapter 11). The simpli-
ﬁed neuron models of Part II will be the starting point of the analysis of large neuronal
networks in Part III.


5
Nonlinear integrate-and-ﬁre models
Detailed conductance-based neuron models can reproduce electrophysiological measure-
ments to a high degree of accuracy, but because of their intrinsic complexity these models
are difﬁcult to analyze. For this reason, simple phenomenological spiking neuron models
are highly popular for studies of neural coding, memory, and network dynamics. In this
chapter we discuss formal threshold models of neuronal ﬁring, also called integrate-and-
ﬁre models.
The shape of the action potential of a given neuron is rather stereotyped with very little
change between one spike and the next. Thus, the shape of the action potential which
travels along the axon to a postsynaptic neuron cannot be used to transmit information;
rather, from the point of view of the receiving neuron, action potentials are "events" which
are fully characterized by the arrival time of the spike at the synapse. Note that spikes
from different neuron types can have different shapes and the duration and shape of the
spike does inﬂuence neurotransmitter release; but the spikes that arrive at a given synapse
all come from the same presynaptic neuron and - if we neglect effects of fatigue of ionic
channels in the axon - we can assume that its time course is always the same. Therefore we
make no effort to model the exact shape of an action potential. Rather, spikes are treated as
events characterized by their ﬁring time - and the task consists in ﬁnding a model so as to
reliably predict spike timings.
In generalized integrate-and-ﬁre models, spikes are generated whenever the membrane
potential u crosses some threshold θreset from below. The moment of threshold crossing
deﬁnes the ﬁring time t f ,
t f :
u(t f ) = θreset
and
du(t)
dt

t=t f > 0.
(5.1)
In contrast to the two-dimensional neuron models, encountered in Chapter 4, we don't
have a relaxation variable that enables us to describe the return of the membrane potential
to rest. In the integrate-and-ﬁre models, discussed in this and the following chapters, the
downswing of the action potential is replaced by an algorithmic reset of the membrane
potential to a new value ur each time the threshold θreset is reached. The duration of an
action potential is sometimes, but not always, replaced by a dead-time Δabs after each
spike, before the voltage dynamics restarts with u = ur as initial condition.

120
Nonlinear integrate-and-ﬁre models
In this chapter, we focus on integrate-and-ﬁre models with a single variable u which
describes the time course of the membrane potential. In Chapter 6, we extend the models
developed in this chapter so as to include adaptation of neuronal ﬁring during extended
strong stimulation. In Chapters 7-11 we consider questions of coding, noise, and relia-
bility of spike-time prediction - using the generalized integrate-and-ﬁre model which we
introduce now.
5.1 Thresholds in a nonlinear integrate-and-ﬁre model
In a general nonlinear integrate-and-ﬁre model with a single variable u, the membrane
potential evolves according to
τ d
dt u = f(u)+R(u)I .
(5.2)
As mentioned above, the dynamics is stopped if u reaches the threshold θreset. In this case
the ﬁring time t f is noted and integration of the membrane potential equation restarts at
time t f +Δabs with initial condition ur. A typical example of the function f(u) in Eq. (5.2) is
shown in Fig. 5.1. If not speciﬁed otherwise, we always assume in the following a constant
input resistance R(u) = R independent of voltage.
A comparison of Eq. (5.2) with the equation of the standard leaky integrate-and-ﬁre
model
τ d
dt u = −(u−urest)+RI ,
(5.3)
which we encountered in Chapter 1, shows that the nonlinear function R(u) can be inter-
preted as a voltage-dependent input resistance while f(u) replaces the leak term −(u −
urest). Some well-known examples of nonlinear integrate-and-ﬁre models include the expo-
nential integrate-and-ﬁre model (Section 5.2) and the quadratic integrate-and-ﬁre model
(Section 5.3). Before we turn to these speciﬁc models, we discuss some general aspects of
nonlinear integrate-and-ﬁre models.
Example: Rescaling and standard forms (*)
It is always possible to rescale the variables in Eq. (5.2) so that the threshold and
membrane time constant are equal to unity and the resting potential vanishes. Further-
more, there is no need to interpret the variable u as the membrane potential. For example,
starting from the nonlinear integrate-and-ﬁre model Eq. (5.2), we can introduce a new
variable ˜u by the transformation
u(t) −→˜u(t) = τ
 u(t)
0
dx
R(x),
(5.4)
which is possible if R(x) ̸= 0 for all x in the integration range. In terms of ˜u we have a

5.1 Thresholds in a nonlinear integrate-and-ﬁre model
121
urest
ϑ
u
0
I0 = 0
θreset
u
t
d
d
(a)
urest
ϑ
u
0
I0 > 0
ϑrh
θreset
(b)
u
t
d
d
Fig. 5.1 Thresholds in a nonlinear integrate-and-ﬁre model. The change du/dt of the voltage is
plotted as a function f(u) of the voltage u. (a) In the absence of stimulation I0 = 0, the zero-crossings
du/dt = 0 deﬁne the resting potential urest and the ﬁring threshold ϑ of the nonlinear integrate-and-
ﬁre model. A positive change in the membrane potential du/dt = f(u) > 0 implies that the voltage
increases (ﬂow arrow to the right), while du/dt < 0 implies a decay of the voltage. The pattern of
arrows indicates a stable ﬁxed point at rest, but an unstable ﬁxed point at ϑ. Whenever the voltage
reaches the value θreset the voltage is reset to a lower value. (b) For a constant positive input I0 > 0,
the curve of du/dt is shifted vertically upward. The rheobase threshold ϑrh indicates the maximal
voltage that can be reached with constant current injection before the neuron starts repetitive ﬁring.
new nonlinear integrate-and-ﬁre model of the form
d ˜u
dt = d( ˜u)+I(t)
(5.5)
with d( ˜u) = f(u)/R(u). In other words, a general integrate-and-ﬁre model (5.2) can
always be reduced to the standard form (5.5). By a completely analogous transformation,
we could eliminate the voltage-dependence of the function f in Eq. (5.2) and move all
the dependence into a new voltage-dependent R(u) (Abbott and van Vreeswijk, 1993).
5.1.1 Where is the ﬁring threshold?
In the standard leaky integrate-and-ﬁre model, the linear equation Eq. (5.3) is combined
with a numerical threshold θreset. We may interpret θreset as the ﬁring threshold in the sense
of the minimal voltage necessary to cause a spike, whatever stimulus we choose. In other
words, if the voltage is currently marginally below θreset and no further stimulus is applied,
the neuron inevitably returns to rest. If the voltage reaches θreset, the neuron ﬁres. For
nonlinear integrate-and-ﬁre models, such a clear-cut picture of a ﬁring threshold no longer
holds.
The typical shape of a function f(u) used in the nonlinear integrate-and-ﬁre model
deﬁned in Eq. (5.2) is sketched in Fig. 5.1. Around the resting potential, the function f is
linear and proportional to (u−urest). But in contrast to the leaky integrate-and-ﬁre model

122
Nonlinear integrate-and-ﬁre models
0
250
J
Jrh
500
−80
−60
−40
−20
0
u [mV]
0
250
500
t [ms]
0
500
1000
1500
I [pA]
I =1110
I =1130
I = 79
I =80
Fig. 5.2 Stimulation of a nonlinear integrate-and-ﬁre model with pulses and step currents. Voltage
as a function of time (top) in response to the currents indicated at the bottom. The ﬁring threshold ϑ
found with pulse stimuli and the threshold ϑrh for repetitive ﬁring under prolonged current injection
are indicated by the dashed horizontal lines.
of Eq. (5.3) where the voltage dependence is linear everywhere, the function f(u) of the
nonlinear model turns at some point sharply upwards.
If the nonlinear integrate-and-ﬁre model is stimulated with currents of various shapes,
we can identify, from the simulation of the model, the threshold for spike generation. We
search for the maximal voltage which can be reached before the model ﬁres a spike. Fig-
ure 5.2 shows that the voltage threshold ϑ determined with pulse-like input currents is
different from the voltage threshold determined with prolonged step currents.
For an explanation, we return to Fig. 5.1a which shows du/dt as a function of u. There
are two zero-crossings du/dt = f(u) = 0, which we denote as urest and ϑ, respectively. The
ﬁrst one, urest, is a stable ﬁxed point of the dynamics, whereas ϑ is an unstable one.
A short current pulse I(t) = qδ(t −t0) injected into Eq. (5.2) delivers at time t0 a total
charge q and causes a voltage step of size Δu = Rq/τ (see Section 1.3.2). The new voltage
u = urest +Δu serves as initial condition for the integration of the differential equation after
the input pulse. For u < ϑ the membrane potential returns to the resting potential, while
for u > ϑ the membrane potential increases further, until the increase is stopped at the
numerical threshold θreset. Thus the unstable ﬁxed point ϑ serves as a voltage threshold, if
the neuron model is stimulated by a short current pulse.
Under the application of a constant current, the picture is different (Fig. 5.1b). Since we
plot du/dt along the vertical axis, a constant current I0 shifts the curve of du/dt shown
in Fig. 5.1a vertically upward to a new value f(u) + RI0; see Eq. (5.2). If the current is
sufﬁciently large, both ﬁxed points disappear so that du/dt is always positive. As a result,
the voltage increases until it hits the numerical threshold θreset, at which point it is reset
and the same picture repeats. In other words, the neuron model has entered the regime of
repetitive ﬁring.

5.1 Thresholds in a nonlinear integrate-and-ﬁre model
123
The critical current for initiation of repetitive ﬁring corresponds to the voltage where
the stable ﬁxed point disappears, or ϑrh = Ic R. In the experimental literature, the critical
current Ic = ϑrh/R is called the "rheobase" current. In the mathematical literature, it is
called the bifurcation point. Note that a stationary voltage u > ϑrh is not possible. On the
other hand, for pulse inputs or time-dependent currents, voltage transients into the regime
ϑrh < u(t) < ϑ routinely occur without initiating a spike.
5.1.2 Detour: Analysis of one-dimensional differential equations
For those readers who are not familiar with ﬁgures such as Fig. 5.1, we add a few mathe-
matical details.
The momentary state of one-dimensional differential equations such as Eq. (5.2) is com-
pletely described by a single variable, called u in our case. This variable is plotted in
Fig. 5.1 along the horizontal axis. An increase in voltage corresponds to a movement to
the right, a decrease to a movement to the left. Thus, in contrast to the phase plane analysis
of two-dimensional neuron models, encountered in Section 4.3, the momentary state of the
system always lies on the horizontal axis.
Let us suppose that the momentary value of the voltage is u(t0). The value a short time
afterwards is given by u(t0 +Δt) = u(t0)+ ˙uΔt where ˙u = du/dt is given by the differential
equation Eq. (5.2). The difference u(t0 +Δt)−u(t0) is positive if ˙u > 0 and indicated by a
ﬂow arrow to the right; the arrow points leftwards if ˙u < 0.
A nice aspect of a plot such as in Fig. 5.1a is that, for each u, the vertical axis of the
plot indicates ˙u = f(u), i.e., we can directly read off the value of the ﬂow without further
calculation. If the value of the function f(u) is above zero, the ﬂow is to the right; if it is
negative, the ﬂow is to the left.
By deﬁnition, the ﬂow du/dt vanishes at the ﬁxed points. Thus ﬁxed points are given by
the zero-crossings f(u) = 0 of the curve. Moreover, the ﬂow pattern directly indicates the
stability of a ﬁxed point. From the ﬁgure, we can read off that a ﬁxed point at u0 is stable
(arrows pointing towards the ﬁxed point) if the slope of the curve d f/du evaluated at u0 is
negative.
The mathematical proof goes as follows. Suppose that the system is, at time t0, slightly
perturbed around the ﬁxed point to a new value u0 +x(t0). We focus on the evolution of the
perturbation x(t). The perturbation follows the differential equation dx/dt = ˙u = f(u0 +x).
Taylor expansion of f around u0 gives dx/dt = f(u0) + (df/du)u0 x. At the ﬁxed point,
f(u0) = 0. The solution of the differential equation therefore is x(t) = x(t0) exp[b(t −t0)].
If the slope b = (df/du)u0 is negative, the amplitude of the perturbation x(t) decays back
to zero, indicating stability. Therefore, negative slope (df/du)u0 < 0 implies stability of
the ﬁxed point.

124
Nonlinear integrate-and-ﬁre models
5.2 Exponential integrate-and-ﬁre model
In the exponential integrate-and-ﬁre model (Fourcaud-Trocme et al., 2003), the differential
equation for the membrane potential is given by
τ d
dt u = −(u−urest)+ΔT exp
u−ϑrh
ΔT

+RI .
(5.6)
The ﬁrst term on the right-hand side of Eq. (5.6) is identical to Eq. (5.3) and describes the
leak of a passive membrane. The second term is an exponential nonlinearity with "sharp-
ness" parameter ΔT and "threshold" ϑrh.
The moment when the membrane potential reaches the numerical threshold θreset deﬁnes
the ﬁring time t f . After ﬁring, the membrane potential is reset to ur and integration restarts
at time t f + Δabs where Δabs is an absolute refractory time, typically chosen in the range
0 < Δabs < 5ms. If the numerical threshold is chosen sufﬁciently high, θreset ≫ϑ +ΔT, its
exact value does not play any role. The reason is that the upswing of the action potential
for u ≫ϑ + ΔT is so rapid that it goes to inﬁnity in an incredibly short time (Touboul,
2009). The threshold θreset is introduced mainly for numerical convenience. For a formal
mathematical analysis of the model, the threshold can be pushed to inﬁnity.
Example: Rheobase threshold and interpretation of parameters
The exponential integrate-and-ﬁre model is a special case of the general nonlinear
model deﬁned in Eq. (5.2) with a function
f(u) = −(u−urest)+ΔT exp
u−ϑrh
ΔT

.
(5.7)
In the absence of external input (I = 0), the differential equation of the exponential
integrate-and-ﬁre model (5.6) has two ﬁxed points, deﬁned by the zero-crossings f(u) =
0; see Fig. 5.1a. We suppose that parameters are chosen such that ϑrh ≫urest +ΔT. Then
the stable ﬁxed point is at u ≈urest because the exponential term becomes negligibly
small for u ≪ϑrh −ΔT. The unstable ﬁxed point which acts as a threshold for pulse
input lies to the right-hand side of ϑrh.
If the external input increases slowly in a quasi-constant fashion, the two ﬁxed points
move closer together until they ﬁnally merge at the bifurcation point; see Fig. 5.1b. The
voltage at the bifurcation point can be determined from the condition d f/du = 0 to lie at
u = ϑrh. Thus ϑrh is the threshold found with constant (rheobase) current, which justiﬁes
its name.
Example: Relation to the leaky integrate-and-ﬁre model
In the exponential integrate-and-ﬁre model, the voltage threshold ϑ for pulse input is
different from the rheobase threshold ϑrh for constant input (Fig. 5.1). However, in the
limit ΔT →0, the sharpness of the exponential term increases and ϑ approaches ϑrh

5.2 Exponential integrate-and-ﬁre model
125
Fig. 5.3 Exponential and leaky integrate-and-ﬁre model. The function f(u) is plotted for different
choices of the "sharpness" of the threshold (ΔT = 1, 0.5, 0.25, 0.05 mV). In the limit ΔT →0 the
exponential integrate-and-ﬁre model becomes equivalent to a leaky integrate-and-ﬁre model (dashed
line). The inset shows a zoom onto the threshold region (dotted box).
(Fig. 5.3). In the limit, ΔT →0, we can approximate the nonlinear function by the linear
term
f(u) = −(u−urest)
for u < ϑrh
(5.8)
and the model ﬁres whenever u reaches ϑrh = ϑ. Thus, in the limit ΔT →0, we return
to the leaky integrate-and-ﬁre model.
5.2.1 Extracting the nonlinearity from data
Why should we choose an exponential nonlinearity rather than any other nonlinear depen-
dence in the function f(u) of the general nonlinear integrate-and-ﬁre model? Can we use
experimental data to determine the "correct" shape of f(u) in Eq. (5.2)?
We can rewrite the differential equation (5.2) of the nonlinear integrate-and-ﬁre model
by moving the function f(u) to the left-hand side and all other terms to the right-hand-side
of the equation. After rescaling with the time constant τ, the nonlinearity ˜f(u) = f(u)/τ is
˜f(u(t)) = 1
C I(t)−d
dt u(t),
(5.9)
where C = τ/R can be interpreted as the capacity of the membrane.
In order to determine the function ˜f(u), an experimenter injects a time-dependent current
I(t) into the soma of a neuron while measuring with a second electrode the voltage u(t).
From the voltage time course, one ﬁnds the voltage derivative du/dt.
A measurement at time t yields a value u(t) (which we use as value along the x-axis of
a plot) and a value [(I(t)/C)−(du/dt)] (which we plot along the y-axis). With a thousand
or more time points per second, the plot ﬁlls up rapidly. For each voltage u there are many
data points with different values along the y-axis. The best choice of the parameter C is the
one that minimizes the width of this distribution. At the end, we average across all points
at a given voltage u to ﬁnd the empirical function (Badel et al., 2008a)
˜f(u(t)) =
 1
C I(t)−d
dt u(t)

,
(5.10)

126
Nonlinear integrate-and-ﬁre models
(a)
(b)
Fig. 5.4 Extracting nonlinear integrate-and-ﬁre models from data. The function f(u) characterizing
the nonlinearity of an integrate-and-ﬁre model according to Eq. (5.2) is derived from experimental
data using random current injection into neurons. (a) Cortical pyramidal cells. Experimental data
points (symbols) and ﬁt by an exponential integrate-and-ﬁre model. (b) As in (a), but for an inhibitory
interneuron. Data courtesy of Laurent Badel and Sandrine Lefort (Badel et al., 2008a).
where the angle brackets indicate averaging. This function is plotted in Fig. 5.4. We ﬁnd
that the empirical function extracted from experiments is well approximated by a combi-
nation of a linear and exponential term
˜f(u) = −u−urest
τ
+ ΔT
τ exp
u−ϑrh
ΔT

,
(5.11)
which provides an empirical justiﬁcation of the choice of nonlinearity in the exponential
integrate-and-ﬁre model.
We note that the slope of the curve at the resting potential is related to the membrane
time constant τ while the threshold parameter ϑrh is the voltage at which the function ˜f
goes through its minimum.
Example: Refractory exponential integrate-and-ﬁre model
The above procedure for determining the nonlinearity can be repeated for a set of
data points restricted to a few milliseconds after an action potential (Fig. 5.6). After a
spike, the threshold ϑrh is slightly higher, which is one of the signs of refractoriness.
Moreover, the location of the zero-crossing urest and the slope of the function ˜f at urest
are different, which is to be expected since after a spike the sodium channel is inacti-
vated while several other ion channels are open. All parameters return to the "normal"
values within a few tens of milliseconds. An exponential integrate-and-ﬁre model where
the parameters depend on the time since the last spike has been called the "refractory
exponential integrate-and-ﬁre model" (Badel et al., 2008a). The refractory exponential
integrate-and-ﬁre model predicts the voltage time course of a real neuron for novel time-
dependent stimuli to a high degree of accuracy, if the input statistics is similar to the one
used for parameter extraction (Fig. 5.5).

5.2 Exponential integrate-and-ﬁre model
127
100 ms
20mV
25ms
25 mV
Experiment
(a)
25ms
20 mV
100ms
20 mV
Experiment
(b)
Fig. 5.5 Predicting the membrane voltage with an exponential integrate-and-ﬁre model. (a) Com-
parison of membrane voltage in experiments (thick line) with the predictions of the exponential
integrate-and-ﬁre model (thin line). The ﬁt is excellent, except during a short period after a spike. (b)
Same as in (a), but in a model with refractoriness. Modiﬁed from Badel et al. (2008b).
2 ms
20mV
5 to 10ms
10 to 20ms
20 to 30ms
30 to 50ms
Fig. 5.6 Refractory effects in the exponential integrate-and-ﬁre model. Top: Because of refractori-
ness immediately after a spike, the exponential integrate-and-ﬁre model has a higher ﬁring threshold
and increased slope in the linear section. Data points and ﬁt as in Fig. 5.4, but data points restricted
to intervals 5-10 ms (far left), 10-20 ms (left), 20-30 ms (right), or 30-50 ms (far right) after a spike.
As the time since the last spike increases, refractoriness decays and the parameters of the exponen-
tial integrate-and-ﬁre model approach their standard values (dashed lines). Bottom: Sample voltage
traces during and after a spike. From Badel et al. (2008b).
5.2.2 From Hodgkin-Huxley to exponential integrate-and-ﬁre
In Section 4.2 we have already seen that the four-dimensional system of equations of
Hodgkin and Huxley can be reduced to two equations. Here we show how to take a further
step so as to arrive at a single nonlinear differential equation combined with a reset (Jolivet
et al., 2004).
After appropriate rescaling of all variables, the system of two equations that summarizes
a Hodgkin-Huxley model reduced to two dimensions can be written as
du
dt = F(u,w)+I,
(5.12)
dw
dt = ε G(u,w),
(5.13)
which is just a copy of Eqs. (4.33) and (4.34) in Section 4.6; note that time is measured
in units of the membrane time constant τm and that the resistance has been absorbed into

128
Nonlinear integrate-and-ﬁre models
the deﬁnition of the currrent I. The function F(u,w) is given by Eqs. (4.3) and (4.4). The
exact shape of the function G(u,w) has been derived in Section 4.2, but plays no role in the
following. We recall that the ﬁxed points are deﬁned by the condition du/dt = dw/dt = 0.
For the case without stimulation I = 0, we denote the variables at the stable ﬁxed point as
urest (resting potential) and wrest (resting value of the second variable).
In the following we assume that there is a separation of time scales (ε ≪1) so that the
evolution of the variable w is much slower than that of the voltage. As discussed in Sec-
tion 4.6, this implies that all ﬂow arrows in the two-dimensional phase plane are horizontal
except those in the neighborhood of the u-nullcline. In particular, after a stimulation with
short current pulses, the trajectories move horizontally back to the resting state (no spike
elicited) or horizontally leftward (upswing of an action potential) until they hit one of the
branches of the u-nullcline; see Fig. 4.22. In other words, the second variable stays at its
resting value w = wrest and can therefore be eliminated - unless we want to describe the
exact shape of the action potential. As long as we are only interested in the initiation phase
of the action potential we can assume a ﬁxed value w = wrest.
For constant w, Eq. (5.12) becomes
du
dt = F(u,wrest)+I = f(u)+I,
(5.14)
which has the form of a nonlinear integrate-and-ﬁre neuron. The resulting function f(u) is
plotted in Fig. 5.7a. It has three zero-crossings: the ﬁrst one (left) at urest, corresponding to
a stable ﬁxed point; a second one (middle) which acts as a threshold ϑ; and a third one to
the right, which is again a stable ﬁxed point and limits the upswing of the action potential.
The value of the reset threshold θreset > ϑ should be reached during the upswing of the
spike and must therefore be chosen between the second and third ﬁxed point. While in the
two-dimensional model the variable w is necessary to describe the downswing of the action
potential on a smooth trajectory back to rest, we replace the downswing in the nonlinear
integrate-and-ﬁre model by an artiﬁcial reset of the voltage variable to a value ur whenever
u hits θreset.
If we focus on the region u < θreset, the function f(u) = F(u,wrest) is very well approx-
imated by the nonlinearity of the exponential integrate-and-ﬁre model (Fig. 5.7b).
Example: Exponential activation of sodium channels
In the previous section, we followed a series of formal mathematical steps, from
the two-dimensional version of the Hodgkin-Huxley model to a one-dimensional
differential equation which looked like a combination of linear and exponential terms,
i.e., an exponential integrate-and-ﬁre model. For a more biophysical derivation and
interpretation of the exponential integrate-and-ﬁre model, it is, however, illustrative
to start directly with the voltage equation of the Hodgkin-Huxley model, (2.4)-(2.5),
and replace the variables h and n by their values at rest, hrest and nrest, respectively.
Furthermore, we assume that m approaches instantaneously its equilibrium value m0(u).

5.3 Quadratic integrate and ﬁre
129
(a)
(b)
Fig. 5.7 Approximating Hodgkin-Huxley by an exponential integrate-and-ﬁre model. (a) The value
of the F(u,wrest) for ﬁxed value of the second variable w = wrest is plotted as a function of the
voltage variable u. The choice of a reset threshold θreset is indicated. (b) Solid line as in A, restricted
to u < θreset. The dashed line shows the approximation by an exponential integrate-and-ﬁre model.
This yields
Cdu
dt = −gNa[m0(u)]3 hrest (u−ENa)−gK (nrest)4 (u−EK)−gL (u−EL)+I .
(5.15)
Potassium and leak currents can now be summed up to a new effective leak term
geff (u −Eeff). In the voltage range close to the resting potential the driving force
(u−ENa) of the sodium current can be well approximated by (urest−ENa). Then the only
remaining nonlinearity on the right-hand side of Eq. (5.15) arises from m0(u). For volt-
ages around rest, m0(u) has, however, an exponential shape. In summary, the right-hand
side of Eq. (5.15) can be approximated by a linear and an exponential term - and this
gives rise to the exponential integrate-and-ﬁre model (Fourcaud-Trocme et al., 2003).
5.3 Quadratic integrate and ﬁre
A speciﬁc instance of a nonlinear integrate-and-ﬁre model is the quadratic model (Latham
et al., 2000; Hansel and Mato, 2001),
τ d
dt u = a0 (u−urest)(u−uc)+RI ,
(5.16)
with parameters a0 > 0 and uc > urest; see Fig. 5.8a. For I = 0 and initial condition u < uc,
the voltage decays to the resting potential urest. For u > uc it increases so that an action
potential is triggered. The parameter uc can therefore be interpreted as the critical voltage
for spike initiation by a short current pulse. We will see in the next subsection that the
quadratic integrate-and-ﬁre model is closely related to the so-called Θ-neuron, a canonical
type-I neuron model (Ermentrout, 1996; Latham et al., 2000).
For numerical implementation of the model, the integration of Eq. (5.16) is stopped
if the voltage reaches a numerical threshold θreset and restarted with a reset value ur as

130
Nonlinear integrate-and-ﬁre models
(a)
(b)
Fig. 5.8 Quadratic integrate-and-ﬁre model. (a) The quadratic integrate-and-ﬁre model (dashed line),
compared with an exponential integrate-and-ﬁre model (solid line). (b) The quadratic integrate-and-
ﬁre model can be seen as an approximation of an exponential integrate-and-ﬁre model (or any other
type I model) depolarized to a state close to repetitive ﬁring. In (a) and (b), the value f(u) and
curvature d2 f/du2 are matched at u = ϑrh. Note that the rise in the quadratic model is slower in the
superthreshold regime u > ϑrh.
new initial condition (Fig. 5.9b). For a mathematical analysis of the model, however, the
standard assumption is θreset →∞and ur →−∞.
We have seen in the previous section that experimental data suggests an exponential,
rather than quadratic nonlinearity. However, close to the threshold for repetitive ﬁring, the
exponential integrate-and-ﬁre model and the quadratic integrate-and-ﬁre model become
very similar (Fig. 5.8b). Therefore the question arises whether the choice between the two
models is a matter of personal preference only.
For a mathematical analysis, the quadratic integrate-and-ﬁre model is sometimes more
handy than the exponential one. However, the ﬁt to experimental data is much better with
the exponential than with the quadratic integrate-and-ﬁre model. For a prediction of spike
times and voltage of real neurons (see Fig. 5.5), it is therefore advisable to work with
the exponential rather than the quadratic integrate-and-ﬁre model. Loosely speaking, the
quadratic model is too nonlinear in the subthreshold regime and the upswing of a spike is
not rapid enough once the voltage is above threshold. The approximation of the exponential
integrate-and-ﬁre model by a quadratic one only holds if the mean driving current is close
to the rheobase current.
Example: Approximating the exponential integrate-and-ﬁre
Let us suppose that an exponential integrate-and-ﬁre model is driven by a depolariz-
ing current that shifts its effective equilibrium potential ueff
r
close to the rheobase ﬁring
threshold ϑrh. The stable ﬁxed points at u = ueff
r
and the unstable ﬁxed point at u = ϑ eff
corresponding to the effective ﬁring threshold for pulse injection now lie symmetrically
around ϑrh (Fig. 5.8b). In this region, the shape of the function f(u) is well approximated

5.3 Quadratic integrate and ﬁre
131
(a)
(b)
Fig. 5.9 Repetitive ﬁring in nonlinear integrate-and-ﬁre models. (a) Exponential integrate-and-ﬁre
model and (b) quadratic integrate-and-ﬁre model receiving a constant current sufﬁcient to elicit repet-
itive ﬁring. Note the comparatively slow upswing of the action potential in the quadratic integrate-
and-ﬁre model. Numerical simulation with parameters of equivalent models as illustrated in Fig. 5.8.
by a quadratic function (dashed line). In other words, in this regime the exponential and
quadratic integrate-and-ﬁre neuron become identical.
If the constant input current is increased further, the stable and unstable ﬁxed point
move closer together and ﬁnally merge and disappear at the bifurcation point, corre-
sponding to a critical current Ic. More generally, any type I neuron model close to the
bifurcation point can be approximated by a quadratic integrate-and-ﬁre model - and this
is why it is sometimes called the "canonical" type I integrate-and-ﬁre model (Ermen-
trout, 1996; Ermentrout and Kopell, 1986).
5.3.1 Canonical type I model (*)
In this section, we show that there is a one-to-one relation between the quadratic integrate-
and-ﬁre model (5.16) and the canonical type I phase model,
dφ
dt = [1−cosφ] +ΔI [1+cosφ],
(5.17)
deﬁned in Chapter 4; see Section 4.4.1 (Ermentrout, 1996; Ermentrout and Kopell, 1986).
Let us denote by Iθ the minimal current necessary for repetitive ﬁring of the quadratic
integrate-and-ﬁre neuron. With a suitable shift of the voltage scale and constant current
I = Iθ +ΔI the equation of the quadratic neuron model can then be cast into the form
du
dt = u2 +ΔI .
(5.18)
For ΔI > 0 the voltage increases until it reaches the ﬁring threshold ϑ ≫1 where it is
reset to a value ur ≪−1. Note that the ﬁring times are insensitive to the actual values

132
Nonlinear integrate-and-ﬁre models
of ﬁring threshold and reset value because the solution of Eq. (5.18) grows faster than
exponentially and diverges for ﬁnite time (hyperbolic growth). The difference in the ﬁring
times for a ﬁnite threshold of, say, ϑ = 10 and ϑ = 10000 is thus negligible.
We want to show that the differential equation (5.18) can be transformed into the canon-
ical phase model (5.17) by the transformation
u(t) = tan
φ(t)
2

.
(5.19)
To do so, we take the derivative of (5.19) and use the differential equation (5.17) of the
generic phase model. With the help of the trigonometric relations dtanx/dx = 1/cos2(x)
and 1+cosx = 2cos2(x/2) we ﬁnd
du
dt =
1
cos2(φ/2)
1
2
dφ
dt
= tan2(φ/2)+ΔI = u2 +ΔI .
(5.20)
Thus Eq. (5.19) with φ(t) given by (5.17) is a solution to the differential equation of the
quadratic integrate-and-ﬁre neuron. The quadratic integrate-and-ﬁre neuron is therefore (in
the limit ϑ →∞and ur →−∞) equivalent to the generic type I neuron (5.17).
5.4 Summary
The standard leaky integrate-and-ﬁre model is rather limited in scope, since it has one uni-
versal voltage threshold. Nonlinear integrate-and-ﬁre neurons, however, can account for
the fact that in real neurons the effective voltage threshold for repetitive ﬁring is different
than the voltage threshold found with short current pulses. These two voltage thresholds,
which are related to the minimum of the nonlinearity f(u) and to the unstable ﬁxed point,
respectively, are intrinsic features of nonlinear integrate-and-ﬁre models. Once the mem-
brane potential is above the intrinsic threshold, the upswing of the membrane potential
starts. The integration is stopped at a numerical threshold θreset which is much higher and
conceptually very different than the intrinsic ﬁring threshold of the model. In fact, the
exact value of the numerical threshold does not matter, since, without such a threshold, the
membrane potential would go to inﬁnity in ﬁnite time.
In principle, many different forms of nonlinearity are imaginable. It turns out, how-
ever, that many neurons are well described by a linear term (the "leak" term) combined
with an exponential term (the "activation" term); see Fig. 5.4. Therefore, the exponential
integrate-and-ﬁre model has the "correct" nonlinearity, whereas the quadratic integrate-
and-ﬁre model is too nonlinear in the subthreshold regime and too slow in the superthresh-
old regime.

5.4 Summary
133
Both the exponential and the quadratic integrate-and-ﬁre model show a frequency-
current curve of type I. Indeed, close to the bifurcation point the two models become
identical and can be mapped onto the canonical type I model.
Literature
Nonlinear generalizations of the one-dimensional equation of the leaky integrate-and-ﬁre
model can be found in the paper by Abbott and van Vreeswijk (1993). While the form of
the nonlinearity was left open at that time, analytical methods from bifurcation theory sug-
gested that there was a canonical one-dimensional model which describes the saddle-node-
onto-limit-cycle bifurcation of type I models. This is called the canonical type I model
or Theta model or Ermentrout-Kopell model (Ermentrout and Kopell, 1986; Ermentrout,
1996). While the quadratic nonlinearity in the voltage appeared in many early papers on
bifurcations and type I models (Ermentrout, 1996; Ermentrout and Kopell, 1986; Strogatz,
1994; Hoppensteadt and Izhikevich, 1997) the active use of the quadratic integrate-and-
ﬁre model for simulations seems to have been started by Latham et al. in 2000 and later
popularized by Izhikevich (2007b).
Based on biophysical and mathematical arguments, the exponential integrate-and-ﬁre
model was introduced in 2003 by Fourcaud-Trocme, Hansel, Vreeswijk and Brunel. While
the quadratic integrate-and-ﬁre model is the canonically correct type I model close to the
bifurcation point, i.e., at the transition to repetitive ﬁring, there is no fundamental reason
why the quadratic nonlinearity should also be correct further away from the threshold, and
it was unclear at that time what the nonlinearity of real neurons would look like. The issue
was settled by the work of Badel et al. (2008a,b) who designed an experimental method to
measure the nonlinearity directly in experiments. The nonlinearity found in experiments is
extremely well matched by the exponential integrate-and-ﬁre model.
The link between ion channel activation or inactivation in conductance-based neuron
models and the parameters of an exponential integrate-and-ﬁre model with refractoriness
(Badel et al., 2008a,b) is discussed in the overview paper by Platkiewicz and Brette (2010).
We shall see in the next chapter that the single-variable exponential integrate-and-ﬁre
model as it stands is not sufﬁcient to account for the wide variety of neuronal ﬁring patterns,
but needs to be complemented by a second variable to account for slow processes such as
adaptation - and this leads eventually to the adaptive exponential integrate-and-ﬁre model.
Exercises
1. Quadratic vs. exponential integrate-and-ﬁre. For a comparison of the two models, take a look
at Fig. 5.8b and answer the following questions:
(a) Show for the exponential integrate-and-ﬁre model that the minimum of the nonlinearity
f(u) occurs at u = ϑrh. Calculate the curvature d2/du2 f(u) at u = ϑrh.
(b) Find parameters of the quadratic integrate-and-ﬁre model so that it matches the location
and curvature of the exponential model in (a).
(c) Suppose that the value of the numerical threshold is θreset = ϑrh +2ΔT. When the threshold

134
Nonlinear integrate-and-ﬁre models
is reached the membrane potential is reset to ur = ϑrh −2ΔT. Sketch qualitatively the trajectory
u(t) for both neuron models in the repetitive ﬁring regime. Pay particular attention to the fol-
lowing questions: (i) For u > ϑrh which of the two trajectories rises more rapidly towards the
numerical threshold? (ii) For u = ϑrh, do both trajectories have the same speed of rise du/dt or
a different one? (iii) For u < ϑrh, which of the two trajectories rises more rapidly? (iv) Should
your drawing of the trajectories follow any symmetry rules? Compare your results with Fig. 5.9.
2. Zero-curvature and rheobase threshold. Experimenters sometimes determine the threshold
voltage for spike initiation by searching for the zero-curvature point in the voltage trajectory,
just before the upswing of the action potential. Show for a general nonlinear integrate-and-ﬁre
model that the zero-curvature point is equivalent to the rheobase threshold ϑrh. Hints: (i) Min-
imal curvature means that the voltage trajectory passes through a point d2u/dt2 = 0. (ii) Note
that the slope of the voltage trajectory du/dt is given by the function f(u). (iii) Recall that the
minimum of f is taken at u = ϑrh.
3. Exponential integrate-and-ﬁre and sodium activation. To derive the exponential integrate-
and-ﬁre model from a Hodgkin-Huxley model with multiple channels, follow the procedure indi-
cated in Section 5.2.2 and perform the following steps.
(a) Show that N linear currents can always be rewritten as one effective leak current ∑k gk (u−
Ek) = geff (u−Eeff). Determine the effective conductance geff and the effective reversal potential
Eeff.
(b) Assume that the sodium activation is rapid and approaches an equilibrium value m0(u) =
1/{1+exp[−β (u−θact)]} = 0.5{1+tanh[−β (u−θact)/2]} where θact is the activation thresh-
old of the sodium channel and β the sharpness of the threshold. Using a Taylor expansion,
show that for u < θact −β −1 the activation function can be approximated by an exponential
m0(u) = exp[β (u−θact)].
(c) Assume that u < θact −β −1 < ENa and show that the sodium current
INa = gNa[m0(u)]3 hrest (u−ENa)
(5.21)
gives rise to the exponential term.
(d) Using the steps (a) - (c), map (5.15) to the exponential integrate-and-ﬁre model
du
dt = ˜f(u) = −u−urest
τ
+ ΔT
τ exp
u−ϑrh
ΔT

.
(5.22)
Determine the parameters urest, τ and ΔT .
4. Refractory exponential integrate-and-ﬁre model and sodium inactivation. In the previous
exercise, we have assumed that h = hrest is constant throughout the spiking process. Repeat the
steps of the previous calculation, but set h(t) = hrest +x(t) and show that the sodium inactivation
dynamics leads to an increase in the the ﬁring threshold a few milliseconds after the spike.
Hints. (i) Linearize the dynamics of gating variable h in the Hodgkin-Huxley model around
h = hrest so as to derive dx/dt = −x/τ0. (ii) Assume that during each spike, the inactivation
variable h increases by a ﬁxed amount Δh.
5. Quadratic integrate-and-ﬁre model.
Consider the dimensionless quadratic integrate-and-ﬁre model
d
dt u = (u−urest)(u−uc)+I ,
(5.23)
with urest = −1 and uc = 1 and I = 0.
(a) Suppose that a trajectory starts at time t = 0 at −∞. How long does it take to get close to
the resting state and reach the value u = −1−ε where ε ≪1?
(b) Suppose that a trajectory is initialized at u(0) = 1+ε, where ε ≪1. How long does it take
to reach u = ∞?
(c) Initialize as in (b) but stop the integration at u = θreset. How long does the trajectory take
to reach the reset threshold? Is the difference between (b) and (c) important?

5.4 Summary
135
Hint: Use
 dx/[1 −x2] = arcoth(x) = 0.5[ln(x + 1) −ln(x −1)] and cothh(x) = [ex + e−x]/
[ex −e−x].
6. Gain function of the quadratic integrate-and-ﬁre model.
We consider a quadratic integrate-and-ﬁre model in the superthreshold regime
d
dt u = u2 +I ,
(5.24)
with constant current I > 0.
(a) Give a transformation of variables from Eq. (5.23) to (5.24).
(b) Calculate the duration T of a trajectory which starts at time t = 0 at u(0) = −∞and ends
at time T at u(T) = +∞.
Hint: Use
 dx/[1+x2] = artan(x).
(c) Plot the frequency ν = 1/T as a function of I.

6
Adaptation and ﬁring patterns
When an experimenter injects a strong step current into the soma of a neuron, the response
consists of a series of spikes separated by long or short intervals. The stereotypical arrange-
ment of short, long or very long interspike intervals deﬁnes the neuronal ﬁring pattern. In
Chapter 2 we have already encountered ﬁring patterns such as tonic, adapting, or delayed
spike ﬁring. In addition to these, several variants of burst ﬁring have also been observed
in real neurons (see Fig. 6.1). This diversity of ﬁring patterns can be explained, to a large
extent, by adaptation mechanisms which in turn depend on the zoo of available ion chan-
nels (Chapter 2) and neuronal anatomy (Chapter 3).
In order to describe ﬁring patterns, and in particular adaptation, in a transparent mathe-
matical framework, we start in this chapter with the simpliﬁed model of spike initiation
from Chapter 5 and include a phenomenological equation for subthreshold and spike-
triggered adaptation. The resulting model is called the adaptive exponential integrate-and-
ﬁre (AdEx; Section 6.1). We then use this simple model to explain the main ﬁring patterns
(Section 6.2). In Section 6.3, we describe how the parameters of the subthreshold and
spike-triggered adaptation reﬂect the contribution of various ion channels and of dendritic
morphology. Finally, we introduce the Spike Response Model (SRM; Section 6.4) as a
transparent framework to describe neuronal dynamics. The Spike Response Model will
serve as a starting point for the Generalized Linear Models which we will discuss later, in
Chapter 9.
6.1 Adaptive exponential integrate-and-ﬁre
In the previous chapter we have explored nonlinear integrate-and-ﬁre neurons where the
dynamics of the membrane voltage is characterized by a function f(u). A single equation
is, however, not sufﬁcient to describe the variety of ﬁring patterns that neurons exhibit in
response to a step current. We therefore couple the voltage equation to abstract current

6.1 Adaptive exponential integrate-and-ﬁre
137
variables wk, each described by a linear differential equation. The set of equations is
τm
du
dt = f(u)−R ∑
k
wk +RI(t),
(6.1)
τk
dwk
dt = ak (u−urest)−wk +bkτk∑
t f
δ(t −t f ).
(6.2)
The coupling of voltage to the adaptation current wk is implemented by the parameter
ak and evolves with time constant τk. The adaptation current is fed back to the voltage
equation with resistance R. Just as in other integrate-and-ﬁre models, the voltage variable
u is reset if the membrane potential reaches the numerical threshold Θreset. The moment
u(t) = Θreset deﬁnes the ﬁring time t f = t. After ﬁring, integration of the voltage restarts
at u = ur. The δ-function in the wk equations indicates that, during ﬁring, the adapta-
tion currents wk are increased by an amount bk. For example, a value bk = 10 pA means
that the adaptation current wk is 10 pA stronger after a spike than it was just before the
spike. The parameters bk are the "jump" of the spike-triggered adaptation. One possi-
ble biophysical interpretation of the increase is that during the action potential calcium
enters the cell so that the amplitude of a calcium-dependent potassium current is increased.
The biophysical origins of adaptation currents will be discussed in Section 6.3. Here we
are interested in the dynamics and neuronal ﬁring patterns generated by such adaptation
currents. Various choices are possible for the nonlinearity f(u) in the voltage equation.
We have seen in the previous chapter (Section 5.2) that the experimental data suggests
a nonlinearity consisting of a linear leak combined with an exponential activation term,
f(u) = −(u−urest)+ΔT exp

u−ϑrh
ΔT
	
. The adaptive exponential integrate-and-ﬁre model
(AdEx) consists of such an exponential nonlinearity in the voltage equation coupled to a
single adaptation variable w
τm
du
dt = −(u−urest)+ΔT exp
u−ϑrh
ΔT

−Rw+RI(t),
(6.3)
τw
dw
dt = a(u−urest)−w+bτw ∑
t f
δ(t −t f ).
(6.4)
At each threshold crossing the voltage is reset to u = ur and the adaptation variable w is
increased by an amount b. Adaptation is characterized by two parameters: the parameter
a is the source of subthreshold adaptation because it couples adaptation to the voltage.
Spike-triggered adaptation is controlled by a combination of a and b. The choice of a and
b largely determines the ﬁring patterns of the neuron (Section 6.2) and can be related to
the dynamics of ion channels (Section 6.3). Before exploring the AdEx model further, we
discuss two other examples of adaptive integrate-and-ﬁre models.
Example: Izhikevich model
While the AdEx model exhibits the nonlinearity of the exponential integrate-and-ﬁre
model, the Izhikevich model uses the quadratic integrate-and-ﬁre model for the ﬁrst

138
Adaptation and ﬁring patterns
350ms
35mV 
30mV 
1s 
Low
High
Low
High
High
Low
Tonic
Initial burst
Delay - tonic
Transient
Regular burst
Burst - tonic
Adapting
Burst - adapting
Delay - adapting
Fig. 6.1 Multiple ﬁring patterns in cortical neurons. For each type, the neuron is stimulated with
a step current with low or high amplitude. Modiﬁed from Markram et al. (2004).
equation
τm
du
dt = (u−urest)(u−ϑ)−Rw+RI(t),
(6.5)
τw
dw
dt = a(u−urest)−w+bτw ∑
t f
δ(t −t f ).
(6.6)

6.1 Adaptive exponential integrate-and-ﬁre
139
High
Low
High
Low
High
Low
Tonic
Adapting
Bursting
Initiation pattern
Steady-state pattern
Tonic
Initial burst
Delay
Fig. 6.2 Multiple ﬁring patterns in the AdEx neuron model. For each set of parameters, the model is
stimulated with a step current with low or high amplitude. The spiking response can be classiﬁed by
the steady-state ﬁring behavior (vertical axis: tonic, adapting, bursting) and by its transient initiation
pattern as shown along the horizontal axis: tonic (i.e., no special transient behavior), initial burst, or
delayed spike initiation.
If u = θreset, the voltage is reset to u = ur and the adaptation variable w is increased by
an amount b. Normally b is positive, but b < 0 is also possible.
Example: Leaky model with adaptation
Adaptation variables wk can also be combined with a standard leaky integrate-and-ﬁre

140
Adaptation and ﬁring patterns
Type
Fig.
τm (ms)
a (nS)
τw (ms)
b (pA)
ur (mV)
Tonic
6.3a
20
0.0
30.0
60
−55
Adapting
6.3b
200
0.0
100
5.0
−55
Init. burst
6.4a
5.0
0.5
100
7.0
−51
Bursting
6.4c
5.0
−0.5
100
7.0
−46
Irregular
6.5a
9.9
−0.5
100
7.0
−46
Transient
6.9a
10
1.0
100
10
−60
Delayed
6.9c
5.0
−1.0
100
10
−60
Table 6.1 Exemplar parameters for the AdEx model. In all cases, the resting potential
was urest = −70 mV, the resistance was R = 500 MΩ, the threshold was ϑrh = −50 mV
with sharpness ΔT = 2 mV, and the current step was ﬁxed to 65 pA except for "delayed"
where it was at 25 pA.
model
τm
du
dt = −(u−urest)−R ∑
k
wk +RI(t),
(6.7)
τk
dwk
dt = a(u−urest)−wk +bkτk ∑
t f
δ(t −t f ).
(6.8)
At the moment of ﬁring, deﬁned by the threshold condition u(t f ) = θreset, the voltage
is reset to u = ur and the adaptation variables wk are increased by an amount bk. Note
that in the leaky integrate-and-ﬁre model the numerical threshold θreset coincides with
the voltage threshold ϑ that one would ﬁnd with short input current pulses.
6.2 Firing patterns
The AdEx model is capable of reproducing a large variety of ﬁring patterns that have
been observed experimentally. In this section, we show some typical ﬁring patterns, and
show how the patterns can be understood mathematically, adapting the tools of phase plane
analysis previously encountered in Chapter 4.
6.2.1 Classiﬁcation of ﬁring patterns
How are the ﬁring patterns classiﬁed? Across the vast ﬁeld of neuroscience and over more
than a century of experimental work, different classiﬁcation schemes have been proposed.
For a rough qualitative classiﬁcation (Fig. 6.2, exemplar parameters in Table 6.1), it is
advisable to separate the steady-state pattern from the initial transient phase (Markram
et al., 2004). The initiation phase refers to the ﬁring pattern right after the onset of the

6.2 Firing patterns
141
0
100
200
300
t [ms]
−70
−60
−50
−40
−30
−20
−10
0
u [mV]
1
4
(a)
(b)
(c)
0
100
200
300
t[ms]
−70
−60
−50
−40
−30
−20
−10
0
u [mV]
1
7
(d)
7
2
1
Fig. 6.3 Tonic and adapting ﬁring patterns in the AdEx model. (a) Tonic spiking with a strong spike-
triggered current (b = 60 pA) of short duration (τw = 30 ms). (b) If the reset (empty squares) leads to
a value above the u-nullcline, the trajectories make a detour to lower values of u. (c) Spike-frequency
adaptation with a weak spike-triggered current (b = 5 pA) and slow decay (τw = 100 ms). (d) If the
reset lands below the u-nullcline, the membrane potential immediately increase towards the next
spike. Parameters in Table 6.1.
current step. There are three main initiation patterns: the initiation cannot be distinguished
from the rest of the spiking response (tonic); the neuron responds with a signiﬁcantly
greater spike frequency in the transient (initial burst) than in the steady state; the neuronal
ﬁring starts with a delay (delay).
After the initial transient, the neuron exhibits a steady-state pattern. Again there are
three main types: regularly spaced spikes (tonic); gradually increasing interspike intervals
(adapting); or regular alternations between short and long interspike intervals (bursting).
Irregular ﬁring patterns are also possible in the AdEx model, but their relation to irregular
ﬁring patterns in real neurons is less clear because of potential noise sources in biological
cells (Chapter 7). The discussion in the next sections is restricted to deterministic models.
Example: Tonic, adapting and facilitating
When the subthreshold coupling a is small and the voltage reset is low (ur ≈urest),

142
Adaptation and ﬁring patterns
0
100
200
300
t [ms]
−70
−60
−50
−40
−30
−20
−10
0
u [mV]
1
3
4
7
(a)
(b)
0
100
200
300
t [ms]
−70
−60
−50
−40
−30
−20
−10
0
u [mV]
1
5
6 7
(c)
(d)
Fig. 6.4 Phase plane analysis of initial bursting and sustained bursting patterns. (a) Voltage trace
of an AdEx model with parameters producing an initial burst. (b) In the phase plane, the initial
burst is generated by a series of resets below the u-nullcline. Only the fourth reset arrives above the
u-nullcline. (c) Voltage trace of an AdEx model exhibiting regular bursts. (d) The phase plane for
regular bursting is similar to those of initial burst, except that the ﬁrst reset above the u-nullcline
yields a trajectory that travels below at least one of the previous resets. Hence, the neuron model
alternates between direct and detour resets.
the AdEx response is either tonic or adapting. This depends on the two parameters regu-
lating the spike-triggered current: the jump b and the time scale τw. A large jump with a
small time scale creates evenly spaced spikes at low frequency (Fig. 6.3a). On the other
hand, a small spike-triggered current decaying on a long time scale can accumulate
strength over several spikes and therefore successively decreases the net driving cur-
rent I −w (Fig. 6.3b). In general, weak but long-lasting spike-triggered currents cause
spike-frequency adaptation, while short but strong currents lead only to a prolongation
of the refractory period. There is a continuum between purely tonic spiking and strongly
adapting.
Similarly, when the spike-triggered current is depolarizing (b < 0) the interspike inter-
val may gradually decrease, leading to spike-frequency facilitation.

6.2 Firing patterns
143
6.2.2 Phase plane analysis of nonlinear integrate-and-ﬁre models in two dimensions
Phase plane analysis, which has been a useful tool to understand the dynamics of the
reduced Hodgkin-Huxley model (Chapter 4), is also helpful to illustrate the dynamics of
the AdEx model. Let us plot the two state variables u(t) and w(t) in the plane and indicate
the regions where ˙u = 0 (u-nullcline) and ˙w = 0 (w-nullcline) with solid lines.
In the AdEx model, the nullclines look similar to the one-dimensional ﬁgures of the
exponential integrate-and-ﬁre model in Chapter 5. The u-nullcline is again linear in the
subthreshold regime and rises exponentially when u is close to ϑ. Upon current injection,
the u-nullcline is shifted vertically by an amount proportional to the magnitude of the
current I. The w-nullcline is a straight line with a slope tuned by the parameter a. If there
is no coupling between the adaptation variable and the voltage in the subthreshold regime
(a = 0), then the w-nullcline is horizontal. The ﬁxed points are the points where the curved
u-nullcline intersects with the straight w-nullcline. Solutions of the system of differential
equations (6.3) and (6.4) appear as a trajectory in the (u,w)-plane.
In constrast to the two-dimensional models in Chapter 4, the AdEx model exhibits a reset
which correspond to a jump of the trajectory. Each time the trajectory reaches u = θreset,
it will be reinitialized at a reset value (ur,w + b) indicated by an empty square (Fig. 6.3).
We note that for the voltage variable the reinitialization occurs always at the same value
u = ur; for the adaptation variable, however, the reset involves a vertical shift upwards by
an amount b compared with the value of w just before the reset. Thus, the reset maps w to
a potentially new initial value after each ﬁring.
There are three regions of the phase plane with qualitatively different ensuing dynamics.
These regions are distinguished by whether the reset point is in a region where trajectories
are attracted to the stable ﬁxed point or not; and whether the reset is above or below the
u-nullcline. Trajectories attracted to a ﬁxed point will simply converge to it. Trajectories
not attracted to a ﬁxed point all go eventually to θreset but they can do so directly or with a
detour. A detour is introduced whenever the reset falls above the u-nullcline, because in the
area above the u-nullcline the derivative is ˙u < 0 so that the voltage u(t) must ﬁrst decrease
before it can eventually increase again. Thus a "detour reset" corresponds to a downswing of
the membrane potential after the end of the action potential. The distinction between detour
and direct resets is helpful to understand how different ﬁring patterns arise. Bursting, for
instance, can be generated by a regular alternation between direct resets and detour resets.
Example: Bursting
Before considering regular bursting, we describe the dynamics of an initial burst. By
deﬁnition, an initial burst means a neuron ﬁrst ﬁres a group of spikes at a considerably
higher spiking frequency than the steady-state frequency (Fig. 6.4a). In the phase plane,
initial bursting is caused by a series of one or more direct resets followed by detour
resets (Fig. 6.4b). This ﬁring pattern may appear very similar to strong adaptation where

144
Adaptation and ﬁring patterns
0
100
200
300
t [ms]
−70
−60
−50
−40
−30
−20
−10
0
u [mV]
(a)
(b)
Fig. 6.5 Phase plane analysis of an irregular ﬁring pattern. (a) Voltage trace of an AdEx model
showing irregularly spaced spikes. (b) The evolution of trajectories in the phase plane during the
simulation in (a) shows that the model switches irregularly between direct and detour resets.
the ﬁrst spikes also have a larger frequency, but the shape of the voltage trajectory after
the end of the action potential (downswing or not) can be used to distinguish between
adapting (strictly detour or strictly direct resets) and initial bursting (ﬁrst direct then
detour resets).
Regular bursting can arise from a similar process, by alternation between direct and
detour resets. In the phase plane, regular bursting is made possible by a reset ur higher
than the effective threshold ϑ. After a series of direct resets, the ﬁrst reset that falls above
the u-nullcline must make a large detour and is forced to pass under the u-nullcline.
When this detour trajectory is mapped below at least one of the previous reset points,
the neuron may burst again (Fig. 6.4b).
While the AdEx can generate a regular alternation between direct and detour resets,
it can also produce an irregular alternation (Fig. 6.5). Such irregular ﬁring patterns can
occur in the AdEx model despite the fact that the equations are deterministic. The aperi-
odic mapping between the two types of reset is a manifestation of chaos in the discrete
map (Naud et al., 2008; Touboul and Brette, 2008). This ﬁring pattern appears for a
restricted set of parameters such that, unlike regular and initial bursting, it occupies a
small and patchy volume in parameter space.
6.2.3 Exploring the space of reset parameters
The AdEx model in the form of Eqs. (6.3) and (6.4) has nine parameters. Some combi-
nations of parameters lead to initial bursting, others to adaptation, yet others to delayed
spike onset, and so on. As we change parameters, we ﬁnd that each ﬁring pattern occurs
in a restricted region of the nine-dimensional parameter space - and this can be labeled by
the corresponding ﬁring pattern, e.g., bursting, initial bursting, or adaptive. While inside
a given region the dynamics of the model can exhibit small quantitative changes; the big
qualitative changes occur at the transition from one region of parameter space to the next.

6.2 Firing patterns
145
b [pA]
ur[mV]
ur[mV]
-40
-50
-60
-70
-40
-50
-60
-70
0
100
200
i
t
t
a
b
i
t
t
a
b
(a)
(b)
Fig. 6.6 Parameter space of the AdEx model. (a) Combinations of the voltage reset ur and of the
spike-triggered jump b of the adaptation current leading to a tonic (t), adapting (a), initial burst (i) and
bursting (b) ﬁring patterns for a long adaptation time constant (τw = 100 ms) and small subthreshold
coupling (a = 0.001 nS). (b) Same as (a) but for τw = 5 ms. Current was switched from zero to twice
the rheobase current and all other parameters are ﬁxed at τm = 10 ms, R = 100 MΩ, urest = −70 mV,
ϑrh = −50 mV and ΔT = 2 mV.
Thus, boundaries in the parameter space mark transitions between different types of ﬁring
pattern - which are often correlated with types of cells.
To illustrate the above concept of regions inside the parameter space, we apply a step
current with an amplitude twice as large as the minimal current necessary to elicit a spike
and study the dependence of the observed ﬁring pattern on the reset parameters ur and b
(Fig. 6.6). All the other parameters are kept ﬁxed. We ﬁnd that the line separating initial
bursting and tonic ﬁring resembles the shape of the u-nullcline. This is not unexpected
given that the location of the reset with respect to the u-nullcline plays an important role in
determining whether the reset is "direct" or leads to a "detour." Regular bursting is possible,
if the voltage reset ur is located above the voltage threshold ϑ. Irregular ﬁring patterns are
found within the bursting region of the parameter space. Adapting ﬁring patterns occur
only over a restricted range of jump amplitudes b of the spike-triggered adaptation current.
Example: Piecewise-linear model (*)
In order to understand the location of the boundaries in parameter space we consider
a piecewise-linear version of the AdEx model
f(u) =

−(u−urest)
if u ≤ϑrh,
ΔT (u−up)
otherwise,
(6.9)

146
Adaptation and ﬁring patterns
X
x
u [mV]
-40
-50
-60
-70
t
t
b
i
b [pA]
0
100
200
(a)
(b)
(c)
w
u 
u 
J 
b 
rh
J rh
0
r 
u r 
u r 
Fig. 6.7 Piecewise-linear model. (a) Parame-
ter space analogous to Fig. 6.6 but for the
piecewise-linear model. (b) Evolution of the
trajectory (thick solid lines) in the phase plane
during tonic spiking. Open squares indicate
the initial condition and resets after the ﬁrst,
second, and third spike. Nullclines drawn as
thin solid lines. The trajectories follow the u-
nullcline at a distance x (inset). The u-nullcline
before the application of the step current is
shown with a dashed line. (c) As in (b), but dur-
ing regular bursting.
with
up = ϑrh + ϑrh −urest
ΔT
,
(6.10)
which we insert into the voltage equation τmdu/dt = f(u)+RI −Rw; compare Eq. (6.1)
with a single adaptation variable of the form (6.2). Note that the u-nullcline is given by
w = f(u)/R+I and takes at u = ϑrh its minimum value wmin = f(ϑrh)/R+I.
We assume separation of time scale (τm/τw << 1) and exploit the fact that the trajec-
tories in the phase plane are nearly horizontal (w takes a constant value) - unless they
approach the u-nullcline. In particular, all trajectories that start at a value wr < wmin stay
horizontal and pass unperturbed below the u-nullcline.
To determine the ﬁring pattern, we need to map the initial condition (ur,wr) after a
ﬁrst reset to the value we of the adaptation variable at the end of the trajectory: we =
M(ur,wr). The next reset starts then from (ur,we +b) and with the help of the mapping
function M we can iterate the above procedure. We know already that all trajectories
with wr < wmin remain horizontal, so that we = wr.
The more interesting situation is wr > wmin. We distinguish two possible cases. The
ﬁrst one corresponds to a voltage reset below the threshold, ur < ϑrh. A trajectory ini-
tiated at ur < ϑrh evolves horizontally until it comes close to the left branch of the
u-nullcline. It then follows the u-nullcline at a small distance x(u) below it (see Sec-
tion 4.6). This distance can be shown to be
x(u) = τm
τw

I −(a+R−1)(u−urest)

,
(6.11)

6.2 Firing patterns
147
u 
u rest 
I 
0
w 
(a)
aR
tm/tw
Hopf
Saddle-node
RESONATOR
MIXED
INTEGRATOR
1
2
3
4
0
0
0.5
1.0
(b)
Fig. 6.8 Hopf bifurcation and space of subthreshold parameters. (a) Nullclines and ﬁxed points
(ﬁlled and open circles) during a Hopf bifurcation. A step current I shifts the u-nullcline upward
(solid line). The stability of the stable ﬁxed point (ﬁlled circle) is lost in a Hopf bifurcation before
the two ﬁxed points merge. If it is not lost before the merge then the bifurcation is saddle-node.
(b) The ratio of time constants τm/τw (horizontal axis) and the factor aR which controls the coupling
between voltage and adaptation. The straight diagonal line separates the region where the station-
ary state of the system loses stability through a Hopf bifurcation (aR > τm/τw) from the region of
saddle-node bifurcation. The linear response of the subthreshold dynamics is characterized as res-
onator (dotted region), integrator (blank), or mixed (stripes).
which vanishes in the limit τm/τw →0. When the u-nullcline reaches its mini-
mum, the trajectory is again free to evolve horizontally. Therefore the ﬁnal w-value
of the trajectory is the one it takes at the minimum of the u-nullcline, so that for
ur < ϑrh
M(ur,wr) =
wr
ifwr < f(ϑrh)/R+I,
f(ϑrh)/R+I
otherwise.
(6.12)
If ur > ϑrh then we have a direct reset (i.e., movement starts to the right) if (ur,wr) lands
below the right branch of the u-nullcline (Fig. 6.7c) and a detour reset otherwise
M(ur,wr) =
wr
ifwr < f(ur)/R+I,
f(ϑrh)/R+I
otherwise.
(6.13)
The map M uniquely deﬁnes the ﬁring pattern. Regular bursting is possible only if ur >
ϑrh and b < f(ur) −f(ϑrh) so that at least one reset in each burst lands below the u-
nullcline (Fig. 6.7a). For ur > ϑrh, we have tonic spiking with detour resets when b >
f(ur)+I and initial bursting if f(ur)+I > b > f(ur)−f(ϑrh)+x(ϑrh).
If ur ≤ϑ we have tonic spiking with detour resets when b > f(ur)+I, tonic spiking
with direct reset when b < f(ur)−f(ϑrh) and initial bursting if f(ur)+I > b > f(ur)−
f(ϑrh). Note that the rough layout of the parameter regions in Fig. 6.7a, which we just
calculated analytically, matches qualitatively the organization of the parameter space in
the AdEx model (Fig. 6.6).

148
Adaptation and ﬁring patterns
6.2.4 Exploring the space of subthreshold parameters
While the exponential integrate-and-ﬁre model loses stability always via a saddle-node
bifurcation, the AdEx can become unstable either via a Hopf or a saddle-node bifurca-
tion. Thus, we see again that the addition of an adaptation variable leads to a much richer
dynamics.
In the absence of external input, the AdEx has two ﬁxed points, a stable one at urest and
an unstable one at some value u > ϑrh. We recall from Chapter 4 that a gradual increase
of the driving current corresponds to a vertical shift of the u-nullcline (Fig. 6.8a), and to
a slow change in the location of the ﬁxed points. The stability of the ﬁxed points, and
hence the potential occurrence of a Hopf bifurcation, depends on the slope of the u- and
w-nullclines. In the AdEx, an eigenvalue analysis shows that the stable ﬁxed point loses
stability via a Hopf bifurcation if aR > τm/τw. Otherwise, when the coupling from voltage
to adaptation (parameter a) and back from adaptation to voltage (parameter R) are both
weak (aR < τm/τw), an increase in the current causes the stable ﬁxed point to merge with
the unstable one, so that both disappear via a saddle-node bifurcation - just like in the
normal exponential integrate-and-ﬁre model. Note, however, that the type of bifurcation
has no inﬂuence on the ﬁring pattern (bursting, adapting, tonic), which depends mainly on
the choice of reset parameters.
However, the subthreshold parameters do control the presence or absence of oscillations
in response to a short current pulse. A model showing damped oscillations is often called
a resonator while a model without is called an integrator. We have seen in Chapter 4 that
Hopf bifurcations are associated with damped oscillations, but this statement is valid only
close to the bifurcation point or rheobase-threshold. The properties can be very different
far from the threshold. Indeed, the presence of damped oscillations depends nonlinearly on
a/gL and τm/τw as summarized in Fig. 6.8b. The frequency of the damped oscillation is
given by
ω = 4
τw

aR−2τw
τm

1−τm
τw
2
.
(6.14)
Example: Transient spiking
Upon the onset of a current step, some neurons may ﬁre a small number of spikes
and then remain silent, even if the stimulus is maintained for a very long time. An AdEx
model with subthreshold coupling a > 0 can explain this phenomenon whereas pure
spike-triggered adaptation (a = 0;b > 0) cannot account for it, because adaptation would
eventually decay back to zero so that the neuron ﬁres another spike.
To understand the role of subthreshold coupling, let us choose parameters a and τw
such that the neuron is in the resonator regime. The voltage response to a step input
then exhibits damped oscillations (Fig. 6.9a). Similar to the transient spiking in the
Hodgkin-Huxley model, the AdEx can generate a transient spike if the peak of the

6.3 Biophysical origin of adaptation
149
0
100
200
300
t [ms]
−75
−70
−65
−60
−55
−50
−45
−40
u [mV]
ii
i
(a)
(b)
Fig. 6.9 Phase plane analysis of transient spiking in the AdEx model. (a) Voltage trace of an AdEx
model with parameters producing transient spiking upon a strong step current input (solid line marked
ii). A weaker step input generates damped oscillations (dashed line marked i). (b) Phase plane with
nullclines after application of the strong (solid lines: u- and w-nullclines) or weak step current
(dashed line: u-nullcline). Upon injection of the weak step, the stable ﬁxed point is reached after
a short transient. Upon injection of the strong current, a stable ﬁxed point remains, but the initial
state is outside the region where it would be attracted to the stable ﬁxed point. Only after the second
reset (open squares), does the trajectory converge to the ﬁxed point.
oscillation is sufﬁcient to reach the ﬁring threshold. Phase plane analysis reveals that
sometimes several resets are needed before the trajectory is attracted towards the ﬁxed
point (Fig. 6.9b). In Chapter 2, damped oscillations were due to sodium channel inacti-
vation or Ih. Indeed, the subthreshold coupling can be seen as a simpliﬁcation of Ih, but
many other biophysical mechanisms can be responsible.
6.3 Biophysical origin of adaptation
We have introduced, in Section 6.1, formal adaptation variables wk which evolve according
to a linear differential equation (6.2). We now show that the variables wk can be linked to
the biophysics of ion channels and dendrites.
6.3.1 Subthreshold adaptation by a single slow channel
First we focus on one variable w at a time and study its subthreshold coupling to the
voltage. In other words, the aim is to give a biophysical interpretation of the parameters a,
τw, and the variable w that show up in the adaptation equation
τw
dw
dt = a(u−E0)−w.
(6.15)
The biophysical components of spike-triggered adaptation (i.e., the interpretation of the
reset parameter b) is deferred to Section 6.3.2. Here and in the following we write E0
instead of urest in order to simplify notation and keep the treatment slightly more general.

150
Adaptation and ﬁring patterns
As discussed in Chapter 2, neurons contain numerous ion channels (Section 2.3). Rapid
activation of the sodium channels, important during the upswing of action potentials, is
well approximated (Fig. 5.4) by the exponential nonlinearity in the voltage equation of the
AdEx model, Eq. (6.3). We will see now that the subthreshold current w is linked to the
dynamics of other ion channels with a slower dynamics.
Let us focus on the model of a membrane with a leak current and a single, slow, ion
channel, say a potassium channel of the Hodgkin-Huxley type
τm
du
dt = −(u−EL)−RL gK np (u−EK)+RL Iext,
(6.16)
where RL and EL are the resistance and reversal potential of the leak current, τm = RLC is
the membrane time constant, gK the maximal conductance of the open channel and n the
gating variable (which appears with arbitrary power p) with dynamics
dn
dt = −n−n0(u)
τn(u)
.
(6.17)
As long as the membrane potential stays below threshold, we can linearize the equa-
tions (6.16) and (6.17) around the resting voltage E0, given by the ﬁxed point condition
E0 = EL +(RL gK)n0(E0)p EK
1+(RL gK)n0(E0)p
.
(6.18)
The resting potential is shifted with respect to the leak reversal potential if the channel is
partially open at rest, n0(E0) > 0. We introduce a parameter β = gK pn0(E0)p−1 (E0 −EK)
and expand n0(u) = n0(E0) + n′
0 (u −E0) where n′
0 is the derivative dn0/du evaluated at
E0.
The variable w = β [n−n0(E0)] then follows the linear equation
τn(E0)dw
dt = a(u−E0)−w.
(6.19)
We emphasize that the time constant of the variable w is given by the time constant of
the channel at the resting potential. The parameter a is proportional to the sensitivity of
the channel to a change in the membrane voltage, as measured by the slope dn0/du at the
equilibrium potential E0.
The adaptation variable w is coupled into the voltage equation in the standard form
τeff
m
du
dt = −(u−E0)−Rw+RIext.
(6.20)
Note that the membrane time constant and the resistance are rescaled by a factor [1 +
(RL gK)n0(E0)p ]−1 with respect to their values in the passive membrane equation,
Eq. (6.16). In fact, both are smaller because of partial opening of the channel at rest.
In summary, each channel with nonzero slope dn0/du at the equilibrium potential E0
gives rise to an effective adaptation variable w. Since there are many channels, we can
expect many variables wk. Those with similar time constants can be summed and grouped
into a single equation. But if time constants are different by an order of magnitude or more,

6.3 Biophysical origin of adaptation
151
Type
Fig.
Act./inact.
τw (ms)
β (pA)
a (nS)
δx
b (pA)
INa
2.3
inact.
20
−120
5.0
−
−
IM
2.13
act.
61
12
0.0
0.0085
0.1
IA
2.14
act.
33
12
0.3
0.04
0.5
IHVA +IK[Ca]
2.15
act.
150
12
0
0.05
0.6
Ih
2.17
inact.
8.5
−48
0.8
−
−
INaS
2.18
act
200
−120
−0.08
0.0041
−0.48
Table 6.2 Parameter values for ion channels presented in Chapter 2 for model linearized
around −65 mV for Rgk = 1. The action potential is assumed to consist of a pulse of 1 ms
duration at 0 mV. The approximation to obtain δx and b is valid only when τx(0 mV) is
signiﬁcantly larger than one millisecond.
then several adaptation variables are needed, which leads to the model equations (6.1)
and (6.2).
6.3.2 Spike-triggered adaptation arising from a biophysical ion channel
We have seen in Chapter 2 that some ion channels are partially open at the resting potential,
while others react only when the membrane potential is well above the ﬁring threshold. We
now focus on the second group in order to give a biophysical interpretation of the jump
amplitude b of a spike-triggered adaptation current.
Let us return to the example of a single ion channel of the Hodgkin and Huxley type such
as the potassium current in Eq. (6.16). In contrast to the treatment earlier, we now study the
change in the state of the ion channel induced during the large-amplitude excursion of the
voltage trajectory during a spike. During the spike, the target n0(u) of the gating variable is
close to 1; but since the time constant τn is long, the target is not reached during the short
time that the voltage stays above the activation threshold. Nevertheless, the ion channel
is partially activated by the spike. Unless the neuron is ﬁring at a very large ﬁring rate,
each additional spike activates the channel further, always by the same amount Δn, which
depends on the duration of the spike and the activation threshold of the current (Table 6.2).
The spike-triggered jump in the adapting current w is then
b = βΔn ,
(6.21)
where β = gK pn0(E0)p−1 (E0 −EK) has been deﬁned before.
Again, real neurons with their large quantity of ion channels have many adaptation cur-
rents wk, each with its own time constant τk, subthreshold coupling ak and spike-triggered
jump bk. The effective parameter values depend on the properties of the ion channels
(Table 6.2).

152
Adaptation and ﬁring patterns
0
500
1000
1500
t [ms]
−70
−60
−50
−40
−30
−20
−10
0
u [mV]
(a)
0
50
100
150
200
250
−10
0
10
20
30
40
50
Δ u [mV]
Reset
Facilitation
Adaptation
(b)
Fig. 6.10 Another type of bursting in a model with two spike-triggered currents. (a) Voltage trace of
the neuron model Eqs. (6.3)-(6.4) with ureset = −55 mV, ϑrh = −50 mV, b1 = −12 pA, b2 = 60 pA,
τ1 = 20 ms, τ2 = 61 ms, a1 = −3 nS and a2 = 0. Parameters were chosen to correspond to a neuron
coupled with a dendritic compartment and IM. (b) Voltage deﬂection brought by an isolated spike.
Each spike brings ﬁrst refractoriness, then a facilitation and ﬁnally adaptation on a longer time scale.
Example: Calculating the jump b of the spike-triggered adaptation current
We consider a gating dynamics
dn
dt = −n−n0(u)
τn(u)
,
(6.22)
with the steplike activation function n0(u) = Θ(u −uact
0 ) where uact
0
= −30 mV and
τn(u) = 100 ms independent of u. Thus, the gating variable n approaches a target value
of 1 whenever the voltage u is above the activation threshold uact
0 . Since the activation
threshold of −30 mV is above the ﬁring threshold (typically in the range of −40 mV)
we can safely state that the neuron activation of the channel can only occur during an
action potential. Assuming that during an action potential the voltage remains above uact
0
for t = 1 ms, we can integrate Eq. (6.22) and ﬁnd that each spike causes an increase
Δn = t/τn where we have exploited that t ≪τn. If we plug in the above numbers, we
see that each spike causes an increase of n by a value of 0.01. If the duration of the
spike were twice as long, the increase would be 0.02. After the spike the gating variable
decays with the time constant τn back to zero. The increase Δn leads to a jump amplitude
of the adaptation current given by Eq. (6.21).

6.3 Biophysical origin of adaptation
153
6.3.3 Subthreshold adaptation caused by passive dendrites
While in the previous section, we have focused on the role of ion channels, here we
show that a passive dendrite can also give rise to a subthreshold coupling of the form
of Eq. (6.15).
We focus on a simple neuron model with two compartments, representing the soma and
the dendrite, superscripts s and d respectively. The two compartments are both passive
with membrane potential V s, V d, transversal resistance Rs
T, Rd
T, capacity Cs, Cd and resting
potential ur, Ed. The two compartments are linked by a longitudinal resistance RL (see
Chapter 3). If current is injected only in the soma, then the two-compartment model with
passive dendrites corresponds to
d
dtV s = 1
Cs

−(V s −urest)
Rs
T
−V s −V d
RL
+I(t)

,
(6.23)
d
dtV d = 1
Cd

−(V d −Ed)
Rd
T
−V d −V s
RL

.
(6.24)
Such a system of differential equations can be mapped to the form of Eq. (6.15) by con-
sidering that the variable w represents the current ﬂowing from the dendrite into the soma.
In order to keep the treatment transparent, we assume that Ed = urest = E. In this case the
adaptation current is w = −(V d −urest)/RL and the two equations above reduce to
τeff dV s
dt = −(V s −E)−Reff w
(6.25)
τw
dw
dt = a(V s −E)−w
(6.26)
with an effective input resistance Reff = Rs
T/[1+(Rs
T/RL)], an effective somatic time con-
stant τeff = Cs Reff, an effective adaptation time constant τw = RLCd/[1+(RL/RD)] and a
coupling between somatic voltage and adaptation current a = −[RL +(R2
L/RD)]−1.
There are three conclusions we should draw from this mapping. First, a is always neg-
ative, which means that passive dendrites introduce a facilitating subthreshold coupling.
Second, facilitation is particularly strong with a small longitudinal resistance. Third, the
timescale of the facilitation τw is smaller than the dendritic time constant Rd
TCd - so that,
compared with other "adaptation" currents, the dendritic current is a relatively fast one.
In addition to the subthreshold coupling discussed here, dendritic coupling can also lead
to a spike-triggered current as we shall see in the next example.
Example: Bursting with a passive dendrite and IM
Suppose that the action potential can be approximated by a 1 ms pulse at 0 mV. Then
each spike brings an increase in the dendritic membrane potential. In terms of the

154
Adaptation and ﬁring patterns
current w, the increase is b = −aE0(1 −e1 ms/τw). Again, the spike-triggered jump is
always negative, leading to spike-triggered facilitation. Figure 6.10 shows an example
where we combined a dendritic compartment with the linearized effects of the M-current
(Table 6.2) to result in regular bursting. The bursting is mediated by the dendritic facil-
itation which is counterbalanced by the adapting effects of IM. The ﬁring pattern looks
different to the bursting in the AdEx (Fig. 6.4) as there is no alternation between detour
and direct resets. Indeed, many different types of bursting are possible (see Izhike-
vich 2007a). This example (especially Fig. 6.10b) suggests that the dynamics of spike-
triggered currents on multiple time scales can be understood in terms of their stereotyp-
ical effect on the membrane potential - and this insight is the starting point for the Spike
Response Model in the next section.
6.4 Spike Response Model (SRM)
So far, we have described neuronal dynamics in terms of systems of differential equations.
There is another approach that was introduced in Section 1.3.5 as the "ﬁlter picture." In this
picture, the parameters of the model are replaced by (parametric) functions of time, gener-
ically called "ﬁlters." The neuron model is therefore interpreted in terms of a membrane
ﬁlter as well as a function describing the shape of the spike (Fig. 6.11) and, potentially, also
a function for the time course of the threshold. Together, these three functions establish the
Spike Response Model (SRM).
The Spike Response Model is - just like the nonlinear integrate-and-ﬁre models in Chap-
ter 5 or the AdEx in Section 6.1 - a generalization of the leaky integrate-and-ﬁre model. In
contrast to nonlinear integrate-and-ﬁre models, the SRM has no "intrinsic" ﬁring threshold
but only the sharp numerical threshold for reset. If the nonlinear function of the AdEx is ﬁt-
ted to experimental data, the transition between the linear subthreshold and superthreshold
behavior is found to be rather abrupt, so that the nonlinear transition is, for most neurons,
well approximated by a sharp threshold (see Fig. 5.3). Therefore, in the SRM, we work
with a sharp threshold combined with a linear voltage equation.
While the SRM is therefore somewhat simpler than other models on the level of the
spike generation mechanism, the subthreshold behavior of the SRM is richer than that
of the integrate-and-ﬁre model discussed so far and can account for various aspects of
refractoriness and adaptation. In fact, the SRM combines the most general linear model
with a sharp threshold.
It turns out that the integral formulation of the SRM is very useful for data ﬁtting and
also the starting point for the Generalized Linear Models in Chapter 9 and 10. Despite the
apparent differences between integrate-and-ﬁre models and the SRM, the leaky integrate-
and-ﬁre model, with or without adaptation variables, is a special case of the SRM. The
relation of the SRM to integrate-and-ﬁre models is the topic of Sections 6.4.3-6.4.4. We
now start with a detailed explanation.

6.4 Spike Response Model (SRM)
155
Stochastic
spiking
+
Spike- 
Nonlinearity
Moving
Spike train
Membrane
filter
f(u -q )
u
h
I(t)
S(t)
q1
k
h
Fig. 6.11 Spike Response Model (SRM). Input current I(t) is ﬁltered with a ﬁlter κ(s) and yields the
input potential h(t) =
 ∞
0 κ(s)I(t −s)ds. Firing occurs if the membrane potential u reaches the thresh-
old ϑ. Spikes S(t) = ∑f δ(t −t f ) are fed back into the threshold process in two distinct ways. Each
spike causes an increase θ1 of the threshold: ϑ(t) = ϑ0 +
 ∞
0 θ1(s)S(t −s)ds. Moreover, each spike
generates a voltage contribution η to the membrane potential: u(t) = h(t)+
 ∞
0 η(s)S(t −s)ds, where
η captures the time course of the action potential and the spike-afterpotential; schematic ﬁgure.
6.4.1 Deﬁnition of the SRM
In the framework of the Spike Response Model (SRM) the state of a neuron is described
by a single variable u which we interpret as the membrane potential. In the absence of
input, the variable u is at its resting value, urest. A short current pulse will perturb u and
it takes some time before u returns to rest (Fig. 6.11). The function κ(s) describes the
time course of the voltage response to a short current pulse at time s = 0. Because the
subthreshold behavior of the membrane potential is taken as linear, the voltage response
h to an arbitrary time-dependent stimulating current Iext(t) is given by the integral h(t) =
 ∞
0 κ(s)Iext(t −s)ds.
Spike ﬁring is deﬁned by a threshold process. If the membrane potential reaches the
threshold ϑ, an output spike is triggered. The form of the action potential and the after-
potential is described by a function η. Let us suppose that the neuron has ﬁred some earlier
spikes at times t f < t. The evolution of u is given by
u(t) =∑
f
η(t −t f )+
 ∞
0 κ(s)Iext(t −s)ds+urest.
(6.27)
The sum runs over all past ﬁring times t f with f = 1,2,3,... of the neuron under consid-
eration. Introducing the spike train S(t) = ∑f δ(t −t f ), Eq. (6.27) can be also written as a
convolution
u(t) =
 ∞
0 η(s)S(t −s)ds+
 ∞
0 κ(s)Iext(t −s)ds+urest.
(6.28)
In contrast to the leaky integrate-and-ﬁre neuron discussed in Chapter 1 the threshold ϑ
is not ﬁxed, but time-dependent
ϑ
−→
ϑ(t).
(6.29)

156
Adaptation and ﬁring patterns
Firing occurs whenever the membrane potential u reaches the dynamic threshold ϑ(t) from
below
t = t f
⇔
u(t) = ϑ(t) and d[u(t)−ϑ(t)]
dt
> 0.
(6.30)
Dynamic thresholds can be directly measured in experiments (Fuortes and Mantegazzini,
1962; Badel et al., 2008a; Mensi et al., 2012) and are a standard feature of phenomenolog-
ical neuron models.
Example: Dynamic threshold - and how to get rid of it
A standard model of the dynamic threshold is
ϑ(t) = ϑ0 +∑
f
θ1(t −t f ) = ϑ0 +
 ∞
0 θ1(s)S(t −s)ds,
(6.31)
where ϑ0 is the "normal" threshold of neuron i in the absence of spiking. After each out-
put spike, the ﬁring threshold of the neuron is increased by an amount θ1(t −t f ) where
t f < t denote the ﬁring times in the past. For example, during an absolute refractory
period Δabs, we may set θ1 for a few milliseconds to a large and positive value so as to
avoid any ﬁring and let it relax back to zero over the next few hundred milliseconds; see
Fig. 6.12a.
From a formal point of view, there is no need to interpret the variable u as the mem-
brane potential. It is, for example, often convenient to transform the variable u so as to
remove the time dependence of the threshold. In fact, a general Spike Response Model
with arbitrary time-dependent threshold as in Eq. (6.31) can always be transformed into
a Spike Response Model with ﬁxed threshold ϑ0 by a change of variables
η(t −t f ) −→ηeff(t −t f ) = η(t −t f )−θ1(t −t f ).
(6.32)
In other words, the dynamic threshold can be absorbed in the deﬁnition of the η kernel.
Note, however, that in this case η can no longer be interpreted as the experimentally
measured spike afterpotential, but must be interpreted as an "effective" spike afterpoten-
tial.
The argument can also be turned the other way round, so as to remove the spike after-
potential and only work with a dynamic threshold; see Fig. 6.12b. However, when an
SRM is ﬁtted to experimental data, it is convenient to separate the spike after-effects that
are visible in the voltage trace (e.g., in the form of a hyperpolarizing spike-afterpotential,
described by the kernel η), from the spike after-effects caused by an increase in the
threshold which can be observed only indirectly via the absence of spike ﬁring. Whereas
the prediction of spike times is insensitive to the relative contribution of η and θ1, the
prediction of the subthreshold voltage time course is not. Therefore, it is useful to explic-
itly work with two distinct adapatation mechanisms in the SRM (Mensi et al., 2012).

6.4 Spike Response Model (SRM)
157
t
u
S(t)
ft
q(t)
h
(a)
t
S(t)
ft
q(t)
h
h
(b)
Fig. 6.12 Spike-afterpotential and dynamic threshold in the SRM. (a) At time t f a spike occurs
because the membrane potential hits the threshold ϑ(t). The threshold jumps to a higher value
(dashed line) and, at the same time, a contribution η(t −t f ) is added to the membrane potential,
i.e., the spike and its spike-afterpotential are "pasted" into the picture. If no further spikes are trig-
gered, the threshold decays back to its resting value and the spike-afterpotential decays back to zero.
The total membrane potential (thick solid line) after a spike is u(t) = h(t)+∑f η(t −t f ) where h(t)
is the input potential (thin dotted line). (b) If the model is used to predict spike times, but not the
membrane potential, the spike-afterpotential η can be integrated into the dynamic threshold so that
u(t) = h(t). At the moment of spiking the value of the threshold is increased, but the membrane
potential is not affected (either through reset or spike-afterpotential).
6.4.2 Interpretation of η and κ
So far Eq. (6.27) in combination with the threshold condition (6.30) deﬁnes a mathematical
model. Can we give a biological interpretation of the terms?
The kernel κ(s) is the linear response of the membrane potential to an input current. It
describes the time course of a deviation of the membrane potential from its resting value
that is caused by a short current pulse ("impulse response").
The kernel η describes the standard form of an action potential of neuron i including the
negative overshoot which typically follows a spike (the spike-afterpotential). Graphically
speaking, a contribution η is "pasted in" each time the membrane potential reaches the
threshold ϑ (Fig. 6.12a). Since the form of the spike is always the same, the exact time
course of the action potential carries no information. What matters is whether there is the
event "spike" or not. The event is fully characterized by the ﬁring time t f .
In a simpliﬁed model, the form of the action potential may therefore be neglected as long
as we keep track of the ﬁring times t f . The kernel η then describes simply the "reset" of
the membrane potential to a lower value after the spike at t f just as in the integrate-and-ﬁre
model
η(t −t f ) = −η0 exp

−t −t f
τrecov

,
(6.33)

158
Adaptation and ﬁring patterns
with a parameter η0 > 0. The spike-afterpotential decays back to zero with a recovery time
constant τrecov. The leaky integrate-and-ﬁre model is in fact a special case of the SRM,
with parameter η0 = (ϑ −ur) and τrecov = τm.
Example: Refractoriness
Refractoriness may be characterized experimentally by the observation that imme-
diately after a ﬁrst action potential it is impossible (absolute refractoriness) or more
difﬁcult (relative refractoriness) to excite a second spike. In Fig. 5.5. we have already
seen that refractoriness shows up as increased ﬁring threshold and increased conduc-
tance immediately after a spike.
Absolute refractoriness can be incorporated in the SRM by setting the dynamic thresh-
old during a time Δabs to an extremely high value that cannot be attained.
Relative refractoriness can be mimicked in various ways. First, after a spike the ﬁring
threshold returns only slowly back to its normal value (increase in ﬁring threshold).
Second, after the spike the membrane potential, and hence η, passes through a regime of
hyperpolarization (spike-afterpotential) where the voltage is below the resting potential.
During this phase, more stimulation than usual is needed to drive the membrane potential
above threshold. In fact, this is equivalent to a transient increase of the ﬁring threshold
(see above).
Third, the responsiveness of the neuron is reduced immediately after a spike. In the
SRM we can model the reduced responsiveness by making the shape of ε and κ depend
on the time since the last spike timing ˆt.
We label output spikes such that the most recent one receives the label t1 (i.e., t > t1 >
t2 > t3 ...). This means that, after each ﬁring event, output spikes need to be relabeled.
The advantage, however, is that the last output spike always keeps the label t1. For
simplicity, we often write ˆt instead of t1 to denote the most recent spike.
With this notation, a slightly more general version of the Spike Response Model is
u(t) = ∑
f
η(t −t f )+
 ∞
0 κ(t −ˆt,s)Iext(t −s)ds+urest .
(6.34)
6.4.3 Mapping the integrate-and-ﬁre model to the SRM
In this section, we show that the leaky integrate-and-ﬁre neuron with adaptation deﬁned
above in Eqs. (6.7) and (6.8) is a special case of the Spike Response Model. Let us recall
that the leaky integrate-and-ﬁre model follows the equation of a linear circuit with resis-
tance R and capacity C
τm
dui
dt = −(ui −E0)−R ∑
k
wk +RIi(t),
(6.35)

6.4 Spike Response Model (SRM)
159
where τm = RC is the time constant, E0 the leak reversal potential, wk are adaptation vari-
ables, and Ii is the input current to neuron i. At each ﬁring time
{t f
i } ∈{t|ui(t) = ϑ} ,
(6.36)
the voltage is reset to a value ur. At the same time, the adaptation variables are increased
by an amount bk
τk
dwk
dt = ak (ui −E0)−wk +τk bk∑
t f
δ(t −t f ).
(6.37)
The equations of the adaptive leaky integrate-and-ﬁre model, Eqs. (6.35) and (6.37), can
be classiﬁed as linear differential equations. However, because of the reset of the mem-
brane potential after ﬁring, the integration is not completely trivial. In fact, there are two
different ways of proceeding with the integration. The ﬁrst method is to treat the reset after
each ﬁring as a new initial condition - this is the procedure typically chosen for a numer-
ical integration of the model. Here we follow a different path and describe the reset as a
current pulse. As we shall see, the result enables a mapping of the leaky integrate-and-ﬁre
model to the SRM.
Let us consider a short current pulse Iout
i
= −qδ(t) applied to the RC circuit. It removes
a charge q from the capacitor C and lowers the potential by an amount Δu = −q/C. Thus,
a reset of the membrane potential from a value of u = ϑ to a new value u = ur corresponds
to an "output" current pulse which removes a charge q = C(ϑ −ur). The reset takes place
every time when the neuron ﬁres. The total reset current is therefore
Iout
i
(t) = −C(ϑ −ur) ∑
f
δ(t −t f
i ),
(6.38)
where the sum runs over all ﬁring times t f
i . We add the output current (6.38) on the right-
hand side of (6.35),
τm
dui
dt = −(ui −E0)−R∑
k
wk +RIi(t)−RC(ϑ −ur) ∑
f
δ(t −t f
i ),
(6.39)
τk
dwk
dt = ak (ui −E0)−wk +τk bk∑
t f
δ(t −t f ).
(6.40)
Since Eqs. (6.39) and (6.40) deﬁne a system of linear equations, we can integrate each
term separately and superimpose the result at the end. To perform the integration, we pro-
ceed in three steps. First, we shift the voltage so as to set the equilibrium potential to
zero. Second, we calculate the eigenvalues and eigenvectors of the "free" equations in the
absence of input (and therefore no spikes). If there are K adaptation variables, we have a
total of K +1 eigenvalues which we label as λ1,λ2,... The associated eigenvectors are ek
with components (ek0,ek1,...,ekK)T . Third, we express the response to an impulse Δu = 1
in the voltage (no perturbation in the adaptation variables) in terms of the K + 1 eigen-
vectors: (1,0,0,...,0)T = ∑K
k=0 βkek. Finally, we express the pulse caused by a reset of

160
Adaptation and ﬁring patterns
(a)
0
500
1000
t [ms]
−60
−40
−20
0
u [mV]
(b)
0
50
100
t [ms]
0
10
20
30
40
u [mV]
Fig. 6.13 SRM with a choice of η leading to adaptation. (a) The response of the neuron model to
injection of a step current. (b) The spike-afterpotential η with adaptation time constant τw = 100 ms.
A short (0.5 ms) period at +40 mV replaces the stereotypical shape of the action potential.
voltage and adaptation variables in terms of the eigenvectors (−ϑ +ur,b1,b2,...,bK)T =
∑K
k=0 γkek.
The response to the reset pulses yields the kernel η while the response to voltage pulses
yields the ﬁlter κ(s) of the SRM
ui(t) = ∑
f
η(t −t f
i )
+
 ∞
0 κ(s)Ii(t −s)ds,
(6.41)
with kernels
η(s) =
K
∑
k=0
γkek0 exp(λk s)Θ(s),
(6.42)
κ(s) =
K
∑
k=0
βkek0 exp(λk s)Θ(s).
(6.43)
As usual, Θ(x) denotes the Heaviside step function.
Example: Adaptation and bursting
Let us ﬁrst study a leaky integrate-and-ﬁre model with a single slow adaptation vari-
able τw ≫τm which is coupled to the voltage in the subthreshold regime (a > 0) and

6.4 Spike Response Model (SRM)
161
increased during spiking by an amount b. In this case there are only two equations,
one for the voltage and one for adaptation, so that the eigenvectors and eigenvalues
can be calculated "by hand." With a parameter δ = τm/τw ≪1, the eigenvalues are
λ1 = −τw [1 −aδ] and λ2 = −τw δ [1 + a], associated to eigenvectors e1 = (1,aδ)T
and e2 = (1,−1 + δ + aδ)T. The resulting spike-afterpotential kernel η(s) is shown
in Fig. 6.13b. Because of the slow time constant τw ≫τm, the kernel η has a long hyper-
polarizing tail. The neuron model responds to a step current with adaptation, because of
accumulation of hyperpolarizing spike-afterpotentials over many spikes.
As a second example, we consider four adaptation currents with different time con-
stants τ1 < τ2 < τ3 < τ4. We assume pure spike-triggered coupling (a = 0) so that the
integration of the differential equations of wk gives each an exponential current
wk(t) = ∑
f
bk exp

−t −t f
τk

Θ(t −t f ).
(6.44)
We choose the time constant of the ﬁrst current to be very short and b1 < 0 (inward
current) so as to model the upswing of the action potential (a candidate current would
be sodium). A second current (e.g., a fast potassium channel) with a slightly longer
time constant is outgoing (b2 > 0) and leads to the downswing and rapid reset of the
membrane potential. The third current, with a time constant of tens of milliseconds,
is inward (b3 < 0), while the slowest current is again hyperpolarizing (b4 > 0). Inte-
gration of the voltage equation with all four currents generates the spike-afterpotential
η shown Fig. 6.14b. Because of the depolarizing spike-afterpotential induced by the
inward current w3, the neuron model responds to a step current of appropriate amplitude
with bursts. The bursts end because of the accumulation of the hyperpolarizing effect of
the slowest current.
6.4.4 Multi-compartment integrate-and-ﬁre model as an SRM (*)
The models discussed in this chapter are point neurons, i.e., models that do not take into
account the spatial structure of a real neuron. In Chapter 3 we have already seen that the
electrical properties of dendritic trees can be described by compartmental models. In this
section, we want to show that neurons with a linear dendritic tree and a voltage threshold
for spike ﬁring at the soma can be mapped to the Spike Response Model.
We study an integrate-and-ﬁre model with a passive dendritic tree described by n
compartments. Membrane resistance, core resistance, and capacity of compartment μ are
denoted by Rμ
T, Rμ
L, and Cμ, respectively. The longitudinal core resistance between com-
partment μ and a neighboring compartment ν is rμν = (Rμ
L + Rν
L)/2; see Fig. 3.8. Com-
partment μ = 1 represents the soma and is equipped with a simple mechanism for spike
generation, i.e., with a threshold criterion as in the standard integrate-and-ﬁre model. The
remaining dendritic compartments (2 ≤μ ≤n) are passive.

162
Adaptation and ﬁring patterns
0.0
10.0
20.0
30.0
t [ms]
0
40
80
 η [mV]
0.0
500.0
t [ms]
-60
40
u [mV]
(a)
(b)
Fig. 6.14 SRM with choice of η leading to bursting. (a) The refractory kernel η of an integrate-
and-ﬁre model with four spike-triggered currents. (b) The voltage response to a step current exhibits
bursting. Adapted from Gerstner et al. (1996b).
Each compartment 1 ≤μ ≤n of neuron i may receive input Iμ
i (t) from presynaptic
neurons. As a result of spike generation, there is an additional reset current Ωi(t) at the
soma. The membrane potential V μ
i of compartment μ is given by
d
dtV μ
i = 1
Cμ
i

−V μ
i
Rμ
T,i
−∑
ν
V μ
i −V ν
i
rμν
i
+Iμ
i (t)−δ μ 1 Ωi(t)

,
(6.45)
where the sum runs over all neighbors of compartment μ. The Kronecker symbol δ μν
equals unity if the upper indices are equal; otherwise, it is zero. The subscript i is the index
of the neuron; the upper indices μ or ν refer to compartments. Below we will identify the
somatic voltage V 1
i with the potential ui of the Spike Response Model.
Equation (6.45) is a system of linear differential equations if the external input current is
independent of the membrane potential. The solution of Eq. (6.45) can thus be formulated
by means of Green's functions Gμν
i (s) that describe the impact of a current pulse injected
in compartment ν on the membrane potential of compartment μ. The solution is of the
form
V μ
i (t) = ∑
ν
1
Cν
i
 ∞
0 Gμν
i (s)

Iν
i (t −s)−δ ν1 Ωi(t −s)

ds.
(6.46)
Explicit expressions for the Green's function Gμν
i (s) for arbitrary geometry have been
derived by Abbott et al. (1991) and Bressloff and Taylor (1994).
We consider a network made up of a set of neurons described by Eq. (6.45) and a simple
threshold criterion for generating spikes. We assume that each spike t f
j of a presynaptic
neuron j evokes, for t > t f
j , a synaptic current pulse α(t −t f
j ) into the postsynaptic neuron
i. The actual amplitude of the current pulse depends on the strength Wi j of the synapse that

6.4 Spike Response Model (SRM)
163
connects neuron j to neuron i. The total input to compartment μ of neuron i is thus
Iμ
i (t) = ∑
j∈Γμ
i
Wi j ∑
f
α(t −t f
j ).
(6.47)
Here, Γμ
i denotes the set of all neurons that have a synapse with compartment μ of neuron
i. The ﬁring times of neuron j are denoted by t f
j .
In the following we assume that spikes are generated at the soma in the manner of
the integrate-and-ﬁre model. That is to say, a spike is triggered as soon as the somatic
membrane potential reaches the ﬁring threshold, ϑ. After each spike the somatic membrane
potential is reset to V 1
i = ur < ϑ. This is equivalent to a current pulse
γi(s) = C1
i (ϑ −ur)δ(s),
(6.48)
so that the overall current due to the ﬁring of action potentials at the soma of neuron i
amounts to
Ωi(t) = ∑
f
γi(t −t f
i ).
(6.49)
We will refer to Eqs. (6.46)-(6.49) together with the threshold criterion for generating
spikes as the multi-compartment integrate-and-ﬁre model.
Using the above specializations for the synaptic input current and the somatic reset cur-
rent the membrane potential (6.46) of compartment μ in neuron i can be rewritten as
V μ
i (t) = ∑
f
ημ
i (t −t f
i )+∑
ν ∑
j∈Γν
i
Wi j∑
f
εμν
i
(t −t f
j ),
(6.50)
with
εμν
i
(s) = 1
Cν
i
 ∞
0 Gμν
i (s′)α(s−s′)ds′ ,
(6.51)
ημ
i (s) = 1
C1
i
 ∞
0 Gμ1
i (s′)γi(s−s′)ds′.
(6.52)
The kernel εμν
i
(s) describes the effect of a presynaptic action potential arriving at com-
partment ν on the membrane potential of compartment μ. Similarly, ημ
i (s) describes the
response of compartment μ to an action potential generated at the soma.
The triggering of action potentials depends on the somatic membrane potential only. We
deﬁne ui = V 1
i , ηi(s) = η1
i (s) and, for j ∈Γν
i , we set εi j = ε1ν
i . This yields the equation of
the SRM
ui(t) = ∑
f
ηi(t −t f
i )+∑
j
Wi j∑
f
εi j(t −t f
j ).
(6.53)
Example: Two-compartment integrate-and-ﬁre model
We illustrate the methodology by mapping a simple model with two compartments
and a reset mechanism at the soma (Rospars and Lansky, 1993) to the Spike Response

164
Adaptation and ﬁring patterns
0
10
20
30
40
s
0.5
0
0.5
1
h(s)
(a)
0
10
20
30
40
s
0
0.01
0.02
0.03
0.04
0.05
e(s)
(b)
Fig. 6.15 Two-compartment integrate-and-ﬁre model. (a) Response kernel η0(s) of a neuron with
two compartments and a ﬁre-and-reset threshold dynamics. The response kernel is a double expo-
nential with time constants τ12 = 2 ms and τ0 = 10 ms. The spike at s = 0 is indicated by a vertical
arrow. (b) Response kernel ε0(s) for excitatory synaptic input at the dendritic compartment with a
synaptic time constant τs = 1 ms. The response kernel is a superposition of three exponentials and
exhibits the typical time course of an excitatory postsynaptic potential.
Model. The two compartments are characterized by a somatic capacitance C1 and a
dendritic capacitance C2 = aC1. The membrane time constant is τ0 = R1C1 = R2C2 and
the longitudinal time constant τ12 = r12C1C2/(C1 +C2). The neuron ﬁres if V 1(t) = ϑ.
After each ﬁring the somatic potential is reset to ur. This is equivalent to a current pulse
γ(s) = qδ(s),
(6.54)
where q = C1 [ϑ −ur] is the charge lost during the spike. The dendrite receives spike
trains from other neurons j and we assume that each spike evokes a current pulse with
time course
α(s) = 1
τs
exp

−s
τs

Θ(s).
(6.55)
For the two-compartment model it is straightforward to integrate the equations and
derive the Green's function. With the Green's function we can calculate the response
kernels η0(s) = η(1)
i
and ε0(s) = ε12
i
as deﬁned in Eqs. (6.51) and (6.52). We ﬁnd
η0(s) = −ϑ −ur
(1+a) exp

−s
τ0
 
1+a exp

−s
τ12

,
(6.56)
ε0(s) =
1
(1+a) exp

−s
τ0
 
1−e−δ1s
τs δ1
−exp

−s
τ12
 1−e−δ2s
τs δ2

,
with δ1 = τ−1
s
−τ−1
0
and δ2 = τ−1
s
−τ−1
0
−τ−1
12 . Figure 6.15 shows the two response
kernels with parameters τ0 = 10 ms, τ12 = 2 ms, and a = 10. The synaptic time constant
is τs = 1 ms. The kernel ε0(s) describes the voltage response of the soma to an input at
the dendrite. It shows the typical time course of an excitatory or inhibitory postsynaptic

6.5 Summary
165
potential. The time course of the kernel η0(s) is a double exponential and reﬂects the
dynamics of the reset in a two-compartment model.
6.5 Summary
By adding one or several adaptation variables to integrate-and-ﬁre models, a large variety
of ﬁring patterns found in real neurons, such as adaptation, bursting or initial bursting,
can be explained. The dynamics of the adaptation variables has two components: (i) a
coupling to the voltage u via a parameter a which provides subthreshold adaptation and,
in nonlinear neuron models, also a contribution to spike-triggered adaptation; and (ii) an
explicit spike-triggered adaptation via an increase of the adaptation current during each
ﬁring by an amount b. While positive values for a and b induce a hyperpolarization of the
membrane and therefore lead to spike-frequency adaptation, negative values induce a depo-
larization and lead to delayed onset of spiking and spike frequency facilitation. Bursting is
most easily achieved by a suitable combination of the reset parameters ur and b.
The phenomenological adaptation variables wk can be derived from the ionic currents
ﬂowing through different ion channels. Coupling of an integrate-and-ﬁre model to a pas-
sive dendrite also yields effective adaptation variables which have, however, a facilitating
inﬂuence.
The adaptation variables can be combined with a quadratic integrate-and-ﬁre model
which leads to the Izhikevich model; with an exponential integrate-and-ﬁre model which
leads to the AdEx model; or with a leaky integrate-and-ﬁre model. In the latter case, the dif-
ferential equations can be analytically integrated in the presence of an arbitrary number of
adaptation variable. Integration leads to the Spike Response Model (SRM) which presents
a general linear model combined with a sharp ﬁring threshold. The Spike Response Model
is the starting point for the Generalized Linear Models in the presence of noise which we
will introduce in Chapter 9.
Literature
Formal neuron models where spikes are triggered by a threshold process were popular in
the 1960s (Stein, 1965, 1967b; Geisler and Goldberg, 1966; Weiss, 1966), but the ideas
can be traced back much earlier (Lapicque, 1907; Hill, 1936). It was recognized early
that these models lend themselves for hardware implementations (French and Stein, 1970)
and mathematical analysis (Stein, 1965, 1967a), and can be ﬁtted to experimental data
(Brillinger, 1988, 1992).
Dynamic thresholds that increase after each spike have been a standard feature of phe-
nomenological neuron models for a long time (Fuortes and Mantegazzini, 1962; Geisler
and Goldberg, 1966; Weiss, 1966) and so have the slow subthreshold processes of adap-
tation (Sabah and Leibovic, 1969; Mauro et al., 1970; Fishman et al., 1977; Sirovich

166
Adaptation and ﬁring patterns
and Knight, 1977). While the linear subthreshold coupling of voltage and adaptation cur-
rents via a coupling parameter a is nicely presented and analyzed in Richardson et al.
(2003), the spike-triggered jump b of the adaptation current has been mainly popularized by
Izhikevich (2003) - but can be found in earlier papers (e.g., Gerstner et al., 1996b; Liu and
Wang, 2001), and much earlier in the form of a spike-triggered increase in the threshold
(Fuortes and Mantegazzini, 1962; Geisler and Goldberg, 1966; Weiss, 1966).
The phase plane analysis of the AdEx model presented in this chapter is based on Naud
et al. (2008). The main difference between the AdEx model (Brette and Gerstner, 2005)
and the highly inﬂuential model of Izhikevich (2003) is that the AdEx uses in the voltage
equation an exponential nonlinearity (as suggested by experiments (Badel et al., 2008a))
whereas the Izhikevich model uses a quadratic nonlinearity (as suggested by bifurcation
analysis close to the bifurcation point (Ermentrout, 1996)).
The book by Izhikevich (2007a) as well as the Scholarpedia articles on the Spike
Response Model (SRM) and the adaptive exponential integrate-and-ﬁre (AdEx) model
(Gerstner, 2008; Gerstner and Brette, 2009), present readable reviews of the model class
discussed in this chapter.
The functions η, κ, and εi j are response kernels that describe the effect of spike emis-
sion and spike reception on the variable ui. This interpretation has motivated the name
"Spike Response Model." While the name and the speciﬁc formulation of the model equa-
tions (6.27)-(6.30) has been used since 1995 (Gerstner, 1995; Gerstner et al., 1996b;
Kistler et al., 1997), closely related models can be found in earlier works; see, e.g., Hill
(1936); Geisler and Goldberg (1966).
Exercises
1. Time scale of ﬁring rate decay. The characteristic feature of adaptation is that, after the onset
of a superthreshold step current, interspike intervals become successively longer, or, equivalently,
the momentary ﬁring rate drops. The aim is to make a quantitative prediction of the decay of the
ﬁring rate of a leaky integrate-and-ﬁre model with a single adaptation current.
(a) Show that the ﬁring rate of Eqs. (6.7) and (6.8) with constant I, constant w and a = 0 is
f(I,w) = −

τm log

1−ϑrh −ureset
R(I −w)
−1
.
(6.57)
(b) For each spike (i.e., once per interspike interval), w jumps by an amount b. Show that for I
constant and w averaged over one interspike interval, Eq. (6.8) becomes:
τw
dw
dt = −w+bτw f(I,w).
(6.58)
(c) At time t0, a strong current of amplitude I0 is switched on that causes transiently a ﬁring rate
f ≫τw. Afterward the ﬁring rate decays. Find the effective time constant of the ﬁring rate for the
case of strong input current.
Hint: Start from Eq. (6.58) and consider a Taylor expansion of f (I,w).
2. Subthreshold resonance. We study a leaky integrate-and-ﬁre model with a single adaptation
variable w.
(a) Assume E0 = urest and cast equation Eqs. (6.7) and (6.8) in the form of Eq. (6.27). Set

6.5 Summary
167
ε = 0 and calculate η and κ. Show that κ(t) can be written as a linear combination κ(t) =
k+eλ+t +k−eλ−t with
λ± =
1
2τmτw

−(τm +τw)±

τm +τw −4τmτw(1+aR)
	
(6.59)
and
k± = ± R(λ±τw +1)
τmτw(λ+ −λ−).
(6.60)
(b) What are the parameters of Eqs. (6.7)-(6.8) that lead to oscillations in κ(t)?
(c) What is the frequency of the oscillation?
Hint: Section 4.4.3.
(d) Take the Fourier transform of Eqs. (6.7)-(6.8) and ﬁnd the function ˆR(ω) that relates the
current ˆI(ω) at frequency ω to the voltage ˆu(ω) at the same frequency, i.e., ˆu(ω) = ˆR(ω) ˆI(ω).
Show that, in the case where κ has oscillations, the function ˆR(ω) has a global maximum. What
is the frequency where this happens?
3. Integrate-and-ﬁre model with slow adaptation.
The aim is to relate the leaky integrate-and-ﬁre model with a single adaptation variable, deﬁned
in Eqs. (6.7) and (6.8), to the Spike Response Model in the form of Eq. (6.27). Adaptation is
slow so that τm/τw = δ ≪1 and all calculations can be done to ﬁrst order in δ.
(a) Show that the spike-afterpotential is given by
η(t) = γ1eλ1t +γ2eλ2t,
(6.61)
γ1 = Δu(1−δ −δa)−b(1+δ),
(6.62)
γ2 = Δu−γ1.
(6.63)
(b) Derive the input response kernel κ(s).
Hint: Use the result from (a).
4. Integrate-and-ﬁre model with time-dependent time constant. Since many channels are open
immediately after a spike, the effective membrane time constant after a spike is smaller than
the time constant at rest. Consider an integrate-and-ﬁre model with spike-time-dependent time
constant, i.e., with a membrane time constant τ that is a function of the time since the last post-
synaptic spike,
du
dt = −
u
τ(t −ˆt) + 1
C Iext(t);
(6.64)
see Wehmeier et al. (1989); Stevens and Zador (1998). As usual, ˆt denotes the last ﬁring time of
the neuron. The neuron ﬁres if u(t) hits a ﬁxed threshold ϑ and integration restarts with a reset
value ur.
(a) Suppose that the time constant is τ(t −ˆt) = 2ms for t −ˆt < 10ms and τ(t −ˆt) = 20ms for
t −ˆt ≥10ms. Set ur = −10mV. Sketch the time course of the membrane potential for an input
current I(t) = qδ(t −t′) arriving at t′ = 5ms or t′ = 15ms. What are the differences between the
two cases?
(b) Integrate Eq. (6.64) for arbitrary input with u(ˆt) = ur as initial condition and interpret the
result.
5. Spike-triggered adaptation currents. Consider a leaky integrate-and-ﬁre model. A spike at time
t f generates several adaptation currents dwk/dt = −wk
τk +bkδ(t −t f ) with k = 1,...,K.
(a) Calculate the effect of the adaptation current on the voltage.
(b) Construct a combination of spike-triggered currents that could generate slow adaptation.
(c) Construct a combination of spike-triggered currents that could generate bursts.

7
Variability of spike trains and neural codes
The neuron models discussed in the previous chapters are deterministic and generate, for
most choices of parameters, spike trains that look regular when driven by a constant stimu-
lus. In vivo recordings of neuronal activity, however, are characterized by a high degree of
irregularity. The spike train of an individual neuron is far from being periodic, and correla-
tions between the spike timings of neighboring neurons are weak. If the electrical activity
picked up by an extracellular electrode is made audible by a loudspeaker then what we
basically hear is noise. The question whether this is indeed just noise or rather a highly
efﬁcient way of coding information cannot easily be answered. Indeed, listening to a com-
puter modem or a fax machine might also leave the impression that this is just noise. Being
able to decide whether we are witnessing the neuronal activity that is underlying the com-
position of a poem (or the electronic transmission of a love letter) and not just meaningless
ﬂicker is one of the most burning problems in neuroscience.
Several experiments have been undertaken to tackle this problem. It seems that a neuron
in vitro, once it is isolated from the network, can react in a very reliable and reproducible
manner to a ﬂuctuating input current, and so can neurons in the sensory cortex in vivo
when driven by a strong time-dependent signal. On the other hand, neurons produce irreg-
ular spike trains in the absence of any temporally structured stimuli. Irregular spontaneous
activity, i.e., activity that is not related in any obvious way to external stimulation, and
trial-to-trial variations in neuronal responses are often considered as noise.
The origin of this irregularity of neuronal dynamics in vivo is poorly understood. In
integrate-and-ﬁre models, noise is therefore often added explicitly to neuronal dynamics so
as to mimic the unpredictability of neuronal recordings. How to add noise to neuron models
is the topic of Chapters 8 and 9. The aim of the present chapter is a mere description and
quantiﬁcation of the variability of neuronal spike trains. We review in Section 7.1 some
experimental evidence for noise in neurons and introduce in Sections 7.2-7.5 a statistical
framework of spike-train analysis. In particular, we present the deﬁnitions of ﬁring rate,
interval distribution, power spectrum, and renewal statistics. In Section 7.6 we ask whether
the ﬁring rate, which is such a useful measure for quantiﬁcation of spike trains, can also be
considered as the code used by neurons in the brain.

7.1 Spike-train variability
169
Fig. 7.1 Spontaneous activity in vivo. Sample of a voltage trace (whole-cell recording) of a cortical
neuron when the animal receives no experimental stimulation. The neuron is from layer 2/3 of the C2
cortical column, a region of the cortex associated with whisker movement. The recording corresponds
to a period of time where the mouse is awake and freely whisking. Data courtesy of Sylvain Crochet
and Carl Petersen (Crochet et al., 2011).
7.1 Spike-train variability
If neuron models such as the Hodgkin-Huxley or the integrate-and-ﬁre model are driven
by a sufﬁciently strong constant current, they generate a regular sequence of spikes. In
neuronal models with adaptation currents1 there might be a short transient phase at the
beginning, but then all interspike intervals are constant. Spike trains of typical neurons in
vivo show much more irregular behavior. Whether the irregularity is the sign of thermal
noise, microscopic chaos, or rather the signature of an intricate neural code is at present
an open question. In the ﬁrst subsection we review some evidence for neuronal variability
and spike-train irregularity. We then discuss potential sources of noise.
7.1.1 Are neurons noisy?
Many in vivo experiments show noisy behavior of cortical neurons. The activity of neurons
from the visual cortex, for example, can be recorded while a slowly moving bar is presented
on a screen within the visual ﬁeld of the animal. As soon as the bar enters the neuron's
receptive ﬁeld the ﬁring rate goes up. The spike train, however, varies considerably from
trial to trial, if the same experiment is repeated several times. Similarly, neurons in a region
of the sensory cortex of rats or mice respond systematically to whisker movements, but the
response is somewhat different between one trial and the next. Furthermore, the very same
neuron occasionally emits a spontaneous spike, even if no external stimulus is applied.
During spontaneous activity, the voltage trajectory ﬂuctuates considerably and intervals
between one spike and the next exhibit a large degree of variability (Fig. 7.1).
Are these experiments convincing evidence for ubiquitous noise in the central nervous
system? The above observations refer to experiments on the neural system as a whole.
The cortical neuron that is recorded from receives input not only from the sensors, but
1We neglect here intrinsically bursting and chaotic neurons.

170
Variability of spike trains and neural codes
10 ms
10 mV
Fig. 7.2 Variability across four repetitions of the same stimulus in vitro. Sample voltage traces during
stimulation with a time-dependent current. Modiﬁed from Naud and Gerstner (2012b) with kind
permission from Springer Science and Business Media.
also from many other neurons in the brain. The effective input to this neuron is basically
unknown. It is thus possible that there is a substantial ﬂuctuation in the input current to
cortical neurons, even though the external (e.g., visual or tactile) stimulus is always the
same.
The advantage of experiments in vitro is that the stimulus injected into the neuron can
be well controlled. If the stimulation consists of a known time-dependent current directly
injected into the neuron, the neuronal response also varies from one trial to the next, even if
the very same stimulation is repeated several times (Fig. 7.2). Is this an indication of "real"
noise? The variability is visible only if the stimulating current is nearly constant (Fig. 7.3).
In fact, when neurons are driven by a current with large-amplitude ﬂuctuations of the input
signal, neurons behave more or less deterministically (Bryant and Segundo, 1976; Mainen
and Sejnowski, 1995).
Similarly, in the full and intact brain, neurons react much more reliably to a rapidly
changing external stimulus than to constant or slowly moving stimuli. For example, spa-
tially uniform random ﬂicker of an image elicits more or less the same spike train in retinal
ganglion cells if the same ﬂicker sequence is presented again (Berry et al., 1997). A sim-
ilar behavior has been reported for motion-sensitive neurons of the visual system in ﬂies
(de Ruyter van Steveninck et al., 1997) and monkey cortex (Bair and Koch, 1996); see Fig.
7.4 for an example of a cortical neuron. Whether a neuron behaves nearly deterministically
or rather randomly thus depends, at least to a certain extent, on the stimulus.
In the following, we distinguish between intrinsic noise sources that generate stochastic
behavior on the level of the neuronal dynamics and are present even in an isolated neuron
in vitro; and extrinsic sources that arise from network effects and synaptic transmission
naturally occurring in vivo.
7.1.2 Intrinsic noise sources
A source of noise which is literally omnipresent is thermal noise. Owing to the discrete
nature of electric charge carriers, the voltage u across any electrical resistor R ﬂuctuates
at ﬁnite temperature (Johnson noise). The variance of the ﬂuctuations at rest is ⟨Δu2⟩∝

7.1 Spike-train variability
171
25
1
Trial # 200 pA
0
250
500
(a)
(b)
(c)
750
1000
Time [ms]
0
250
500
750
1000
Time [ms]
Reliability
1.0
0.5
0.0
0
50
100
s[pA]
Fig. 7.3 Variability across repetitions of the same stimulus in vitro. (a) A constant stimulus leads to
a large variability of spike timing between one trial and the next. (b) A stimulus with large-amplitude
signal ﬂuctuations generates reliable spike timing so that spike times vary across trials. (c) Reliability
of spike timing (arbitrary units) as a function of the amplitude σ of signal ﬂuctuations. Modiﬁed from
Mainen and Sejnowski (1995) with permission from AAAS.
RkT B where k is the Boltzmann constant, T the temperature and B the bandwidth of the
system. Since neuronal dynamics is described by an equivalent electrical circuit containing
resistors (see Chapter 2), the neuronal membrane potential ﬂuctuates as well. Fluctuations
due to Johnson noise are, however, of minor importance compared to other noise sources
in neurons (Manwani and Koch, 1999).
Another source of noise that is speciﬁc to neuronal cells and present already in an iso-
lated neuron arises from the ﬁnite number of ion channels in a patch of neuronal membrane.
Most ion channels have only two states: they are either open or closed. The electrical con-
ductivity of a patch of membrane for ion type i is proportional to the number of open ion
channels. For a given constant membrane potential u, a fraction Pi(u) of ion channel of type
i is open on average. The actual number of open channels ﬂuctuates around Ni Pi(u) where
Ni is the total number of ion channels of type i in that patch of membrane; see Fig. 2.5.
The formulation of the Hodgkin-Huxley equations in terms of ion channel conductivities
(see Chapter 2) is implicitly based on the assumption of a large number of ion channels so
that ﬂuctuations can be neglected. Since, in reality, Ni is ﬁnite, the conductivity ﬂuctuates
and so does the potential. If the membrane potential is close to the threshold, channel noise
can be critical for the generation of action potentials. Models that take the ﬁnite number
of ion channels into account can reproduce the observed variability of real neurons with
intracellular stimulation (Schneidman et al., 1998; Chow and White, 1996). In particular,
they show little spike jitter if the input current is rapidly changing, but are less reliable if
the input current is constant.
7.1.3 Noise from the network
Apart from intrinsic noise sources at the level of an individual neuron there are also sources
of noise that are due to signal transmission and network effects (extrinsic noise). Synaptic
transmission failures, for instance, seem to impose a substantial limitation to signal trans-
mission within a neuronal network. Experiments with double electrode recordings from

172
Variability of spike trains and neural codes
200
0
Spikes/s
t[s]
0
0.5
1.0
1.5
2.0
Trial #
1
15
Fig. 7.4 Variability across repetitions of the same stimulus in vivo. Activity of a neuron in visual
cortex (area MT) driven by a stimulus consisting of randomly moving dots. The same stimulus is
repeated many times. Spikes in a single trial are shown as short vertical dashes along a horizontal line.
Only 15 trials are shown. The peri-stimulus-time-histogram (accumulated over many more trials) is
indicated at the bottom. Redrawn after Bair and Koch (1996), who show data from the Newsome lab
(Newsome et al., 1989).
two synaptically connected neurons suggest that only 10-30% of presynaptic spikes gen-
erate a postsynaptic response (Hessler et al., 1993; Markram and Tsodyks, 1996).
Finally, an important part of the irregularity of neuronal spiking during spontaneous
activity seems to be due to properties of the network - even if the network itself is com-
pletely deterministic. Model studies show that networks of excitatory and inhibitory neu-
rons with ﬁxed random connectivity can produce highly irregular spike trains - even in
the absence of any source of noise. An example of variability in a deterministic network
of leaky integrate-and-ﬁre neurons with random excitatory and inhibitory interactions is
shown in Fig. 7.5. We will discuss the underlying mechanisms in Part III of this book
(see Sections 12.3.4 and 12.4.4). As a result of the network activity, each neuron receives
as input an irregular spike sequence that can be described as stochastic spike arrival; see
Chapter 8. The difference between the large variability of neurons in vivo compared to
the variability during intracellular stimulation in vitro can therefore be, at least partially,
attributed to network effects.
7.2 Mean ﬁring rate
In the next few sections, we introduce some important concepts commonly used for the
statistical description of neuronal spike trains. Central notions will be the interspike inter-
val distribution (Section 7.3), the noise spectrum (Section 7.4), but most importantly the
concept of "ﬁring rate," which we discuss ﬁrst.
A quick glance at the experimental literature reveals that there is no unique and well-
deﬁned concept of "mean ﬁring rate." In fact, there are at least three different notions of
rate, which are often confused and used simultaneously. The three deﬁnitions refer to three

7.2 Mean ﬁring rate
173
(a)
(b)
(c)
0
10
20
30
A [Sp./s]
(d)
0
1
2
3
4
5
t [s]
0.0
0.5
1.0
Input
Fig. 7.5 Variability in a deterministic model network of 8000 excitatory and 2000 inhibitory neurons,
both modeled as leaky integrate-and-ﬁre neurons. (a) Voltage trace as a function of time for a single
model neuron. Spikes (vertical lines) are generated whenever the membrane potential (solid line)
hits the ﬁring threshold. (b) Spike raster of 100 neurons in the network. Spike times (dots) of a single
neuron appear along a horizontal line. (C) Population activity A as a function of time t, measured
by averaging across the spikes of the subpopulation of 100 neurons shown in (b). From time t = 1 s
to t = 3 s, all neurons in this population receive a nonzero input. (d) Input to the subpopulation of
100 neurons. Simulation results courtesy of F. Zenke and T. P. Vogels (Vogels et al., 2011).
different averaging procedures: an average over time, or an average over several repeti-
tions of the experiment, or an average over a population of neurons. The following three
subsections will revisit in detail these three concepts.
7.2.1 Rate as a spike count and Fano factor
The ﬁrst and most commonly used deﬁnition of a ﬁring rate refers to a temporal average.

174
Variability of spike trains and neural codes
t
nsp
T
Spike count
=
T
 Rate =  average over time
(single neuron, single run)
n
Fig. 7.6 The spike count measure: deﬁnition of
the mean ﬁring rate by temporal average.
An experimenter observes in trial k the spikes of a given neuron (see Fig. 7.6). The ﬁring
rate in trial k is the spike count nsp
k in an interval of duration T divided by T
νk = nsp
k
T .
(7.1)
The length T of the time window is set by the experimenter and depends on the type of
neuron and the stimulus. In practice, to get sensible averages, several spikes should occur
within the time window. Typical values are T = 100 ms or T = 500 ms, but the duration
may also be longer or shorter.
This deﬁnition of rate has been successfully used in many preparations, particularly in
experiments on sensory or motor systems. A classical example is the stretch receptor in
a muscle spindle (Adrian, 1926). The number of spikes emitted by the receptor neuron
increases with the force applied to the muscle.
If the same experiment is repeated several times, the measured spike count varies between
one trial and the next. Let us denote the spike count in trial k by the variable nsp
k , its mean
by ⟨nsp⟩and deviations from the mean as Δnsp
k = nsp
k −⟨nsp⟩. Variability of the spike count
measure is characterized by the Fano factor, deﬁned as the variance of the spike count
⟨(Δnsp)2⟩divided by its mean
F = ⟨(Δnsp)2⟩
⟨nsp⟩
.
(7.2)
In experiments, the mean and variance are estimated by averaging over K trials ⟨nsp⟩=
(1/K)∑K
k=1 nsp
k and ⟨(Δnsp)2⟩= (1/K)∑K
k=1 (Δnsp
k )2.
If we ﬁnd on average ⟨nsp⟩spikes in a long temporal window of duration T, the mean
interval between two subsequent spikes is T/⟨nsp⟩. Indeed, using the notion of interspike-
interval distribution to be introduced below (Section 7.3), we can make the following state-
ment: the ﬁring rate deﬁned here as spike count divided by the measurement time T is
identical to the inverse of the mean interspike interval. We will come back to interspike
intervals in Section 7.3.
It is tempting, but misleading, to consider the inverse interspike interval as a "momen-
tary ﬁring rate:" if a ﬁrst spike occurs at time tk and the next one at time tk+1, we could
artiﬁcially assign a variable ˜ν(t) = 1/(tk+1−tk) for all times tk < t ≤tk. However, the tem-
poral average of ˜ν(t) over a much longer time T is not the same as the mean rate ν deﬁned
here as spike count divided by T, simply because 1/⟨x⟩̸= ⟨(1/x)⟩. A practical deﬁnition
of "instantaneous ﬁring rate" will be given below in Section 7.2.2.

7.2 Mean ﬁring rate
175
Example: Homogeneous Poisson process
Iftherateν isdeﬁnedviaaspikecountoveratimewindowofdurationT,theexactﬁring
time of a spike does not matter. It is therefore tempting to describe spiking as a Poisson
process where spikes occur independently and stochastically with a constant rate ν.
Let us divide the duration T (say 500 ms) into a large number of short segments Δt
(say Δt = 0.1 ms). In a homogeneous Poisson process, the probability of ﬁnding a spike
in a short segment of duration Δt is
PF(t;t +Δt) = ν Δt .
(7.3)
In other words, spike events are independent of each other and occur with a constant
rate (also called stochastic intensity) deﬁned as
ν = lim
Δt→0
PF(t;t +Δt)
Δt
.
(7.4)
The expected number of spikes to occur in the measurement interval T is therefore
⟨nsp⟩= ν T,
(7.5)
so that the experimental procedure of (i) counting spikes over a time T and (ii) dividing
by T gives an empirical estimate of the rate ν of the Poisson process.
For a Poisson process, the Fano factor is exactly 1. Therefore, measuring the Fano
factor is a powerful test so as to ﬁnd out whether neuronal ﬁring is Poisson-like; see the
discussion in Rieke et al. (1997).
7.2.2 Rate as a spike density and the peri-stimulus-time histogram
An experimenter records from a neuron while stimulating with some input sequence. The
same stimulation sequence is repeated several times and the neuronal response is reported
in a peri-stimulus-time histogram (PSTH) with bin width Δt; see Fig. 7.7. The time t is
measured with respect to the start of the stimulation sequence and Δt deﬁnes the time bin
for generating the histogram, it is typically of the order of milliseconds.
The number of occurrences of spikes nK(t;t + Δt) summed over all repetitions of the
experiment divided by the number K of repetitions is a measure of the typical activity of
the neuron between time t and t +Δt. A further division by the interval length Δt yields the
spike density
ρ(t) = 1
Δt
nK(t;t +Δt)
K
.
(7.6)
Sometimes the result is smoothed to get a continuous (time-dependent) rate variable, usu-
ally reported in units of hertz. As an experimental procedure, the PSTH measure is a useful
method to evaluate neuronal activity, in particular in the case of time-dependent stimuli;
see Fig. 7.4. We call it the time-dependent ﬁring rate.

176
Variability of spike trains and neural codes
Fig.
7.7 The
peri-stimulus-time
histogram
(PSTH)
and
the
time-
dependent ﬁring rate as an average
over several runs of the experiment.
In order to see the relation of Eq. (7.6) to a time-dependent ﬁring rate, we recall that
spikes are formal events characterized by their ﬁring time t f where f counts the spikes. In
Chapter 1 we have deﬁned (Eq. (1.14)) the spike train as a sum of δ-functions:
S(t) = ∑
f
δ(t −t f ).
(7.7)
If each stimulation can be considered as an independent sample from the identical stochas-
tic process, we can deﬁne an instantaneous ﬁring rate as an expectation over trials
ν(t) = ⟨S(t)⟩.
(7.8)
An expectation value over δ-functions may look strange to the reader not used to seeing
such mathematical objects. Let us therefore consider the experimental procedure to esti-
mate the expectation value. First, in each trial k, we count the number of spikes that occur
in a short time interval Δt by integrating the spike train over time, nsp
k (t) =
 t+Δt
t
Sk(t′)dt′
where the lower index k denotes the trial number. Note that integration removes the
δ-function. Obviously, if the time bin Δt is small enough we will ﬁnd at most one spike so
that nsp
k is either zero or 1. Second, we average over the K trials and divide by Δt in order
to obtain the empirical estimate
ν(t) =
1
K Δt
K
∑
k=1
nsp
k (t).
(7.9)
The PSTH, deﬁned as spike count per time bin averaged over several trials and divided by
the bin length (the right-hand side of Eq. (7.9)), provides therefore an empirical estimate
of the instantaneous ﬁring rate (the left-hand side).
Example: Inhomogeneous Poisson process
An inhomogeneous Poisson process can be used to describe the spike density mea-
sured in a PSTH. In an inhomogeneous Poisson process, spike events are independent
of each other and occur with an instantaneous ﬁring rate
ν(t) = lim
Δt→0
PF(t;t +Δt)
Δt
.
(7.10)

7.2 Mean ﬁring rate
177
Postsynaptic
neuron
Population
(a)
Am
t
1
A = 
Activity
N
nact (t; t+  t)
j=1
3
N
2
...
t
Rate = average over pool of equivalent neurons
(several neurons, single run)
(b)
Fig. 7.8 (a) A postsynaptic neuron receives spike input from the population m with activity Am.
(b) The population activity is deﬁned as the fraction of neurons that are active in a short interval
[t,t +Δt] divided by Δt.
Therefore, the probability of ﬁnding a spike in a short segment of duration Δt, say, a time
bin of 1 ms, is PF(t;t +Δt) = ν(t)Δt. More generally, the expected number of spikes in
an interval of ﬁnite duration T is ⟨nsp⟩=
 T
0 ν(t)dt and the Fano factor is 1, as was the
case for the homogeneous Poisson process.
Once we have measured a PSTH, we can always ﬁnd an inhomogeneous Poisson
process which reproduces the PSTH. However, this does not imply that neuronal ﬁring
is Poisson-like. A Poisson process has, for example, the tendency to generate spikes
with very short interspike intervals, which cannot occur for real neurons because of
refractoriness.
7.2.3 Rate as a population activity (average over several neurons)
The number of neurons in the brain is huge. Often many neurons have similar properties
and respond to the same stimuli. For example, neurons in the primary visual cortex of cats
and monkeys are arranged in columns of cells with similar properties (Hubel and Wiesel,
1962). Let us idealize the situation and consider a population of neurons with identical
properties. In particular, all neurons in the population should have the same pattern of
input and output connections. The spikes of the neurons in a population m are sent off to
another population n. In our idealized picture, each neuron in population n receives input
from all neurons in population m. The relevant quantity, from the point of view of the
receiving neuron, is the proportion of active neurons in the presynaptic population m; see
Fig. 7.8a. Formally, we deﬁne the population activity
A(t) = 1
Δt
nact(t;t +Δt)
N
= 1
Δt
 t+Δt
t
∑j ∑f δ(t −t f
j )dt
N
,
(7.11)
where N is the size of the population, nact(t;t +Δt) is the number of spikes (summed over
all neurons in the population) that occur between t and t + Δt, where Δt is a small time

178
Variability of spike trains and neural codes
(a)
(b)
I0
s1
sk
0
P0(s)
t
t
s
Fig. 7.9 Stationary interval distribution. (a) A neuron driven by a constant input produces spikes
with variable intervals. (b) A histogram of the interspike intervals s1,s2,... can be used to estimate
the interval distribution P0(s).
interval; see Fig. 7.8. Eq. (7.11) deﬁnes a variable with units inverse time - in other words,
a rate.
As we can see from Fig. 7.5c, the population activity may vary rapidly and can reﬂect
changes in the stimulus conditions nearly instantaneously. Before we discuss the problem
of neural coding (Section 7.6), let us ﬁrst study further statistical measures of spike train
statistics.
7.3 Interval distribution and coefﬁcient of variation
The estimation of interspike-interval (ISI) distributions from experimental data is a com-
mon method to study neuronal variability given a certain stationary input. In a typical
experiment, the spike train of a single neuron (e.g., a neuron in the visual cortex) is recorded
while driven by a constant stimulus. The stimulus might be an external input applied to the
system (e.g., a visual contrast grating moving at constant speed); or it may be an intra-
cellularly applied constant driving current. The spike train is analyzed and the distribution
of intervals sk between two subsequent spikes is plotted in a histogram. For a sufﬁciently
long spike train, the histogram provides a good estimate of the ISI distribution, which we
denote as P0(s); see Fig. 7.9. The interval distribution can be interpreted as a conditional
probability density
P0(s) = P(t f +s|t f ),
(7.12)
where
 t+Δt
t
P(t′|t f )dt′ is the probability that the next spike occurs in the interval [t,t +Δt]
given that the last spike occurred at time t f .
In order to extract the mean ﬁring rate from a stationary interval distribution P0(s), we
start with the deﬁnition of the mean interval,
⟨s⟩=
 ∞
0 sP0(s)ds.
(7.13)
The mean ﬁring rate is the inverse of the mean interval
ν = 1
⟨s⟩=
 ∞
0 sP0(s)ds
−1
.
(7.14)

7.4 Autocorrelation function and noise spectrum
179
7.3.1 Coefﬁcient of variation CV
Interspike-interval distributions P0(s) derived from a spike train under stationary condi-
tions can be broad or sharply peaked. To quantify the width of the interval distribution,
neuroscientists often evaluate the coefﬁcient of variation, CV , deﬁned as the ratio of the
standard deviation and the mean. Therefore the square of the CV is
C2
V = ⟨Δs2⟩
⟨s⟩2 ,
(7.15)
where ⟨s⟩=
 ∞
0 sP0(s)ds and ⟨Δs2⟩=
 ∞
0 s2 P0(s)ds −⟨s⟩2. A Poisson process produces
distributions with CV = 1. A value of CV > 1 implies that a given spike train is less regular
than a Poisson process with the same ﬁring rate. If CV < 1, then the spike train is more
regular. Most deterministic integrate-and-ﬁre neurons ﬁre periodically when driven by a
constant stimulus and therefore have CV = 0. Intrinsically bursting neurons, however, can
have CV > 1.
Example: Poisson process with absolute refractoriness
We study a Poisson neuron with absolute refractory period Δabs. For times since the
last spike larger than Δabs, the neuron is supposed to ﬁre stochastically with rate r. The
interval distribution of a Poisson process with absolute refractoriness (Fig. 7.10a) is
given by
P0(s) =
 0
for
s < Δabs,
r exp

−r(s−Δabs)

for
s > Δabs,
(7.16)
and has a mean ⟨s⟩= Δabs +1/r and variance ⟨Δs2⟩= 1/r2. The coefﬁcient of variation
is therefore
CV = 1−Δabs
⟨s⟩.
(7.17)
Let us compare the CV of Eq. (7.17) with that of a homogeneous Poisson process of the
same mean rate ν = ⟨s⟩−1. As we have seen, a Poisson process has CV = 1. A refractory
period Δabs > 0 lowers the CV , because a neuron with absolute refractoriness ﬁres more
regularly than a Poisson neuron. If we increase Δabs, we must increase the instantaneous
rate r in order to keep the same mean rate ν. In the limit of Δabs →⟨s⟩, the CV approaches
zero, since the only possible spike train is regular ﬁring with period ⟨s⟩.
7.4 Autocorrelation function and noise spectrum
Suppose that, during a stationary input scenario, we observe a neuron i ﬁring a ﬁrst spike
at time t. While the interval distribution P0(s) describes the probability that the next spike
occurs at time t +s, the autocorrelation function C(s) focuses on the probability of ﬁnding

180
Variability of spike trains and neural codes
another spike at time t +s - independent of whether this is the next spike of the neuron or
not.
In order to make the notion of an autocorrelation function more precise, let us consider a
spike train Si(t) = ∑f δ(t −t f
i ) of length T. The ﬁring times t f
i might have been measured
in an experiment or else generated by a neuron model. We suppose that T is sufﬁciently
long so that we can formally consider the limit T →∞. The autocorrelation function Cii(s)
of the spike train is a measure for the probability of ﬁnding two spikes at a time interval s,
i.e.,
Cii(s) = ⟨Si(t)Si(t +s)⟩t ,
(7.18)
where ⟨·⟩t denotes an average over time t,
⟨f(t)⟩t = lim
T→∞
1
T
 T/2
−T/2 f(t)dt .
(7.19)
We note that the right-hand side of Eq. (7.18) is symmetric so that Cii(−s) = Cii(s) holds.
The calculation of the autocorrelation function for a stationary renewal process is the topic
of Section 7.5.2.
It turns out that the autocorrelation function is intimately linked to the power spectrum
of a neuronal spike train, also called the noise spectrum. The power spectrum (or power
spectral density) of a spike train is deﬁned as P(ω) = limT→∞PT(ω), where PT is the
power of a segment of length T of the spike train,
PT(ω) = 1
T

 T/2
−T/2 Si(t)e−iω t dt

2
.
(7.20)
The power spectrum P(ω) of a spike train is equal to the Fourier transform ˆCii(ω) of its
autocorrelation function (Wiener-Khinchin theorem). To see this, we use the deﬁnition of
the autocorrelation function
ˆCii(ω) =
 ∞
−∞⟨Si(t)Si(t +s)⟩e−iω s ds
= lim
T→∞
1
T
 T/2
−T/2 Si(t)
 ∞
−∞Si(t +s)e−iω s dsdt
= lim
T→∞
1
T
 T/2
−T/2 Si(t)e+iω t dt
 ∞
−∞Si(s′)e−iω s′ ds′
= lim
T→∞
1
T

 T/2
−T/2 Si(t)e−iω t dt

2
.
(7.21)
In the limit of T →∞, Eq. (7.20) becomes identical to (7.21) so that the assertion follows.
The power spectral density of a spike train during spontaneous activity is called the noise
spectrum of the neuron. Noise is a limiting factor to all forms of information transmission
and in particular to information transmission by neurons. An important concept of the
theory of signal transmission is the signal-to-noise ratio. A signal that is transmitted at a
certain frequency ω should be stronger than (or at least of the same order of magnitude

7.5 Renewal statistics
181
as) the noise at the same frequency. For this reason, the noise spectrum P(ω) of the
transmission channel is of interest. As we shall see in the next section, the noise spectrum
of a stationary renewal process is intimately related to the interval distribution P0(s).
7.5 Renewal statistics
Poisson processes do not account for neuronal refractoriness and cannot be used to describe
realistic interspike-interval distributions. In order to account for neuronal refractoriness in
the stochastic description of spike trains, we need to switch from a Poisson processes to a
renewal process. Renewal processes keep a memory of the last event (last ﬁring time) ˆt, but
not of any earlier events. More precisely, spikes are generated in a renewal process, with a
stochastic intensity (or "hazard")
ρ(t|ˆt) = ρ0(t −ˆt)
(7.22)
which depends on the time since the last spike. One of the simplest example of a renewal
system is a Poisson process with absolute refractoriness which we have already encoun-
tered in the previous section; see Eq. (7.16).
Renewal processes are a class of stochastic point processes that describe a sequence of
events in time (Cox, 1962; Papoulis, 1991). Renewal systems in the narrow sense (sta-
tionary renewal processes), presuppose stationary input and are deﬁned by the fact that the
state of the system, and hence the probability of generating the next event, depends only on
the "age" t −ˆt of the system, i.e., the time that has passed since the last event (last spike).
The central assumption of renewal theory is that the state does not depend on earlier events
(i.e., earlier spikes of the same neuron). The aim of renewal theory is to predict the proba-
bility of the next event given the age of the system. In other words, renewal theory allows
us to calculate the interval distribution
P0(s) = P(t f +s|t f ),
(7.23)
i.e., the probability density that the next event occurs at time t f +s given that the last event
was observed at time t f .
While for a Poisson process all events occur independently, in a renewal process gener-
ation of events (spikes) depends on the previous event, so that events are not independent.
However, since the dependence is restricted to the most recent event, intervals between
subsequent events are independent. Therefore, an efﬁcient way of generating a spike train
of a renewal system is to draw interspike intervals from the distribution P0(s).
Example: Light bulb failure as a renewal system
A generic example of a renewal system is a light bulb. The event is the failure of the
bulb and its subsequent exchange. Obviously, the state of the system only depends on
the age of the current bulb, and not on that of any previous bulb that has already been

182
Variability of spike trains and neural codes
exchanged. If the usage pattern of the bulbs is stationary (e.g., the bulb is switched on
for 10 hours each night) then we have a stationary renewal process. The aim of renewal
theory is to calculate the probability of the next failure given the age of the bulb.
7.5.1 Survivor function and hazard
The interval distribution P(t|ˆt) as deﬁned above is a probability density. Thus, integration
of P(t|ˆt) over time yields a probability. For example,
 t
ˆt P(t′|ˆt)dt′ is the probability that a
neuron which has emitted a spike at ˆt ﬁres the next action potential between ˆt and t. Thus
S(t|ˆt) = 1−
 t
ˆt P(t′|ˆt)dt′
(7.24)
is the probability that the neuron stays quiescent between ˆt and t. S(t|ˆt) is called the sur-
vivor function: it gives the probability that the neuron "survives" from ˆt to t without ﬁring.
The survivor function S(t|ˆt) has an initial value S(ˆt|ˆt) = 1 and decreases to zero for
t →∞. The rate of decay of S(t|ˆt) will be denoted by ρ(t|ˆt) and is deﬁned by
ρ(t|ˆt) = −
d
dt S(t|ˆt)
S(t|ˆt) =
P(t|ˆt)
1−
 t
ˆt P(t′|ˆt)dt′ .
(7.25)
In the language of renewal theory, ρ(t|ˆt) is called the "age-dependent death rate" or "haz-
ard" (Cox, 1962; Cox and Lewis, 1966).
Integration of the differential equation dS/dt = −ρ S [see the ﬁrst identity in Eq. (7.25)]
yields the survivor function
S(t|ˆt) = exp

−
 t
ˆt ρ(t′|ˆt)dt′

.
(7.26)
According to the deﬁnition of the survivor function in Eq. (7.24), the interval distribution
is given by
P(t|ˆt) = −d
dt S(t|ˆt) = ρ(t|ˆt)S(t|ˆt),
(7.27)
which has a nice intuitive interpretation: In order to emit its next spike at t, the neuron
has to survive the interval (ˆt,t) without ﬁring and then ﬁre at t. The survival probability
is S(t|ˆt) and the hazard of ﬁring a spike at time t is ρ(t|ˆt). Multiplication of the survivor
function S with the momentary hazard ρ gives the two factors on the right-hand side of
Eq. (7.27). Inserting Eq. (7.26) in (7.27), we obtain an explicit expression for the interval
distribution in terms of the hazard:
P(t|ˆt) = ρ(t|ˆt) exp

−
 t
ˆt ρ(t′|ˆt)dt′

.
(7.28)
On the other hand, given the interval distribution we can derive the hazard from Eq. (7.25).
Thus, each of the three quantities ρ(t|ˆt), P(t|ˆt), and S(t|ˆt) is sufﬁcient to describe the

7.5 Renewal statistics
183
0
20
40
s [ms]
0.0
0.1
0.2
(a)
P0(s)
0
20
40
s [ms]
0.0
1.0
 S0(s)
0
20
40
s [ms]
0.0
0.2
0.4
 r0(s)  [kHz]
0
20
40
s [ms]
0.0
0.1
(b)
P0(s)
0
20
40
s [ms]
0.0
1.0
 S0(s)
0
20
40
s [ms]
0.0
0.2
0.4
r0(s)  [kHz]
0
20
40
s [ms]
0.0
0.1
(c)
P0(s)
0
20
40
s [ms]
0.0
1.0
 S0(s)
0
20
40
s [ms]
0.0
0.2
0.4
r0(s) [kHz]
Fig. 7.10 Interval distribution P0(s) (top), survivor function S0(s) (middle) for three different hazard
functions (bottom). (a) Hazard function corresponds to a Poisson neuron with absolute refractoriness
of 5 ms. (b) Hazard function deﬁned by ρ0(s) = a0 (s −Δabs)Θ(s −Δabs) with a0 = 0.01ms−2 and
Δabs = 2 ms. (c) Hazard function deﬁned by ρ0(s) = ν{1 −exp[−λ (s −Δabs)]}Θ(s −Δabs) with
ν = 0.1 kHz, λ = 0.2 kHz, and Δabs = 2 ms.
statistical properties of a renewal system. Since we focus on stationary renewal systems,
the notation can be simpliﬁed and Eqs. (7.24)-(7.28) hold with the replacement
P(t|ˆt) = P0(t −ˆt),
(7.29)
S(t|ˆt) = S0(t −ˆt),
(7.30)
ρ(t|ˆt) = ρ0(t −ˆt).
(7.31)
Eqs. (7.24)-(7.28) are standard results of renewal theory. The notation that we have chosen
in Eqs. (7.24)-(7.28) will turn out to be useful in later chapters and highlights the fact that
these quantities are conditional probabilities, probability densities, or rates.
Example: From interval distribution to hazard function
Let us suppose that we have found under stationary experimental conditions an inter-

184
Variability of spike trains and neural codes
val distribution that can be approximated as
P0(s) =

0
for
s ≤Δabs,
a0 (s−Δabs),e−a0
2 (s−Δabs)2
for
s > Δabs,
(7.32)
with a constant a0 > 0; see Fig. 7.10b. From Eq. (7.25), the hazard is found to be
ρ0(s) =
 0
for
s ≤Δabs,
a0 (s−Δabs)
for
s > Δabs .
(7.33)
Thus, during an interval Δabs after each spike the hazard vanishes. We may interpret
Δabs as the absolute refractory time of the neuron. For s > Δabs the hazard increases
linearly, i.e., the longer the neuron waits the higher its probability of ﬁring. In Chapter
9, the hazard of Eq. (7.33) can be interpreted as the instantaneous rate of a non-leaky
integrate-and-ﬁre neuron subject to noise.
7.5.2 Renewal theory and experiments
Renewal theory is usually associated with stationary input conditions. The interval distribu-
tion P0 can then be estimated experimentally from a single long spike train. The applicabil-
ity of renewal theory relies on the hypothesis that a memory back to the last spike sufﬁces
to describe the spike statistics. In particular, there should be no correlation between one
interval and the next. In experiments, the renewal hypothesis can be tested by measuring
the correlation between subsequent intervals. Under some experimental conditions, corre-
lations are small, indicating that a description of spiking as a stationary renewal process
is a good approximation (Goldberg et al., 1964); however, under experimental conditions
where neuronal adaptation is strong, intervals are not independent (Fig. 7.11). Given a
time series of events with variable intervals s j, a common measure of memory effects is
the serial correlation coefﬁcients
ck =
⟨s j+ks j⟩j −⟨s j⟩2
j
⟨s2
j⟩−⟨sj⟩2
.
(7.34)
Spike-frequency adaptation causes a negative correlation between subsequent intervals
(c1 < 0). Long intervals are most likely followed by short ones, and vice versa, so that
the assumption of renewal theory does not hold (Schwalger et al., 2010; Ratnam and Nel-
son, 2000; Chacron et al., 2000).
The notion of stationary input conditions is a mathematical concept that cannot be easily
translated into experiments. With intracellular recordings under in vitro conditions, con-
stant input current can be imposed and thus the renewal hypothesis can be tested directly.
Under in vivo conditions, the assumption that the input current to a neuron embedded in
a large neural system is constant (or has stationary statistics) is questionable; see (Perkel

7.5 Renewal statistics
185
Probability
ISI (i+ 1)
ISI (i)
Normalized ISI
(a)
(b)
Fig. 7.11 Limitations of the renewal assumption. (a) The interval distribution P0(s) of an afferent
sensory ﬁber in the weakly electric ﬁsh exhibits periodic peaks, which are associated to the back-
ground oscillation normalized to period T = 1. The most likely interval is exactly one period, but
longer intervals are possible. (b) Testing for renewal in a plot of the joint density of the interval i
(horizontal axis) and the next interval i + 1 (vertical axis). Size of symbol indicates probability of
occurrence. The most likely sequence is that an interval of length 4 is followed by an interval of
length 1; moreover, a short interval of length 1 is most likely followed by a long interval of length 4.
Modiﬁed from Ratnam and Nelson (2000).
et al., 1967a,b) for a discussion. While the externally controlled stimulus can be made sta-
tionary (e.g., a grating drifting at constant speed), the input to an individual neuron is out
of control.
Let us suppose that, for a given experiment, we have checked that the renewal hypothesis
holds to a reasonable degree of accuracy. From the experimental interval distribution P0 we
can then calculate the survivor function S0 and the hazard ρ0 via Eqs. (7.24) and (7.25). If
some additional assumptions regarding the nature of the noise are made, the form of the
hazard ρ0(t|ˆt) can be interpreted in terms of neuronal dynamics. In particular, a reduced
hazard immediately after a spike is a signature of neuronal refractoriness (Goldberg et al.,
1964; Berry and Meister, 1998).
Example: Plausible hazard function and interval distributions
Interval distributions and hazard functions have been measured in many experiments.
For example, in auditory neurons of the cat driven by stationary stimuli, the hazard func-
tion ρ0(t −ˆt) increases, after an absolute refractory time, to a constant level (Goldberg
et al., 1964). We approximate the time course of the hazard function as
ρ0(s) =

0
for
s ≤Δabs,
ν [1−e−λ (s−Δabs)]
for
s > Δabs,
(7.35)
with parameters Δabs,λ, and ν; Fig. 7.10c. In Chapter 9 we shall see how the hazard
(7.35) can be related to neuronal dynamics. Given the hazard function, we can calculate

186
Variability of spike trains and neural codes
the survivor function and interval distributions. Application of Eq. (7.26) yields
S0(s) =

1
for
s < Δabs,
e−ν (s−Δabs) eρ0(s)/λ
for
s > Δabs.
(7.36)
The interval distribution is given by P0(s) = ρ0(s)S0(s). Interval distribution, survivor
function, and hazard are shown in Fig. 7.10c.
We may compare the above hazard function and interval distribution with that of
the Poisson neuron with absolute refractoriness. The main difference is that the hazard
in Eq. (7.16) jumps from the state of absolute refractoriness to a constant ﬁring rate,
whereas in Eq. (7.35) the transition is smooth.
7.5.3 Autocorrelation and noise spectrum of a renewal process (*)
In case of a stationary renewal process, the interval distribution P0 contains all the statistical
information so that the autocorrelation function and noise spectrum can be derived. In this
section we calculate the noise spectrum of a stationary renewal process. As we have seen
above, the noise spectrum of a neuron is directly related to the autocorrelation function
of its spike train. Both noise spectrum and autocorrelation function are experimentally
accessible.
Let νi = ⟨Si⟩denote the mean ﬁring rate (expected number of spikes per unit time) of the
spike train. Thus the probability of ﬁnding a spike in a short segment [t,t +Δt] of the spike
train is ν Δt. For large intervals s, ﬁring at time t +s is independent of whether or not there
was a spike at time t. Therefore, the expectation of ﬁnding a spike at t and another spike at
t +s approaches for s →∞a limiting value lims→∞⟨Si(t)Si(t +s)⟩= lims→∞Cii(s) = ν2
i . It
is convenient to subtract this baseline value and introduce a "normalized" autocorrelation,
C0
ii(s) = Cii(s)−ν2
i ,
(7.37)
with lims→∞C0
ii(s) = 0. The Fourier transform of Eq. (7.37) yields
ˆCii(ω) = ˆC0
ii(ω)+2πν2
i δ(ω).
(7.38)
Thus ˆCii(ω) diverges at ω = 0; the divergence is removed by switching to the normalized
autocorrelation. In the following we will calculate the noise spectrum ˆCii(ω) for ω ̸= 0.
In the case of a stationary renewal process, the autocorrelation function is closely related
to the interval distribution P0(s). This relation will now be derived. Let us suppose that we
have found a ﬁrst spike at t. To calculate the autocorrelation we need the probability density
for a spike at t + s. Let us construct an expression for Cii(s) for s > 0. The correlation
function for positive s will be denoted by νiC+(s) or
C+(s) = 1
νi
Cii(s)Θ(s).
(7.39)

7.5 Renewal statistics
187
t
S
S¢
S-S¢
(a)
-1
0
1
w/2p [kHz] 
0.0
1.0
Cii(w)/n
(b)
Fig. 7.12 (a) The autocorrelation of a spike train describes the chance to ﬁnd two spikes at a dis-
tance s, independent of the number of spikes that occur in between. (b) Fourier transform of the
autocorrelation function Cii of a Poisson neuron with absolute refractoriness (Δax = 5ms) and con-
stant stimulation (ν = 100 Hz).
The factor νi in Eq. (7.39) takes care of the fact that we expect a ﬁrst spike at t with rate
νi; C+(s) gives the conditional probability density that, given a spike at t, we will ﬁnd
another spike at t +s > t. The spike at t +s can be the ﬁrst spike after t, or the second one,
or the nth one; see Fig. 7.12. Thus for s > 0
C+(s) = P0(s)+
 ∞
0 P0(s′)P0(s−s′)ds′
+
 ∞
0
 ∞
0 P0(s′)P0(s′′)P0(s−s′ −s′′)ds′ ds′′ +···
(7.40)
or
C+(s) = P0(s)+
 ∞
0 P0(s′)C+(s−s′)ds′
(7.41)
as can be seen by inserting Eq. (7.40) on the right-hand side of (7.41); see Fig. 7.13.
Owing to the symmetry of Cii, we have Cii(s) = νC+(−s) for s < 0. Finally, for s = 0,
the autocorrelation has a δ peak reﬂecting the trivial autocorrelation of each spike with
itself. Hence,
Cii(s) = νi [δ(s)+C+(s)+C+(−s)] .
(7.42)
In order to solve Eq. (7.41) for C+ we take the Fourier transform of Eq. (7.41) and ﬁnd
ˆC+(ω) =
ˆP0(ω)
1−ˆP0(ω) .
(7.43)
Together with the Fourier transform of Eq. (7.42), ˆCii = νi [1+2Re{ ˆC+(ω)}], we obtain
ˆCii(ω) = νi Re
1+ ˆP0(ω)
1−ˆP0(ω)

for
ω ̸= 0.
(7.44)

188
Variability of spike trains and neural codes
Fig. 7.13 The autocorrelation function (ACF) is a sum of interspike-interval distributions convolved
with itself (graphical representation of Eq. (7.40)). The interspike-interval distribtion (P0(s), thick
line) is added sequentially to self-convolutions such as
 ∞
0 P0(s′)P0(s −s′)ds′ (dashed lines). The
partial sums (solid lines) gradually converge to the autocorrelation function (C+(s), dotted line).
For ω = 0, the Fourier integral over the right-hand side of Eq. (7.40) diverges, since
 ∞
0 P0(s)ds = 1. If we add the diverging term from Eq. (7.38), we arrive at
ˆCii(ω) = νi Re
1+ ˆP0(ω)
1−ˆP0(ω)

+2π ν2
i δ(ω).
(7.45)
This is a standard result of stationary renewal theory (Cox and Lewis, 1966) which has
been repeatedly applied to neuronal spike trains (Edwards and Wakeﬁeld, 1993; Bair et al.,
1994).
Example: Stationary Poisson process
In Sections 7.2.1 and 7.5 we have already discussed the Poisson neuron from the
perspective of mean ﬁring rate and renewal theory, respectively. The autocorrelation of
a Poisson process is
Cii(s) = ν δ(s)+ν2.
(7.46)
We want to show that Eq. (7.46) follows from Eq. (7.40).
Since the interval distribution of a Poisson process is exponential [see Eq. (7.16) with
Δabs = 0], we can evaluate the integrals on the right-hand side of Eq. (7.40) in a straight-
forward manner. The result is
C+(s) = ν e−ν s
1+ν s+ 1
2(ν s)2 +···

= ν .
(7.47)
Hence, with Eq. (7.42), we obtain the autocorrelation function (7.46) of a homogeneous
Poisson process. The Fourier transform of Eq. (7.46) yields a ﬂat spectrum with a δ peak
at zero:
ˆCii(ω) = ν +2π ν2 δ(ω).
(7.48)
The result could have also been obtained by evaluating Eq. (7.45).

7.5 Renewal statistics
189
Example: Poisson process with absolute refractoriness
We return to the Poisson process with absolute refractoriness deﬁned in Eq. (7.16).
Apart from an absolute refractory time Δabs, the neuron ﬁres with rate r. For ω ̸= 0,
Eq. (7.45) yields the noise spectrum
ˆCii(ω) = ν

1+2 ν2
ω2 [1−cos(ω Δabs)]+2 ν
ω sin(ω Δabs)
−1
;
(7.49)
see Fig. 7.12b. In contrast to the stationary Poisson process Eq. (7.46), the noise spec-
trum of a neuron with absolute refractoriness Δabs > 0 is no longer ﬂat. In particular,
for ω →0, the noise spectrum is decreased by a factor [1 + 2(ν Δabs) + (ν Δabs)2]−1.
Eq. (7.49) and generalizations thereof have been used to ﬁt the power spectrum of, e.g.,
auditory neurons (Edwards and Wakeﬁeld, 1993) and MT (middle temporal) neurons
(Bair et al., 1994).
Can we understand the decrease in the noise spectrum for ω →0? The mean interval
of a Poisson neuron with absolute refractoriness is ⟨s⟩= Δabs + r−1. Hence the mean
ﬁring rate is
ν =
r
1+Δabs r .
(7.50)
For Δabs = 0 we retrieve the stationary Poisson process Eq. (7.3) with ν = r. For ﬁnite
Δabs the ﬁring is more regular than that of a Poisson process with the same mean rate ν.
We note that, for ﬁnite Δabs > 0, the mean ﬁring rate remains bounded even if r →∞.
The neuron then ﬁres regularly with period Δabs. Because the spike train of a neuron with
refractoriness is more regular than that of a Poisson neuron with the same mean rate, the
spike count over a long interval, and hence the spectrum for ω →0, is less noisy. This
means that Poisson neurons with absolute refractoriness can transmit slow signals more
reliably than a simple Poisson process.
7.5.4 Input-dependent renewal theory (*)
It is possible to use the renewal concept in a broader sense and deﬁne a renewal process as
a system where the state at time t (and hence the probability of generating an event at t),
depends both on the time that has passed since the last event (i.e., the ﬁring time ˆt) and the
input I(t′), ˆt < t′ < t, that the system received since the last event. Input-dependent renewal
systems are also called modulated renewal processes (Reich et al., 1998), non-stationary
renewal systems (Gerstner, 1995, 2000), or inhomogeneous Markov interval processes
(Kass and Ventura, 2001). The aim of a theory of input-dependent renewal systems is to
predict the probability density
PI(t|ˆt)
(7.51)

190
Variability of spike trains and neural codes
t
t
t
t
I (t)
^
^
I
t-t^
^
P ( t | t )
(a)
(b)
Fig. 7.14 Input-dependent interval distribution. (a) A neuron, stimulated by the current I(t) has emit-
ted a ﬁrst spike at ˆt. (b) The interval distribution PI(t|ˆt) gives the probability density that the next
spike occurs after an interval t −ˆt.
of the next event to occur at time t, given the timing ˆt of the last event and the input I(t′)
for ˆt < t′ < t; see Fig. 7.14. The relation between hazard, survivor function, and interval
distribution for the input-dependent case is the same as the one given in Eqs. (7.25)-
(7.28). The generalization to a time-dependent renewal theory will be useful later on, in
Chapter 9.
The lower index I of PI(t|ˆt) is intended to remind the reader that the probability density
PI(t|ˆt) depends on the time course of the input I(t′) for t′ < t. Since PI(t|ˆt) is conditioned
on the spike at ˆt, it can be called a spike-triggered spike density. We interpret PI(t | ˆt) as
the distribution of interspike intervals in the presence of an input current I or as the input-
dependent interval distribution. For stationary input, PI(t|ˆt) reduces to P0(t −ˆt).
7.6 The problem of neural coding
We have discussed in the preceding sections measures to quantify neural spike train data.
This includes measures of interval distribution, autocorrelation, noise spectrum, but also
simple measures such as the ﬁring rate. All of these measures are useful tools for an experi-
menter who plans to study a neural system. A completely different question, however, is
whether neurons transmit information by using any of these quantities as a neural code.
In this section we critically review the notion of rate codes, and contrast rate coding
schemes with spike codes.
7.6.1 Limits of rate codes
The successful application of rate concepts to neural data does not necessarily imply that
the neuron itself uses a rate code. Let us look at the limitations of the spike count measure
and the PSTH.
Limitations of the spike count code
An experimenter as an external observer can evaluate and classify neuronal ﬁring by a
spike count measure - but is this really the code used by neurons in the brain? In other

7.6 The problem of neural coding
191
words, is a cortical neuron which receives signals from a sensory neuron only looking at
and reacting to the number of spikes it receives in a time window of, say, 500 ms? We will
approach this question from a modeling point of view later on in the book. Here we discuss
some critical experimental evidence.
From behavioral experiments it is known that reaction times are often rather short. A ﬂy
can react to new stimuli and change the direction of ﬂight within 30-40 ms; see the discus-
sion in (Rieke et al., 1997). This is not long enough for counting spikes and averaging over
some long time window. The ﬂy has to respond after a postsynaptic neuron has received
one or two spikes. Humans can recognize visual scenes in just a few hundred milliseconds
(Thorpe et al., 1996), even though recognition is believed to involve several processing
steps. Again, this does not leave enough time to perform temporal averages on each level.
From the point of view of rate coding, spikes are just a convenient way to transmit the
analog output variable ν over long distances. In fact, the best coding scheme to transmit the
value of the rate ν would be by a regular spike train with intervals 1/ν. In this case, the rate
could be reliably measured after only two spikes. From the point of view of rate coding,
the irregularities encountered in real spike trains of neurons in the cortex must therefore be
considered as noise. In order to get rid of the noise and arrive at a reliable estimate of the
rate, the experimenter has to average over a larger number of spikes.
Temporal averaging can work well in cases where the stimulus is constant or slowly
varying and does not require a fast reaction of the organism - and this is the situation
encountered in many experimental protocols. Real-world input, however, is rarely station-
ary, but often changing on a fast time scale. For example, even when viewing a static image,
humans perform saccades, rapid changes of the direction of gaze. The image projected onto
the retinal photo receptors changes therefore every few hundred milliseconds - and with
each new image the retinal photo receptors change the response (Fig. 7.16c). Since, in a
changing environment, a postsynaptic neuron does not have the time to perform a temporal
average over many (noisy) spikes, we consider next whether the PSTH could be used by a
neuron to estimate a time-dependent ﬁring rate.
Limitations of the PSTH
The obvious problem with the PSTH is that it needs several trials to build up. Therefore
it cannot be the decoding scheme used by neurons in the brain. Consider, for example, a
frog that wants to catch a ﬂy. It cannot wait for the insect to ﬂy repeatedly along exactly
the same trajectory. The frog has to base its decision on a single run - each ﬂy and each
trajectory is different.
Nevertheless, the PSTH measure of the instantaneous ﬁring rate can make sense if there
are large populations of similar neurons that receive the same stimulus. Instead of recording
from a population of N neurons in a single run, it is experimentally easier to record from
a single neuron and average over N repeated runs. Thus, a neural code based on the PSTH
relies on the implicit assumption that there are always populations of neurons with similar
properties.

192
Variability of spike trains and neural codes
Stimulus
Fig. 7.15 Time-to-ﬁrst-spike. The spike train
of three neurons are shown. The third neuron
from the top is the ﬁrst one to ﬁre a spike
after the stimulus onset (arrow). The dashed
line indicates the time course of the stimulus.
Limitations of rate as a population average
A potential difﬁculty with the deﬁnition (7.11) of the ﬁring rate as an average over a popu-
lation of neurons is that we have formally required a homogeneous population of neurons
with identical connections, which is hardly realistic. Real populations will always have a
certain degree of heterogeneity both in their internal parameters and in their connectivity
pattern. Nevertheless, rate as a population activity (of suitably deﬁned pools of neurons)
may be a useful coding principle in many areas of the brain.
For inhomogeneous populations, the deﬁnition (7.11) may be replaced by a weighted
average over the population. To give an example of a weighted average in an inhomoge-
neous population, we suppose that we are studying a population of neurons which respond
to a stimulus x. We may think of x as the location of the stimulus in input space. Neuron i
responds best to stimulus xi, another neuron j responds best to stimulus xj. In other words,
we may say that the spikes of a neuron i "represent" an input vector xi and those of j an
input vector xj. In a large population, many neurons will be active simultaneously when a
new stimulus x is represented. The location of this stimulus can then be estimated from the
weighted population average
xest(t) =
 t+Δt
t
∑j ∑f x j δ(t −t f
j )dt
 t+Δt
t
∑j ∑f δ(t −t f
j )dt
.
(7.52)
Both numerator and denominator are closely related to the population activity (7.11).
The estimate (7.52) has been successfully used for an interpretation of neuronal activ-
ity in primate motor cortex (Georgopoulos et al., 1986) and hippocampus (Wilson and
McNaughton, 1993). It is, however, not completely clear whether postsynaptic neurons
really evaluate the fraction (7.52) - a potential problem for a neuronal coding and decod-
ing scheme lies in the normalization by division.
7.6.2 Candidate temporal codes
Rate coding in the sense of a population average is one of many candidate coding schemes
that could be implemented and used by neurons in the brain. In this section, we introduce
some potential coding strategies based on spike timing.

7.6 The problem of neural coding
193
(a)
(b)
Relative latency [ms]
-30
30
(c)
Fig. 7.16 Time-to-ﬁrst-spike. (a) Touching the ﬁnger tip with a sharp object can be quantiﬁed by a
force vector with total strength in the normal direction (N), possibly superimposed with a tangential
component in one of four possible directions (P, U, D, R). (b) Spike response to onset of touch force
in the ﬁve possible direction (P, U, D, R, N). Different stimuli yield different spike latencies which are
consistent across the ﬁve repetitions. Different neurons have different response patterns (two selected
neurons are shown). The location where stimulation yields maximal response is shown with a ﬁlled
circle. (c) (Top) Presentation of an image on the retina. The grid of recording electrodes is indicated
by dots. (Bottom) The latency of the ﬁrst spike detected at each electrode reﬂects the original image.
Each pixel corresponds to one recorded neuron. (a) and (b) modiﬁed from Johansson and Birznieks
(2004), (c) is modiﬁed from Gollisch and Meister (2008) with permission from AAAS.
Time-to-ﬁrst-spike: latency code
Let us study a neuron which abruptly receives a new constant input at time t0. For example,
a neuron might be driven by an external stimulus which is suddenly switched on at time
t0. This seems to be somewhat artiﬁcial, but even in a realistic situation abrupt changes in
the input are quite common. When we look at a picture, our gaze jumps from one point to
the next. After each saccade, the photo receptors in the retina receive a new visual input.
Information about the onset of a saccades should easily be available in the brain and could
serve as an internal reference signal. We can then imagine a code where for each neuron
the timing of the ﬁrst spike after the reference signal contains all information about the
new stimulus. A neuron which ﬁres shortly after the reference signal is interpreted as a
strong stimulation of this neuron, whereas ﬁring somewhat later would signal a weaker
stimulation; see Fig. 7.15.
In a pure version of this coding scheme, each neuron needs to ﬁre only a single spike
to transmit information. If it emits several spikes, only the ﬁrst spike after the reference
signal counts. All following spikes would be irrelevant. To implement a clean version of
such a coding scheme, we imagine that each neuron is shut off by inhibition as soon as it
has ﬁred a spike. Inhibition ends with the onset of the next stimulus (e.g., after the next
saccade). After the release from inhibition the neuron is ready to emit its next spike, which
now transmits information about the new stimulus. Since each neuron in such a scenario

194
Variability of spike trains and neural codes
Background oscillation
(a)
(b)
Fig. 7.17 Phase and synchrony. (a) Phase coding: the neurons ﬁre at different phases with respect
to the background oscillation (dashed). The phase could code relevant information. (b) Coding by
synchrony: the upper four neurons are nearly synchronous: two other neurons at the bottom are not
synchronized with the others.
transmits exactly one spike per stimulus, it is clear that only the timing conveys information
and not the number of spikes.
Experimental evidence indicates that a coding scheme based on the latency of the ﬁrst
spike transmit a large amount of information. For example, touch sensors in the ﬁnger tip
encode the strength and direction of the touch in the timing of the ﬁrst spike emitted by
each neuron (Fig. 7.16). Similarly, the relative latency of ﬁrst spikes of retinal neurons
encode the image projected on the retina (Fig. 7.16c). In a slightly different context coding
by ﬁrst spikes has been discussed by Thorpe et al. (1996). Thorpe argues that the brain
does not have time to evaluate more than one spike from each neuron per processing step.
Therefore the ﬁrst spike should contain most of the relevant information, which is read out
by neurons further down the processing chain. Using information-theoretic measures on
their experimental data, several groups have shown that most of the information about a
new stimulus is indeed conveyed during the ﬁrst 20 or 50 milliseconds after the onset of
the neuronal response (Optican and Richmond, 1987; Tovee and Rolls, 1995).
Phase
We can apply a code by "time to ﬁrst spike" also in the situation where the reference signal
is not a single event, but a periodic signal. In the hippocampus, in the olfactory system, and
also in other areas of the brain, oscillations of some global variable (for example the pop-
ulation activity) are quite common. These oscillations could serve as an internal reference
signal. Neuronal spike trains could then encode information in the phase of a pulse with
respect to the background oscillation. If the input does not change between one cycle and
the next, then the same pattern of phases repeats periodically; see Fig. 7.17a.
The concept of coding by phases has been studied by several different groups. There is,
for example, evidence that the phase of a spike during an oscillation in the hippocampus
of the rat conveys information on the spatial location of the animal which is not fully
accounted for by the ﬁring rate of the neuron (O'Keefe and Recce, 1993).

7.6 The problem of neural coding
195
Correlations and synchrony
We can also use spikes from other neurons as the reference signal for a spike code. For
example, synchrony of a pair or of many neurons could signify special events and convey
information which is not contained in the ﬁring rate of the neurons; see Fig. 7.17b. One
famous idea is that synchrony could mean "belonging together." Consider, for example, a
complex scene consisting of several objects. It is represented in the brain by the activity of
a large number of neurons. Neurons that represent the same object could be "labeled" by
the fact that they ﬁre synchronously (von der Malsburg, 1981; Eckhorn et al., 1988; Gray
and Singer, 1989).
More generally, not only synchrony but any precise spatio-temporal pulse pattern could
be a meaningful event. For example, a spike pattern of three neurons, where neuron 1 ﬁres
at some arbitrary time t1 followed by neuron 2 at time t1 +δ12 and by neuron 3 at t1 +δ13,
might represent a certain stimulus condition. The same three neurons ﬁring with different
relative delays might signify a different stimulus. The relevance of precise spatio-temporal
spike patterns has been studied intensively by Abeles (1991). Similarly, but on a somewhat
coarse time scale, correlations of auditory and visual neurons are found to be stimulus
dependent and might convey information beyond that contained in the ﬁring rate alone
(deCharms and Merzenich, 1996; Steinmetz et al., 2000).
Stimulus reconstruction and reverse correlation
Let us consider a neuron which is driven by a time-dependent stimulus s(t). Every time a
spike occurs, we note the time course of the stimulus in a time window of about 100 ms
immediately before the spike. Averaging the results over several spikes yields the typ-
ical time course of the stimulus just before a spike (de Boer and Kuyper, 1968). Such
a procedure is called a "reverse correlation" approach; see Fig. 7.18. In contrast to the
PSTH experiment sketched in Section 7.2.2 where the experimenter averages the neu-
ron's response over several trials with the same stimulus, reverse correlation means that
the experimenter averages the input under the condition of an identical response, i.e., a
spike. In other words, it is a spike-triggered average (see, e.g., de Ruyter van Stevenhick
and Bialek 1988; Rieke et al. 1997). The results of the reverse correlation, i.e., the typical
time course of the stimulus that has triggered a spike, can be interpreted as the "mean-
ing" of a single spike. Reverse correlation techniques have made it possible to measure,
for example, the spatio-temporal characteristics of neurons in the visual cortex (Eckhorn
et al., 1993; DeAngelis et al., 1995).
With a somewhat more elaborate version of this approach, W. Bialek and his coworkers
have been able to "read" the neural code of the H1 neuron in the ﬂy and to reconstruct a
time-dependent stimulus (Bialek et al., 1991; Rieke et al., 1997). Here we give a simpliﬁed
version of their argument.
Results from reverse correlation analysis suggest that each spike signiﬁes the time course
of the stimulus preceding the spike. If this is correct, a reconstruction of the complete
time course of the stimulus s(t) from the set of ﬁring times F = {t(1),...t(n)} should be

196
Variability of spike trains and neural codes
Stimulus
Fig. 7.18 Reverse correlation tech-
nique (schematic). The stimulus in
the top trace has caused the spike
train shown immediately below. The
time course of the stimulus just
before the spikes (dashed boxes) has
been averaged to yield the typical
time course (bottom).
possible; see Fig. 7.19. As a simple test of this hypothesis, Bialek and coworkers have
studied a linear reconstruction. A spike at time t f gives a contribution κ(t −t f ) to the
estimation sest(t) of the time course of the stimulus. Here, t f ∈F is one of the ﬁring times
and κ(t −t f ) is a kernel which is nonzero during some time before and around t f ; see Fig.
7.19b. A linear estimate of the stimulus is
sest(t) =
n
∑
f=1
κ(t −t f ).
(7.53)
The form of the kernel κ was determined through optimization so that the average recon-
struction error
 dt[s(t)−sest(t)]2 was minimal. The quality of the reconstruction was then
tested on additional data which was not used for the optimization. Surprisingly enough, the
simple linear reconstruction (7.53) gave a fair estimate of the time course of the stimulus
even though the stimulus varied on a time scale comparable to the typical interspike inter-
val (Bialek et al., 1991; Rieke et al., 1997). This reconstruction method shows nicely that
information about a time-dependent input can indeed be conveyed by spike timing. Chapter
11 will revisit the spike train decoding in the presence of refractoriness and adaptation.
Rate versus temporal codes (*)
The dividing line between spike codes and ﬁring rates is not always as clearly drawn as it
may seem at ﬁrst sight. Some codes which were ﬁrst proposed as pure examples of pulse
codes have later been interpreted as variations of rate codes. For example, the stimulus
reconstruction (7.53) with kernels seems to be a clear example of a spike code. Neverthe-
less, it is also not so far from a rate code based on spike counts (Abbott, 1994; Theunissen
and Miller, 1995). To see this, consider a spike count measure with a running time window
K(.). We can estimate the rate ν at time t by
ν(t) =
 K(τ)S(t −τ)dτ
 K(τ)dτ
,
(7.54)
where S(t) = ∑n
f=1 δ(t −t f ) is the spike train under consideration. The integrals run from
minus to plus inﬁnity. For a rectangular time window K(τ) = 1 for −T/2 < τ < T/2 and
zero otherwise, (7.54) reduces exactly to our deﬁnition of a rate as a spike count measure
in Eq. (7.1).

7.6 The problem of neural coding
197
Stimulus
(a)
Estimate
Sensory system
(encoding)
Estimation algorithm
(decoding)
k(t−t i
f)
(b)
sest (t)
Fig. 7.19 Reconstruction of a stimulus (schematic). (a) A stimulus evokes a spike train of a neuron.
The time course of the stimulus may be estimated from the spike train; redrawn after Rieke et al.,
(1996). (b) In the framework of linear stimulus reconstruction, the estimation sest(t) (dashed) is the
sum of the contributions κ (solid lines) of all spikes.
The time window in (7.54) can be made rather short so that at most a few spikes fall
into the interval T. Furthermore, there is no need for the window K(.) to be symmetric and
rectangular. We might just as well take an asymmetric time window with smooth borders.
Moreover, we can perform the integration over the δ-function, which yields
ν(t) = c
n
∑
f=1
K(t −t f ),
(7.55)
where c = [
 K(s)ds]−1 is a constant. Except for the constant c (which sets the overall
scale to units of 1 over time), the generalized rate formula (7.55) is now identical to the
reconstruction formula (7.53). In other words, the linear reconstruction is just the ﬁring
rate measured with a cleverly optimized time window.
Similarly, a code based on the "time-to-ﬁrst-spike" is also consistent with rate coding.
If, for example, the mean ﬁring rate of a neuron is high for a given stimulus, then the ﬁrst
spike is expected to occur early. If the rate is low, the ﬁrst spike is expected to occur later.
Thus the timing of the ﬁrst spike contains a lot of information about the underlying rate.
The discussion of whether or not to call a given code a rate code is still ongoing. What
is important, in our opinion, is to have a coding scheme which allows neurons to quickly
respond to stimulus changes. A na¨ıve spike count code with a long time window is unable
to do this, but a code based on population activities introduced above and many of the other
codes are. The name of such a code, whether it is deemed a rate code or not is of minor
importance.
Example: Towards a deﬁnition of rate codes
We have seen above in Eq. (7.55) that stimulus reconstruction with a linear kernel
can be seen as a special instance of a rate code. This suggests a formal deﬁnition of a

198
Variability of spike trains and neural codes
rate code via the reconstruction procedure: if all information contained in a spike train
can be recovered by the linear reconstruction procedure of Eq. (7.53), then the neuron
is, by deﬁnition, using a rate code. Spike codes would then be codes where a linear
reconstruction is not successful. Theunissen and Miller have proposed a deﬁnition of
rate coding that makes the above ideas more precise (Theunissen and Miller, 1995).
To see how their deﬁnition works, we have to return to the reconstruction for-
mula (7.53). It is, in fact, the ﬁrst term of a systematic Volterra expansion for the esti-
mation of the stimulus from the spikes (Bialek et al., 1991)
sest(t) = ∑
f
κ1(t −t f ) + ∑
f, f ′
κ2(t −t f ,t −t f ′) +··· .
(7.56)
For a speciﬁc neuron, inclusion of higher-order terms κ2,κ3,... may or may not improve
the quality of the estimation. For most neurons where the reconstruction has been car-
ried through, it seems that the higher-order terms do not contribute a large amount of
information (Rieke et al., 1997). The neurons would then be classiﬁed as rate coding.
Let us now suppose that the reconstruction procedure indicates a signiﬁcant contribu-
tion of the second-order term. Does this exclude rate coding? Unfortunately this is not
the case. We have to exclude two other possibilities. Firstly, we might have chosen a
suboptimal stimulus. A neuron might, for example, encode the variable x by a rate code,
so that a nearly perfect linear reconstruction of x would be possible,
x(t) ≈xest =
n
∑
f=1
κ1(t −t f ).
(7.57)
But if we chose a stimulus s = x2 instead of x, then the reconstruction for sest would
involve second-order terms, even though the neuron is really using rate code.
Secondly, according to Theunissen and Miller (1995) a spike code should show a
temporal structure that is more precise than the temporal structure of the stimulus. The
fact that neurons show precise and reliable spike timing as such is, for them, not suf-
ﬁcient to classify the neuron as a temporal encoder, since the neuronal precision could
just be the image of precise temporal input. For a more quantitative treatment, let us
consider a stimulus with cut-off frequency ω. In order to exclude the possibility that
the timing is induced by the stimulus, Theunissen and Miller propose to consider the
Fourier spectrum of the higher-order reconstruction kernels. If the Fourier transform of
the higher-order kernels contains frequencies less than ω only, then the code is a rate
code. If higher-order kernels are signiﬁcant and contain frequencies above ω, then the
information is encoded temporally. A positive example of a spike code (or of "temporal
encoding") according to this deﬁnition would be the code by correlation and synchrony
introduced above. Another example would be the phase code, in particular if the number
of spikes per cycle is independent of the stimulus strength.

7.7 Summary
199
7.7 Summary
Variability of spike timing is a common phenomenon in biological neurons. Variability
can be quantiﬁed by the CV value of interval distributions, by the Fano factor of the spike
count, or by the repeatability of spike timings between one trial and the next. Whether
the variability represents noise or uncontrolled components of a signal which is not well
characterized is a topic of debate. Experiments show that a neuron in vitro, or in one of the
sensory areas in vivo, shows highly reliable spike timings if driven by a strong stimulus
with large-amplitude ﬂuctuations of the signal. Spontaneous activity in vivo, however, is
unreliable and exhibits large variability of interspike intervals and spike counts.
The simplest stochastic description of neuronal ﬁring is a Poisson process. However,
since each spike ﬁring in a Poisson process is independent of earlier spikes, Poisson ﬁring
cannot account for refractoriness. In renewal processes, the probability of ﬁring depends
on the time since the last spike. Therefore refractoriness is taken care of. The indepen-
dent events are the interspike intervals which are drawn from an interval distribution P0(s).
Knowledge of P0(s) is equivalent to knowing the survivor function S0(s) or the hazard
ρ0(s). In neurons showing strong adaptation, interspike intervals are not independent so
that renewal theory is not sufﬁcient. Moreover, standard renewal theory is limited to sta-
tionary stimuli, whereas real-world stimuli have a strong temporal component - the solu-
tion is then a time-dependent generalization of renewal theory which we will encounter in
Chapter 14.
A description of neuronal spike trains in terms of ﬁring rates or interval distributions
does not imply that neurons use the ﬁring rate (or interval distribution) to transmit sig-
nals. In fact, neither the spike count (averaging over time) nor the time-dependent rate of
the PSTH (averaging over trials) can be the neural code of sensory processing because
they are too slow given known reaction times. A ﬁring rate in the sense of a population
activity, deﬁned as the instantaneous average of spikes across a population of neurons with
similar properties, is, however, a candidate neural code. Other candidate codes, with some
experimental support are a latency code (time-to-ﬁrst-spike), or a phase code.
In models, noise is usually added ad hoc to account for the observed variability of neural
spike trains: two standard ways of adding noise to neuron models will be presented in the
next two chapters. But even without explicit noise source, neural activity may look noisy
if the neuron is embedded in a large deterministic network with ﬁxed random connectivity.
The analysis of such networks will be the topic of Part III.
Literature
A review of noise in the nervous system with a focus on internal noise sources can be found
in Faisal et al. (2008). Analysis of spike trains in terms of stochastic point processes has a
long tradition (Perkel et al., 1967a; Gerstein and Perkel, 1972) and often involves concepts

200
Variability of spike trains and neural codes
from renewal theory (Cox and Lewis, 1966). Some principles of spike-train analysis with
an emphasis on modern results have been reviewed by Gabbiani and Koch (1998) and
Rieke et al. (1997). For a discussion of the variability of interspike intervals see the debate
of Shadlen and Newsome (1994), Softky (1995), and Bair and Koch (1996); these papers
also give a critical discussion of the concept of temporal averaging. An accessible mathe-
matical treatment of the inhomogeneous Poisson model in the context of neuronal signals
is given in Rieke et al. (1997). The same book can also be recommended for its excellent
discussion of rate codes, and their limits, as well as the method of stimulus reconstruction
(Rieke et al., 1997).
Exercises
1. Poisson process in discrete and continuous time. We consider a Poisson neuron model in dis-
crete time. In every small time interval Δt, the probability that the neuron ﬁres is given by ν Δt.
Firing in different time intervals is independent. The limit Δt →0 will be taken only at the end.
(a) What is the probability that the neuron does not ﬁre during a time of arbitrarily large length
t = N Δt?
Hint: Consider ﬁrst the probability of not ﬁring during a single short interval Δt, and then extend
your reasoning to N time steps.
(b) Suppose that the neuron has ﬁred at time t = 0. Calculate the distribution of intervals P(t),
i.e., the probability density that the neuron ﬁres its next spike at a time t = N Δt.
(c) Start from your results in (a) and (b) and take the limit N →∞, Δt →0, while keeping t ﬁxed.
What is the resulting survivor function S0(t) and the interval distribution P0(s) in continuous
time?
(d) Suppose that the neuron is driven by some input. For t < t0 , the input is weak, so that its
ﬁring rate is ν = 2 Hz. For t0 < t < t1 = t0 + 100 ms, the input is strong and the neuron ﬁres
at ν = 20 Hz. Unfortunately, however, the onset time t0 of the strong input is unknown; can an
observer, who is looking at the neurons output, detect the period of strong input? How reliably?
Hint: Calculate the interval distributions for weak and strong stimuli. What is the probability of
having a burst consisting of two intervals of less than 20 ms each if the input is weak/strong?
2. Autocorrelation of a Poisson process in discrete time. The autocorrelation
Cii(s) = ⟨Si(t)Si(t +s)⟩t
(7.58)
is deﬁned as the joint probability density of ﬁnding a spike at time t and a spike at time t +s. In
Eq. (7.46) we have stated the autocorrelation of the homogeneous Poisson process in continuous
time. Derive this result by starting with a Poisson process in discrete time where the probability
of ﬁring in a small time interval Δt is given by ν Δt. To do so, take the following steps:
(a) What is the joint probability of ﬁnding a spike in the bin [t,t +Δt] AND in the bin [t′,t′ +Δt]
where t ̸= t′?
(b) What is the joint probability of ﬁnding a spike in the bin [t,t +Δt] AND in the bin [t′,t′ +Δt]
where t = t′?
(c) What is the probability of ﬁnding two spikes in the bin [t,t + Δt]? Why can this term be
neglected in the limit Δt →0?
(d) Take the limit Δt →0 while keeping t and t′ ﬁxed so as to ﬁnd the autocorrelation function
C0(s) in continuous time.
3. Repeatability and random coincidences. Suppose that a Poisson neuron with a constant rate
of 20 Hz emits, in a trial of 5-second duration, 100 spikes at times t(1);t(2);...t(100). Afterward,
the experiment is repeated and a second spike train with a duration of 5 seconds is observed.
How many spikes in the ﬁrst trial can be expected to coincide with a spike in the second trial?
More generally, what percentage of spikes coincide between two trials of a Poisson neuron with
arbitrary rate ν0 under the assumption that trials are sufﬁciently long?

7.7 Summary
201
4. Spike count and Fano factor. A homogeneous Poisson process has a probability to ﬁre in a very
small interval Δt equal to ν Δt.
(a) Show that the probability of observing exactly k spikes in the time interval T = N Δt is Pk(T) =
[1/k!](ν T)k exp(−ν T).
Hint: Start in discrete time and write the probability of observing k events in N slots using the
binomial distribution: P(k;N) = [N!/k!(N −k)!] pk (1−p)N−k where p is the probability of ﬁring
in a time bin of duration Δt. Take the continuous time limit with Stirling's formula N! ≈(N/e)N.
(b) Repeat the above argument for an inhomogeneous Poisson process.
(c) Show for the inhomogeneous Poisson process that the mean spike count in an interval of
duration T is ⟨k⟩=
 T
0 ν(t)dt.
(d) Calculate the variance of the spike count and the Fano factor for the inhomogeneous Poisson
process.
5. From interval distribution to hazard. During stimulation with a stationary stimulus, interspike
intervals in a long spike train are found to be independent and given by the distribution
P(t|t′) = (t −t′)
τ2
exp

−t −t′
τ

(7.59)
for t > t′.
(a) Calculate the survivor function S(t|t′), i.e., the probability that the neuron survives from time
t′ to t without ﬁring.
Hint: You can use
 y
0 xeaxdx = eay[ay−1]/a2.
(b) Calculate the hazard function ρ(t|t′), i.e., the stochastic intensity that the neuron ﬁres, given
that its last spike was at t′ and interpret the result: what are the signs of refractoriness?
(c) A spike train starts at time 0 and we have observed a ﬁrst spike at time t1. We are interested
in the probability that the nth spike occurs around time tn = t1 + s. With this deﬁnition of spike
labels, calculate the probability density P(t3|t1) that the third spike occurs around time t3.
6. Gamma distribution. Stationary interval distributions can often be ﬁtted by a Gamma distribu-
tion (for s > 0)
P(s) =
1
(k −1)!
sk−1
τk e−s/τ,
(7.60)
where k is a positive natural number. We consider in the following k = 1.
(a) Calculate the mean interval ⟨s⟩and the mean ﬁring rate.
(b) Assume that intervals are independent and calculate the power spectrum.
Hint: Use Eq. (7.45).
7. CV value of Gamma distribution. Stationary interval distributions can often be ﬁtted by a
Gamma distribution
P(s) =
1
(k −1)!
sk−1
τk e−s/τ,
(7.61)
where k is a positive natural number.
Calculate the coefﬁcient of variation CV for k = 1,2,3. Interpret your result.
8. Poisson with dead time as a renewal process. Consider a process where spikes are generated
with rate ρ0, but after each spike there is a dead time of duration Δabs. More precisely, we have a
renewal process
ρ(t|ˆt) = ρ0
fort > ˆt +Δabs,
(7.62)
and zero otherwise.
(a) Calculate the interval distribution, using Eqs. ((7.26)) and ((7.27)).
(b) Calculate the Fano factor.
(c) If a ﬁrst spike occurred at time t = 0, what is the probability that a further spike (there could
be other spikes in between) occurs at t = xΔabs where x = 0.5,1.5,2.5.

8
Noisy input models: barrage of spike arrivals
Neurons in the brain receive input from thousands of other, presynaptic neurons, which
emit action potentials and send their spikes to their postsynaptic targets. From the perspec-
tive of a postsynaptic neuron receiving a barrage of spikes, spike arrival times may look
completely random, even under the assumption that presynaptic neurons generate their
spikes by a deterministic process. Indeed, as we have seen in the preceding chapter, inter-
nal noise sources of a cell, such as spontaneous opening of ion channels, do not account for
all the variability of spike-trains encountered in freely behaving animals in vivo. Rather, it
is likely that a large fraction of the apparent variability is generated by the network. Mod-
eling studies conﬁrm that networks with ﬁxed random connectivity can lead to chaos on
the microscopic level, so that spike arrival times appear to be random even if generated by
a deterministic network.
In this chapter, we discuss the consequences of stochastic spike arrivals for modeling.
The "noise" generated by the network is often described by a noise term in the differential
equation of the membrane voltage (Section 8.1). Such a noise term, typically modeled as
white noise or colored noise, can be derived in a framework of stochastic spike arrival,
as shown in Section 8.2. Stochastic spike arrival leads to ﬂuctuations of the membrane
potential which will be discussed in the case of a passive membrane (Section 8.2.1) - or,
more generally, for neuron models in the subthreshold regime. In Section 8.3 we discuss
the differences between subthreshold and superthreshold stimulation and explain its con-
sequences for spike-train variability. We close the discussion of stochastic spike arrival
models in Section 8.4 with a more mathematically oriented exposition of the diffusion
limit and the Fokker-Planck equation.
8.1 Noise input
Neurons are driven by an input current I(t) which summarizes the effect of synaptic input
from other neurons in the network in vivo or the current injected by an experimenter into a
cell in vitro. Modeling the noisiness of the input amounts to splitting the input current into
two components, a deterministic and a stochastic one
I(t) = Idet(t)+Inoise(t),
(8.1)

8.1 Noise input
203
(a)
(b)
Fig. 8.1 Noisy input. (a). A Hodgkin-Huxley model with parameters as in Chapter 2 driven with
white-noise input. (b). The same model driven with colored noise with time constant τs = 50 ms.
Note that the ﬂuctuations of the membrane potential are slower.
where the deterministic term Idet summarizes the part of the current which is known, or at
least predictable, while the stochastic term Inoise is the unpredictable, or noisy, part of the
current.
For example, during an in vitro study with intracellular current injection, Idet would be
the current that is set on the switchboard of the current generator, but the actual current
ﬂuctuates around the preset value because of ﬁnite temperature. In a neural recording dur-
ing a visual psychophysics experiment in vivo, the part of the input current that does not
change across trials with the same visual stimulus would be summarized as Idet, while all
the remaining inputs to the neuron, which vary from one trial to the next, are treated as
noise and summarized as Inoise.
For modeling, the noise term is simply added on the right-hand side of the differential
equation of the voltage. For example, a nonlinear integrate-and-ﬁre model with noisy input
has the voltage equation
τm
d
dt u = f(u)+RIdet(t)+RInoise(t).
(8.2)
If u reaches the threshold θreset, the integration is stopped and the membrane potential reset
to ur. The procedure of adding input noise is completely analogous for biophysical models
of the Hodgkin-Huxley type or integrate-and-ﬁre models with adaptation; see Fig. 8.1.
8.1.1 White noise
The standard procedure of implementing the noise term RInoise in the differential equation
of the membrane voltage is to formulate it as a "white noise," RInoise(t) = ξ(t). White
noise ξ is a stochastic process characterized by its expectation value,
⟨ξ(t)⟩= 0,
(8.3)

204
Noisy input models: barrage of spike arrivals
and the autocorrelation
⟨ξ(t)ξ(t′)⟩= σ2 τm δ(t −t′),
(8.4)
where σ is the amplitude of the noise (in units of voltage) and τm the time constant of the
differential equation (8.2). Eq. (8.4) indicates that the process ξ is uncorrelated in time:
knowledge of the value ξ at time t does not enable us to predict its value at any other
time t′ ̸= t. The Fourier transform of the autocorrelation function (8.4) yields the power
spectrum; see Section 7.4. The power spectrum of white noise is ﬂat, i.e., the noise is
equally strong at all frequencies.
If the white noise term is added on the right-hand side of (8.2), we arrive at a stochastic
differential equation, i.e., an equation for a stochastic process,
τm
d
dt u(t) = f(u(t))+RIdet(t)+ξ(t),
(8.5)
also called Langevin equation. In Section 8.2 we will indicate how the noise term ξ(t) can
be derived from a model of stochastic spike arrival.
In the mathematical literature, instead of a "noise term" ξ(t), a different style of writing
the Langevin equation dominates. To arrive at this alternative formulation we ﬁrst divide
both sides of Eq. (8.5) by τm and then multiply by the short time step dt,
du = f(u) dt
τm
+RIdet(t) dt
τm
+σdWt,
(8.6)
where dWt are the increments of the Wiener process in a short time dt, i.e., dWt are random
variables drawn from a Gaussian distribution with zero mean and variance proportional to
the step size dt. This formulation therefore has the advantage that it can be directly used
for simulations of the model in discrete time. White noise which is Gaussian distributed
is called Gaussian white noise. Note for a numerical implementation of Eq. (8.6) that it is
the variance of the Gaussian which is proportional to the step size; therefore its standard
deviation is proportional to
√
dt.
Example: Leaky integrate-and-ﬁre model with white noise input
In the case of the leaky integrate-and-ﬁre model (with voltage scale chosen such that
the resting potential is at zero), the stochastic differential equation is
τm
d
dt u(t) = −u(t)+RIdet(t)+ξ(t),
(8.7)
which is called the Ornstein-Uhlenbeck process (Uhlenbeck and Ornstein, 1930; van
Kampen, 1992).
We note that the white noise term on the right-hand side is integrated by a time con-
stant τm to yield the membrane potential. Therefore ﬂuctuations of the membrane poten-
tial have an autocorrelation with characteristic time τm. We will refer to Eq. (8.7) as the
Langevin equation of the noisy integrate-and-ﬁre model.

8.1 Noise input
205
J
t^
t
Fig. 8.2 Noisy integration. A stochastic contribution in the input current of an integrate-and-ﬁre
neuron causes the membrane potential to drift away from the reference trajectory (thick solid line).
The neuron ﬁres if the noisy trajectory (thin line) hits the threshold ϑ.
A realization of a trajectory of the noisy integrate-and-ﬁre model deﬁned by Eq. (8.7)
is implemented in discrete time by the iterative update
du = (−u+RIdet) dt
τm
+σ
√
dt y,
(8.8)
where y is a random number drawn from a zero-mean Gaussian distribution of unit
variance (i.e., dW =
√
dt y has variance proportional to dt). Note that for small step size
dt and ﬁnite current amplitude Idet, the voltage steps du are small as well so that, despite
the noise, the trajectory becomes smooth in the limit of dt →0.
A noisy integrate-and-ﬁre neuron is said to ﬁre an action potential whenever the mem-
brane potential u updated via (8.8) reaches the threshold ϑ; see Fig. 8.2. The analysis
of Eq. (8.7) in the presence of the threshold ϑ is one of the major topics of this chap-
ter. Before turning to the problem with threshold, we determine now the amplitude of
membrane potential ﬂuctuations in the absence of a threshold.
8.1.2 Noisy versus noiseless membrane potential
The Langevin equation of the leaky integrate-and-ﬁre model with white noise input is
particularly suitable to compare the membrane potential trajectory of a noisy neuron model
with that of a noiseless one.
Let us consider Eq. (8.7) for constant σ. At t = ˆt the membrane potential starts at a value
u = ur = 0. Since (8.7) is a linear equation, its solution for t > ˆt is
u(t) = R
τm
 t−ˆt
0
e−s/τm I(det)(t −s)ds + 1
τm
 t−ˆt
0
e−s/τm ξ(t −s)ds.
(8.9)
Since ⟨ξ(t)⟩= 0, the expected trajectory of the membrane potential is
u0(t) = ⟨u(t|ˆt)⟩= R
τm
 t−ˆt
0
e−s/τm I(det)(t −s)ds.
(8.10)

206
Noisy input models: barrage of spike arrivals
In particular, for constant input current I(det)(t) ≡I0 we have
u0(t) = u∞

1−e−(t−ˆt)/τm

(8.11)
with u∞= RI0. Note that, in the absence of a threshold, the expected trajectory is that of
the noiseless model.
The ﬂuctuations of the membrane potential have variance ⟨Δu2⟩= ⟨[u(t|ˆt) −u0(t)]2⟩
with u0(t) given by Eq. (8.10). The variance can be evaluated with the help of Eq. (8.9),
i.e.,
⟨Δu2(t)⟩= 1
τ2m
 t−ˆt
0
ds
 t−ˆt
0
ds′ e−s/τm e−s′/τm⟨ξ(t −s)ξ(t −s′)⟩.
(8.12)
We use ⟨ξ(t −s)ξ(t −s′)⟩= σ2 τm δ(s−s′) and perform the integration. The result is
⟨Δu2(t)⟩= 1
2 σ2 
1−e−2(t−ˆt)/τm

.
(8.13)
Hence, noise causes the actual membrane trajectory to drift away from the noiseless ref-
erence trajectory u0(t). If the threshold is high enough so that ﬁring is a rare event, the
typical distance between the actual trajectory and the mean trajectory approaches with
time constant τm/2 a limiting value

⟨Δu2∞⟩= 1
√
2
σ.
(8.14)
In proximity to the ﬁring threshold the above arguments break down; however, in the
subthreshold regime the mean and the variance of the membrane potential are well approx-
imated by formulas (8.11) and (8.13), respectively. The mean trajectory and the standard
deviation of the ﬂuctuations can also be estimated in simulations, as shown in Fig. 8.3 for
the leaky and the exponential integrate-and-ﬁre models.
8.1.3 Colored noise
A noise term with a power spectrum which is not ﬂat is called colored noise. Colored noise
Inoise(t) can be generated from white noise by suitable ﬁltering. For example, low-pass
ﬁltering
τs
dInoise(t)
dt
= −Inoise(t)+ξ(t),
(8.15)
where ξ(t) is the white noise process deﬁned above, yields colored noise with reduced
power at frequencies above 1/τs. Eq. (8.15) is another example of an Ornstein-Uhlenbeck
process.
To calculate the power spectrum of the colored noise deﬁned in Eq. (8.15), we proceed
in two steps. First we integrate (8.15) so as to arrive at
Inoise(t) =
 ∞
0 κ(s)ξ(t −s)ds,
(8.16)

8.2 Stochastic spike arrival
207
(a)
(b)
Fig. 8.3 Mean trajectory and ﬂuctuations for (a) the leaky integrate-and-ﬁre model and (b) the expo-
nential integrate-and-ﬁre model driven by white noise superimposed on a constant input that drives
the neuron half-way between resting potential and ﬁring threshold. Integration starts at u = ur and is
repeated for 15 trials (gray lines). The solid line indicates mean trajectories and dashed lines indicate
one standard deviation around the mean. Both models have a time constant of 10 ms. The threshold is
at 1 for the leaky integrate-and-ﬁre neuron (a) and at −50 mV for the exponential integrate-and-ﬁre
neuron (b). The numerical threshold is set at θreset = −30 mV.
where κ(s) is an exponential low-pass ﬁlter with time constant τs. The autocorrelation
function is therefore
⟨Inoise(t)Inoise(t′)⟩=
 ∞
0
 ∞
0 κ(s)κ(s′)⟨ξ(t −s)ξ(t′ −s′)⟩ds′ds.
(8.17)
Second, we exploit the deﬁnition of the white noise correlation function in (8.4), and ﬁnd
⟨Inoise(t)Inoise(t′)⟩= a exp

−|t −t′|
τs

(8.18)
with an amplitude factor a. Therefore, knowledge of the input current at time t gives us a
hint about the input current shortly afterward, as long as |t′ −t| ≪τs.
The noise spectrum is the Fourier transform of (8.18). It is ﬂat for frequencies ω ≪1/τs
and falls off for ω > 1/τs. Sometimes 1/τs is called the cut-off frequency.
The colored noise deﬁned in (8.15) is a suitable noise model for synaptic input, if spikes
arrive stochastically and synapses have a ﬁnite time constant τs. The relation of input noise
to stochastic spike arrival is the topic of the next section.
8.2 Stochastic spike arrival
A typical neuron, for example, a pyramidal cell in the vertebrate cortex, receives input
spikes from thousands of other neurons, which in turn receive input from their presynaptic
neurons and so forth; see Fig. 8.4. While it is not impossible to incorporate millions of
integrate-and-ﬁre neurons into a huge network model, it is often reasonable to focus the
modeling efforts on a speciﬁc subset of neurons, for example, a column in the visual cortex,
and describe input from other parts of the brain as a stochastic background activity.

208
Noisy input models: barrage of spike arrivals
Fig. 8.4 Each neuron receives input spikes from a large number of presynaptic neurons. Only a
small portion of the input comes from neurons within the model network; other input is described as
stochastic spike arrival.
Let us consider a nonlinear integrate-and-ﬁre neuron with index i that is part of a large
network. Its input consists of (i) an external input Iext
i
(t); (ii) input spikes t f
j from other
neurons j of the network; and (iii) stochastic spike arrival t f
k due to the background activity
in other parts of the brain. The membrane potential ui evolves according to
d
dt ui = f(ui)
τm
+ 1
CIext(t)+∑
j ∑
t f
j
wi j δ(t −t f
j ) +∑
k ∑
t f
k
wik δ(t −t f
k ),
(8.19)
where δ is the Dirac δ-function and wi j is the coupling strength from a presynaptic neuron
j in the network to neuron i. Input from background neurons is weighted by the factor wik.
While the ﬁring times t f
j are generated by the threshold crossings of presynaptic integrate-
and-ﬁre neurons, the ﬁring times t f
k of a background neuron k are generated by a Poisson
process with mean rate νk.
To simplify the following discussions we adopt three simpliﬁcations. First, we focus on
a leaky integrate-and-ﬁre neuron and shift the voltage so that the resting potential is at
zero. Hence we can set f(u) = −u. Second, we concentrate on a single neuron receiving
stochastic input from background neurons. Hence we can drop the sum over j which repre-
sents input from the network and also drop the index i of our speciﬁc neuron. We therefore
arrive at
d
dt u = −u
τm
+ 1
CIext(t)+∑
k ∑
t f
k
wk δ(t −t f
k ).
(8.20)
The membrane potential is reset to ur whenever it reaches the threshold ϑ. Eq. (8.20) is
called Stein's model (Stein, 1965, 1967b).
In Stein's model, each input spike generates a postsynaptic potential Δu(t) = wkε(t −t( f)
k )
with ε(s) = e−s/τm Θ(s), i.e., the potential jumps upon spike arrival by an amount wk and
decays exponentially thereafter. Integration of Eq. (8.20) yields
u(t|ˆt) = ur exp

−t −ˆt
τm

+ 1
C
 t−ˆt
0
exp

−s
τm

I(t −s)ds+
N
∑
k=1∑
t f
k
wkε(t −t f
k )
(8.21)

8.2 Stochastic spike arrival
209
for t > ˆt where ˆt is the last ﬁring time of the neuron. It is straightforward to generalize
the model so as to include a synaptic time constant and work with arbitrary postsynaptic
potentials ε(s) that are generated by stochastic spike arrival; see Fig. 8.5a.
8.2.1 Membrane potential ﬂuctuations caused by spike arrivals
To calculate the ﬂuctuations of the membrane potential caused by stochastic spike arrival,
we assume that the ﬁring threshold is relatively high and the input weak so that the neuron
does not reach its ﬁring threshold. Hence, we can safely neglect both threshold and reset.
The leaky integrate-and-ﬁre model of Stein (Eq. (8.21)) is then equivalent to a model of a
passive membrane driven by stochastic spike arrival.
We assume that each input spike evokes a postsynaptic potential w0 ε(s) of the same
amplitude and shape, independent of k. The input statistics is assumed to be Poisson, i.e.,
ﬁring times are independent. Thus, the total input spike train (summed across all synapses)
S(t) =
N
∑
k=1∑
t f
k
δ(t −t f
k )
(8.22)
that arrives at neuron i is a random process with expectation
⟨S(t)⟩= ν0
(8.23)
and autocorrelation
⟨S(t)S(t′)⟩−ν2
0 = ν0 δ(t −t′);
(8.24)
see Eq. (7.46).
Suppose that we start the integration of the passive membrane equation at t = −∞with
initial condition ur = 0. We rewrite Eq. (8.21) using the deﬁnition of the spike train in Eq.
(8.22)
u(t) = 1
C
 ∞
0 exp

−s
τm

I(t −s)ds+w0
 ∞
0 ε(s)S(t −s)ds.
(8.25)
Obviously, the integration over the δ-function in the last term on the right-hand side is
possible and would lead back to the more compact representation w0 ∑t f
k ε(t −t f
k ). The
advantage of having the spike train S(t) appear explicitly is that we can exploit the deﬁni-
tion of the random process S, in particular, its mean and variance.
We are interested in the mean potential u0(t) = ⟨u(t)⟩and the variance ⟨Δu2⟩= ⟨[u(t)−
u0(t)]2⟩. Using Eqs. (8.23) and (8.24) we ﬁnd
u0(t) = 1
C
 ∞
0 exp

−s
τm

I(t −s)ds+w0 ν0
 ∞
0 ε(s)ds
(8.26)

210
Noisy input models: barrage of spike arrivals
0
t [ms]
0.0
0.2
0.4
u
10
20
(a)
0
200
400
600
t [ms]
0.0
0.2
0.4
0.6
0.8
u
(b)
Fig. 8.5 Input spikes arrive stochastically (upper panel) at a mean rate of 1 kHz. (a). Each input
spike evokes an excitatory postsynaptic potential (EPSP) ε(s) ∝sexp(−s/τ) with τ = 4ms. The
ﬁrst EPSP (the one generated by the spike at t = 0) is plotted. The EPSPs of all spikes sum up and
result in a ﬂuctuating membrane potential u(t). (b). Continuation of the simulation shown in (a).
The horizontal lines indicate the mean (solid line) and the standard deviation (dashed lines) of the
membrane potential.
and
⟨Δu2⟩= w2
0
 ∞
0
 ∞
0 ε0(s)ε0(s′) ⟨S(t)S(t′)⟩dsds′ −u2
0
= w2
0 ν0
 ∞
0 ε2(s)ds.
(8.27)
In Fig. 8.5 we have simulated a neuron which receives input from N = 100 background
neurons with rate ν0 = 10 Hz. The total spike arrival rate is therefore ν0 = 1 kHz. Each
spike evokes an EPSP w0 ε(s) = 0.1(s/τ) exp(−s/τ) with τ = 4 ms. The evaluation of
Eqs. (8.26) and (8.27) for constant input I = 0 yields u0 = 0.4 and

⟨Δu2⟩= 0.1.
Example: Stein's model with step current input
In Stein's model each background spike evokes an EPSP ε(s) = e−s/τm. In addition,
we assume a step current input which switches at t = 0 from zero to I0 (I0 < 0).
Mean and ﬂuctuations for Stein's model can be derived by evaluation of Eqs. (8.26)
and (8.27) with ε(s) = e−s/τm. The result is
u0 = I0 [1−exp(−t/τm)]+w0 ν0 τm,
(8.28)
⟨Δu2⟩= 0.5w2
0 ν0 τm.
(8.29)
Note that with stochastic spike arrival at excitatory synapses, as considered here, mean
and variance cannot be changed independently. As we shall see in the next subsection, a

8.2 Stochastic spike arrival
211
0
50
100
150
200
t [ms]
0.0
1.0
2.0
u
(a)
0
50
100
150
200
t [ms]
0.0
1.0
2.0
u
(b)
Fig. 8.6 (a). Voltage trajectory of an integrate-and-ﬁre neuron (τm = 10ms, ur = 0) driven by
stochastic excitatory and inhibitory spike input at ν+ = ν−= 1 kHz. Each input spike causes a
jump of the membrane potential by w± = ±0.1. The neuron is biased by a constant current I0 = 0.8
which drives the membrane potential to a value just below the threshold of ϑ = 1 (horizontal line).
Spikes are marked by vertical lines. (b). Similar plot as in (a) except that the jumps are smaller
(w± = ±0.025) while rates are higher (ν± = 16kHz).
combination of excitation and inhibition allows us to increase the variance while keeping
the mean of the potential ﬁxed.
8.2.2 Balanced excitation and inhibition
Let us suppose that an integrate-and-ﬁre neuron deﬁned by Eq. (8.20) with τm = 10 ms
receives input from 100 excitatory neurons (wk = +0.1) and 100 inhibitory neurons
(wk = −0.1). Each background neuron k ﬁres at a rate of νk = 10 Hz. Thus, in each mil-
lisecond, the neuron receives on average one excitatory and one inhibitory input spike.
Each spike leads to a jump of the membrane potential of ±0.1. The trajectory of the mem-
brane potential is therefore similar to that of a random walk subject to a return force caused
by the leak term that drives the membrane potential always back to zero; see Fig. 8.6a.
If, in addition, a constant stimulus Iext = I0 > 0 is applied so that the mean membrane
potential (in the absence of the background spikes) is just below threshold, then the pres-
ence of random background spikes may drive u toward the ﬁring threshold. Whenever
u ≥ϑ, the membrane potential is reset to ur = 0.
Since ﬁring is driven by the ﬂuctuations of the membrane potential, the interspike inter-
vals vary considerably; see Fig. 8.6. Balanced excitatory and inhibitory spike input could
thus contribute to the large variability of interspike intervals in cortical neurons; see Sec-
tion 8.3.
With the above set of parameters, the mean of the stochastic background input vanishes
since ∑k wk νk = 0. Using the same arguments as in the previous example, we can con-
vince ourselves that the stochastic arrival of background spikes generates ﬂuctuations of

212
Noisy input models: barrage of spike arrivals
the voltage with variance
⟨Δu2⟩= 0.5τm∑
k
w2
k νk = 0.1;
(8.30)
see Section 8.4 for a different derivation.
Let us now increase all rates by a factor of a > 1 and at the same time multiply the synap-
tic efﬁcacies by a factor 1/√a. Then both mean and variance of the stochastic background
input are the same as before, but the size wk of the jumps is decreased; see Fig. 8.6b. In the
limit a →∞the jump process turns into a diffusion process and we arrive at the stochastic
model of Eq. (8.7). In other words, the balanced action of the excitatory and inhibitory
spike trains, Sexc and Sinh respectively, arriving at the synapses with Poisson input rate
⟨Sexc⟩= ⟨Sinh⟩= aν yields in the limit a →∞a white noise input
w
√aSexc −w
√aSinh −→ξ(t).
(8.31)
The above transition is called the diffusion limit and will be systematically discussed in
Section 8.4. Intuitively, the limit process implies that in each short time interval Δt a large
number of excitatory and inhibitory input spikes arrive, each one causing the membrane
potential to jump by a tiny amount upward or downward.
Example: Synaptic time constants and colored noise
In contrast to the previous discussion of balanced input, we now assume that each
spike arrival generated a current pulse α(s) of ﬁnite duration so that the total synaptic
input current is
RI(t) = wexc
 ∞
0 α(s)Sexc(t −s)ds−winh
 ∞
0 α(s)Sinh(t −s)ds.
(8.32)
If the spike arrival is Poisson with rates ⟨Sexc⟩= ⟨Sinh⟩= aν and the synaptic weights
are wexc = winh = w/√a, then we can take the limit a →∞with no change of mean or
variance. The result is colored noise.
An instructive case is α(s) = (1/τs)exp(−s/τs)Θ(s) with synaptic time constant τs.
In the limit τs →0 we are back to white noise.
8.3 Subthreshold vs. superthreshold regime
One of the aims of noisy neuron models is to mimic the large variability of interspike
intervals found, for example, in vertebrate cortex. To arrive at broad interval distributions,
it is not just sufﬁcient to introduce noise into a neuron model. Apart from the noise level,
other neuronal parameters such as the ﬁring threshold or a bias current have to be tuned so
as to make the neuron sensitive to noise. In this section we introduce a distinction between
super- and subthreshold stimulation (Abeles, 1991; Shadlen and Newsome, 1994; K¨onig
et al., 1996; Troyer and Miller, 1997; Bugmann et al., 1997).

8.3 Subthreshold vs. superthreshold regime
213
An arbitrary time-dependent stimulus I(t) is called subthreshold if it generates a mem-
brane potential that stays - in the absence of noise - below the ﬁring threshold. Owing to
noise, however, even subthreshold stimuli can induce action potentials. Stimuli that induce
spikes even in a noise-free neuron are called superthreshold.
The distinction between sub- and superthreshold stimuli has important consequences for
the ﬁring behavior of neurons in the presence of noise. To see why, let us consider a leaky
integrate-and-ﬁre neuron with constant input I0 for t > 0. Starting from u(t = 0) = ur, the
trajectory of the membrane potential is
u0(t) = u∞

1−e−t/τm

+ur e−t/τm .
(8.33)
In the absence of a threshold, the membrane potential approaches the value u∞= RI0 for
t →∞. If we take the threshold ϑ into account, two cases may be distinguished. First,
if u∞< ϑ (subthreshold stimulation), the neuron does not ﬁre at all. Second, if u∞> ϑ
(superthreshold stimulation), the neuron ﬁres regularly. The interspike interval is s0 derived
from u0(s0) = ϑ. Thus
s0 = τ lnu∞−ur
u∞−ϑ .
(8.34)
We now add diffusive noise. In the superthreshold regime, noise has little inﬂuence,
except that it broadens the interspike interval distribution. Thus, in the superthreshold
regime, the spike train in the presence of diffusive noise is simply a noisy version of the
regular spike train of the noise-free neuron.
On the other hand, in the subthreshold regime, the spike train changes qualitatively if
noise is switched on; see K¨onig et al. (1996) for a review. Stochastic background input
turns the quiescent neuron into a spiking one. In the subthreshold regime, spikes are gener-
ated by the ﬂuctuations of the membrane potential, rather than by its mean (Abeles, 1991;
Shadlen and Newsome, 1994; Troyer and Miller, 1997; Bugmann et al., 1997; Feng, 2001).
The interspike interval distribution is therefore broad; see Fig. 8.7.
Example: Interval distribution in the superthreshold regime
For small noise amplitude 0 < σ ≪u∞−ϑ, and superthreshold stimulation, the inter-
val distribution is centered at the deterministic interspike interval s0. Its width can be
estimated from the width of the ﬂuctuations ⟨Δu2
∞⟩of the free membrane potential;
see Eq. (8.13). After the reset, the variance of the distribution of membrane potentials is
zero and increases slowly thereafter. As long as the mean trajectory is far away from the
threshold, the distribution of membrane potentials has a Gaussian shape.
As time goes on, the distribution of membrane potentials is pushed across the thresh-
old. Since the membrane potential crosses the threshold with slope u′
0, there is a scaling
factor u′
0 = du0(t)/dt evaluated at t = s0 between the (approximately) Gaussian distri-
bution of membrane potential and the interval distribution; see Fig. 8.8. The interval

214
Noisy input models: barrage of spike arrivals
0
50
100
150
200
t [ms]
0.0
1.0
2.0
u
(a)
0
50
100
150
200
t [ms]
0.0
1.0
2.0
u
(b)
0
50
100
150
200
t [ms]
0.0
1.0
2.0
u
(c)
0
50
100
150
200
t [ms]
0.0
1.0
2.0
u
(d)
0
50
100
150
200
s [ms]
0.0
0.1
P0(s)
(e)
0
50
100
150
200
s [ms]
0.0
0.1
P0(s)
(f)
Fig. 8.7 Integrate-and-ﬁre neuron (τm = 10ms) with superthreshold (left column) and subthresh-
old (right column) stimulation. (a). Without noise, a neuron with superthreshold stimulus Ia ﬁres
regularly. Spikes are marked by vertical lines. The threshold is indicated by a horizontal line. The
dashed line shows the evolution of the membrane potential in the absence of the threshold. (b). The
same neuron with subthreshold stimulation Ib does not ﬁre. (c). If we add stochastic excitatory and
inhibitory spike input (w± = 0.05 at ν± = 1.6 kHz) to the constant input Ia, the membrane potential
drifts away from the noise-free reference trajectory, but ﬁring remains fairly regular. (d). The same
sequence of input spikes added to the subthreshold current Ib generates irregular spiking. (e) and (f)
Histogram of interspike intervals in (c) and (d), respectively, as an estimator of the interval distribu-
tion P0(s) in the super- and subthreshold regime. The mean interval ⟨s⟩is 12 ms (e) and 50 ms (f);
the CV values are 0.30 and 0.63, respectively.

8.4 Diffusion limit and Fokker-Planck equation (*)
215
u0(t )
P (t|0)
0
u
J
t
0
p(u,t )
Fig. 8.8 Interval distribution P0(t|0) for superthreshold stimuli. The membrane potential distribution
p(u,t) is shifted across the threshold and generates an interval distribution P0(t|0) (schematic ﬁgure).
distribution is therefore also approximately given by a Gaussian with mean s0 and width
σ/
√
2u′
0 (Tuckwell, 1988), i.e.,
P0(t|0) =
1
√π
u′
0
σ exp

−(u′
0)2 (t −s0)2
σ2

.
(8.35)
8.4 Diffusion limit and Fokker-Planck equation (*)
In this section we analyze the model of stochastic spike arrival deﬁned in Eq. (8.20) and
show how to map it to the diffusion model deﬁned in Eq. (8.7) (Gluss, 1967; Johannesma,
1968; Capocelli and Ricciardi, 1971). Suppose that the neuron has ﬁred its last spike at
time ˆt. Immediately after the ﬁring the membrane potential was reset to ur. Because of
the stochastic spike arrival, we cannot predict the membrane potential for t > ˆt, but we
can calculate its probability density, p(u,t). The evolution of the probability density as
a function of time is described, in the diffusion limit, by the Fokker-Planck equation
which we derive here in the context of a single neuron subject to noisy input. In Part III
(Section 13.1.1) the Fokker-Planck equation will be introduced systematically in the
context of populations of neurons.
For the sake of simplicity, we set for the time being Iext = 0 in Eq. (8.20). The input
spikes at synapse k are generated by a Poisson process and arrive stochastically with rate
νk(t). The probability that no spike arrives in a short time interval Δt is therefore
Prob

no spike in [t,t +Δt]

= 1−∑
k
νk(t)Δt .
(8.36)
If no spike arrives in [t,t + Δt], the membrane potential changes from u(t) = u′ to u(t +
Δt) = u′ exp(−Δt/τm). On the other hand, if a spike arrives at synapse k, the membrane

216
Noisy input models: barrage of spike arrivals
potential changes from u′ to u′ exp(−Δt/τm)+wk. Given a value of u′ at time t, the prob-
ability density of ﬁnding a membrane potential u at time t +Δt is therefore given by
Ptrans(u,t +Δt|u′,t) =

1−Δt∑
k
νk(t)

δ

u−u′ e−Δt/τm
	
+Δt∑
k
νk(t)δ

u−u′ e−Δt/τm −wk
	
.
(8.37)
We will refer to Ptrans as the transition law. Since the membrane potential is given by
the differential equation (8.20) with input spikes generated by a Poisson distribution, the
evolution of the membrane potential is a Markov Process (i.e., a process without memory)
and can be described by (van Kampen, 1992)
p(u,t +Δt) =

Ptrans(u,t +Δt|u′,t) p(u′,t)du′.
(8.38)
We insert Eq. (8.37) in Eq. (8.38). To perform the integration, we have to recall the rules
for δ-functions, namely, δ(au) = a−1 δ(u). The result of the integration is
p(u,t +Δt) =

1−Δt∑
k
νk(t)

eΔt/τm p

eΔt/τm u,t
	
+Δt∑
k
νk(t)eΔt/τm p

eΔt/τm u−wk,t
	
.
(8.39)
Since Δt is assumed to be small, we expand Eq. (8.39) about Δt = 0 and ﬁnd to ﬁrst order
in Δt
p(u,t +Δt)−p(u,t)
Δt
= 1
τm
p(u,t)+ 1
τm
u ∂
∂u p(u,t)
+∑
k
νk(t) [p(u−wk,t)−p(u,t)] .
(8.40)
For Δt →0, the left-hand side of Eq. (8.40) turns into a partial derivative ∂p(u,t)/∂t.
Furthermore, if the jump amplitudes wk are small, we can expand the right-hand side of
Eq. (8.40) with respect to u about p(u,t):
τm
∂
∂t p(u,t) = −∂
∂u

−u+τm∑
k
νk(t)wk

p(u,t)
+ 1
2

τm∑
k
νk(t)w2
k

∂2
∂u2 p(u,t),
(8.41)
where we have neglected terms of order w3
k and higher. The expansion in wk is called the
Kramers-Moyal expansion. Eq. (8.41) is an example of a Fokker-Planck equation (van
Kampen, 1992), i.e., a partial differential equation that describes the temporal evolution
of a probability distribution. The right-hand side of Eq. (8.41) has a clear interpretation:
the ﬁrst term in rectangular brackets describes the systematic drift of the membrane poten-
tial due to leakage (∝−u) and mean background input (∝∑k νk(t)wk). The second term in
rectangular brackets corresponds to a "diffusion constant" and accounts for the ﬂuctuations

8.4 Diffusion limit and Fokker-Planck equation (*)
217
of the membrane potential. The Fokker-Planck equation (8.41) is equivalent to the Langevin
equation (8.7) with RI(t) = τm ∑k νk(t)wk and time-dependent noise amplitude
σ2(t) = τm ∑
k
νk(t)w2
k .
(8.42)
The speciﬁc process generated by the Langevin equation (8.7) with constant noise ampli-
tude σ is called the Ornstein-Uhlenbeck process (Uhlenbeck and Ornstein, 1930), but
Eq. (8.42) indicates that, in the context of neuroscience, the effective noise amplitude
generated by stochastic spike arrival is in general time-dependent. We will return to the
Fokker-Planck equation in Chapter 13.
For the transition from Eq. (8.40) to (8.41) we have suppressed higher-order terms in the
expansion. The missing terms are
∞
∑
n=3
(−1)n
n!
An(t) ∂n
∂un p(u,t)
(8.43)
with An = τm ∑k νk(t)wn
k. What are the conditions that these terms vanish? As in the
example of Fig. 8.6a and b, we consider a sequence of models where the size of the weights
wk decreases so that An →0 for n ≥3 while the mean ∑k νk(t)wk and the second moment
∑k νk(t)w2
k remain constant. It turns out, that, given both excitatory and inhibitory input,
it is always possible to ﬁnd an appropriate sequence of models (Lansky, 1984, 1997). For
wk →0, the diffusion limit is attained and Eq. (8.41) is exact. For excitatory input alone,
however, such a sequence of models does not exist (Plesser, 1999).
8.4.1 Threshold and ﬁring
The Fokker-Planck equation (8.41) and the Langevin equation (8.7) are equivalent descrip-
tions of drift and diffusion of the membrane potential. Neither of these describe spike ﬁring.
To turn the Langevin equation (8.7) into a sensible neuron model, we have to incorporate
a threshold condition. In the Fokker-Planck equation (8.41), the ﬁring threshold is incor-
porated as a boundary condition
p(ϑ,t) ≡0
for all t .
(8.44)
The boundary condition reﬂects the fact that, under a white noise model, in each short
interval Δt many excitatory and inhibitory input spikes arrive which each cause a tiny jump
of size ±δ of the membrane potential. Any ﬁnite density p(u,t) at a value ϑ −δ < u ≤ϑ
would be rapidly removed, because one of the many excitatory spikes which arrive at each
moment would push the membrane potential above threshold. The white noise limit corre-
sponds to inﬁnite spike arrival rate and jump size δ →0, as discussed above. As a conse-
quence there are, in each short interval Δt inﬁnitely many "attempts" to push the membrane
potential above threshold. Hence the density at u = ϑ must vanish. The above argument
also shows that for colored noise the density at threshold is ﬁnite, because the effective
frequency of "attempts" is limited by the cut-off frequency of the noise.

218
Noisy input models: barrage of spike arrivals
Before we continue the discussion of the diffusion model in the presence of a threshold,
let us study the solution of Eq. (8.41) without threshold.
Example: Free distribution
The solution of the Fokker-Planck equation (8.41) with initial condition p(u, ˆt) =
δ(u−ur) is a Gaussian with mean u0(t) and variance ⟨Δu2(t)⟩, i.e.,
p(u,t) =
1

2π ⟨Δu2(t)⟩
exp

−[u(t|ˆt)−u0(t)]2
2⟨Δu2(t)⟩

,
(8.45)
as can be veriﬁed by inserting Eq. (8.45) into (8.41). In particular, the stationary distri-
bution that is approached in the limit of t →∞for constant input I0 is
p(u,∞) =
1
√π
1
σ exp
[u−RI0]2
σ2

,
(8.46)
which describes a Gaussian distribution with mean u∞= RI0 and variance σ/
√
2.
8.4.2 Interval distribution for the diffusive noise model
Let us consider a leaky integrate-and-ﬁre neuron that starts at time ˆt with a membrane
potential ur and is driven for t > ˆt by a known input I(t). Because of the diffusive noise
generated by stochastic spike arrival, we cannot predict the exact value of the neuronal
membrane potential u(t) at a later time t > ˆt, only the probability that the membrane poten-
tial is in a certain interval [u0,u1]. Speciﬁcally, we have
Prob{u0 <u(t)<u1 |u(ˆt)=ur} =
 u1
u0
p(u,t)du,
(8.47)
where p(u,t) is the probability density of the membrane potential at time t. In the diffusion
limit, p(u,t) can be found by solution of the Fokker-Planck equation (8.41) with initial
condition p(u, ˆt) = δ(u−ur) and boundary condition p(ϑ,t) = 0.
The boundary is absorbing. In other words, in a simulation of a single realizations of the
stochastic process, the simulation is stopped when the trajectory passes the threshold for the
ﬁrst time. To be concrete, imagine that we run 100 simulation trials, i.e., 100 realizations
of a leaky integrate-and-ﬁre model with diffusive noise. Each trial starts at the same value
u(ˆt) = ur and uses the same input current I(t′) for t′ > ˆt. Some of the trials will exhibit
trajectories that reach the threshold at some point t′ < t. Others stay below threshold for
the whole period ˆt < t′ < t. The expected fraction of simulations that have not yet reached
the threshold and therefore still "survive" up to time t is given by the survivor function,
SI(t|ˆt) =
 ϑ
−∞p(u,t)du.
(8.48)
In other words, the survivor function in the diffusive noise model is equal to the probability
that the membrane potential has not yet reached the threshold between ˆt and t.

8.4 Diffusion limit and Fokker-Planck equation (*)
219
J
t
^t
u
Fig. 8.9 Without a threshold, several trajectories can reach at time t the same value u = ϑ from
above or below.
In view of Eq. (7.24), the input-dependent interval distribution is therefore
PI(t|ˆt) = −d
dt
 ϑ
−∞p(u,t)du.
(8.49)
We recall that PI(t|ˆt)Δt for Δt →0 is the probability that a neuron ﬁres its next spike
between t and t +Δt given a spike at ˆt and input I. In the context of noisy integrate-and-ﬁre
neurons PI(t|ˆt) is called the distribution of "ﬁrst passage times." The name is motivated by
the fact, that ﬁring occurs when the membrane potential crosses ϑ for the ﬁrst time. Unfor-
tunately, no general solution is known for the ﬁrst passage time problem of the Ornstein-
Uhlenbeck process. For constant input I(t) = I0, however, it is at least possible to give a
moment expansion of the ﬁrst passage time distribution. In particular, the mean of the ﬁrst
passage time can be calculated in closed form.
Example: Numerical evaluation of PI(t|ˆt)
We have seen that, in the absence of a threshold, the Fokker-Planck equation (8.41)
can be solved; see Eq. (8.45). The transition probability from an arbitrary starting value
u′ at time t′ to a new value u at time t is
Ptrans(u,t|u′,t′) =
1

2π ⟨Δu2(t)⟩
exp

−[u−u0(t)]2
2⟨Δu2(t)⟩

(8.50)
with
u0(t) = u′ e−(t−t′)/τm +
 t−t′
0
e−s′/τm I(t −s′)ds,
(8.51)
⟨Δu2(t)⟩= σ2
2

1−e−2(t−s)/τm

.
(8.52)
A method due to Schr¨odinger uses the solution of the unbounded problem in order to
calculate the input-dependent interval distribution PI(t|ˆt) of the diffusion model with
threshold (Schr¨odinger, 1915; Plesser and Tanaka, 1997; Burkitt and Clark, 1999). The

220
Noisy input models: barrage of spike arrivals
0.1
0.3
PI (t|0)
0
100
200
0.5
1.0
   u  (t )
0
t[ms]
Fig. 8.10 A time-dependent input current I(t) generates a noise-free membrane potential u0(t)
shown in the lower part of the ﬁgure. In the presence of diffusive noise, spikes can be triggered
although the reference trajectory stays below the threshold (dashed line). This gives rise to an input-
dependent interval distribution PI(t|0) shown in the upper panel. Taken from Plesser and Gerstner
(2000).
idea of the solution method is illustrated in Fig. 8.9. Because of the Markov property,
the probability density of crossing the threshold (not necessarily for the ﬁrst time) at a
time t is equal to the probability of crossing it for the ﬁrst time at t′ < t and returning
back to ϑ at time t, i.e.,
Ptrans(ϑ,t|ur, ˆt) =
 t
ˆt PI(t′|ˆt)Ptrans(ϑ,t|ϑ,t′)dt′ .
(8.53)
This integral equation can be solved numerically for the distribution PI(t′|ˆt) for arbitrary
input current I(t) (Plesser, 2000). An example is shown in Fig. 8.10. The probability of
emitting a spike is high whenever the noise-free trajectory is close to the ﬁring threshold.
Very long intervals are unlikely, if the noise-free membrane potential was already several
times close to the threshold before, so that the neuron has had ample opportunity to ﬁre
earlier.
8.4.3 Mean interval and mean ﬁring rate (diffusive noise)
For constant input I0 the mean interspike interval is ⟨s⟩=
 ∞
0 sPI0(s|0)ds =
 ∞
0 sP0(s)ds;
see Eq. (7.13). For the diffusion model Eq. (8.7) with threshold ϑ, reset potential ur, and

8.5 Summary
221
−1
0
1
2
Normalized I0
0
0.1
0.2
n [kHz]
Fig. 8.11 Mean ﬁring rate of a leaky
integrate-and-ﬁre model as a function of con-
stant input evaluated for different levels of
diffusive noise, using the Siegert formula, Eq.
(8.54). From top to bottom: σ = 1.0, σ = 0.5,
σ = 0.2 (solid line), σ = 0.1, σ = 0.0.
membrane time constant τm, the mean interval is
⟨s⟩= τm
√π

ϑ−h0
σ
ur−h0
σ
du exp

u2
[1+erf(u)] ,
(8.54)
where h0 = RI0 is the input potential caused by the constant current I0 (Siegert, 1951;
Johannesma, 1968). Here "erf" denotes the error function erf(x) =
2
√π
 x
0 exp(−u2)du. This
expression, sometimes called the Siegert formula, can be derived by several methods; for
reviews see, for example, van Kampen (1992). The inverse of the mean interval is the
mean ﬁring rate. Hence, Eq. (8.54) enables us to the express the mean ﬁring rate of a
leaky integrate-and-ﬁre model with diffusive noise as a function of a (constant) input I0
(Fig. 8.11). We will derive Eq. (8.54) in Chapter 13 in the context of populations of spiking
neurons.
8.5 Summary
Each spike arrival at a synapse causes an excursion of the membrane potential of the post-
synaptic neuron. If spikes arrive stochastically the membrane potential exhibits ﬂuctua-
tions around a mean trajectory. If the ﬂuctuations stay in the subthreshold regime where
the membrane properties can be approximated by a linear equation, the mean and the stan-
dard deviation of the trajectory can be calculated analytically, given the parameters of the
stochastic process that characterize spike arrivals. In the presence of a ﬁring threshold,
the ﬂuctuations in the membrane potential caused by stochastic spike arrivals can make the
neuron ﬁre even if the mean trajectory would never reach the ﬁring threshold.
In the limit that the rate of spike arrival at excitatory and inhibitory synapses is high
while each spike causes only a small jump of the membrane potential, synaptic bombard-
ment can be approximated by the sum of two terms: a mean input current and a Gaussian
white noise input. The white noise leads to a "diffusion" of the membrane potential tra-
jectory around the mean trajectory. The evolution of the probability distribution p(u,t) of
the membrane potential over time is described by a Fokker-Planck equation. For the leaky

222
Noisy input models: barrage of spike arrivals
integrate-and-ﬁre model and stationary input, the Fokker-Planck equation can be solved
analytically. For nonlinear integrate-and-ﬁre neurons and time-dependent input numerical
solutions are possible. We will return to the Fokker-Planck equations in Chapter 13 where
further results will be derived.
Literature
Stochastic spike arrival as an important source of noise has been discussed by Stein in
the context of integrate-and-ﬁre models (Stein, 1965, 1967b). The accessible review arti-
cle of K¨onig et al. (1996) highlights how stochastic spike arrival in the input can lead
to a broad interspike interval distribution in the output of a neuron. The close relation
between stochastic spike arrival and diffusive noise has been known for a long time (Gluss,
1967; Johannesma, 1968). The leaky integrate-and-ﬁre model with diffusive noise is equiv-
alent to the Ornstein-Uhlenbeck process (Uhlenbeck and Ornstein, 1930) with an absorb-
ing boundary. Mathematical results for integrate-and-ﬁre models with diffusive noise are
reviewed in Tuckwell (1989). An in-depth treatment of the mathematical theory of stochas-
tic processes and Fokker-Planck equations can be found in van Kampen (1992).
Exercises
1. Colored noise.
(a) Calculate the noise spectrum of the colored noise deﬁned by Eq. (8.15) which we repeat
here:
τs
dInoise(t)
dt
= −Inoise(t)+ξ(t),
(8.55)
where ξ(t) is white noise with mean zero and variance
⟨ξ(t)ξ(t′)⟩= σ2 τs δ(t −t′).
(8.56)
(b) Calculate the membrane potential ﬂuctuations ⟨(Δu(t))2⟩caused by the colored noise in
Eq. (8.55), using the differential equation
τm
d
dt u(t) = −u(t)+RIdet(t)+RInoise(t).
(8.57)
(c) Show that the limit process of balanced excitatory and inhibitory input with synaptic time
constant τs leads to colored noise.
2. Autocorrelation of the membrane potential. Determine the autocorrelation ⟨u(t)u(t′)⟩of the
Langevin equation (8.7) where ξ(t) is white noise.
3. Membrane potential ﬂuctuations and balance condition. Assume that each spike arrival at an
excitatory synapse causes an EPSP with weight wexc = +w and time course εexc(t) = (t2/τ3exc)
exp(−t/τexc) for t > 0. Spike arrival at an inhibitory synapse causes an IPSP with weight −bwexc
and, for t > 0, a time course εinh(t) = (t/τ2
inh) exp(−t/τinh) where τinh > τexc and b > 1.
The membrane potential is
u(t) = wexc∑
t f
εexc(t −t f )−bwinh∑
t f
εinh(t −t f ).
(8.58)

8.5 Summary
223
Excitatory and inhibitory spike arrival are generated by Poisson processes rate νexc = ν1 and
νinh = βν1, respectively.
(a) Determine the mean membrane potential.
(b) Calculate the variance of the ﬂuctuations of the membrane potential.
(c) You want to increase the rate ν1 without changing the mean or the variance of the mem-
brane potential. Does this limit exist for all combinations of parameters b and β or do you have
to impose a speciﬁc relation b = f(β)? Interpret your result.

9
Noisy output: escape rate and soft threshold
There are various ways to introduce noise in formal spiking neuron models. In the previous
chapter we focused on input noise in the form of stochastic spike arrival. In this chapter
we assume that the input is known or can be estimated. Stochasticity arises at the level of
the neuronal spike generation, i.e., at the moment of the output. The noisy output can be
interpreted as arising from a "soft" threshold that enables an "escape" of the membrane
potential across the threshold even before the threshold is reached. Models with a noisy
threshold or escape noise are the basis of Generalized Linear Models which will be used
in Chapters 10 and 11 as a powerful statistical tool for modeling spike-train data.
In Section 9.1, the notion of escape noise is introduced. In Section 9.2 we determine
the likelihood that a speciﬁc spike train is generated by a neuron model with escape noise.
In Section 9.3 we apply the escape noise formalism to the Spike Response Model already
encountered in Chapter 6 and show an interesting link to the renewal statistics encountered
in Chapter 7. The escape rate formalism gives rise to an efﬁcient description of noise
processes, independently of their biophysical nature, be it channel noise or stochastic spike
arrival. Indeed, as shown in Section 9.4, noisy input models and noisy output models can
behave rather similarly.
9.1 Escape noise
In the escape noise model, we imagine that an integrate-and-ﬁre neuron with threshold ϑ
can ﬁre even though the formal threshold ϑ has not been reached, or may stay quiescent
even though the formal threshold has transiently been passed. To do this consistently, we
introduce an "escape rate" or "ﬁring intensity" which depends on the momentary state of
the neuron.
9.1.1 Escape rate
Given the input I(t′) for t′ < t and the past ﬁring times t f < t, the membrane potential of a
generalized integrate-and-ﬁre model (e.g., the adaptive leaky integrate-and-ﬁre model) or a
Spike Response Model (SRM) can be calculated from Eq. (6.7) or Eq. (6.27) respectively;

9.1 Escape noise
225
u
u(t)
ϑ
t
u - ϑ
ρ
t^
Fig. 9.1 Noisy threshold. A neuron can ﬁre at time t with probability density ρ(t) = f[u(t) −ϑ]
even though the membrane potential u has not yet reached the threshold ϑ. In other words, the sharp
threshold of the deterministic neuron is replaced by a "soft" threshold.
see Chapter 6. For example, the value of the membrane potential of an SRM can be
expressed as
u(t) = ∑
f
η(t −t f )+
 ∞
0 κ(s)Idet(t −s)ds+urest,
(9.1)
where Idet is the known driving current (the superscript "det" stands for deterministic) and
κ and η are ﬁlters that describe the response of the membrane to an incoming pulse or
an outgoing spike; see Chapter 6. In the deterministic model the next spike occurs when u
reaches the threshold ϑ. In order to introduce some variability into the neuronal spike gen-
erator, we replace the strict threshold by a stochastic ﬁring criterion. In the noisy threshold
model, spikes can occur at any time with a probability density
ρ(t) = f(u(t)−ϑ)
(9.2)
that depends on the momentary distance between the (noiseless) membrane potential and
the threshold; see Fig. 9.1. We can think of f as an escape rate similar to the one encoun-
tered in models of chemical reactions (van Kampen, 1992). In the mathematical theory
of point processes, the quantity ρ is called a "stochastic intensity." Since we use ρ in the
context of neuron models we will refer to it as a ﬁring intensity.
The choice of the escape function f in Eq. (9.2) is arbitrary. A reasonable condition is
to require f →0 for u →−∞so that the neuron does not ﬁre if the membrane potential is
far below threshold. A common choice is the exponential,
f(u−ϑ) = 1
τ0
exp[β (u−ϑ)],
(9.3)
where β and τ0 are parameters. For β →∞, the soft threshold turns into a sharp one so
that we return to the noiseless model. Below we discuss some further choices of the escape
function in Eq. (9.2).
The SRM of Eq. (9.1) together with the exponential escape rate of Eq. (9.3) is an
example of a Generalized Linear Model. Applying the theory of Generalized Linear Mod-

226
Noisy output: escape rate and soft threshold
Stochastic
spiking
+
Spike
afterpotential 
Nonlinearity
Moving
threshold
Spike train
η
θ
Membrane
filter
f(u-   )
κ
u
h
I(t)
S(t)
θ
1
Fig. 9.2 Flow diagram for a Spike Response Model (SRM) with escape noise. The stochasticity at the
noisy threshold is indicated by the dice; see Fig. 6.11. The noisy SRM (Gerstner and van Hemmen,
1992; Gerstner and Kistler, 2002) is an example of a Generalized Linear Model (GLM) (Truccolo
et al., 2005; Pillow et al., 2008).
els (see Chapter 10) to the SRM with escape noise enables a rapid extraction of model
parameters from experimental data.
In slice experiments it was found (Jolivet et al., 2006) that the exponential escape rate
of Eq. (9.3) provides an excellent ﬁt to the spiking intensity of real neurons (Fig. 9.3).
Moreover, the ﬁring times of an AdEx model driven by a deterministic ﬂuctuating current
Idet(t) and a unknown white noise current ξ(t) can also be well ﬁtted by the Spike Response
Model of Eq. (9.1) combined with an exponential escape rate as we shall see below in
Section 9.4.
Nevertheless, we may wonder whether Eq. (9.2) is a sufﬁciently general noise model.
We have seen in Chapter 2 that the concept of a pure voltage threshold is questionable.
More generally, the spike trigger process could, for example also depend on the slope
˙u = du/dt with which the "threshold" is approached. In the noisy threshold model, we
may therefore also consider an escape rate (or hazard) which depends not only on u but
also on its derivative ˙u
ρ(t) = f[u(t)−ϑ, ˙u(t)].
(9.4)
We will return to Eq. (9.4) in Section 9.4.
Note that the time dependence of the ﬁring intensity ρ(t) on the right-hand side of
Eq. (9.4) arises implicitly via the membrane potential u(t). In an even more general model,
we could in addition include an explicit time dependence, for example, to account for a
reduced spiking probability immediately after a spike at t f . Instead of an explicit depen-
dence, a slightly more convenient way to implement an additional time dependence is via
a time-dependent threshold ϑ −→ϑ(t) which we have already encountered in Eq. (6.31).
An even more general escape rate model therefore is
ρ(t) = f[u(t)−ϑ(t), ˙u(t)].
(9.5)
In Chapter 11 we shall see that a Spike Response Model with escape noise and dynamic
threshold can explain neuronal ﬁring with a high degree of accuracy.

9.1 Escape noise
227
(a)
Repetitions
0.4 nA
50 mV
Time [s] 
u-J  [mV]
-40
-20
0
20
Firing probability
0.2
0.4
0.6
0.8
1.0
0
0
9000
Bin count
(b)
Fig. 9.3 The instantaneous ﬁring intensity extracted from experiments can be ﬁtted by an exponen-
tial escape rate. (a) A real neuron is driven by a time-dependent input current (top) generating a
ﬂuctuating voltage with occasional spikes (middle), which are repeated with high precision, but not
perfectly, across several trials (bottom). (b) The black histogram (very small) shows the number of
times (bin count, vertical axis) that the model voltage calculated from Eq. (9.1) falls in the bin u−ϑ
(horizontal axis) and the real neuron ﬁres. The gray histogram indicates distribution of voltage when
the real neuron does not ﬁre. The ratio (black/black plus gray) in each bin gives the ﬁring probability
PF(u −ϑ) (open circles, probability scale on the right) which can be ﬁtted by Eq. (9.8) using an
exponential escape rate (solid line), f(u−ϑ) = 1
τ0 exp[β (u−ϑ)] with a steepness of β = (4mV)−1
and a mean latency at threshold of τ0 = 19 ms. From Jolivet et al. (2006) with kind permission from
Springer Science and Business Media.
Example: Bounded versus unbounded escape rate
A stochastic intensity which diverges for u ≫ϑ, such as the exponential escape rate of
Eq. (9.3), may seem surprising at a ﬁrst glance, but it is in fact a necessary requirement for
the transition from a soft to a sharp threshold process. Since the escape model has been
introduced as a noisy threshold, there should be a limit of low noise that leads us back
to the sharp threshold. In order to explore the relation between noisy and deterministic
threshold models, we consider as a ﬁrst step a bounded escape function f deﬁned as
f(u−ϑ) =
 0
for u < ϑ,
Δ−1
for u ≥ϑ.
(9.6)
Thus, the neuron never ﬁres if the voltage is below the threshold. If u > ϑ, the neuron
ﬁres stochastically with a rate Δ−1. Therefore, the mean latency, or expected delay, of a
spike is Δ. This implies that the neuron responds slowly and imprecisely, even when the
membrane potential is signiﬁcantly above threshold - and this result looks rather odd.
Only in the limit where the parameter Δ goes to zero would the neuron ﬁre immediately
and reliably as soon as the membrane potential crosses the threshold. Thus, a rapid
response requires the escape to diverge.
The argument here was based on a step function for the escape rate. A simple choice

228
Noisy output: escape rate and soft threshold
Δ−1
θ
u
f
Fig. 9.4 Soft threshold escape rates. Exponential
function (solid), piecewise linear function (dot-
ted), step function (dashed), and error function
(dot-dashed). The step function and error function
saturate at a maximum rate of Δ−1. The threshold
is ϑ.
for a soft threshold which enables a rapid response is a piecewise linear escape rate,
f(u−ϑ) = α [u−ϑ]+ =
 0
for u < ϑ,
α (u−ϑ)
for u ≥ϑ,
(9.7)
with slope α for u > ϑ. For u > ϑ, the ﬁring intensity is proportional to u −ϑ; see
Fig. 9.4. This corresponds to the intuitive idea that instantaneous ﬁring rates increase
with the membrane potential. Variants of the linear escape-rate model are commonly
used to describe spike generation in, for example, auditory nerve ﬁbers (Siebert and
Gray, 1963; Miller and Mark, 1992).
9.1.2 Transition from continuous time to discrete time
In discrete time, we consider the probability PF(u) of ﬁring in a ﬁnite time step given that
the neuron has membrane potential u. It is bounded from above by 1 - despite the fact
that the escape rate can be arbitrarily large. We start from a model in continuous time and
discretize time as is often done in simulations. In a straightforward discretization scheme,
we would calculate the probability of ﬁring during a time step Δt as
 t+Δt
t
ρ(t′)dt′ ≈ρ(t)Δt.
However, for u ≫ϑ, the hazard ρ(t) = f(u(t)−ϑ) can take large values; see, for example,
Eq. (9.3). Thus Δt must be taken extremely short so as to guarantee ρ(t)Δt < 1.
To arrive at an improved discretization scheme, we calculate the probability that a neuron
does not ﬁre in a time step Δt. The probability S(t) of surviving for a time t without ﬁring
decays according to dS/dt = −ρ(t)S(t). Integration of the differential equation over a ﬁnite
time Δt yields an exponential factor S(t) = exp[−
 t
0 ρ(t′)dt′]; compare the discussion of
the survivor function in Chapter 7 (Section 7.5). If the neuron does not survive, it must
have ﬁred. Therefore we arrive at a ﬁring probability
PF(u) = Prob{spike in [t,t +Δt]|u(t)} ≈1−exp{−Δt f(u(t)−ϑ)} .
(9.8)
Even if f diverges for u →∞, the probability of ﬁring remains bounded between zero and
1. Also, we see that, for small Δt, the probability PF scales as fΔt. We see from Fig. 9.5a
that, for an exponential escape rate, an increase in the discretization Δt mainly shifts the

9.2 Likelihood of a spike train
229
−1.0
0.0
1.0
2.0
u
0.0
0.5
1.0
Probability
(a)
−1.0
0.0
1.0
2.0
u
0.0
0.5
1.0
Probability
(b)
Fig. 9.5 The unbounded exponential escape rate yields a bounded ﬁring probability in a discrete time
step. (a) Probability of ﬁring in a discrete time interval Δt as a function of the membrane potential u
for different discretizations Δt = 0.5 ms (dashed line), Δt = 1 ms (solid line), and Δt = 2 ms (dotted
line) with β = 5. (b) Similar plot as in A but for different noise levels β = 10 (dotted line), β = 5
(solid line), β = 2 (dashed line), and β = 1 (dot-dashed line) with Δt = 1 ms. The escape rate is
given by (9.3) with parameters ϑ = 1 and τ0 = 1ms.
ﬁring curve to the left while the form remains roughly the same. An increase of the noise
level makes the curve ﬂatter; see Fig. 9.5b.
Note that, because of refractoriness, it is impossible for integrate-and-ﬁre models (and
for real neurons) to ﬁre more than one spike in a short time bin Δt. Refractoriness is imple-
mented in the model of Eq. (9.1) by a signiﬁcant reset of the membrane potential via the
refractory kernel η.
9.2 Likelihood of a spike train
In the previous subsection, we calculated the probability of ﬁring in a short time step Δt
from the continuous-time ﬁring intensity ρ(t). Here we ask a similar question, not on the
level of a single spike, but on that of a full spike train.
Suppose we know that a spike train has been generated by an escape noise process
ρ(t) = f(u(t)−ϑ)
(9.9)
as in Eq. (9.2), where the membrane potential u(t) arises from the dynamics of one of the
generalized integrate-and-ﬁre models such as the SRM.
The likelihood Ln that spikes occur at the times t1,...,t f ,...,tn is (Brillinger, 1988)
Ln({t1,t2,...,tn}) = ρ(t1)·ρ(t2)· ...ρ(tn) exp

−
 T
0 ρ(s)ds

,
(9.10)
where [0,T] is the observation interval. The product on the right-hand side contains the
momentary ﬁring intensity ρ(t f ) at the ﬁring times t1,t2,...,tn. The exponential factor

230
Noisy output: escape rate and soft threshold
takes into account that the neuron needs to "survive" without ﬁring in the intervals between
the spikes.
In order to highlight this interpretation it is convenient to take a look at Fig. 9.6a and
rewrite Eq. (9.10) in the equivalent form
Ln({t1,t2,...,tn}) = exp

−
 t1
0 ρ(s)ds

·ρ(t1)
exp

−
 t2
t1 ρ(s)ds

(9.11)
· ρ(t2)
exp

−
 t3
t2 ρ(s)ds

·...ρ(tn)
exp

−
 T
tn ρ(s)ds

.
Intuitively speaking, the likelihood of ﬁnding n spikes at times t f depends on the instanta-
neous rate at the time of the spikes and the probability of surviving the intervals in between
without ﬁring; see the survivor function introduced in Chapter 7, Eq. (7.26).
Instead of the likelihood, it is sometimes more convenient to work with the logarithm of
the likelihood, called the log-likelihood
logLn({t1,...,t f ,...,tn}) = −
 T
0 ρ(s)ds+
n
∑
f=1
logρ(t f ).
(9.12)
The three formulations Eqs. (9.10)-(9.12) are equivalent and it is a matter of taste if one
is preferred over the others.
Example: Discrete-time version of likelihood and generative model
In a discrete-time simulation of an SRM or generalized integrate-and-ﬁre model with
escape noise, we divide the simulation interval [0,T] into N time steps Δt = T/N; see
Fig. 9.6b. In each time step, we ﬁrst calculate the membrane potential u(t) and then gen-
erate a spike with probability Pt = PF(u(t)) given by Eq. (9.8). To do so, we generate on
the computer a random number rt between zero and unity. If Pt > rt, a spike is gener-
ated, i.e., the spike count number in this time bin is nt = 1. The probability of ﬁnding an
empty time bin (spike count nt = 0) is
Prob{silent in [t,t +Δt]} = 1−Pt = exp{−Δt ρ(t)} ,
(9.13)
where we have assumed that time bins are short enough so that the membrane potential
does not change a lot from one time step to the next. The spike train can be summarized
as a binary sequence {0,0,1,0,0,0,1,0,...} of N numbers nt ∈{0,1}. We emphasize
that, with the above discrete-time spike generation model, it is impossible to have two
spikes in a time bin Δt. This reﬂects the fact that, because of neuronal refractoriness,

9.2 Likelihood of a spike train
231
neurons cannot emit two spikes in a time bin shorter than, say, half the duration of an
action potential.
Since we generate an independent random number in each time bin, a speciﬁc spike
train occurs with a probability given by the product of the probabilities per bin:
Ptotal = Πbins with spike[Pt] · Πempty bins[1−Pt]
(9.14)
= Πt

[Pt]nt · [1−Pt]1−nt
,
(9.15)
where the product runs over all time bins and nt ∈{0,1} is the spike count number in
each bin.
We now switch our perspective and study an observed spike train in continuous time
with spike ﬁrings at times t f with 0 < t1,t2,...,tn < T. The spike train was generated
by a real neuron in a slice experiment under current injection with a known current I(t).
We now ask the following question: What is the probability that the observed spike train
could have been generated by our model? Thus, we consider our discrete-time model
with escape noise as a generative model of the spike train. To do so, we calculate the
voltage using a discrete-time version of Eq. (9.1). Given the (known) injected input I(t)
and the (observed) spike times t f , we can calculate the voltage u(t) of our model and
therefore the probability of ﬁring in each time step.
The observed spike train has n spikes at times 0 < t1,t2,...,tn < T. Let us denote time
bins containing a spike by tk with index k (i.e., t1 < t1 ≤t1 + Δt; t2 < t2 ≤t2 + Δt;...)
and empty bins by tk′ with a dummy index k′. Using Eq. (9.14), the probability that the
observed spike train could have been generated by our model is
Ptotal = Πn
k=1[Ptk] · Πk′,tk′̸=tk[1−Ptk′ ].
(9.16)
Eq. (9.16) is the starting point for ﬁnding optimal parameters of neuron models (Chapter
10).
We can gain some additional insights, if we rearrange the terms on the right-hand side
of Eq. (9.16) differently. All time bins that fall into the interval between two spikes can
be regrouped as follows
Π{k′|tk<tk′≤tk+1}[1−Ptk′] = Π{k′|tk<tk′≤tk+1} exp{−Δt ρ(tk′)}
= exp

−
∑
tk<tk′<tk+1
Δt ρ(tk′)
 
.
(9.17)
Ideally, a spike train in continuous time should be described by a model in continuous
time. We therefore ask whether the discretization of time is critical or whether we can
get rid of it. The transition to continuous time corresponds to the limit of N →∞while
T is kept ﬁxed. The Riemann sum on the right-hand side of Eq. (9.17) then turns into an
integral. In the same limit, the contribution of the bins containing a spike to Eq. (9.16)
can be written as Ptk = ρ(tk)Δt. We are led back from the discrete-time generative model

232
Noisy output: escape rate and soft threshold
0
T
3
2
exp
( ')
t
t
t
dt'
-
t 1
t 2
t 3
ρ(t 1)
ρ(t 2)
ρ(t 3)
ρ
(a)
0 
T 
kt
'kt
'
[1-
]
k
tP
[
]
ktP
0 0 1 0 0 1 0 0 0 0 0 0 0
0
1
(b)
Fig. 9.6 Likelihood of a spike train. Three spikes (thick vertical lines) have been observed in the
interval [0,T]. (a) The instantaneous ﬁring rates at the moment of the spikes are ρ(t1),ρ(t2),ρ(t3),
respectively. The intervals without spike ﬁring are indicated by horizontal braces. The probability
of staying quiescent during these intervals decays exponentially with the time-dependent rate ρ(t′).
(b) Likelihood of a spike train in discrete time. Top: The probability that a time bin tk′ contains no
spike is 1 −Ptk′ whereas the probability that a spike occurs in bin tk is Ptk. Middle: The spike count
numbers nt ∈{0,1} in each time bin. Bottom: The same spike train can also be described using a
ﬁner time discretization.
to Eq. (9.11) in continuous time with the replacement
Ptotal = Ln({t1,t2,...tn})(Δt)n ,
(9.18)
i.e., the continuum limit exists. In other words, once the time steps Δt are short enough,
the exact discretization scheme does not play a role. Alternative, more efﬁcient, sampling
schemes exist that avoid discretization (Brown et al., 2002); see Section 10.3.3.
9.3 Renewal approximation of the Spike Response Model
We focus on a Spike Response Model with escape noise; see Eqs. (9.1)-(9.3). If the ﬁring
rate is low, so that the interspike interval is much longer than the decay time of the refrac-
tory kernel η, then we can truncate the sum over past ﬁring times and keep track only of
the effect of the most recent spike (Gerstner, 1995)
u(t) = η(t −ˆt)+
 ∞
0 κ(s)Idet(t −s)ds+urest,
(9.19)
where ˆt denotes the last ﬁring time t f < t.
Eq. (9.19) is called the "short-term memory" approximation of the SRM and abbreviated
as SRM0. This model can be efﬁciently ﬁtted to neural data (Kass and Ventura, 2001) and
will play an important role in Chapter 14. In order to emphasize that the value of the
membrane potential depends only on the most recent spike, in what follows we write u(t|ˆt)

9.3 Renewal approximation of the Spike Response Model
233
-1.0
0.0
1.0
2.0
3.0
4.0
I0
0
100
200
300
ν  [Hz]
0
20
40
s [ms] 
0.0
0.1
P0(s)
(a)
(b)
Fig. 9.7 (a) Interval distribution P0(s) for an SRM0 neuron with absolute refractory period Δabs =
4 ms followed by an exponentially decreasing afterpotential as in Eq. (9.24) with η0 = 1 and τ =
4 ms. The model neuron is stimulated by a constant current I0 = 0.7,0.5,0.3 (from top to bottom).
(b) Output rate ν as a function of I0 (gain function). The escape rate is given by Eq. (9.3) with ϑ = 1,
β = 5, and τ0 = 1ms.
instead of u(t). Let us summarize the total effect of the input by introducing the "input
potential"
h(t) =
 ∞
0 κ(s)Idet(t −s)ds,
(9.20)
which allows us to rewrite Eq. (9.19) as
u(t|ˆt) = η(t −ˆt)+h(t)+urest .
(9.21)
The escape rate
ρ(t|ˆt) = f(u(t|ˆt))
(9.22)
depends on the time since the last spike and, implicitly, on the stimulating current Idet(t).
Hence ρ(t|ˆt) is similar to the hazard variable of stationary renewal theory. The arguments
of Chapter 7 can be generalized to the case of time-dependent input Idet(t) which gives rise
to a time-dependent input potential h(t). Given that the neuron has ﬁred its last spike at
time ˆt and that we know the input Idet(t′) for t′ < t we can calculate the probability density
that the next spike occurs at time t > ˆt
PI(t|ˆt) = ρ(t|ˆt) exp

−
 t
ˆt ρ(t′|ˆt)dt′

.
(9.23)
Eq. (9.23) generalizes renewal theory to the time-dependent case. Time-dependent renewal
theory will play an important role in Chapter 14.
Compared to the standard stationary renewal theory discussed in Chapter 7, there are
two important differences. First, the Spike Response Model with escape noise provides a
direct path from stationary to time-dependent renewal theory. Second, interval distributions
can be linked to refractoriness and vice versa. More precisely, a reduced ﬁring intensity
ρ(t|ˆt) immediately after a spike is an indication that the distance between the membrane

234
Noisy output: escape rate and soft threshold
0
20
40
t [ms]
0.0
0.1
P 
I(t|0)
(a)
0
20
40
t [ms]
-1.0
0.0
1.0
u(t|0)
(b)
Fig. 9.8 (a) Input-dependent interval distribution PI(t|0) for an SRM0 neuron as in Fig. 9.7 stimu-
lated by a periodically modulated input ﬁeld h(t) = h0 +h1 cos(2π ft) with h0 = 0.5, h1 = 0.1, and
frequency f = 500 Hz. (b) The membrane potential u(t|0) = η(t)+h(t) during stimulation as in (a).
potential u(t|ˆt) and the threshold is increased. The reason can be either a hyperpolarizing
spike-afterpotential η(t) or an increase in the ﬁring threshold ϑ(t|ˆt) immediately after a
spike
Example: Interval distribution with exponential escape noise
We study a model SRM0 with membrane potential u(t|ˆt) = η(t −ˆt)+h(t) and choose
a refractory kernel with absolute and relative refractoriness deﬁned as
η(s) =

−∞
for s < Δabs,
−η0 exp

−s−Δabs
τ
	
for s > Δabs .
(9.24)
We adopt the exponential escape rate (9.3).
Fig. 9.7 shows the interval distribution for constant input current I0 as a function of
s=t −ˆt. With the normalization
 ∞
0 κ(s)ds = 1, we have h0 = I0. Owing to the refrac-
tory term η, extremely short intervals are impossible and the maximum of the interval
distribution occurs at some ﬁnite value of s. If I0 is increased, the maximum is shifted
to the left. The interval distributions of Fig. 9.7a have qualitatively the same shape as
those found for cortical neurons. The gain function ν = g(I0) of a noisy SRM0 neuron
is shown in Fig. 9.7b.
We now study the same model with periodic input Idet(t) = I0 +I1 cos(Ωt). This leads
to an input potential h(t) = h0 +h1 cos(Ωt +ϕ1) with bias h0 = I0 and a periodic com-
ponent with a certain amplitude h1 and phase ϕ1.
Suppose that a spike has occurred at ˆt = 0. The probability density that the next spike
occurs at time t is given by PI(t|ˆt) and can be calculated from Eq. (9.23). The result is
shown in Fig. 9.8a.

9.4 From noisy inputs to escape noise
235
We note that the periodic component of the input is well represented in the response
of the neuron. This example illustrates how neurons in the auditory system can transmit
stimuli of frequencies higher than the mean ﬁring rate of the neuron. We emphasize that
the threshold in Fig. 9.8b is at ϑ = 1. Without noise there would be no output spike. On
the other hand, at very high noise levels, the modulation of the interval distribution would
be much weaker. Thus a certain amount of noise is beneﬁcial for signal transmission. The
existence of an optimal noise level is a phenomenon called stochastic resonance and will
be discussed below in Section 9.4.2.
9.4 From noisy inputs to escape noise
The total input current I(t) which drives a neuron can often be separated into a determin-
istic component Idet, which is known and repeats between one trial and the next; and a
stochastic component ξ which is unknown and potentially changes between trials:
I(t) = Idet(t)+ξ(t).
(9.25)
In this section we show that the noisy, unknown part in the input can be approximated to a
high degree of accuracy by an appropriately chosen escape function.
Example: Adaptive exponential integrate-and-ﬁre model with noisy input
Suppose that the AdEx model which we encountered in Chapter 6 (see Eqs. (6.3) and
(6.4)) is driven by an input as in Eq. (9.25) containing a rapidly moving deterministic
signal Idet(t) as well as a white noise component ξ(t). This model generates spikes
with a millisecond precision and a high degree of reliability from one trial to the next
(Fig. 9.9). We now approximate the voltage of the AdEx model by a linear model
u(t) = ∑
f
η(t −t f
i )+
 ∞
0 κ(s)Idet(t −s)ds+urest .
(9.26)
In the subthreshold regime u < ϑ −ΔT, the ﬁlters κ and η can be calculated analytically
using the methods discussed in Chapter 6. The voltage equation (9.26) is then combined
with the exponential escape rate
f(u−ϑ) = 1
τ0
exp[β (u−ϑ)].
(9.27)
The resulting SRM with escape noise (i.e., a linear model with exponential soft-
threshold noise in the output) describes the activity of the AdEx with noisy input (i.e.,
an exponential neuron model with additive white noise in the input) surprisingly well
(Fig. 9.9). In other words, in the presence of an input noise ξ(t) the exponential term in
the voltage equation of the AdEx model can be replaced by an exponential escape rate
(Mensi et al., 2011).

236
Noisy output: escape rate and soft threshold
(a)
(b)
(c)
(d)
Fig. 9.9 From input noise to output noise. (a) An AdEx model neuron is driven by a ﬂuctuating
current containing a deterministic part which is the same during each trial and a stochastic white
noise part. (b) Voltage trace of the AdEx model (black) and the SRM with exponential escape rate
(gray) during a single trial. The SRM is driven by the determinstic part of the input current. (c) Spike
times during 20 trials with the same determinstic current for the AdEx model (black) and SRM with
exponential escape noise (gray). For the AdEx the stochasticity arises from white noise in the input
whereas for the SRM it arises from escape noise in the output. (d) Comparison of the PSTH of the
AdEx model (black) with that of the SRM (gray). Adapted from Mensi et al. (2011).
9.4.1 Leaky integrate-and-ﬁre model with noisy input
In the subthreshold regime, the leaky integrate-and-ﬁre model with stochastic input (white
noise) can be mapped approximately onto an escape noise model with a certain escape rate
f (Plesser and Gerstner, 2000). In this section, we motivate the mapping and the choice
of f.
In the absence of a threshold, the membrane potential of an integrate-and-ﬁre model
has a Gaussian probability distribution around the noise-free reference trajectory u0(t). If
we take the threshold into account, the probability density at u = ϑ of the exact solution
vanishes, since the threshold acts as an absorbing boundary; see Eq. (8.44). Nevertheless,
in a phenomenological model, we can approximate the probability density near u = ϑ by
the "free" distribution (i.e., without the threshold)
Prob

u reaches ϑ in [t,t +Δt]

∝Δt exp

−[u0(t)−ϑ]2
2⟨Δu2(t)⟩

,
(9.28)
where u0(t) is the noise-free reference trajectory. The idea is illustrated in Fig. 9.10. We
note that in a leaky integrate-and-ﬁre model with colored noise (as opposed to white noise)
in the input the density at threshold is not zero.
We have seen in Eq. (8.13) that the variance ⟨Δu2(t)⟩of the free distribution rapidly
approaches a constant value σ2/2 where σ scales with the strength of the diffusive input.
We therefore replace the time-dependent variance 2⟨Δu(t)2⟩by its stationary value σ2. The

9.4 From noisy inputs to escape noise
237
u 0(t)
t
0
u
J
p(u,t)
t 0
^
Fig. 9.10 The distribution of the membrane potential around the noise-free reference trajectory u0(t)
is given by p(u,t). At t = t0, where the reference trajectory has a discontinuity, the distribution of the
membrane potential is shifted instantaneously across the threshold. The probability of ﬁring at t0 is
given by the shaded surface under the distribution.
right-hand side of Eq. (9.28) is then a function of the noise-free reference trajectory only.
To transform the left-hand side of Eq. (9.28) into an escape rate, we divide both sides by Δt.
The ﬁring intensity is thus
f(u0 −ϑ) = c1
τm
exp

−[u0(t)−ϑ]2
σ2

.
(9.29)
The factor in front of the exponential has been split into a constant parameter c1 > 0 and
the time constant τm of the neuron in order to show that the escape rate has units of 1 over
time. Equation (9.29) is the well-known Arrhenius formula for escape across a barrier of
height (ϑ −u0)2 in the presence of thermal energy σ2 (van Kampen, 1992).
Let us now suppose that the neuron receives, at t = t0, an input current pulse which
causes a jump of the membrane trajectory by an amount Δu > 0; see Fig. 9.10. In this
case the Gaussian distribution of membrane potentials is shifted instantaneously across
the threshold so that there is a nonzero probability that the neuron ﬁres exactly at t0. In
other words, the ﬁring intensity ρ(t) = f[u0(t) −ϑ] has a δ peak at t = t0. The escape
rate of Eq. (9.29), however, cannot reproduce this δ peak. More generally, whenever the
noise-free reference trajectory increases with slope ˙u0 > 0, we expect an increase of the
instantaneous rate proportional to ˙u0, because the tail of the Gaussian distribution drifts
across the threshold; see Eq. (8.35). In order to take the drift into account, we generalize
Eq. (9.29) and study
f(u0, ˙u0) =
 c1
τm
+ c2
σ [ ˙u0]+

exp

−[u0(t)−ϑ]2
σ2

,
(9.30)
where ˙u0 = du0/dt and [x]+ = x for x > 0 and zero otherwise. We call Eq. (9.30) the
Arrhenius&Current model (Plesser and Gerstner, 2000).

238
Noisy output: escape rate and soft threshold
0
100
200
t [ms] 
0
0.1
0.3
P (t|0)
I
Fig. 9.11 The interval distributions PI(t|0) for diffusive noise (solid line) and Arrhenius&Current
escape noise (dashed line) are nearly identical. The input potential is the same as in Fig. 8.10. Taken
from Plesser and Gerstner (2000).
We emphasize that the right-hand side of Eq. (9.30) depends only on the dimensionless
variable
x(t) = u0(t)−ϑ
σ
(9.31)
and its derivative ˙x. Thus the amplitude of the ﬂuctuations σ deﬁne a "natural" voltage
scale. The only relevant variable is the momentary distance of the noise-free trajectory
from the threshold in units of the noise amplitude σ. A value of x = −1 implies that the
membrane potential is one σ below threshold. A distance of u −ϑ = −10 mV at high
noise (e.g., σ = 10 mV) is as effective in ﬁring a cell as a distance of 1 mV at low noise
(σ = 1 mV).
Example: Comparison of diffusion model and Arrhenius&Current escape rate
To check the validity of the arguments that led to Eq. (9.30), let us compare the inter-
val distribution generated by the diffusion model with that generated by the Arrhe-
nius&Current escape model. We use the same input potential u0(t) as in Fig. 8.10.
We ﬁnd that the interval distribution for the diffusive white noise model (derived from
stochastic spike arrival; see Chapter 8) and that for the Arrhenius&Current escape model
are nearly identical; see Fig. 9.11. Thus the Arrhenius&Current escape model yields an
excellent approximation to the diffusive noise model.
Even though the Arrhenius&Current model has been designed for subthreshold stim-
uli, it also works remarkably well for superthreshold stimuli. An obvious shortcom-
ing of the escape rate (9.30) is that the instantaneous rate decreases with u for u > ϑ.
The superthreshold behavior can be corrected if we replace the Gaussian exp(−x2) by
2 exp(−x2)/[1 + erf(−x)] (Herrmann and Gerstner, 2001). The subthreshold behavior
remains unchanged compared to Eq. (9.30) but the superthreshold behavior of the escape
rate f becomes linear.

9.4 From noisy inputs to escape noise
239
9.4.2 Stochastic resonance
Noise can - under certain circumstances - improve the signal transmission properties of
neuronal systems. In most cases there is an optimum for the noise amplitude which has
motivated the name stochastic resonance for this rather counterintuitive phenomenon. In
this section we discuss stochastic resonance in the context of noisy spiking neurons.
We study the relation between an input I(t) to a neuron and the corresponding output
spike train S(t) = ∑f δ(t −t f ). In the absence of noise, a subthreshold stimulus I(t) does
not generate action potentials so that no information on the temporal structure of the stim-
ulus can be transmitted. In the presence of noise, however, spikes do occur. As we have
seen in Eq. (9.30), spike ﬁring is most likely at moments when the normalized distance
|x| = |(u −ϑ)/σ| between the membrane potential and the threshold is small. Since the
escape rate in Eq. (9.30) depends exponentially on x2, any variation in the membrane
potential u0(t) that is generated by the temporal structure of the input is enhanced; see
Fig. 9.8. On the other hand, for very large noise (σ →∞), we have x2 →0, and spike ﬁring
occurs at a constant rate, irrespective of the temporal structure of the input. We conclude
that there is some intermediate noise level where signal transmission is optimal.
The optimal noise level can be found by plotting the signal-to-noise ratio as a function
of noise. Even though stochastic resonance does not require periodicity (see, e.g., Collins
et al., 1996), it is typically studied with a periodic input signal such as
Idet(t) = I0 +I1 cos(Ωt).
(9.32)
For t −ˆt ≫τm, the membrane potential of the noise-free reference trajectory has the form
u0(t) = u∞+u1 cos(Ωt +ϕ1),
(9.33)
where u1 and ϕ1 are the amplitude and phase of its periodic component. To quantify the
signal transmission properties, a long spike train is studied and the signal-to-noise ratio
(SNR) is computed. The signal S is measured as the amplitude of the power spectral
density of the spike train evaluated at frequency Ω, i.e., S = P(Ω). The noise level N is
usually estimated from the noise power PPoisson of a Poisson process with the same number
of spikes as the measured spike train, i.e., N = PPoisson. Figure 9.12 shows the signal-to-
noise ratio S /N of a periodically stimulated integrate-and-ﬁre neuron as a function of the
noise level σ. Two models are shown, namely, diffusive noise (solid line) and escape noise
with the Arrhenius&Current escape rate (dashed line). The two curves are rather similar
and exhibit a peak at
σopt ≈2
3 (ϑ −u∞).
(9.34)
Since σ2 = 2⟨Δu2⟩and
√
2·2/3 ≈1, signal transmission is optimal if the stochastic ﬂuctu-
ations of the membrane potential have an amplitude
2

⟨Δu2⟩≈ϑ −u∞.
(9.35)

240
Noisy output: escape rate and soft threshold
0
0
10
SNR
1
Noise
Fig. 9.12 Signal-to-noise ratio (SNR) for the transmission of a periodic signal as a function of the
noise level σ/(ϑ −u0). Solid line: Diffusion model. Dashed line: Arrhenius&Current escape model.
Taken from Plesser and Gerstner (2000).
An optimality condition similar to (9.34) holds over a wide variety of stimulation param-
eters (Plesser, 1999). We will come back to the signal transmission properties of noisy
spiking neurons in Chapter 15.
Example: Extracting oscillations
The optimality condition (9.34) can be fulﬁlled by adapting either the left-hand side
or the right-hand side of the equation. Even though it cannot be excluded that a neuron
changes its noise level so as to optimize the left-hand side of Eq. (9.34) this does not
seem very likely. On the other hand, it is easy to imagine a mechanism that optimizes the
right-hand side of Eq. (9.34). For example, an adaptation current could change the value
of ϑ, or synaptic weights could be increased or decreased so that the mean potential u∞
is in the appropriate regime.
We apply the idea of an optimal threshold to a problem of neural coding. More specif-
ically, we study the question of whether an integrate-and-ﬁre neuron or an SRM neuron
is sensitive only to the total number of spikes that arrive in some time window T, or also
to the relative timing of the input spikes. To do so, we compare two different scenarios
of stimulation. In the ﬁrst scenario, input spikes arrive with a periodically modulated
rate,
νin(t) = ν0 +ν1 cos(Ωt)
(9.36)
with 0 < ν1 < ν0. Thus, even though input spikes arrive stochastically, they have some
inherent temporal structure, since they are generated by an inhomogeneous Poisson pro-
cess. In the second scenario, input spikes are generated by a homogeneous (that is, sta-
tionary) Poisson process with constant rate ν0. In a large interval T ≫Ω−1, however,
we expect in both cases a total number of ν0 T input spikes.
Stochastic spike arrival leads to a ﬂuctuating membrane potential with variance Δ2 =
⟨Δu2⟩. If the membrane potential hits the threshold an output spike is emitted. If stimulus

9.5 Summary
241
1 is applied during the time T, the neuron emits a certain number of action potentials,
say n(1). If stimulus 2 is applied it emits n(2) spikes. It is found that the spike count
numbers n(1) and n(2) are signiﬁcantly different if the threshold is in the range
u∞+

⟨Δu2⟩< ϑ < u∞+3

⟨Δu2⟩.
(9.37)
We conclude that a neuron in the subthreshold regime is capable of transforming a tem-
poral code (amplitude ν1 of the variations in the input) into a spike count code (Kempter
et al., 1998). Such a transformation plays an important role in the auditory pathway
(Miller and Mark, 1992; Konishi, 1993; Kempter et al., 1999b).
9.5 Summary
Neuronal noise in the output can be described as a stochastic ﬁring intensity, or escape rate,
which depends on the momentary distance of the membrane potential from the threshold.
The concept of escape rate can be applied to a large class of generalized integrate-and-ﬁre
models. An SRM with exponential escape rate is particularly attractive for several rea-
sons. First, experimental data suggest an exponential escape rate (Fig. 9.3). Second, a wide
spectrum of subthreshold effects can be captured by the linear ﬁlters of the SRM (Chap-
ter 6). Third, when driven with a noisy input, nonlinear neuron models such as the AdEx
can be well approximated by the SRM with exponential escape noise (Fig. 9.9). Fourth,
the explicit formulas for the likelihood of an observed spike train (Section 9.2) enable a
rapid ﬁt of the neuron model to experimental data, using the concept of Generalized Linear
Models to be discussed in the next chapter.
Escape noise gives rise to variability in spike ﬁring even if the input is perfectly known.
It can therefore be linked to intrinsic noise sources such as channel noise. However, more
generally, any unknown component of the input which may, for example, arise from stochas-
tic spike arrival can also be approximated by an appropriate escape rate function (Sec-
tion 9.4). Thus the escape rate provides a phenomenological noise model that summarizes
effects of biophysical channel noise as well as stochastic input.
Literature
The Spike Response Model with exponential escape noise was introduced in Gerstner and
van Hemmen (1992) and Gerstner (1995), but closely related models had already been
applied to neuronal data by Brillinger (1988) and have an obvious link to Generalized
Linear Models, which were used in statistics as early as the 1970s (Nelder and Wederburn,
1972) and have been repeatedly applied to neuronal data (Truccolo et al., 2005; Pillow
et al., 2008). The choice of an exponential escape rate for experimental data has been
demonstrated by Jolivet et al. (2006).
The term escape noise has been chosen in analogy to the Arrhenius formula which

242
Noisy output: escape rate and soft threshold
describes the escape of a particle (or a chemical process) across an energy barrier in the
presence of thermal energy (van Kampen, 1992).
The relation of diffusive noise in the input to escape noise has been studied by Plesser
and Gerstner (2000), Herrmann and Gerstner (2001) and Mensi et al. (2011). Stochastic
resonance has been a popular topic of research for many years, starting in 1989 (McNamara
and Wiesenfeld, 1989; Douglass et al., 1993; Longtin, 1993; Collins et al., 1996). A nice
review on stochastic resonance can be found in Gammaitoni et al. (1998).
Exercises
1. Integrate-and-ﬁre model with linear escape rates. Consider a leaky integrate-and-ﬁre neuron
with linear escape rate,
ρI(t|ˆt) = β [u(t|ˆt)−ϑ]+.
(9.38)
(a) Start with the non-leaky integrate-and-ﬁre model by considering the limit of τm →∞. The
membrane potential of the model is then
u(t|ˆt) = ur + 1
C
 t
ˆt I(t′)dt′ .
(9.39)
Assume constant input, set ur = 0 and calculate the hazard and the interval distribution.
(b) Consider the leaky integrate-and-ﬁre model with time constant τ and constant input I0.
Determine the membrane potential, the hazard, and the interval distribution.
2. Likelihood of a spike train. In an in-vitro experiment, a time-dependent current I(t) was
injected into a neuron for a time 0 < t < T and four spikes were observed at times 0 < t1 <
t2 < t3 < t4 < T.
(a) What is the likelihood that this spike train could have been generated by a leaky integrate-
and-ﬁre model with linear escape rate deﬁned in Eq. (9.38)?
(b) Rewrite the likelihood in terms of the interval distribution and hazard of time-dependent
renewal theory.

10
Estimating parameters of probabilistic
neuron models
It is helpful to break neural data analysis into two basic problems. The "encoding" problem
concerns how information is encoded in neural spike trains: can we predict the spike trains
of a neuron (or population of neurons), given an arbitrary synaptic input, current injection,
or sensory stimulus? Conversely, the "decoding" problem concerns how much we can learn
from the observation of a sequence of spikes: in particular, how well can we estimate the
stimulus that gave rise to the spike train?
The problems of encoding and decoding are difﬁcult both because neural responses are
stochastic and because we want to identify these response properties given any possible
stimulus in some very large set (e.g., all images that might occur in the world), and there
are typically many more such stimuli than we can hope to sample by brute force. Thus
the neural coding problem is fundamentally statistical: given a ﬁnite number of samples of
noisy physiological data, how do we estimate, in a global sense, the neural codebook?
This basic question has taken on a new urgency as neurophysiological recordings allow
us to peer into the brain with ever greater facility: with the development of fast computers,
inexpensive memory, and large-scale multineuronal recording and high-resolution imaging
techniques, it has become feasible to directly observe and analyze neural activity at a level
of detail that was impossible in the twentieth century. Experimenter now routinely record
from hundreds of neurons simultaneously, providing great challenges for data analysis by
computational neuroscientists and statisticians. Indeed, it has become clear that sophisti-
cated statistical techniques are necessary to understand the neural code: many of the key
questions cannot be answered without powerful statistical tools.
This chapter describes statistical model-based techniques that provide a uniﬁed approach
to both encoding and decoding. These statistical models can capture stimulus dependencies
as well as spike history and interneuronal interaction effects in population of spike trains,
and are intimately related to the generalized integrate-and-ﬁre models discussed in previous
chapters.
In Section 10.1, we establish the notation that enables us to identify relevant model
parameters and introduce the concept of parameter optimization in a linear model. We
then leave the realm of linear models and turn to the models that we have discussed in
preceding chapters (e.g., the Spike Response Model with escape noise in Chapter 9) where
spike generation is stochastic and nonlinear.

244
Estimating models
In Section 10.2, we describe the same neuron models of spike trains in the slightly more
abstract language of statistics. The likelihood of a spike train given the stimulus plays a
central role in statistical models of encoding. As we have seen in Chapter 9, the stochastic-
ity introduced by "escape noise" in the Spike Response Model (SRM) or other generalized
integrate-and-ﬁre models enables us to write down the likelihood that an observed spike
train could have been generated by the neuron model. Likelihood-based optimization meth-
ods for ﬁtting these neuron models to data allow us to predict neuronal spike timing for
future, unknown stimuli. Thus, the SRM and other generalized integrate-and-ﬁre models
can be viewed as encoding models. In Chapter 11 we shall see that the same models can
also be used to perform optimal decoding.
The emphasis of this chapter is on likelihood-based methods for model optimization.
The likelihood-based optimization methods are computationally tractable, due to a key
concavity property of the model likelihood (Paninski, 2004). However, likelihood is just
one of several quantities that can be chosen to compare spike trains, and other measures to
quantify the performance of models can also be used. In Section 10.3 we review different
performance measures for the "goodness-of-ﬁt" of a model. In particular, we present the
notion of "spike train similarity" and the "time rescaling theorem" (Brown et al., 2002).
Finally, in Section 10.4 we apply the ideas developed in this chapter to adaptively choose
the optimal stimuli for characterizing the response function.
10.1 Parameter optimization in linear and nonlinear models
Before we turn to the statistical formulation of models of encoding and decoding, we need
to introduce the language of statistics into neuron modeling. In particular, we will deﬁne
what is meant by convex problems, optimal solutions, linear models and generalized linear
models.
When choosing a neuron model for which we want to estimate the parameters from data,
we must satisfy three competing desiderata:
(i) The model must be ﬂexible and powerful enough to ﬁt the observed data. For exam-
ple, a linear model might be easy to ﬁt, but not powerful enough to account for the
data.
(ii) The model must be tractable: we need to be able to ﬁt the model given the modest
amount of data available in a physiological recording (preferably using modest computa-
tional resources as well); moreover, the model should not be so complex that we cannot
assign an intuitive functional role to the inferred parameters.
(iii) The model must respect what is already known about the underlying physiology
and anatomy of the system; ideally, we should be able to interpret the model parameters
and predictions not only in statistical terms (e.g., conﬁdence intervals, signiﬁcance tests)
but also in biophysical terms (membrane noise, dendritic ﬁltering, etc.). For example, with
a purely statistical "black box" model we might be able to make predictions and test their
signiﬁcance, but we will not be able to make links to the biophysics of neurons.
While in general there are many varieties of encoding models that could conceivably

10.1 Parameter optimization in linear and nonlinear models
245
dt
Kdt
k1
kK
(a)
Time
t =K+1
t =K+2
t =K+3
. 
..
t =T
Input
(b)
x
x1
x2
x3
xK
...
...
...
...
IK
IK-1
IK-1
IK-2
...
IT
dt
IK+1
IK
IK+2
IK+1 IK
I2
I3
I1
IT-1
IT-2
IT-K+1
Fig. 10.1 Measurement of membrane ﬁlter. (a) Schematic of the linear membrane ﬁlter κ in discrete
time. (b) Matrix of temporal inputs (schematic). At each moment in time, the last K time steps of the
input current It serve as an input vector. Rows of the matrix correspond to different input samples.
satisfy these three conditions, in this chapter we will mainly focus on the SRM with escape
noise (Chapter 9). In a more general setting (see Chapter 11), the linear ﬁlter can be inter-
preted not just as local biophysical processes within the neuron, but as a summary of the
whole signal processing chain from sensory inputs to the neuron under consideration. In
such a general setting, the SRM may also be seen as an example of a "generalized linear"
model (GLM) (Paninski, 2004; Truccolo et al., 2005). In the following two subsections, we
review linear and Generalized Linear Models from the point of view of neuronal dynamics:
how is a stimulus I(t) encoded by the neuron?
10.1.1 Linear models
Let us suppose that an experimenter injects, with a ﬁrst electrode, a time-dependent current
I(t) in an interval 0 < t ≤T while recording with a second electrode the membrane voltage
uexp(t). The maximal amplitude of the input current has been chosen small enough for the
neuron to stay in the subthreshold regime. We may therefore assume that the voltage is
well described by our linear model
u(t) =
 ∞
0 κ(s)I(t −s)ds+urest;
(10.1)
see Section 1.3.5. In order to determine the ﬁlter κ that describes the linear properties of the
experimental neuron, we discretize time in steps of dt and denote the voltage measurement
and injected current at time t by uexp
t
and It, respectively. Here the time subscript t ∈Z is
an integer time step counter. We set K = smax/dt where max(s) ∈N and introduce a vector
k = (κ(dt),κ(2dt),...,κ(Kdt))
(10.2)
which describes the time course κ in discrete time; see Fig. 10.1a. Similarly, the input
current I during the last K time steps is given by the vector
xt = (It−1,It−2,...,It−K)dt .
(10.3)

246
Estimating models
The discrete-time version of the integral equation (10.1) is then a simple scalar product
ut =
K
∑
l=1
klIt−ldt +urest = k·xt +urest .
(10.4)
Note that k is the vector of parameters k1,k2,...,kK that need to be estimated. In the lan-
guage of statistics, Eq. (10.4) is a linear model because the observable ut is linear in the
parameters. Moreover, ut is a continuous variable so that the problem of estimating the
parameters falls in the class of linear regression problems. More generally, regression
problems refer to the prediction or modeling of continuous variables whereas classiﬁca-
tion problems refer to the modeling or prediction of discrete variables.
To ﬁnd a good choice of parameters k, we compare the prediction ut of the model equa-
tion (10.4) with the experimental measurement uexp
t
. In a least-square error approach, the
components of the vector k will be chosen such that the squared difference between model
voltage and experimental voltage
E(k) =
T
∑
t=K+1

uexp
t
−ut
2
(10.5)
is minimal. An important insight is the following. For any model that is linear in the param-
eters, the function E in Eq. (10.5) is quadratic and convex in the parameters k of the model.
Therefore
(i) the function E has no non-global local minima as a function of the parameter vector
k (in fact, the set of minimizers of E forms a linear subspace in this case, and simple
conditions are available to verify that E has a single global minimum, as discussed below);
(ii) the minimum can be found either numerically by gradient descent or analytically by
matrix inversion.
While the explicit solution is only possible for linear models, the numerical gradient
descent is possible for all kinds of error functions E and yields a unique solution if the
error has a unique minimum. In particular, for all error functions which are convex, gradient
descent converges to the optimal solution (Fig. 10.2) - and this is what we will exploit in
Section 10.2.
Example: Analytical solution
For the analytical solution of the least-square optimization problem, deﬁned by Eqs.
(10.4) and (10.5), it is convenient to collect all time points ut, K + 1 < t < T into a
single vector u = (uK+1,uK+2,...,uT) which describes the membrane voltage of the
model. Similarly, the observed voltage in the experiment is summarized by the vector
uexp = (uexp
K+1,...,uexp
T ). Furthermore, let us align the observed input vectors x into a
matrix X. More precisely, the matrix has T −K rows consisting of the vector xt; see Fig.
10.1b. With this notation, Eq. (10.4) can be written as a matrix equation
u = X kT +urest,
(10.6)

10.1 Parameter optimization in linear and nonlinear models
247
k
E 
k 
E 
kopt
kopt 
(a)
k 
E 
k 
E 
kopt
kopt  
(b)
Fig. 10.2 Convex function and global minimum. (a) A quadratic function (left) and an arbitrary con-
vex function (right). A convex function is curved upward so that any straight line (dashed) connecting
two points on the curve stays above the curve. A convex function cannot have a non-global minimum.
(b) A non-convex function without (left) and with (right) a non-global minimum. Gradient descent
refers to a change of the parameter k that leads to a downward move (arrow) on the error surface. In
the case on the right, a gradient-descent method can get stuck in the local minimum.
where urest is a vector with all components equal to urest. We suppose that the value of
urest has already been determined in an earlier experiment.
We search for the minimum of Eq. (10.5), deﬁned by ∇kE = 0 (where ∇kE denotes
the gradient of E with respect to k), which gives rise a single linear equation for each
component of the parameter vector k, i.e., a set of K linear equations. With our matrix
notation, the error function is a scalar product
E(k) = [uexp −X k−urest]T ·[uexp −X k−urest]
(10.7)
and the unique solution of the set of linear equations is the parameter vector
ˆkLS = (XTX)−1 XT(uexp −urest),
(10.8)
assuming the matrix (XTX) is invertible. (If this matrix is non-invertible, then a unique
minimum does not exist.) The subscript highlights that the parameter ˆkLS has been deter-
mined by least-square optimization.
10.1.2 Generalized Linear Models
The above linearity arguments not only work in the subthreshold regime, but can be
extended to the case of spiking neurons. In the deterministic formulation of the Spike
Response Model, the membrane voltage is given as
u(t) =
 ∞
0 η(s)S(t −s)ds+
 ∞
0 κ(s)I(t −s)ds+urest,
(10.9)

248
Estimating models
where S(t) = ∑f δ(t −t f ) is the spike train of the neuron; see Eq. (1.22) or (9.1).
Similarly to the passive membrane, the input current enters linearly with a membrane
ﬁlter κ. Similarly, past output spikes t f < t enter linearly with a "refractory kernel" or
"adaptation ﬁlter" η. Therefore, spike history effects are treated in the SRM as linear con-
tributions to the membrane potential. The time course of the spike history ﬁlter η can
therefore be estimated analogously to that of κ.
Regarding the subthreshold voltage, we can generalize Eqs. (10.2)-(10.4). Suppose that
the spike history ﬁlter η extends over a maximum of J time steps. Then we can introduce
a new parameter vector
k = (κ(dt),κ(2dt),...,κ(Kdt),η(dt),η(2dt),...,η(Jdt),urest)
(10.10)
which includes both the membrane ﬁlter κ and the spike history ﬁlter η. The spike train in
the last J time steps is represented by the spike count sequence nt−1,nt−2,...,nt−J, where
nt ∈{0,1}, and included into the "input" vector
xt = (It−1dt,It−2dt,...,It−Kdt,nt−1,nt−2,...,nt−J,1).
(10.11)
The discrete-time version of the voltage equation in the SRM is then again a simple scalar
product
ut =
J
∑
j=1
kK+ jnt−j +
K
∑
k=1
kkIt−kdt +urest = k·xt .
(10.12)
Thus, the membrane voltage during the interspike intervals is a linear regression problem
that can be solved as before by minimizing the mean square error.
Spiking itself, however, is a nonlinear process. In the SRM with escape rate, the ﬁring
intensity is
ρ(t) = f(u(t)−ϑ) = f(k·xt −ϑ).
(10.13)
We have assumed that the ﬁring threshold is constant, but this is no limitation since, in
terms of spiking, any dynamic threshold can be included into the spike-history ﬁlter η.
We emphasize that the ﬁring intensity in Eq. (10.13) is a nonlinear function of the param-
eters k and b that we need to estimate. Nevertheless, rapid parameter estimation is still
possible if the function f has properties that we will identify in Section 10.2. The reason
is that in each time step ﬁring is stochastic with an instantaneous ﬁring intensity f that
only depends on the momentary value of the membrane potential - where the membrane
potential can be written as a linear function of the parameters. This insight leads to the
notion of Generalized Linear Models (GLM). For an SRM with exponential escape noise
ρ(t) = f(u(t)−ϑ) = ρ0 exp(u(t)−ϑ) the likelihood of a spike train
Ln({t(1),t(2),...,t(n)}) = ρ(t(1))·ρ(t(2))· ...·ρ(t(n)) exp

−
 T
0 ρ(s)ds

,
(10.14)
which we have already deﬁned in Eq. (9.10), is a log-concave function of the parameters
(Paninski, 2004); i.e., the loglikelihood is a concave function. We will discuss this result in

10.2 Statistical formulation of encoding models
249
+
f(u)
q1
u
h
I(t)
S(t)
(a)
h
k
k
p
(b)
Fig. 10.3 SRM revisited. (a) The SRM takes as input a time-dependent current I(t) and generates a
spike train S(t) at the output. The parameters of the model control the shape of the ﬁlters κ,θ1 and
η. (b) If the escape rate f(u−ϑ) is exponential and the parameters k enter linearly into the voltage
equation u and the threshold ϑ, then the likelihood p that a speciﬁc spike train is generated by the
model is a concave (i.e., downward curving) function of the parameters (Paninski, 2004).
the next section as it is the fundamental reason why parameter optimization for the SRM
is computationally efﬁcient (Fig. 10.3).
GLMs are fundamental tools in statistics for which a great deal of theory and computa-
tional methods are available. In what follows we exploit the elegant mathematical proper-
ties of GLMs.
10.2 Statistical formulation of encoding models
Let us denote the observed spike train data by D. In general, D could represent measure-
ments from a population of neurons. To keep the arguments simple, we focus for the
moment on a single neuron, but at the end of the section we will extend the approach
to a population of interacting neurons. If the time bins are chosen smaller than the absolute
refractory period, the discretized spike train is described by a sequence of scalar variables
nt in an interval 0 < t ≤T
D = {n1,n2,...,nT}
(10.15)
see Fig. 9.6. If time bins are large, spike counts can take values larger than 1.
A neural "encoding model" is a model that assigns a conditional probability, p(D|x), to
any possible neural response D given a stimulus x. The vector xt can include the momentary
stimulus presented at time t, or more generally the concatenated spatio-temporal stimulus
history up to time t. Examples have been given in Section 10.1.
As emphasized in the introduction to this chapter, it is not feasible to directly measure
this probability p(D|x) for all stimulus-response pairs (x,D), simply because there are
inﬁnitely many potential stimuli. We therefore hypothesize some encoding model,
p(D|x,θ).
(10.16)
Here θ is a short-hand notation for the set of all model parameters. In the examples of the
previous section, the model parameters are θ = {k,b}.

250
Estimating models
Our aim is to estimate the model parameters θ so that the model "ﬁts" the observed data
D. Once θ is in hand we may compute the desired response probabilities as
p(D|x) ≈p(D|x,θ),
(10.17)
i.e., knowing θ allows us to interpolate between the observed (noisy) stimulus-response
pairs, in order to predict the response probabilities for novel stimuli x for which we have
not yet observed any responses.
10.2.1 Parameter estimation
How do we ﬁnd a good estimate for the parameters θ for a chosen model class? The general
recipe is as follows. The ﬁrst step is to introduce a model that makes sense biophysically,
and incorporates our prior knowledge in a tractable manner. Next we write down the likeli-
hood of the observed data given the model parameters, along with a prior distribution that
encodes our prior beliefs about the model parameters. Finally, we compute the posterior
distribution of the model parameters given the observed data, using Bayes' rule, which
states that
p(θ|D) ∝p(D|θ)p(θ);
(10.18)
the left-hand side is the desired posterior distribution, while the right-hand side is just the
product of the likelihood and the prior.
In the current setting, we need to write down the likelihood p(D|X,k) of the observed
spike data D given the model parameter k and the observed set of stimuli summarized in
the matrix X, and then we may employ standard likelihood optimization methods to obtain
the maximum likelihood (ML) or maximum a posteriori (MAP) solutions for k, deﬁned by
ML:
ˆkML = argmaxk{p(D|X,k)},
(10.19)
MAP:
ˆkMAP = argmaxk{p(D|X,k) p(k)},
(10.20)
where the maximization runs over all possible parameter choices.
We assume that spike counts per bin follow a conditional Poisson distribution, given
ρ(t):
nt ∼Poiss[ρ(t)dt];
(10.21)
see text and exercises of Chapter 7. For example, with the rate parameter of the Poisson
distribution given by a GLM or SRM model ρ(t) = f(k·xt), we have
p(D|X,k) = ∏
t
[ f(k·xt)dt]nt
(nt)!
exp[−f(xt ·k)dt]

.
(10.22)
Here Πt denotes the product over all time steps. We recall that, by deﬁnition, nt! = 1 for
nt = 0.
Our aim is to optimize the parameter k. For a given observed spike train, the spike count
numbers nt are ﬁxed. In this case, (dt)nt/(nt)! is a constant which is irrelevant for the

10.2 Statistical formulation of encoding models
251
parameter optimization. If we work with a ﬁxed time step dt and drop all units, we can
therefore reshufﬂe the terms and consider the logarithm of the above likelihood
log p(D|X,k) = c0 +∑
t
(ntlog f(k·xt)−f(xt ·k)dt) .
(10.23)
If we choose the time step dt shorter than the half-width of an action potential, say 1 ms,
the spike count variable nt can only take the values zero or 1. For small dt, the likelihood
of Eq. (10.22) is then identical to that of the SRM with escape noise, deﬁned in Chapter 9;
see Eqs. (9.10) and (9.15)-(9.17).
We don't have an analytical expression for the maximum of the likelihood deﬁned in
Eq. (10.22), but nonetheless we can numerically optimize this function quite easily if we
are willing to make two assumptions about the nonlinear function f(.). More precisely, if
we assume that
(i) f(u) is a convex (upward-curving) function of its scalar argument u, and
(ii) log f(u) is concave (downward-curving) in u,
then the log likelihood above is guaranteed to be a concave function of the parameter k,
since in this case the log-likelihood is just a sum of concave functions of k (Paninski, 2004).
This implies that the likelihood has no non-global maximum (also called local max-
imum). Therefore the maximum likelihood parameter ˆkML may be found by numerical
ascent techniques; see Fig. 10.2. Functions f(.) satisfying these two constraints are easy to
think of: for example, the standard linear rectiﬁer and the exponential function both work.
Fitting model parameters proceeds as follows: we form the (augmented) matrix X where
each row is now
xt = (1,It−1dt,It−2dt,...,It−Kdt,nt−1,nt−2,...,nt−J).
(10.24)
Similarly, the parameter vector is in analogy to Eq. (10.10)
k = (b,κ(dt),κ(2dt),...,κ(Kdt),η(dt),η(2dt),...,η(Jdt));
(10.25)
here b = urest −ϑ is a constant offset term which we want to optimize.
We then calculate the log-likelihood
log p(D|X,k) = ∑
t
(nt log f(Xt ·k)−f(Xt ·k)dt)
(10.26)
and compute the ML or maximum a posteriori (MAP) solution for the model parameters
k by a concave optimization algorithm. Note that, while we still assume that the condi-
tional spike count nt within a given short time bin is drawn from a one-dimensional Poiss
(ρ(t)dt) distribution given ρ(t), the resulting model displays strong history effects (since
ρ(t) depends on the past spike trains) and therefore the output of the model, considered
as a vector of counts D = {nt}, is no longer a Poisson process, unless η = 0. Importantly,
because of the refractory effects incorporated by a strong negative η at small times, the
spike count variable nt cannot take a value larger than 1 if dt is in the range of one or a few
milliseconds. Therefore, we can expect that interspike intervals are correctly reproduced in
the model; see Fig. 10.5 for an example application.

252
Estimating models
Finally, we may expand the deﬁnition of X to include observations of other spike trains,
and therefore develop GLMs not just of single spike trains, but network models of how
populations of neurons encode information jointly (Chornoboy et al., 1988; Paninski et al.,
2004; Truccolo et al., 2005; Pillow et al., 2008). The resulting model is summarized as
follows: Spike counts are conditionally Poisson distributed given ρi(t) ni,t ∼Poiss(ρi(t)dt)
with a ﬁring rate
ρi(t) = f

ki ·xt + ∑
i′̸=i, j
εi′, jni′,t−j

.
(10.27)
Here, ρi(t) denotes the instantaneous ﬁring rate of the ith cell at time t and ki is the cell's
linear receptive ﬁeld including spike-history effects; see Eq. (10.25). The net effect of a
spike of neuron i′ onto the membrane potential of neuron i is summarized by εi′, j; these
terms are summed over all past spike activity ni′,t−j in the population of cells from which
we are recording simultaneously. In the special case that we record from all neurons in
the population, εi′, j can be interpreted as the excitatory or inhibitory postsynaptic potential
caused by a spike of neuron i′ a time jdt earlier.
Example: Linear regression and voltage estimation
It may be helpful to draw an analogy to linear regression here. We want to show that
the standard procedure of least-square minimization can be linked to statistical para-
meter estimation under the assumption of Gaussian noise.
We consider the linear voltage model of Eq. (10.1). We are interested in the temporal
ﬁlter properties of the neuron when it is driven by a time-dependent input I(t). Let us set
xt = (It,It−1,...,It−K)dt and k = (κ(dt),...,κ(K dt)). If we assume that the discrete-
time voltage measurements have a Gaussian distribution around the mean predicted by
the model of Eq. (10.4), then we need to maximize the likelihood
log p(D|X,k) = c1 −c2∑
t
(ut −(k·xt))2 ,
(10.28)
where X = (x1,x2,...,xT) is the matrix of observed stimuli, c1,c2 are constants that do
not depend on the parameter k, and the sum in t is over all observed time bins. Maxi-
mization yields kopt = (XTX)−1 (∑t utxt/dt) which determines the time course of the
ﬁlter κ(s) that characterizes the passive membrane properties. The result is identical to
Eq. (10.8):
ˆkopt = ˆkLS .
(10.29)
10.2.2 Regularization: maximum penalized likelihood
In the linear regression case it is well known that estimates of the components of the para-
meter vector k can be quite noisy when the dimension of k is large. The noisiness of the
estimate ˆkML is roughly proportional to the dimensionality of k (the number of parameters

10.2 Statistical formulation of encoding models
253
k 
log P 
k 
Log-
likelihood
Prior
kML
kMAP
Log-
posterior
Log-
likelihood
Fig. 10.4 Regularization. Because of the concavity, there is only a single global maximum of the
log-likelihood which deﬁnes the optimal parameter choice kML. Right: Example of regularization by
a prior (dashed line) that favors a smaller value for kMAP.
in k that we need to estimate from data) divided by the total number of observed sam-
ples (Paninski, 2003). The same "overﬁtting" phenomenon (estimator variability increasing
with number of parameters) occurs in the GLM context. A variety of methods have been
introduced to "regularize" the estimated k, to incorporate prior knowledge about the shape
and/or magnitude of the true k to reduce the noise in ˆkML. One basic idea is to restrict k to
lie within a lower-dimensional subspace; we then employ the same ﬁtting procedure to esti-
mate the coefﬁcients of k within this lower-dimensional basis (model selection procedures
may be employed to choose the dimensionality of this subspace (Truccolo et al., 2005)).
A slightly less restrictive approach is to maximize the posterior
p(k|X,D) ∝p(D|X,k)p(k)
(10.30)
(with k allowed to take values in the full original basis), instead of the likelihood p(D|X,k);
here p(k) encodes our a priori beliefs about the true underlying k.
It is easy to incorporate this maxima a posteriori idea in the GLM context (Paninski,
2004): we simply maximize
log p(k|X,D) = c+log p(k)+log p(D|X,k)
(10.31)
= c+log p(k)+∑
t
(nt log f(xt ·k)−f(xt ·k)dt).
(10.32)
Whenever log p(k) is a concave function of k, this "penalized" likelihood (where log p(k)
acts to penalize improbable values of k) is a concave function of k, and ascent-based max-
imization may proceed (with no local maximum) as before; see Fig. 10.4.
Example: Linear regression and Gaussian prior
In the linear regression case, the computationally simplest prior is a zero-mean
Gaussian, log p(k) = c −kTAk/2, where A is a positive deﬁnite matrix (the inverse

254
Estimating models
covariance matrix). The Gaussian prior can be combined with the Gaussian noise model
of Eq. (10.28). Maximizing the corresponding posterior analytically (Sahani and Linden,
2003; Smyth et al., 2003) then leads directly to the regularized least-square estimator
ˆkRLS = (XTX +A)−1

∑
t
utxt/dt

.
(10.33)
10.2.3 Fitting generalized integrate-and-ﬁre models to data
Suppose an experimenter has injected a time-dependent current I(t) into a neuron and
has recorded with a second electrode the voltage uexp(t) of the same neuron. The voltage
trajectory contains spikes S(t) = ∑f δ(t −t f ) with ﬁring times t(1),t(2),...,t(N). The natural
approach would be to write down the joint likelihood of observing both the spike times and
the subthreshold membrane potential (Paninski et al., 2005). A simpler approach would
be to maximize the likelihood of observing the spike separately from the likelihood of
observing the membrane potential.
Given the input I(t) and the spike train S(t), the voltage of an SRM is given by Eq.
(10.9) and we can adjust the parameters of the ﬁlter κ and η so as to minimize the squared
error Eq. (10.5). We now ﬁx the parameters for the membrane potential and maximize the
likelihood of observing the spike times given our model voltage trajectory u(t). We insert
u(t) into the escape rate function ρ(t) = f(u(t)−ϑ(t)) which contains the parameters of
the threshold
ϑ(t) = ϑ0 +
 ∞
0 θ1(s)S(t −s)ds.
(10.34)
We then calculate the log-likelihood
log p(D|X,k) = c+∑
t
(nt log f(Xt ·k)−f(Xt ·k)dt)
(10.35)
and compute the ML or maximum a posteriori (MAP) solution for the model parameters
k (which are the parameters of the threshold - the subthreshold voltage parameters are
already ﬁxed) by an optimization algorithm for concave functions.
Fig. 10.5 shows an example application. Both voltage in the subthreshold regime and
spike times are nicely reproduced. Therefore, we can expect that interspike intervals are
correctly reproduced as well. In order to quantify the performance of neuron models, we
need to develop criteria of "goodness-of-ﬁt" for subthreshold membrane potential, spike
timings, and possibly higher-order spike-train statistics. This is the topic of Section 10.3;
we will return to similar applications in the next chapter.
10.2.4 Extensions (*)
The GLM encoding framework described here can be extended in a number of important
directions. We brieﬂy describe two such directions here.

10.3 Evaluating goodness-of-ﬁt
255
First, as we have described the GLM above, it may appear that the model is restricted to
including only linear dependencies on the stimulus xt, through the k·xt term. However, if
we modify our input matrix X once again, to include nonlinear transformations Fj(x) of
the stimulus x, we may ﬁt nonlinear models of the form
ρ(t) = f
!
∑
j
a jF j(x)
"
(10.36)
efﬁciently by maximizing the log-likelihood log p(D|X,a) with respect to the weight para-
meter a (Wu et al., 2006; Ahrens et al., 2008). Mathematically, the nonlinearities Fj(x)
may take essentially arbitrary form; physiologically speaking, it is clearly wise to choose
F j(x) to reﬂect known facts about the anatomy and physiology of the system (e.g., F j(x)
might model inputs from a presynaptic layer whose responses are better-characterized than
are those of the neuron of interest (Rust et al., 2006)).
Second, in many cases it is reasonable to include terms in X that we may not be able
to observe or calculate directly (e.g., intracellular noise, or the dynamical state of the net-
work); ﬁtting the model parameters in this case requires that we properly account for these
"latent," unobserved variables in our likelihood. While inference in the presence of these
hidden parameters is beyond the scope of this chapter, it is worth noting that this type of
model may ﬁt tractably using generalizations of the methods described here, at the cost
of increased computational complexity, but the beneﬁt of enhanced model ﬂexibility and
realism (Smith and Brown, 2003; Yu et al., 2009; Vidne et al., 2012).
Example: Estimating spike triggered currents and dynamic threshold
In Fig. 10.1a, we have suggested estimating the ﬁlter κ(s) by extracting its values
k j = κ( jdt) at discrete equally spaced time steps: the integral
 ∞
0 κ(s)I(t −s)ds =
∑K
j=1 klIt−jdt is linear in the K parameters.
However, the observables remain linear in the parameters (kj) if we set κ(s) = ∑4
j=1 kj
exp(−s/τj) with ﬁxed time constants, e.g., τj = 10 j ms. Again, the integral
 ∞
0 κ(s)
I(t −s)ds = ∑4
j=1 kj
 ∞
0 exp(−s/τ j)I(t −s)ds is linear in the parameters. The exponen-
tials play the role of "basis functions" Fj.
Similarly, the threshold ﬁlter ϑ1(s) or the spike-afterpotential η(s) can be expressed
with basis functions. A common choice is to take rectangular basis functions Fj which
take a value of unity on a ﬁnite interval [t j,t j+1]. Exponential spacing t j = 2 j−1ms of
time points allows us to cover a large time span with a small number of parameters.
Regular spacing leads back to the naive discretization scheme.
10.3 Evaluating goodness-of-ﬁt
No single method provides a complete assessment of goodness-of-ﬁt; rather, model ﬁtting
should always be seen as a loop, in which we start by ﬁtting a model, then examine the

256
Estimating models
{
{
Model
Neuron
0.4 nA
50 mV
Missed
extra
Time [s]
(a)
(b)
(c)
Missed Extra
Fig. 10.5 Comparing models with intracellular recordings. (a) A noisy time-dependent current is
used to stimulate the neurons experimentally (dashed line corresponds to zero current). (b) Recording
from the neuron (thin black line) shows membrane potential ﬂuctuations and action potentials. Sim-
ulating an SRM (thick black line) with the same current and using parameters previously optimized
on a different dataset shows similar membrane potential ﬂuctuations (inset) and action potentials.
Some of the spikes are missed, some are added, but most coincide with the recorded ones. (c) Mul-
tiple repeated stimulations with the same current shows the intrinsic variability of neural responses
(the ﬁrst nine rows are recorded action potentials indicated by thick black ticks). The variability is
matched by the model (the last nine rows are model action potentials). Data and models from Mensi
et al. (2012).
results, attempt to diagnose any model failures, and then improve our model accordingly.
In the following, we describe different methods for assessing the goodness-of-ﬁt.
Before beginning with speciﬁc examples of these methods, we note that it is very impor-
tant to evaluate the goodness-of-ﬁt on data that was not used for ﬁtting. The part of the
data used for ﬁtting model parameters is called the training set and the part of the data
reserved to evaluate the goodness-of-ﬁt is called the test set. Data in the test set is said to
be predicted by the model, while it is simply reproduced in the training set. By simply
adding parameters to the model, the quality of the ﬁt on the training set increases. Given a
sufﬁcient number of parameters, the model might be able to reproduce the training set per-
fectly, but that does not mean that data in the test set is well predicted. In fact it is usually
the opposite: overly complicated models that are "overﬁt" on the training data (i.e., which
ﬁt not only the reproducible signal in the training set but also the noise) will often do a bad
job generalizing and predicting new data in the test set. Thus in the following we assume
that the goodness-of-ﬁt quantities are computed using "cross-validation": parameters are
estimated using the training set, and then the goodness-of-ﬁt quantiﬁcation is performed
on the test set.

10.3 Evaluating goodness-of-ﬁt
257
10.3.1 Comparing spiking membrane potential recordings
Given a spiking membrane potential recording, we can use traditional measures such as
the squared error between model and recorded voltage to evaluate the goodness-of-ﬁt. This
approach, however, implicitly assumes that the remaining error has a Gaussian distribu-
tion (recall the close relationship between Gaussian noise and the squared error, discussed
above). Under diffusive noise, we have seen (Chapter 8) that membrane potential distri-
butions are Gaussian only when all trajectories started at the same point and none have
reached threshold. Also, a small jitter in the ﬁring time of the action potential implies a
large error in the membrane potential, much larger than the typical subthreshold membrane
potential variations. For these two reasons, the goodness-of-ﬁt in terms of subthreshold
membrane potential away from spikes is considered separately from the goodness-of-ﬁt in
terms of the spike times only.
To evaluate how the model predicts subthreshold membrane potential we must compare
the average error with the intrinsic variability. To estimate the ﬁrst of these two quantities,
we compute the squared error between the recorded membrane potential uexp
t
and model
membrane potential umod
t
with forced spikes at the times of the observed ones. Since spike
times in the model are made synchronous with the experimental recordings, all voltage
traces start at the same point. A Gaussian assumption thus justiﬁed, we can average the
squared error over all recorded times t that are not too close to an action potential:
RMSEnm =
#
$
$
%
1
TΩ1Nrep
Nrep
∑
i=1

Ω1

uexp
i
(t)−umod
i
(t)
2 dt,
(10.37)
where Ω1 refers to the ensemble of time bins at least 5 ms before or after any spikes and
TΩ1 is the total number of time bins in Ω1. RMSEnm has index n for "neuron" and index m
for "model." It estimates the error between the real neuron and the model.
To evaluate the second quantity, we compare recorded membrane potential from multiple
repeated stimulations having the same stimulus. Despite the variability in spike timings, it
is usually possible to ﬁnd times which are sufﬁciently away from a spike in any repetition
and compute the averaged squared error
RMSEnn =
#
$
$
%
2
TΩ2Nrep(Nrep −1)
Nrep
∑
i=1
i−1
∑
j=1

Ω2

uexp
j (t)−uexp
i
(t)
	2
dt,
(10.38)
where Ω2 refers to the ensemble of time bins far from the spike times in any repetition
and TΩ2 is the total number of time bins in Ω2. Typically, 20 ms before and 200 ms after
the spike is considered sufﬁciently far. Note that with this approach we implicitly assume
that spike-afterpotentials have vanished 200 ms after a spike. However, as we shall see
in Chapter 11, the spike-afterpotentials can extend for more than one second, so that the
above assumption is a rather bad approximation. Because the earlier spiking history will
affect the membrane potential, the RMSEnn calculated in Eq. (10.38) is an overestimate.
To quantify the predictive power of the model, we ﬁnally compute the model error with

258
Estimating models
the intrinsic error by taking the ratio
RMSER = RMSEnn
RMSEnm
.
(10.39)
The root-mean-squared-error ratio (RMSER) reaches 1 if the model precision is matched
with intrinsic error. When smaller than 1, the RMSER indicates that the model could be
improved. Values larger than 1 are possible because RMSEnn is an overestimate of the true
intrinsic error.
10.3.2 Spike train likelihood
The likelihood is the probability of generating the observed set of spike times S(t) with
the current set of parameters in our stochastic neuron model. It was deﬁned in Eq. (9.10),
which we reproduce here
Ln(S|θ) = ∏
t(i)∈S
ρ(t(i)|S,θ) exp

−
 T
0 ρ(s|S,θ)ds

,
(10.40)
where we use ρ(t(i)|S,θ) to emphasize that the ﬁring intensity of a spike at t(i) depends on
both the stimulus and spike history as well as the model parameters θ.
The likelihood Ln is a conditional probability density and has units of inverse time to the
power of n (where n is the number of observed spikes). To arrive at a more interpretable
measure, it is common to compare Ln with the likelihood of a homogeneous Poisson model
with a constant ﬁring intensity ρ0 = n/T, i.e., a Poisson process which is expected to
generate the same number of spikes in the observation interval T. The difference in log-
likelihood between the Poisson model and the neuron model is ﬁnally divided by the total
number n of observed spikes in order to obtain a quantity with units of "bits per spike":
1
n log2
Ln(S|θ)
ρn
0e−ρT .
(10.41)
This quantity can be interpreted as an instantaneous mutual information between the spike
count in a single time bin and the stimulus given the parameters. Hence, it is interpreted
as a gain in predictability produced by the set of model parameters θ. One advantage of
using the log-likelihood of the conditional ﬁring intensity is that it does not require multiple
stimulus repetitions. It is especially useful to compare on a given dataset the performances
of different models: better models achieve higher cross-validated likelihood scores.
10.3.3 Time-rescaling theorem
For a spike train with spikes at t1 < t2 < ... < tn and with ﬁring intensity ρ(t|S,θ), the
time-rescaling transformation t →Λ(t) is deﬁned as
Λ(t) =
 t
0 ρ(x|S,θ)dx.
(10.42)

10.3 Evaluating goodness-of-ﬁt
259
(a)
Quantiles
Cumulative distrib.
(b)
Quantiles
Cumulative distrib.
Fig. 10.6 Time-rescaling theorem as a goodness-of-ﬁt. Illustrating the K-S test by plotting the cumu-
lative probability of zk as a function of quantiles. (a) Rescaling time using an inadequate model does
not result in a uniform distribution of zk as can be seen by comparing the empirical distribution (thick
black line) with the diagonal. Dashed lines illustrate 95% conﬁdence bounds. (b) As in (a) but with a
better rescaling of time. The empirical distribution follows the cumulative of the uniform distribution
within the conﬁdence bounds.
It is a useful and somewhat surprising result that Λ(tk) (evaluated at the measured ﬁring
times) is a Poisson process with unit rate (Brown et al., 2002). A correlate of this time-
rescaling theorem is that the time intervals
Λ(tk)−Λ(tk−1)
(10.43)
are independent random variables with an exponential distribution (see Chapter 7). Re-
scaling again the time axis with the transformation
zk = 1−exp

−

Λ(tk)−Λ(tk−1)
	
(10.44)
forms independent uniform random variables on the interval zero to 1.
Therefore, if the model ρ(t|S,θ) is a valid description of the spike train S(t), then the
resulting zk should have the statistics of a sequence of independent uniformly distributed
random variables. As a ﬁrst step, one can verify that the zks are independent by looking at
the serial correlation of the interspike intervals or by using a scatter plot of zk+1 against zk.
Testing whether the zks are uniformly distributed can be done with a Kolmogorov-Smirnov
(K-S) test. The K-S statistic evaluates the distance between the empirical cumulative dis-
tribution function of zk, P(z), and the cumulative distribution of the reference function. In
our case, the reference function is the uniform distribution, so that its cumulative is simply
z. Thus,
D = sup
z
|P(z)−z|.
(10.45)
The K-S statistic converges to zero as the empirical probability P(z) converges to the
reference. The K-S test then compares D with the critical values of the Kolmogorov dis-
tribution. Figure 10.6 illustrates two examples: one where the empirical distribution was

260
Estimating models
||S2 − S3||2
S2
S2
S3
S3
S1
S1
(a)
(b)
Fig. 10.7 Distance and angular separation between spike trains seen as vectors. (a) Three
schematic spike trains where the ﬁrst two have the same number of spikes and roughly the same tim-
ing. (b) The spike trains in (a) can be represented as vectors where S1 and S2 have the same length
but a slightly different orientation due to small differences in spike timing. The third spike train S3 is
much longer due to the larger number of spikes. It is at a squared distance D23 = ||S2 −S3||2 from S2
and at angle θ.
far from a uniform distribution and the other where the model rescaled time correctly. See
(Gerhard et al., 2011) for a multivariate version of this idea that is applicable to the case
of coupled neurons. To summarize, the time-rescaling theorem along with the K-S test
provide a useful goodness-of-ﬁt measure for spike train data with conﬁdence intervals that
does not require multiple repetitions.
10.3.4 Spike-train metric
Evaluating the goodness-of-ﬁt in terms of log-likelihood or the time-rescaling theorem
requires that we know the conditional ﬁring intensity ρ(t|S,θ) accurately. For biophysical
models as seen in Chapter 2 but complemented with a source of variability, the ﬁring inten-
sity is unavailable analytically. The intensity can be estimated numerically by simulating
the model with different realizations of noise, or by solving a Fokker-Planck equation, but
this is sometimes impractical.
Another approach for comparing spike trains involves deﬁning a metric between spike
trains. Multiple spike timing metrics have been proposed, with different interpretations. A
popular metric was proposed by Victor and Purpura (1996). Here, we describe an alterna-
tive framework for the comparison of spike trains that makes use of vector space ideas,
rather than more general metric spaces.
Let us consider spike trains as vectors in an abstract vector space, with these vectors
denoted with boldface: S. A vector space is said to have an inner (or scalar) product if for
each vector pair Si and S j there exists a unique real number (Si,Sj) satisfying the follow-
ing axioms: commutativity, distributivity, associativity, and positivity. There are multiple
candidate inner products satisfying the above axioms. The choice of inner product will be
related to the type of metric being considered. For now, consider the general form
(Si,Sj) =
 T
0
 ∞
−∞
 ∞
−∞KΔ(s,s′)Si(t −s)Sj(t −s′)dsds′dt,
(10.46)

10.3 Evaluating goodness-of-ﬁt
261
...
...
(a)
(b)
S1
SN
S2
Fig. 10.8 The spike density vector. (a) A set of N spike trains (S1, S2, ..., SN) is combined to yield an
estimate of the spike density ˆν. At the limit N →∞the spike density converges to the instantaneous
ﬁring rate ν. (b) Schematic representation of the quantities in (a). The variability V measures the
scatter of the individual spike trains around their mean ˆνX.
where KΔ is a two-dimensional coincidence kernel with a scaling parameter Δ, and T is
the maximum length of the spike trains. Here KΔ is required to be a non-negative func-
tion with a global maximum at s = s′ = 0. Moreover, KΔ(s,s′) should fall off rapidly so
that KΔ(s,s′) ≈0 for all s,s′ > Δ. Examples of kernels include KΔ(s,s′) = k1(s)k2(s′). For
instance, k1(s) = k2(s) = 1
Δe−s/ΔΘ(s) is a kernel that was used by van Rossum (2001). The
scaling parameter Δ must be small, much smaller than the length T of the spike train.
For a comparison of spike trains seen as vectors the notions of angular separation, dis-
tance, and norm of spike trains are particularly important. The squared norm of a spike
train will be written ||Si||2 = (Si,Si). With KΔ(s,s′) = δ(s)δ(s′), we observe that (Si,Si) =
 T
0 Si(t)dt = ni where ni is the number of spikes in Si. Therefore the norm of a spike train
is related to the total number of spikes it contains. The Victor and Purpura metric is of a
different form than the form discussed here, but it has similar properties (see exercies).
The norm readily deﬁnes a distance, Di j, between two spike trains
D2
i j = ||Si −S j||2 = (Si −S j,Si −S j) = ||Si||2 +||Sj||2 −2(Si,Sj).
(10.47)
The right-hand side of Eq. (10.47) shows that that the distance between two spike trains is
maximum when (Si,Sj) is zero. On the other hand, D2
i j becomes zero only when Si = S j.
This implies that (Si,Sj) = (Si,Si) = (S j,Sj). Again consider KΔ(s,s′) = δ(s)δ(s′), then
Di j is the total number of spikes in both Si and S j reduced by 2 for each spike in Si that
coincided with one in Sj. For the following, it is useful to think of a distance between spike
trains as a number of non-coincident spikes.
The cosine of the angle between Si and S j is
cosθi j =
(Sj,Si)
||Si||||Sj||.
(10.48)
This angular separation relates to the fraction of coincident spikes. Fig. 10.7 illustrates the
concepts of angle and distance for spike trains seen as vectors.

262
Estimating models
-
||
||
2
(a)
(b)
Fig. 10.9 Distance and angular separation between spike densities. (a) Two spike densities corre-
sponding to a sum of spike trains labeled X and Y. (b) Schematic representation of the densities ˆνX
and ˆνY seen as vectors. Both are separated by a distance ||ˆνX −ˆνY ||2 and angle θ. The variability is
shown as a gray cloud centered on the vectors.
10.3.5 Comparing sets of spike trains
Metrics such as Di j described above can quantify the similarity between two spike trains.
In the presence of variability, however, a simple comparison of spike trains is not sufﬁcient.
Instead, the spike train similarity measure must be maximally sensitive to differences in the
underlying stochastic processes.
We want to know if spike trains generated from a neuron model could well have been
generated by a real neuron. We could simply calculate the distance between a spike train
from the neuron and a spike train from the model, but neurons are noisy and we will ﬁnd
a different distance each time we repeat the recording. To achieve better statistics, we can
compare a set of spike trains from the model with a set of spike trains from the neuron.
Let the two sets of spike trains be denoted by X and Y, containing NX and NY spike
trains, respectively. First, it is useful to deﬁne some characteristics of such sets of spike
trains. A natural quantity to consider is the average of the norms of each spike train within
a set, say X,
ˆLX = 1
NX
NX
∑
i=1
||S(x)
i ||2,
(10.49)
where we have used ˆ to denote that the quantity is an experimental estimate. We note
that ˆLX is related to the averaged spike count. LX is exactly the averaged spike count if
the inner product satisﬁes (i)
  KΔ(s,s′)dsds′ = 1 and (ii) KΔ(s,s′) = 0 whenever |s−s′|
is greater than the minimum interspike interval of any of the spike trains considered. The
interpretation LX ∼spike count is helpful for the discussion in the remainder of this section.
Furthermore, the vector of averaged spike trains,
ˆνX = 1
NX
NX
∑
i=1
S(x)
i ,
(10.50)
is another occurrence of the spike density seen in Chapter 7. It deﬁnes the instantaneous
ﬁring rate of the the spiking process, ν(t) = ⟨ˆν⟩. In the vector space, ˆνX can be thought of
as lying at the center of the spike trains seen as vectors (Fig. 10.9); note that other "mean

10.4 Closed-loop stimulus design
263
spike trains" could be deﬁned (Wu and Srivastava, 2012). The size of the cloud quantiﬁes
the variability in the spike timing. The variability is deﬁned as the variance
ˆVX =
1
NX −1
NX
∑
i=1
||S(x)
i
−ˆνX||2.
(10.51)
A set of spike trains where spikes always occur at the same times has low variability. When
the spikes occur with some jitter around a given time, the variability is larger. Variability
relates to reliability. While variability is a positive quantity that cannot exceed LX, relia-
bility is usually deﬁned between zero and 1, where 1 means perfectly reliable spike timing:
ˆRX = 1−ˆVX/ˆLX .
Finally, we come to a measure of match between the set of spike trains X and Y. The
discussion in Chapter 7 about the neural code would suggest that neuron models should
reproduce the detailed time structure of the PSTH. We therefore deﬁne
ˆM =
2(ˆνX, ˆνY )
ˆRX ˆLX + ˆRY ˆLY
.
(10.52)
We have M (for match) equal to 1 if X and Y have the same instantaneous ﬁring rate.
The smaller M is, the greater the mismatch between the spiking processes. The quantity
RXLX can be interpreted as a number of reliable spikes. Since (ˆνX, ˆνY ) is interpreted as a
number of coincident spikes between X and Y, we can still regard M as a factor counting
the fraction of coincident spikes. A similar quantity can be deﬁned for metrics that cannot
be cast into an inner product (Naud et al., 2011).
If the kernel KΔ(s,s′) is chosen to be kg(s)kg(s′) and kg is a Gaussian distribution of
width Δ, then M relates to a mean square error between PSTHs that were ﬁltered with kg.
Therefore, the kernel used in the deﬁnition of the inner product (Eq. (10.46)) can be related
to the smoothing ﬁlter of the PSTH (see Exercises).
10.4 Closed-loop stimulus design
In the previous sections we have developed robust and tractable approaches to understand
neural encoding, based on GLMs, and quantifying the performance of models. The frame-
work we have developed is ultimately data-driven; both our encoding and decoding meth-
ods fail if the observed data do not sufﬁciently constrain our encoding model parameters θ.
Therefore we will close by describing how to take advantage of the properties of the GLM
to optimize our experiments: the objective is to select, in an online, closed-loop manner,
the stimuli that will most efﬁciently characterize the neuron's response properties.
An important property of GLMs is that not all stimuli will provide the same amount of
information about the unknown coefﬁcients k. As a concrete example, we can typically
learn much more about a visual neuron's response properties if we place stimulus energy
within the receptive ﬁeld, rather than "wasting" stimulus energy outside the receptive ﬁeld.
To make this idea more rigorous and generally applicable, we need a well-deﬁned objec-
tive function that will rank any given stimulus according to its potential informativeness.

264
Estimating models
Numerous objective functions have been proposed for quantifying the utility of different
stimuli (Mackay, 1992; Nelken et al., 1994; Machens, 2002). When the goal is estimating
the unknown parameters of a model, it makes sense to choose stimuli xt which will on aver-
age reduce the uncertainty in the parameters θ as quickly as possible (as in the game of 20
questions), given D = {x(s),ns}s<t, the observed data up to the current trial. This posterior
uncertainty in θ can be quantiﬁed using the information-theoretic notion of "entropy"; see
Cover and Thomas (1991), Mackay (1992), Paninski (2005) for further details.
In general, information-theoretic quantities such as the entropy can be difﬁcult to com-
pute and optimize in high-dimensional spaces. However, Lewi et al. (2009) show that the
special structure of the GLM can be exploited (along with a Gaussian approximation to
p(θ|D)) to obtain a surprisingly efﬁcient procedure for choosing stimuli optimally in many
cases. Indeed, a closed-loop optimization procedure leads to much more efﬁcient experi-
ments than does the standard open-loop approach of stimulating the cell with randomly
chosen stimuli that are not optimized adaptively for the neuron under study.
A common argument against online stimulus optimization is that neurons are highly
adaptive: a stimulus which might be optimal for a given neuron in a quiescent state may
quickly become suboptimal due to adaptation (in the form of short- and long-term synap-
tic plasticity, slow network dynamics, etc.). Including spike-history terms in the GLM
allows us to incorporate some forms of adaptation (particularly those due to intrinsic pro-
cesses including, for example, sodium channel inactivation and calcium-activated potas-
sium channels), and these spike-history effects may be easily incorporated into the deriva-
tion of the optimal stimulus (Lewi et al., 2009). However, extending these results to models
with more profound sources of adaptation is an important open research direction; see Lewi
et al. (2009) and DiMattina and Zhang (2011) for further discussion.
10.5 Summary
With modern statistical methods, we have fast and computationally tractable schemes to ﬁt
models of neural encoding and decoding to experimental data. A key insight is that, for a
suitable chosen model class, the likelihood of the data being generated by the model is a
concave function of the model parameters, i.e., there are no local maxima. Because of this,
numerical methods of gradient ascent are bound to lead to the global maximum.
Generalized Linear Models (GLMs) are the representative of this model class. Impor-
tantly, a large ensemble of generalized integrate-and-ﬁre models, in particular the SRM
with escape noise, belong to the family of GLMs. As we have seen in previous chap-
ters, the SRM can account for a large body of electrophysiological data and ﬁring patterns
such as adaptation, burst ﬁring, time-dependent ﬁring threshold, hyperpolarizing spike-
afterpotential, etc. The link from SRM to GLM implies that there are systematic and com-
putationally fast methods to ﬁt biologically plausible neuron models to data.
Interestingly, once neuron models are phrased in the language of statistics, the problems
of coding and stimulus design can be formulated in a single uniﬁed framework. In the

10.5 Summary
265
following chapter we shall see that the problem of decoding can also be analyzed in the
same statistical framework.
Literature
An early application of maximum likelihood approaches to neuronal data can be found
in Brillinger (1988). The application of the framework of Generalized Linear Models to
the ﬁeld of neuroscience has been made popular by Truccolo et al. (2005) and Pillow
et al. (2008). A review of Generalized Linear Models can be found in Dobson and Barnett
(2008).
The inﬂuential book Rieke et al. (1997) gives a broad introduction to the ﬁeld of neural
coding. The time-rescaling theorem was exploited by Brown et al. (2002) to develop useful
goodness-of-ﬁt methods for spike trains. Spike-train metrics were introduced in Victor and
Purpura (1996, 1997), but comparisons of spike trains in terms of PSTHs and other fea-
tures has been commonly used before (Perkel et al., 1967a,b; Gerstein and Perkel, 1972;
MacPherson and Aldridge, 1979; Eggermont et al., 1983; Gawne et al., 1991). Many other
spike-train distances were also proposed (Kistler et al., 1997; van Rossum, 2001; Quiroga
et al., 2002; Hunter and Milton, 2003; Schreiber et al., 2003; Naud et al., 2011) which
can be cast in the general framework of a vector space as outlined in Schrauwen and
Campenhout (2007), Paiva et al. (2009a) and Naud et al. (2011); see also Paiva et al.
(2009b, 2010) and Park et al. (2012). Nonlinear functions of the spike trains can also be
used to relate to different features of the spiking process such as the interval distribution
or the presence of deﬁnite ﬁring patterns (Victor and Purpura, 1996; Quiroga et al., 2002;
Tiesinga, 2004; Kreuz et al., 2007, 2009; Druckmann et al., 2007).
Exercises
1. Concave function and non-global optima
(a) Suppose a function G(x) has a global maximum at location x0. Suppose that f(y) is a
strictly increasing function of y (i.e., df/dy > 0).
Show that f(G(x)) has a maximum at x0. Is it possible that f(G(x)) has further maxima as a
function of x?
(b) A strictly concave function G can be deﬁned as a curve with negative curvature d2G/dx2 <
0 for all x. Show that a concave function can have at most one maximum.
(c) Give an example of a concave function which does not have a maximum. Give an example
of a function G which has a global maximum, but is not concave. Give an example of a function
G which is concave and has a global maximum.
2. Sum of concave functions. Consider a quadratic function fk(x) = 1−(x−ϑk)2.
(a) Show that fk is a concave function of x for any choice of parameter ϑk.
(b) Show that f1(x)+ f2(x) is a concave function.
(c) Show that ∑k bk fk(x) with bk > 0 is a concave function.
(d) Repeat the steps (b) and (c) for a family of functions fk which are concave, but not neces-
sarily quadratic.
3. Comparing PSTHs and spike train similarity measures. Experimentally the PSTH is con-
structed from a set of Nrep spike trains, Si(t), measured from repeated presentations of the same

266
Estimating models
stimulus. The ensemble average of the recorded spike trains:
1
Nrep
Nrep
∑
i=1
Si(t)
(10.53)
is typically convolved with a Gaussian function hg(x) = (2πσ2)−1/2 exp

−x2/2σ2
with σ
around 5 ms, such that A1(t) = (hg ∗
1
Nrep ∑Si)(t) is a smoothed PSTH. Suppose that two sets
of experimental spike trains were recorded in two different conditions, resulting in two smoothed
PSTHs A1(t) and A2(t).
(a) Show that the sum of the squared error (A1(t)−A2(t))2 can be written as a distance between
sets of spike train D2 with the kernel K(t,t′) = hg(t)hg(t′).
(b) Recall that the correlation coefﬁcient between datasets x and y is
c = cov(x,y)/

cov(x,x)cov(y,y).
(10.54)
Show that the correlation coefﬁcient between the two smoothed PSTHs can be written as a angu-
lar separation between the sets of spike trains with kernel K(t,t′) = hg(t)hg(t′).
4. Victor and Purpura metric. Consider the minimum cost C required to transform a spike train
Si into another spike train Sj if the only transformations available are:
- removing a spike has a cost of 1,
- adding a spike has a cost of 1,
- shifting a spike by a distance d has a cost qd where q is a parameter deﬁning temporal preci-
sion.
The C deﬁnes a metric that measures the dissimilarity between spike train Si and spike train Sj.
The smaller C is the more alike the spike trains are in terms of spike timing.
(a) For q = 0 units of cost per seconds, show that C becomes the difference in number of spikes
in spike trains Si and Sj.
(b) For q greater than four times the maximum ﬁring frequency (i.e., the inverse of the short-
est observed interspike interval), show that C can be written as a distance D2
ij with kernel
K(t,t′) = ht(t)δ(t′) and triangular function ht(t) = (1 −|t|q/2)Θ(1 −|t|q/2) where δ(·) is the
Dirac delta function and Θ(·) is the Heaviside function.

11
Encoding and decoding with stochastic neuron models
In the ten preceding chapters, we have come a long way: starting from the biophysical basis
of neuronal dynamics we arrived at a description of neurons that we called generalized
integrate-and-ﬁre models. We have seen that neurons contain multiple types of ion chan-
nels embedded in a capacitive membrane (Chapter 2). We have seen how basic principles
regulate the dynamics of electrical current and membrane potential in synapses, dendrites
and axons (Chapter 3). We have seen that sodium and potassium ion channels form an
excitable system characterized by a threshold mechanism (Chapter 4) and that other ion
channels shape the spike after-effects (Chapter 6). Finally, we have seen in Chapters 4,
5 and 6 how biophysical models can be reduced by successive approximations to other,
simpler, models such as the LIF, EIF, AdEx, and SRM. Moreover, we have added noise to
our neuron models (Chapters 7 and 9). At this point, it is natural to step back and check
whether our assumptions were too stringent, whether the biophysical assumptions were
well-founded, and whether the generalized models can explain neuronal data. We laid out
the mathematical groundwork in Chapter 10; we can now set out to apply these statistical
methods to real data.
We can test the performance of these, and other, models by using them as predictive
models of encoding. Given a stimulus, will the model be able to predict the neuronal
response? Will it be able to predict spike times observed in real neurons when driven by the
same stimulus - or only the mean ﬁring rate or PSTH? Will the model be able to account
for the variability observed in neuronal data across repetitions?
Testing the performance of models addresses an even bigger question. What information
is discarded in the neural code? What features of the stimulus are most important? If we
understand the neural code, will we be able to reconstruct the image that the eye is actu-
ally seeing at any given moment from spike trains observed in the brain? The problem of
decoding neuronal activity is central both for our basic understanding of neural informa-
tion processing (Rieke et al., 1997) and for engineering "neural prosthetic" devices that
can interact with the brain directly (Donoghue, 2002). Given a spike train observed in the
brain, can we read out intentions, thoughts, or movement plans? Can we use the data to
control a prosthetic device?
In Section 11.1 we use the generalized integrate-and-ﬁre models of Chapters 6 and 9
to predict membrane voltage and spike timings of real neurons during stimulation with an

268
Encoding and decoding with stochastic neuron models
arbitrary time-dependent input current in vitro. In Section 11.2, we use the same model
class to predict spike timings in vivo. Finally, in Section 11.3 we examine the question
of decoding: given a measured spike train can we reconstruct the stimulus, or control a
prosthetic arm?
11.1 Encoding models for intracellular recordings
We will focus the discussion on generalized integrate-and-ﬁre models with escape noise,
also called soft-threshold integrate-and-ﬁre models (Fig. 10.3a). The vast majority of stud-
ies achieving good predictions of voltage and spike timing use some variant of this model.
The reasons lie in the model's ease of optimization and in its ﬂexibility; see Chapter 6.
Also, the possibility of casting them into the GLM formalism allows efﬁcient parameter
optimization; see Chapter 10. In Section 11.1.1 we use the SRM as well as soft-threshold
integrate-and-ﬁre models to predict the subthreshold voltage of neurons in slices driven
by a time-dependent external current. We then use these models to also predict the spike
timings of the same neurons (Section 11.1.2).
11.1.1 Predicting membrane potential
The SRM describes somatic membrane potential in the presence of an external current
(Section 6.4)
u(t) = ∑
f
η(t −t f )+
 ∞
0 κ(s)Iext(t −s)ds+urest.
(11.1)
The parameters of this model deﬁne the functional shape of the functions η(t) and κ(t).
Other parameters such as threshold or, in a stochastic model, the sharpness of threshold
β do not contribute to the mean squared error of the membrane potential as deﬁned in
Section 10.3.1. Following the methods of Chapter 10, we can estimate the functions κ(t)
and η(t) from recordings of cortical neurons. We note that the spike-afterpotential has
units of voltage, whereas the membrane ﬁlter κ has units of resistance over time.
Using in vitro intracellular recordings of cells in layer 2-3 of the somatosensory cortex,
Mensi et al. (2012) optimized the functions κ(t) and η(t) on the recorded potential. For
both the main type of excitatory neurons and the main type of inhibitory neurons, the mem-
brane ﬁlter κ(t) is well described by a single exponential (Fig. 11.1a). Different cell types
have different amplitudes and time constants. The inhibitory neurons are typically faster,
with a smaller time constant than the excitatory neurons, suggesting we could discriminate
between excitatory and inhibitory neurons in terms of the shape of κ(t). Discrimination of
cell types, however, is much improved when we take into account the spike-afterpotential.
The shape of η(t) in inhibitory cells is very different than that in excitatory ones
(Fig. 11.1b ).
While the spike-afterpotential is a monotonically decreasing function in the excitatory
cells, in the inhibitory cells the function η(t) is better ﬁtted by two exponentials of opposite

11.1 Encoding models for intracellular recordings
269
0
10
20
30
40
50
60
Time [ms]
0
1
2
3
4
5
6
κ [MΩ/ms]
κI(t) = 6e−t/9
κE(t) = 4.5e−t/18
(a)
0
50 100 150 200 250 300 350
Time [ms]
−3
−2
−1
0
1
2
η [mV]
ηI(t) = 3e−t/9 −8e−t/37 + 4e−t/62
ηE(t) = 7(e−t/18 −e−t/45)
(b)
Fig. 11.1 Parameters of voltage recordings in the main excitatory and inhibitory neuron type of
cortical layer 2-3. (a) Membrane ﬁlter for the main excitatory cell type κE(t) and the fast-spiking
inhibitory cell type κI(t). (b) Spike-afterpotential for the main excitatory cell type ηE(t) and the
main inhibitory cell type ηI(t). Equations have units of ms for time, mV for η and MΩ/ms for κ.
Modiﬁed from Mensi et al. (2012).
polarity. This illustrates that different cell types differ in the functional shape of the spike-
afterpotential η(t). This ﬁnding is consistent with the predictions of Chapter 6 where
we discussed the role of different ion channels in shaping η(t). Similar to Fig. 6.14, the
spike-afterpotential of inhibitory neurons is depolarizing 30-150 ms after the spike time,
another property providing fast-spiking dynamics. Therefore, we conclude that the spike-
afterpotential of inhibitory neurons has an oscillatory component.
Once the parameters have been extracted from a ﬁrst set of data, how well does the
neuron model predict membrane potential recordings? Qualitatively, we have already seen
in Chapter 10 (Fig. 10.5) an example of a typical prediction. Quantitatively, the membrane
potential ﬂuctuations of the inhibitory and excitatory neuron have a RMSER (Eq. (10.39))
below one, meaning that the prediction error is smaller than our estimate of the intrinsic
error. This indicates that our estimate of the intrinsic error is slightly too large, probably
because the actual spike-afterpotential is even longer than a few hundred milliseconds - as
we shall see below.
Subthreshold mechanisms that can lead to a resonance (Chapter 6) would cause κ(t) to
oscillate in time. Mensi et al. (2012) have tested for the presence of a resonance in κ(t)
and found none. Using two exponentials to model κ(t) does not improve the prediction
of subthreshold membrane potential. Thus, the membrane potential ﬁlter is well described
by a single exponential with time constant τm = RC where R is the passive membrane
resistance and C the capacity of the membrane. If we set κ(s) = (1/C)exp(−s/τm), we
can take the derivative of Eq. (11.1) and write it in the form of a differential equation
Cdu(t)
dt
= −1
R(u−urest)+∑
f
˜η(t −t f )+Iext(t),
(11.2)
where ˜η(s) is the time course of the net current triggered after a spike.

270
Encoding and decoding with stochastic neuron models
Fig. 11.2 Voltage prediction. Goodness-of-ﬁt of
voltage recordings in the main excitatory and
inhibitory neuron types of cortical layer 2-3.
RMSER (see Chapter 10) for generalized soft-
threshold integrate-and-ﬁre models of excitatory
and inhibitory neurons (black bars). The gray bars
indicate models where the spike-afterpotential is
mediated by a spike-triggered change in conduc-
tance instead of current. Modiﬁed from Mensi
et al. (2012).
We have seen in Chapters 2 and 6 that spike-triggered adaptation is mediated by ion
channels that change the conductance of the membrane. Biophysics would therefore sug-
gest a spike-triggered change in conductance, such that after every spike the total current
that can charge the membrane capacitance is
Cdu
dt ∝ηC(t −ˆt)(u−Erev),
(11.3)
where ηC is the spike-triggered change in conductance and Erev its reversal potential. The
reversal potential and the time course ηC can be optimized to yield the best goodness-of-
ﬁt. In the excitatory neurons, the resulting conductance change follows qualitatively the
current-based ˜η(t). The prediction performance, however, is not signiﬁcantly improved
(Fig. 11.2), indicating that describing spike after-effects in terms of current is a good
assumption.
11.1.2 Predicting spikes
Using the same intracellular recordings as in Fig. 11.1 (Mensi et al., 2012), we now ask
whether spike ﬁring can be predicted from the model. The results of the previous sub-
section provide us with the voltage trajectory u(t) of the generalized integrate-and-ﬁre
model. Assuming a moving threshold that can undergo a stereotypical change at every
spike ϑ(t) = ϑ0 + ∑f θ1(t −t f ) we can model the conditional ﬁring intensity as follows,
given the spike train, S (compare Eq. (9.27))
ρ(t|S) = 1
τ0
exp

β
!
u(t)−ϑ0 −∑
t f ∈S
θ1(t −t f )
"
.
(11.4)
Since the parameters regulating u(t) were optimized using the subthreshold membrane
potential in Section 11.1.1, the only free parameters left are those of the threshold, i.e., ϑ0,
β, and the function θ1(t). Once the function θ1 is expanded in a linear combination of basis
functions, maximizing the likelihood Eq. (10.40), can be done through a convex gradient
descent because Eq. (11.4) can be cast into a GLM.

11.1 Encoding models for intracellular recordings
271
0
50 100 150 200 250 300 350
Time [ms]
0
2
4
6
8
10
12
14
θ1 [mV]
θ1(t) = 0
θ1(t) = 12e−t/37 + 2e−t/500
(a)
M
(b)
Fig. 11.3 Parameters and spike time prediction in the main excitatory and inhibitory neuron type
of cortical layer 2-3. (a) Moving threshold for the main excitatory cell type was found to be an
exponentially decaying function (top curve and equation). For the main inhibitory cell type, the ﬁtted
moving threshold was not signiﬁcantly different from zero (bottom curve and equation). Equations
have units of ms for time and mV for θ1. (b) The spike-timing prediction in terms of the similarity
measure M (Eq. (10.52)) for models with the moving threshold (black bars) and without the moving
threshold (gray bars). Modiﬁed from Mensi et al. (2012).
Is the dynamic threshold necessary? Optimizing the parameters on a training dataset, we
ﬁnd no need for a moving threshold in the inhibitory neurons (Fig. 11.3a). The threshold in
those cells is constant in time. However, the excitatory cells have a strongly moving thresh-
old (Fig. 11.3a) which is characterized by at least two decay time constants. A moving
threshold can have several potential biophysical causes. Inactivation of sodium channels is
a likely candidate (Fleidervish et al., 1996).
How good is the prediction of spike times in inhibitory and excitatory cortical neurons?
Qualitatively, the model spike trains resemble the recorded ones with a similar intrinsic
variability (Fig. 10.5). Quantitatively, Mensi et al. (2012) used the measure of match M
(see Eq. (10.52)) and K(t,t′) = Θ(t + Δ)Θ(Δ −t)δ(t′) with Δ = 4 ms. They found
M = 87% for the inhibitory neurons and M = 81% for the excitatory neurons (Fig. 11.3b).
Intuitively, this result means that these models predict more than 80% of the "predictable"
spikes.
These numbers are averaged over a set of cells. Some cells were predicted better than
others such that the M reached 95% for inhibitory neurons and 87% for excitatory neurons.
Similar results are found in excitatory neurons of layer 5. Spikes from these neurons can be
predicted with M = 81% on average (Pozzorini et al., 2013). Other optimization methods
but with similar models could improve the spike-timing prediction of inhibitory neurons,
reaching M =100% for some cells (Kobayashi et al., 2009). Thus, the case of inhibitory
neurons seems well resolved. The almost perfect match between predicted and experimen-
tal spike trains leaves little place for model reﬁnement. Unless the stimulus is speciﬁcally

272
Encoding and decoding with stochastic neuron models
designed to probe bursting or postinhibitory rebound, the generalized integrate-and-ﬁre
model is a sufﬁcient description of the fast-spiking inhibitory neuron.
One important feature of the model for spike-timing prediction is adaptation. Optimiz-
ing a generalized integrate-and-ﬁre model with refractory effects but no adaptation reduces
the prediction performance by 20-30% (Jolivet et al., 2008b), for both the excitatory and
inhibitory cortical cells. How long do the effects of spike-triggered adaptation last? Sur-
prisingly, a single spike has a measurable effect more than 10 seconds after the action
potential has occurred (Fig. 11.4). Thus, adaptation is not characterized by a single time
scale (Lundstrom et al., 2008) and shows up as a power-law decay in both spike-triggered
current and threshold (Pozzorini et al., 2013).
11.1.3 How good are generalized integrate-and-ﬁre models?
For excitatory neurons, a value of M = 81% implies that there remains nevertheless 19%
unexplained PSTH variance. Using state-of-the-art model optimization for a full biophys-
ical model with ion channels and extended dendritic tree does not improve the model per-
formance (Druckmann et al., 2007). Considering a dependence on the voltage derivative
in the escape rate (Chapter 9) can slightly improve the performance (Kobayashi and Shi-
nomoto, 2007) but is not sufﬁcient to achieve a ﬂawless prediction. Similarly, taking into
account very long spike-history effects (Fig. 11.4) and experimental drifts improves mostly
the prediction of time-dependent rate performance on long time scales, and only slightly
spike-time prediction at short time scales (Pozzorini et al., 2013). Overall, the situation
gives the impression that a mechanism might be missing in the generalized integrate-and-
ﬁre model and perhaps in the biophysical description as well.
Nevertheless, more than 80% of PSTH variance is predicted by generalized soft-threshold
integrate-and-ﬁre models during current injection into the soma. This result holds for a
time-dependent current which changes on fast as well as slow time scales - a challenging
scenario. The effective current driving single neurons in an awake animal in vivo might
have comparable characteristics in that it comprises slow ﬂuctuations of the mean as well
as fast ﬂuctuations (Crochet et al., 2011; Pozzorini et al., 2013). Similarly, the net driving
current in connected model networks (see Part III), typically also shows ﬂuctuations around
a mean value that changes on a slower time scale. Taken together, generalized integrate-
and-ﬁre models are valid models in the physiological input range observed in vivo, and are
good candidates for large-scale network simulation and analysis.
Linear dendritic effects show up in the membrane ﬁlter and spike-afterpotential; but
strongly nonlinear dendrites as observed with multiple recordings from the same neuron
(Larkum et al., 2001) cannot be accounted for by a generalized soft-threshold integrate-
and-ﬁre model or GLM. If nonlinear interactions between different current injection sites
along the dendrite are important, a different class of neuron models needs to be considered
(Chapter 3).

11.2 Encoding models in systems neuroscience
273
Spike-triggered current [nA]
Time [s]
(a)
Time [s]
Moving Threshold [mV]
(b)
Fig. 11.4 Long spike after-effects in excitatory cortical cells of the layer 5. (a) The spike-triggered
current ﬁtted on the membrane potential of layer 5 pyramidal neurons is shown as a function of
time since spike emission. Although the effect of a spike appears to be over after a few tens of
milliseconds, the log-log scale (inset) reveals that the spike after-current decays with a power law
˜η(t) ∝−t−0.8 over four orders of magnitude. (b) The moving threshold ﬁtted on the spike timing
of layer 5 pyramidal neurons is shown as a function of time since spike emission. As in (a), the
log-log scale (inset) reveals a power law θ1(t) ∝t−0.8 (Pozzorini et al., 2013).
11.2 Encoding models in systems neuroscience
Generalized integrate-and-ﬁre models have been used not only for spike prediction of neu-
rons in brain slices, but also for measurements in systems neuroscience, i.e., in the intact
brain driven by sensory stimuli or engaged in a behavioral task. Traditionally,
electrophysiological measurements in vivo have been performed with extracellular elec-
trodes or multi-electrode probes. With extracellular recording devices, the presence of
spikes emitted by one or several neurons can be detected, but the membrane potential of the
neuron is unknown. Therefore, in the following we aim at predicting spikes in extracellular
recordings from a single neuron, or in groups of connected neurons.
11.2.1 Receptive ﬁelds and linear-nonlinear-poisson model
The linear properties of a simple neuron in the primary visual cortex can be identiﬁed with
its receptive ﬁeld, i.e., the small region of visual space in which the neuron is responsive
to stimuli (see Chapters 1 and 12). Receptive ﬁelds as linear ﬁlters have been analyzed in
a wide variety of experimental preparations.
Experimentally, the receptive ﬁeld of a simple cell in visual cortex can be determined
by presenting a random sequence of spots of lights on a gray screen while the animal is
watching the screen (Fig. 11.5a). In a very limited region of the screen, the spot of light
leads to an increase in the probability of ﬁring of the cell, in an adjacent small region to a

274
Encoding and decoding with stochastic neuron models
x
S(t)
'Encoding'
(a)
S(t)
'Encoding'
( )
f u
u
k
x
fh( )
k
+ 
LNP
GLM
(b)
Fig. 11.5 The encoding problem in the visual neuroscience. (a) A stimulus is presented on a screen
while a spike train is recorded from an area in the visual cortex. (b) Models designed to predict the
spike train ﬁrst ﬁlter the stimulus x with a spatial ﬁlter k (linear processing step), pass the result
u = k · x through a nonlinearity f and then generate spikes stochastically with Poisson statistics.
The main difference between a Linear-Nonlinear-Poisson (LNP, top) and a soft-threshold generalized
integrate-and-ﬁre model (GLM, bottom) is the presence of spike-triggered currents ˜η(s) in the latter.
decrease. The spatial arrangement of these regions deﬁnes the spatial receptive ﬁeld of the
cell and can be visualized as a two-dimensional spatial linear ﬁlter (Fig. 11.5b).
Instead of a two-dimensional notation of screen coordinates, we choose in what follows
a vector notation where we label all pixels with a single index k. For example, on a screen
with 256 × 256 pixels we have 1 ≤k ≤K with K = 65536. A full image corresponds
to a vector x = (x1,...,xK) while a single spot of light corresponds to a vector with all
components equal to zero except one (Fig. 11.6a).
The spatial receptive ﬁeld of a neuron is a vector k of the same dimensionality as x. The
response of the neuron to an arbitrary spatial stimulus x depends on the total drive k · xt,
i.e., the similarity between the stimulus and the spatial ﬁlter.
More generally, the receptive ﬁeld ﬁlter k can be described not only by a spatial com-
ponent, but also by a temporal component: an input 100 ms ago has less inﬂuence on the
spiking probability now than an input 30 ms ago. In other words, the scalar product k · xt
is a short-hand notation for integration over space as well as over time. Such a ﬁlter k is
called a spatio-temporal receptive ﬁeld.
In the Linear-Nonlinear-Poisson (LNP) model, one assumes that spike trains are pro-
duced by an inhomogeneous Poisson process with rate
ρ(t) = f(k·xt),
(11.5)
given by a cascade of two simple steps (Fig. 11.5b). The linear stage, k·xt, is a linear pro-
jection of xt, the (vector) stimulus at time t, onto the receptive ﬁeld k; this linear stage is
then followed by a simple scalar nonlinearity f(.) which shapes the output (and in partic-
ular enforces the non-negativity of the output ﬁring rate ρ(t)). A great deal of the systems
neuroscience literature concerns the quantiﬁcation of the receptive ﬁeld parameters k.

11.2 Encoding models in systems neuroscience
275
1x
2x
3x
Kx
19
x
tx = (x , x , x , ..., x  , ..., x  )
1
2
3
19
K
(a)
t=1
t=2
t =3
. 
. . 
t =T
0  
1     0 
0 
0 
0  
0     1   
0 
0     0     
0  0     1                    0
Time
Inpu
(b)
t
x
x
x
x
1
2
3 ...
dt
1
xK
Fig. 11.6 Spatial receptive ﬁeld measurement. (a) While the animal focuses on the center (star),
light dots are presented at random positions on a gray screen; in the present trial, pixel 19 lights up.
The input is denoted as a vector xt. (b) Schematic of input matrix X. Matrix representing a sparse
input, such as a single spot of light. Rows of the matrix correspond to different trials, marked by the
observation time t.
Note that the LNP model neglects the spike-history effects that are the hallmark of the
SRM and the GLM - otherwise the two models are surprisingly similar; see Fig. 11.5b.
Therefore, an LNP model cannot account for refractoriness or adaptation, while a GLM in
the form of a generalized soft-threshold integrate-and-ﬁre model does. The question arises
whether a model with spike-history effects yields a better performance than the standard
LNP model.
Both models, LNP and GLM, can be ﬁtted using the methods discussed in Chapter 10.
For example, the two models have been compared on a dataset where retinal ganglion cells
have been driven by full-ﬁeld light stimulus, i.e., the stimulus did not have any spatial
structure (Pillow et al., 2005). Prediction performance had a similar range of values as
for cortical neurons driven by intracellular current injection, with up to 90% of the PSTH
variance predicted in some cases. LNP models in this context have signiﬁcantly worse
prediction accuracy; in particular, LNP models greatly overestimate the variance of the
predicted spiking responses. See Fig. 11.7 for an example.
Example: Detour on reverse correlation for receptive ﬁeld estimation
Reverse correlation measurements are an experimental procedure based on spike-
triggered averaging (de Boer and Kuyper, 1968; Chichilnisky, 2001). Stimuli x are
drawn from some statistical ensemble and presented one after the other. Each time the
neuron elicits a spike, the stimulus x presented just before the ﬁring is recorded.
The reverse correlation ﬁlter is the mean of all inputs that have triggered a spike
xRevCorr = ⟨x⟩spike = ∑t ntxt
∑t nt
,
(11.6)

276
Encoding and decoding with stochastic neuron models
where nt is the spike count in trial t. Loosely speaking, the reverse correlation tech-
nique ﬁnds the typical stimulus that causes a spike. In order to make our intuitions more
precise, we proceed in two steps.
First, let us consider an ensemble p(x) of stimuli x with a "power" constraint |x|2 < c.
Intuitively, the power constraint means that the maximal light intensity across the whole
screen is limited. In this case, the stimulus that is most likely to generate a spike under
the linear receptive ﬁeld model (11.10) is the one which is aligned with the receptive
ﬁeld
xopt ∝k;
(11.7)
see Exercises. Thus the receptive ﬁeld vector k can be interpreted as the optimal stimulus
to cause a spike.
Second, let us consider an ensemble of stimuli x with a radially symmetric distribu-
tion, where the probability of a possibly multi-dimensional x is equal to the probability
of observing its norm |x| : p(x) = pc(|x|). Examples include the standard Gaussian dis-
tribution, or the uniform distribution with power constraint p(x) = p0 for |x|2 < c and
zero otherwise. We assume that spikes are generated with the LNP model of Eq. (11.5).
An important result is that the experimental reverse correlation technique yields an unbi-
ased estimator of the ﬁlter k, i.e.,
⟨xRevCorr⟩= k.
(11.8)
The proof (Bussgang, 1952; Simoncelli et al., 2004) follows from the fact that each arbi-
trary input vector xt can be separated into a component parallel to k and one orthogonal
to it. Since we are free to choose the scale of the ﬁlter k we can impose |k| = 1 and write
xt = (k·xt)k+(e·xt)e
(11.9)
where e is a unit vector in the subspace orthogonal to k. For ﬁring, only the compo-
nent parallel to k matters. The symmetry of the distribution p(x) guarantees that spike-
triggered averaging is insensitive to the component orthogonal to k; see Exercises.
In summary, reverse correlations are an experimental technique to determine the
receptive ﬁeld properties of a sensory neuron under an LNP model. The success of
the reverse correlation technique as an experimental approach is intimately linked to
its interpretability in terms of the LNP model.
Reverse correlations in the LNP model can also be analyzed in a statistical framework.
To keep the arguments simple, we focus on the linear case and set
f(k·xt) = ρ0 +k·xt .
(11.10)
The parameters minimizing the squared error between the model ﬁring rate ρ0 +k·x
and the observed ﬁring rate nt are then
kopt = (XTX)−1

∑
t
ntxt

/dt .
(11.11)

11.2 Encoding models in systems neuroscience
277
We note that, for short observation intervals Δ, the spike count nt is either zero or 1.
Therefore the term in parentheses on the right-hand side is proportional to the classical
spike-triggered average; see Eq. (11.6). The factor in front of the parentheses, XTX, is a
scaled estimate of the covariance of the inputs x. For stimuli consisting of uncorrelated
white noise or light dots at random positions, the covariance structure is particularly
simple.
See Paninski (2004) for further connections between reverse correlation and
likelihood-based estimates of the parameters in the LNP model.
Rate [Hz]
Variance
(b)
(a)
(c)
(d)
RGC
LNP
GLM
RGC
LNP
GLM
Time [s]
Time [s]
Fig. 11.7 Example predictions of retinal ganglion ON-cell (RGC) activity using the generalized
linear encoding model with and without spike-history terms. (a) Recorded responses to repeated full-
ﬁeld light stimulus (top) of true ON cell ("RGC"), simulated LNP model (no spike-history terms;
"LNP"), and Generalized Linear Model including spike-history terms ("GLM"). Each row corre-
sponds to the response during a single stimulus presentation. (b) Magniﬁed sections of rasters, with
rows sorted in order of ﬁrst spike time within the window in order to show spike-timing details. Note
that the predictions of the model including spike-history terms are in each case more accurate than
those of the Poisson (LNP) model. (PSTH variance accounted for: 91%, compared to 39% for the
LNP model). (c) Time-dependent ﬁring rate plotted as a PSTH. (d) Variance of the time-dependent
ﬁring rate. All data shown here are cross-validated "test" data (i.e., the estimated model parameters
were in each case computed based on a non-overlapping "training" dataset not shown here). From
Paninski et al. (2007) based on data from Uzzell and Chichilnisky (2004).

278
Encoding and decoding with stochastic neuron models
11.2.2 Multiple neurons
Using multi-electrode arrays, Pillow et al. (2008) recorded from multiple ganglion cells in
the retina provided with spatio-temporal white noise stimuli. This stimulation reaches the
ganglion cells after being transducted by photoreceptors and interneurons of the retina. It
is assumed that the effect of light stimulation can be taken into account by a linear ﬁlter of
the spatio-temporally structured stimulus. An SRM-like model of the membrane potential
of a neuron i surrounded by n other neurons is
ui(t) = ∑
f
ηi(t −t f
i )+ki ·x(t)+∑
j̸=i∑
f
εi j(t −t f
j )+urest.
(11.12)
The light stimulus x(t) ﬁltered by the receptive ﬁeld of neuron i, ki, replaces the artiﬁcially
injected external current in Eq. (11.1). The spike-afterpotential ηi(t) affects the membrane
potential as a function of the neuron's own spikes. Spikes from a neighboring neuron j
modify the membrane potential of neuron i according to the coupling function εi j(t).
The extracellular electrodes used by Pillow et al. (2008) did not probe the membrane
potential. Nonetheless, by comparing the spike times with the conditional ﬁring intensity
ρ(t|{S}) = 1
τ0 exp(u(t)) we can maximize the likelihood of observing the set of spike
trains {S} (Chapter 10). This way we can identify the spatio-temporal receptive ﬁeld ki,
the spike-afterpotential η(t) and the coupling functions εi j(t).
The ﬁtted functions ki showed two types of receptive ﬁelds (Pillow et al., 2008). The
ON cells were sensitive to recent increase in luminosity while the OFF cells were sensitive
to recent decrease. The coupling functions also reﬂect the two different neuron types. The
coupling from ON cells to ON cells is excitatory and the coupling from ON cells to OFF
cells is inhibitory, and conversely for couplings from OFF cells.
How accurate are the predictions of the multi-neuron model? Figure 11.8 describes the
prediction performance. The spike-trains and PSTHs of the real and modeled neurons are
similar. The spike-train likelihood reaches 2 bits per spike and the PSTH is predicted with
80-93% accuracy. Overall, the coupled model appears as a valid description of neurons
embedded in a network.
Pillow et al. (2008) also asked about the relevance of coupling between neurons. Are
the coupling functions an essential part of the model or can the activity be accurately
predicted without them? Optimizing the model with and without the coupling function
independently, they found that the prediction of PSTH variance was unaffected. The spike
prediction performance, however, showed a consistent improvement for the coupled model.
(See (Vidne et al., 2012) for further analysis using a model incorporating unobserved com-
mon noise effects.) Interneuron coupling played a greater role in decoding, as we shall see
in the next section.
11.3 Decoding
"Decoding" refers to the problem of how to "read out" the information contained in a set
of neural spike trains (Fig. 11.9) and has both theoretical and practical implications for the

11.3 Decoding
279
(a)
(b)
RGC
Full model
100
Time [s]
0
1
PSTH prediction
(% variance)
Spike prediction
(bits per spike)
Fully coupled
100
80
60
60
80
100
1.5
1
1
1.5
Uncoupled
PSTH [Hz]
Fully coupled
(c)
(d)
Fig. 11.8 Spike-train prediction of a retinal ganglion cell within its network. (a) Raster of
responses of a retinal ganglion cell (RGC; top) to 25 repetitions of 1 s stimulus, and responses of
the fully coupled model (Full model; bottom) to the same stimulus. (b) PSTH of the RGC (full black
line) and the fully coupled model (dashed black line). (c) PSTH prediction for the fully coupled
model of different cells plotted against the the PSTH prediction of a model ﬁtted without interneu-
ron coupling. (d) Log-likelihood (Eq. (10.41)) for the fully coupled model of different cells plotted
against the log-likelihood of a model ﬁtted without interneuron coupling. Modiﬁed from Pillow et al.
(2008).
study of neural coding (Rieke et al., 1997; Donoghue, 2002). A variety of statistical tech-
niques have been applied to this problem (Rieke et al., 1997; E. Brown et al., 1998; Pillow
et al., 2011; Ahmadian et al., 2011b); in this section, we focus speciﬁcally on decoding
methods that rely on Bayesian "inversion" of the generalized linear encoding model dis-
cussed above and in Chapter 10. That is, we apply Bayes' rule to obtain the posterior
probability of the stimulus, conditional on the observed response:
p(x|D) ∝p(D|x)p(x),
(11.13)
where p(x) is the prior stimulus probability. As an aside we note that a similar idea was
used above when we incorporated prior knowledge to regularize our estimates of the encod-
ing model parameter θ; here we are assuming that θ, or equivalently p(D|x), has already
been estimated to a reasonable degree of precision, and now we want to incorporate our
prior knowledge of the stimulus x.
The primary appeal of such Bayesian decoding methods is that they are optimal if we
assume that the encoding model p(D|x) is correct. Decoding therefore serves as a means
for probing which aspects of the stimulus are preserved by the response, and also as a tool
for comparing different encoding models. For example, we can decode a spike train using
different models (e.g., including vs. ignoring spike-history effects) and examine which

280
Encoding and decoding with stochastic neuron models
x
S(t)
'Decoding' 
Fig. 11.9 The decoding problem in visual neuroscience. How much can we learn about a
stimulus, given the spike trains of a group of neurons in the visual pathway?
encoding model allows us to best decode the true stimulus (Pillow et al., 2005). Such a
test may in principle give a different outcome than a comparison which focuses on the
encoding model's ability to predict spike-train statistics. In what follows, we illustrate how
to decode using the stimulus which maximizes the posterior distribution p(x|D), and show
how a simple approximation to this posterior allows us to estimate how much information
the spike-train response carries about the stimulus.
11.3.1 Maximum a posteriori decoding
The maximum a posteriori (MAP) estimate is the stimulus x that is most probable given
the observed spike response D, i.e., the x that maximizes p(x|D). Computing the MAP
estimate for x once again requires that we search in a high-dimensional space (the space
of all possible stimuli x) to ﬁnd the maximizer of a nonlinear function, p(x|D). Luckily,
in the GLM, the stimulus x interacts linearly with the model parameters θ, implying that
concavity of the log-likelihood with respect to x holds under exactly the same conditions
as does concavity in θ (Paninski, 2004). Moreover, the sum of two concave functions is
concave, so the log-posterior,
log p(x|D) = log p(D|x)+log p(x)+c,
(11.14)
is concave as long as the stimulus log-prior log p(x) is itself a concave function of x (e.g.,
p is Gaussian). In this case, again, we may easily compute ˆxMAP by numerically ascending
the function log p(x|D).
We emphasize that the MAP estimate of the stimulus is, in general, a nonlinear function
of the observed spiking data D. As an empirical test of the MAP estimate, we can compare
its performance with that of the optimal linear estimate (OLE, see example below), the
best linear estimate of the stimulus as a function of the observed spiking data D (Rieke
et al., 1997).
Figure 11.10 shows a comparison of the two decoding techniques, given responses D
generated by a GLM encoding model with known parameters, as a function of stimulus

11.3 Decoding
281
(c)
(a)
(b)
Time [s]
Contrast
Rel. error
Rel. error
Intensity
Intensity
Number of cells
Fig. 11.10 Illustration of MAP (maximum a posteriori) decoding. (a) Simulated spike trains from a
single pair of simulated ON and OFF retinal ganglion cells (above, gray and block dots) were used
to compute the MAP estimate (gray) of a 500 ms Gaussian white noise stimulus (black), sampled
at 100 Hz. (b) Spike trains from 10 identical, independent ON and OFF cells in response to the
same stimulus, with the associated MAP estimate of the stimulus, illustrating convergence to the
true stimulus as the responses of more cells are observed. (c) Comparison of the optimal linear
estimate (OLE) and MAP estimate on simulated data, as a function of the number of observed cells
(top) and stimulus contrast (variance; bottom). For each data point, the parameters of the OLE were
estimated using a long run of simulated data. "Relative error" denotes the average RMS error between
the true and estimated stimulus, averaged over 100 trials, divided by the RMS amplitude of the true
stimulus.
contrast (variance) and size of the neuronal population. The MAP clearly outperforms the
OLE at high contrasts or large population sizes. More importantly, the MAP approach
provides us with a great deal of ﬂexibility in considering different encoding models or
prior distributions: we can simply substitute in a new p(D|x) or p(x) and recompute the
MAP estimator, without having to obtain new estimates of the regression parameters as
required by the OLE; see (Ramirez et al., 2011) for an example of this type of analysis.
Finally, there are close connections between MAP decoding and the optimal control of
neural spiking; see Ahmadian et al. (2011a) for further discussion.
Example: Linear stimulus reconstruction
We predict the stimulus xt by linear ﬁltering of the observed spike times
t1,t2,...,tF < t,
x(t) = x0 +∑
f
k(t −t f )
(11.15)

282
Encoding and decoding with stochastic neuron models
where the sum runs over all spike times. The aim is to ﬁnd the shape of the ﬁlter k, i.e.,
the optimal linear estimator (OLE) of the stimulus (Rieke et al., 1997).
Parameters of the OLE can be obtained using standard least-squares regression of the
spiking data onto the stimulus x. To do so, we discretize time and the temporal ﬁlter k.
Mathematically, the optimization problem is then essentially the same as above where
we aimed at predicting spikes by a linear model of the stimulus (Section 10.2). The only
difference is that here we are regressing the spikes onto the stimulus, whereas previously
we were regressing the stimulus onto the spike response.
11.3.2 Assessing decoding uncertainty (*)
In addition to providing a reliable estimate of the stimulus underlying a set of spike res-
ponses, computing the MAP estimate ˆxMAP gives us easy access to several important quan-
tities for analyzing the neural code. In particular, the variance of the posterior distribution
around ˆxMAP tells us something about which stimulus features are best encoded by the
response D. For example, along stimulus axes where the posterior has small variance (i.e.,
the posterior declines rapidly as we move away from ˆxMAP), we have relatively high cer-
tainty that the true x is close to ˆxMAP. Conversely, we have relatively low certainty about
any feature axis along which the posterior variance is large.
We can measure the scale of the posterior distribution along an arbitrary axis in a fairly
simple manner: since we know (by the above concavity arguments) that the posterior is
characterized by a single "bump," and the position of the peak of this bump is already
characterized by ˆxMAP, it is enough to measure the curvature of this bump at the peak
ˆxMAP. Mathematically, we measure this curvature by computing the "Hessian" matrix A of
second derivatives of the log-posterior,
Ai j = −
∂2
∂xi∂xj
log p(xi|D).
(11.16)
Moreover, the eigendecomposition of this matrix A tells us exactly which axes of stimulus
space correspond to the "best" and "worst" encoded features of the neural response: small
eigenvalues of A correspond to directions of small curvature, where the observed data D
poorly constrains the posterior distribution p(x|D) (and therefore the posterior variance
will be relatively large in this direction), while conversely large eigenvalues in A imply
relatively precise knowledge of x, i.e., small posterior variance (Huys et al., 2006) (for this
reason the Hessian of the log-likelihood p(D|x) is referred to as the "observed Fisher infor-
mation matrix" in the statistics literature). In principle, this posterior uncertainty analysis
can potentially clarify what features of the stimulus a "downstream" neuron might care
most about.
We can furthermore use this Hessian to construct a useful approximation to the posterior
p(x|D). The idea is simply to approximate this log-concave bump with a Gaussian function,
where the parameters of the Gaussian are chosen to exactly match the peak and curvature

11.3 Decoding
283
of the true posterior. This approximation is quite common in the physics and statistics
literature (Kass and Raftery, 1995; E. Brown et al., 1998; Rieke et al., 1997). Speciﬁcally,
p(x|D) ≈(2π)−d/2|A|1/2e−(x−ˆxMAP)TA(x−ˆxMAP)/2,
(11.17)
with d = dim(x). We can then read off the approximate posterior entropy or variance of
xi: e.g., var(xi|D) ≈[A−1]ii. As discussed further in Ahmadian et al. (2011b) and Pillow
et al. (2011), the approximation by the Gaussian of Eq. (11.17) is often quite accurate in
the context of decoding. See Rieke et al. (1997) and Pillow et al. (2011) for discussion of a
related bound on the posterior entropy, which can be used to bound the mutual information
between the stimulus and response.
11.3.3 Decoding in vision and neuroprosthetics
We have established that generalized integrate-and-ﬁre models can predict with good accu-
racy the activity of real neurons. Is it sensible to assert that we have understood how the
neural system translates stimulus into patterns of action potentials? If so we should be able
to read the neuronal activity to reconstruct its tangible meaning. As was brieﬂy discussed
in the introduction to Section 11.3, reading the neural code has practical applications; a
common example of such applications is to help tetraplegic patients to control artiﬁcial
limbs. In this section, we illustrate decoding in two distinct scenarios. In the ﬁrst scenario
(Fig. 11.11), a monochrome movie is reconstructed from the activity of neurons in the
visual pathway. In the second example (Fig. 11.12), it is the time-dependent velocities of
hand movements that are decoded from activity in the area MI of the cortex.
Using the methods described in the introduction to Section 11.3, Pillow et al. (2008)
reconstructed the time-dependent light stimulus from 27 ganglion cells recorded in the
retina. First, coupled integrate-and-ﬁre models were optimized on training data (see Sec-
tion 11.2.2). Once the appropriate set of parameter was determined, spike trains from the
data reserved for testing were used to decode the stimulus. Decoding was performed with
the methods discussed in the introduction to Section 11.3.
The stimulus was a spatio-temporal binary white noise. The decoding performance can
be quantiﬁed by evaluating the signal-to-noise ratio for different frequencies (Fig. 11.11).
For most of the frequencies, the signal-to-noise ratio of the decoded signal was greater
than 1, meaning that the decoded signal was greater than the error. For the fully coupled
model discussed in Section 11.2.2, the signal-to-noise ratio can be higher than 3.5 for some
frequencies. The decoding performance is expected to grow with the number of recorded
neurons, as can be seen in Fig. 11.11c.
We now consider a second example which has applications for neuroprosthetics. The
ultimate aim of neuroprosthetics is to help human patients who have lost a limb. Prosthetic
limbs are often available for these patients. While prosthesis works from a mechanical point
of view, the intuitive control of the prosthetic device poses big challenges. One possible
route of research is to read out, directly from the brain, the intentions of the user of the
prosthetic device.

284
Encoding and decoding with stochastic neuron models
0
500
1000
−0.5
0
0.5
Time [ms]
Light intensity 
(a)
(b)
(c)
Fig. 11.11 Decoding of light stimulus from recordings of neurons in the retina. (a) Binary light
stimulus (thick black) is compared with the decoded stimulus using Bayesian MAP (dashed line,
Section 11.3.1). (b) The signal-to-noise ratio (SNR) as function of frequency for decoding using the
fully coupled model (thick line), the uncoupled model (thin line) or using an optimal linear decoder
(dashed lines). (c) Increasing the number of cells improves the decoding performance of both the
coupled model (thick line) and the optimal linear decoder (dashed lines). (a) and (c) are redrawn
from Pillow et al. (2011), (b) follows a similar ﬁgure to one in Pillow et al. (2008).
In preliminary experiments, a monkey moves a tracking device with his hand while an
electrode records from neurons of its cortex. The electrode is placed in an area associated
with planning movements (Donoghue et al., 1998). Truccolo et al. (2005) used generalized
integrate-and-ﬁre models to decode the hand movements from the recorded activity.
Again here, the ﬁrst step was to ﬁt the model parameters. The model itself was very
similar to the one seen in Section 11.2.2 but without coupling terms and with a different
nonlinear relation between model membrane potential and ﬁring intensity. A more notewor-
thy difference is the input x which consisted of hand velocity such that the receptive ﬁeld
k mapped how the x- and y-components of the velocity inﬂuenced the driving potential.
Instead of the method described in Section 11.3.1, Truccolo et al. (2005) used a point-
process ﬁlter (Eden et al., 2004). The decoding algorithm is a recursive algorithm for cal-
culating the Bayesian estimate of the stimulus at time t in term the past activity. This
recursive approach is necessary in this real-time application. The decoding performance is
illustrated in Fig. 11.12. Signal-to-noise ratio for this decoding was between 1.0 and 2.5,
which is rather impressive given the typical variability of cortical neurons and the small
number of cells used for decoding (between 5 and 20). This exempliﬁes that generalized
integrate-and-ﬁre models can help in building a brain-machine interface for controlling

11.4 Summary
285
'Decoding' 
Intended movement
{S(t)}
(a)
10
−10
0
10
−10
0
(b)
0
8
Fig. 11.12 Decoding hand velocity from spiking activity in area MI of cortex. (a) Schematics. (b) The
real hand velocity (thin black line) is compared to the decoded velocity (thick black line) for the y-
(top) and the x-components (bottom). Modiﬁed from Truccolo et al. (2005).
prosthetic limbs by "reading" the activity of cortical neurons. A number of groups are now
working to further improve these methods for use in prosthetic systems.
11.4 Summary
Generalized integrate-and-ﬁre models can predict the spiking activity of cortical cells such
as the main inhibitory and excitatory cell type in layer 2-3 of the cortex. For excitatory
neurons, more than 80% of spike timings can be predicted by these models, while for
inhibitory neurons the percentage is close to 100%. Similar model performance is seen in
the retina, where the activity of up to 250 neurons can be predicted simultaneously (Vidne
et al., 2012).
The same models can also be used to decode the activity of neurons. For instance, the
spike trains of retinal neurons can be decoded so as to reconstruct a slightly blurred version
of the original image movie shown to the retina. Also, the activity of motor cortical neurons
can be decoded to reconstruct the intended hand movement in two (or more) dimensions.
Thus, the abstract mathematical framework of generalized integrate-and-ﬁre models might
ultimately contribute to technical solutions that help human patients.
Literature
The inﬂuential book by Rieke et al. (1997) gives a broad introduction to the ﬁeld of neural
coding with a special focus on decoding. The LNP model, reverse correlation techniques,
and application to receptive ﬁeld measurements are reviewed in Simoncelli et al. (2004).
Predictions of spike timings for a time-dependent input with models including spike-
history effects were performed by, for example, Keat et al. (2001) and Jolivet et al. (2006),

286
Encoding and decoding with stochastic neuron models
and different methods and approaches were compared in a series of international competi-
tions (Jolivet et al., 2008a,b).
The ﬁrst decoding attempts used time-averaged ﬁring rates to decode information from
a diverse population of neurons (Georgopoulos et al., 1986). Then the methods were made
more precise in an effort to understand the temporal structure of the neural code (Optican
and Richmond, 1987; Bialek et al., 1991). In particular linear stimulus reconstruction from
measured spike trains (Rieke et al., 1997) has been widely applied.
Efﬁcient decoding methods are a necessary requirement if a prosthetic arm is controlled
by the spikes recorded from cortical neurons. Introducing spike history effects (Truccolo
et al., 2005) or interneuron coupling (Pillow et al., 2008) helped to improve decoding
accuracy, but the improvement of decoding techniques went in parallel with other technical
achievements (Shoham, 2001; Brockwell et al., 2004, 2007; Eden et al., 2004; Truccolo
et al., 2005; Srinivasan and Brown, 2007; Kulkarni and Paninski, 2007; Koyama et al.,
2010; Paninski et al., 2010).
The discussion of the statistical principles of encoding and decoding in the present and
the previous chapter is partly based on the treatment in Paninski et al. (2007).
Exercises
1. Linear ﬁlter as optimal stimulus. Consider an ensemble of stimuli x with a "power" constraint
|x|2 < c.
(a) Show that, under the linear rate model of Eq.(11.10), the stimulus that maximizes the
instantaneous rate is x = k.
Hint: Use Lagrange multipliers to implement the constraint |x|2 = c.
(b) Assume that the a spatially localized time-dependent stimulus x(t) is presented in the center
of the positive lobe of the neurons receptive ﬁeld. Describe the neuronal response as
ρ(t) = ρ0 +
 S
0 κ(s)x(t −s)ds,
(11.18)
where ρ0 is the spontaneous ﬁring rate in the presence of a gray screen and S the temporal extent
of the ﬁlter κ. What stimulus is most likely to cause a spike under the constraint
 S
0 [x(t −s)]2ds <
c? Interpret your result.
2. LNP model and reverse correlations. Show that, if an experimenter uses stimuli x with a
radially symmetric distribution p(x) = q(|x|), then reverse correlation measurements provide
an unbiased estimate linear ﬁlter k under an LNP model
ρ(t) = f(k·xt);
(11.19)
i.e., the expectation of the reverse correlation is parallel to k.
Hint: Write the stimulus as
x = (k·x)k+(e·x)e
(11.20)
and determine the reverse correlation measurement by averaging over all stimuli weighted with
their probability to cause a spike.

PART THREE
NETWORKS OF NEURONS AND
POPULATION ACTIVITY


289
RS
Part II
Part I
Ion channels
Ions
Dendrites
t
u(t)
Threshold
Biophysical
models 
Neurotransmitters
Part III
Populations
Neural Field/Mass Models
The organization of this book follows a path of successive simpliﬁcations so as to ulti-
mately bridge scales from micrometers to centimeters, from single cells to cognition. The
ﬁrst two parts focused on isolated neurons. In Part I, we took as our starting point a rather
detailed biophysical description of a neuron, exempliﬁed by the Hodgkin-Huxley model
and variants thereof. Working along from Part I to Part II, this description of a neuron was
simpliﬁed to a point neuron of the integrate-and-ﬁre type.
Part III is the cornerstone for the transition from single neurons to macroscopic phe-
nomena and, ultimately, forms the basis of the cognitive phenomena discussed in Part IV.
Chapter 12 starts the transition from single neurons to populations of neurons; the math-
ematical methods for this transition and the major dynamic phenomena in populations of
neurons are explained in Chapters 13 and 14. Because of their complexity, the mathemat-
ical equations for the dynamics of populations of neurons are often simpliﬁed to so-called
rate models. The limitations of the simpliﬁcation step are highlighted in Chapter 15. The
simpliﬁed rate equations will then be used for the analysis of a few selected large-scale
phenomena in Part IV.


12
Neuronal populations
The brain contains millions of neurons which are organized in different brain areas, within
a brain area organized in different subregions, inside each small region into different lay-
ers, inside each layer into various cell types. The ﬁrst two parts of this book focused on
the mathematical description of an isolated neuron. Starting with this chapter, we shift our
attention to the collective properties of groups of neurons, which we call "neuronal popula-
tions." Instead of modeling the spike times of a single neuron which belongs, for example,
to the cell class "pyramidal" in layer 5 of subregion C4 in brain region S1 (the numbers
here are completely arbitrary), we can ask the question: Suppose a human subject or ani-
mal receives a visual, auditory, or somatosensory stimulus - what is the activity of all the
cells in this layer of this subregion that are of type "pyramidal" in response to the stimulus?
What is the response of this subregion as a whole? What is the response of a brain area? In
other words, at any of the scales of spatial resolution (Fig. 12.1), we may be interested in
the response of the neuronal population as a whole, rather than in the spikes of individual
neurons.
The general idea is presented in Fig. 12.2. A network of 10 000 neurons consisting of
NE = 8000 excitatory and NI = 2000 inhibitory neurons, has been simulated while the
excitatory neurons received a time-dependent input. Instead of analyzing the spike trains
of one or two neurons, we count the number of spikes in a small time step (say Δt =
1 ms) across all the excitatory neurons in the network. After dividing by Δt and NE, we
arrive at the population activity A(t) of the group of excitatory neurons; see Section 7.2.
Analogously, we can determine the population activity of the inhibitory neurons or that of
the network as a whole. The central questions of this and the following chapters are: Can
we predict the population activity A(t) from the properties of its neurons and the network
connectivity? How does the population activity respond to a novel input?
The aim of this chapter is to provide the foundation of the notions of "neuronal popula-
tion" and "population activity." In the ﬁrst section we argue that the organization of cortex
into columns and layers provides the biological substrate of "neuronal populations." In
Section 12.2 we identify the mathematical assumptions and idealizations that will enable
us to predict the population activity from single-neuron properties. The basic idea is that,
for the deﬁnition of a neuronal population, we should group neurons with similar prop-
erties together. The aim of Sections 12.2 and 12.3 is to make this intuition more precise.

292
Neuronal populations
Cellular level
Single population
Multiple layers
Multiple columns
Whole brain
V1
LGN
MICROSCOPIC
MESOSCOPIC
MACROSCOPIC
MT
PFC
Interacting populations
RS
Field models
10 mm 
20mm 
100mm   
1mm 
2cm 
Biophysical level 
Morphological level
1mm 
10nm 
Fig. 12.1 The levels of description in neuroscience models.
I(t)
tON
tOFF
tON
tOFF
tOFF
A(t)
tON
Fig. 12.2 Input and output of a population. A signal I(t), represented by a sinusoidal modulation
of the input starting at tON and ending at tOFF, stimulates the population of 8000 excitatory neurons
in a randomly coupled network of 8000 excitatory and 2000 inhibitory neurons (left). Each neuron
produces a spike train (middle) illustrated here by lines of dots, each dot corresponding to a spike.
Only 1% of the population is shown. The population activity A(t) (right) counts spikes in time bins
of 1 ms averaged over the 8000 excitatory neurons.
In Section 12.4 we give a ﬁrst example of the population activity approach by analyzing
stationary activity in a highly connected population. The notions developed in this chapter
will be used in the next two chapters in order to analyze the dynamics of one or several
connected populations.

12.1 Columnar organization
293
Recorded
activity
Angle
i
i
ii
ii
iii
iii
Fig. 12.3 Orientation tuning. The receptive ﬁelds of simple cells in the visual cortex have positive
and negative subﬁelds. To test orientation tuning, a light bar is slowly moved across the screen (i). The
neuron responds maximally if the light bar with an orientation aligned with that of the receptive ﬁeld
moves into the positive subﬁeld (ii) and responds slightly less if the orientation of the bar is not
optimal (iii). The response as a function of the orientation of the bar is shown at the bottom (schematic
ﬁgure).
12.1 Columnar organization
Before we turn, in Section 12.2, to the rather abstract notion of a "neuronal population,"
we present in this section a short introduction to the structural organization and functional
characterization of the cortex. We will argue that a cortical column, or more precisely, a
group of cells consisting of neurons of the same type in one layer of a cortical column, can
be considered as a plausible biological candidate of a neuronal population.
12.1.1 Receptive ﬁelds
Neurons in sensory cortices can be experimentally characterized by the stimuli to which
they exhibit a strong response. The receptive ﬁeld of so-called simple cells in the visual
cortex (see Chapter 1) has typically two or three elongated spatial subﬁelds. The neuron
responds maximally to a moving light bar with an orientation aligned with the elongation
of the positive subﬁeld. If the orientation of the stimulus changes, the activity of the cell
decreases (Fig. 12.3). Thus simple cells in the visual cortex are sensitive to the orientation
of a light bar (Hubel and Wiesel, 1968).
In this and the following chapters, we exploit the fact that neighboring neurons in the
visual cortex have similar receptive ﬁelds. If the experimenter moves the electrode verti-
cally down from the cortical surface to deeper layers, the location of the receptive ﬁeld and
its preferred orientation does not change substantially. If the electrode is moved to a neigh-
boring location in the cortex, the location and preferred orientation of the receptive ﬁeld of

294
Neuronal populations
neurons at the new location changes only slightly compared to the receptive ﬁelds at the
previous location. This observation has led to the idea that cortical cells can be grouped
into "columns" of neurons with similar properties. Each column stretches across different
cortical layers, but has only a limited extent on the cortical surface (Hubel and Wiesel,
1968). The exact size and anatomical deﬁnition of a cortical column is a matter of debate,
but each column is likely to contain several thousand neurons with similar receptive ﬁelds
(Lund et al., 2003).
In other sensory cortices, the characterization of neuronal receptive ﬁelds is analogous to
that in visual cortex. For example, in the auditory cortex, neurons can be characterized by
stimulation with pure tones. Each neuron has its preferred tone frequency, and neighbor-
ing neurons have similar preferences. In the somatosensory cortex, neurons that respond
strongly to touch on, say, the index ﬁnger are located close to each other. The concepts
of receptive ﬁeld and optimal stimuli are not restricted to mammals or cortex, but are also
routinely used in studies of, for example, retinal ganglion cells, thalamic cells, olfactory
bulb, or insect sensory systems.
Example: Cortical maps
Neighboring neurons have similar receptive ﬁelds, but the exact characteristics of the
receptive ﬁelds change slightly as one moves parallel to the cortical surface. This gives
rise to cortical maps.
A famous example is the representation of the body surface in the somatosensory area
of the human brain. For example, neurons which respond to touch on the thumb are
located in the immediate neighborhood of neurons which are activated by touching the
index ﬁnger, which in turn are positioned next to the subregion of neurons that respond
to touching the middle ﬁnger. The somatosensory map therefore represents a somewhat
stretched and deformed "image" of the surface of the human body projected onto the
surface of the cortex. Similarly, the tonotopic map in the auditory cortex refers to the
observation that the neurons' preferred pure-tone frequency changes continuously along
the cortical surface.
In the visual cortex, the location of the neurons' receptive ﬁeld changes along the
cortical surface giving rise to the retinotopic map. At the same time, the preferred ori-
entation of neurons changes as one moves parallel to the cortical surface giving rise to
orientation maps. With modern imaging methods it is possible to visualize the orienta-
tion map by monitoring the activity of neuronal populations while the visual cortex is
stimulated by the presentation of a slowly moving grating. If the grating is oriented verti-
cally, certain subsets of neurons respond; if the grating is rotated by 60◦, other groups of
neurons respond. Thus we can assign to each location on the cortical surface a preferred
orientation (see Fig. 12.4), except for a few singular points, called the pinwheels, where
regions of different preferred orientations touch each other (Bonhoeffer and Grinvald,
1991; Kaschube et al., 2010).

12.1 Columnar organization
295
L1
L2/3
L4
L5
(a)
(b)
Fig. 12.4 Orientation maps and columns. (a) Top view onto the surface of the visual cortex. Neu-
rons that are optimally activated by a moving grating with an orientation of, say, 60◦, form bands.
The direction of the hash-line texture in the image indicates the preferred orientation. Iso-orientation
contour lines converge to form pinwheels. One of the pinwheels is highlighted by the dashed cir-
cle. (b) Side view of a pinwheel (dashed circle in (a)). Orientation selectivity is indicated by thick
bars. Neurons with the same orientation form vertical columns. Schematic representation following
experimental data shown in Bressloff and Cowan (2002).
12.1.2 How many populations?
The columnar organization of the cortex suggests that all neurons in the same column can
be considered as a single population of neurons. Since these neurons share similar receptive
ﬁelds we should be able to develop mathematical models that describe the net response of
the column to a given stimulation. Indeed the development of those abstract models is one
of the aims of mathematical neuroscience.
However, the transition from single neurons to a whole column might be too big a chal-
lenge to be taken in a single step. Inside a column neurons are organized in different layers.
Each layer contains one or several types of neurons. At a ﬁrst level, we can distinguish
excitatory from inhibitory neurons and at an even ﬁner level of detail different types of
inhibitory interneurons. As we shall see in the next section, the mathematical transition
from single neurons to populations requires that we put only those neurons that have sim-
ilar intrinsic properties into the same group. In other words, pyramidal neurons in, say,
layer 5, of a cortical column are considered as one population whereas pyramidal neurons
in layer 2 are a different population; fast-spiking inhibitory neurons in layer 4 form one
population while non-fast-spiking interneurons in the same layer form a different group.
The number of populations that a theoretician takes into account depends on the level of
"coarse-graining" that he is ready to accept, as well as on the amount of information that
is available from experiments.
Example: Connectivity in the barrel cortex
The somatosensory cortex of mice contains a region which is sensitive to whisker
movement. Each whisker is represented in a different subregion. These subregions are,

296
Neuronal populations
100mm 
L1
L2
L3
L4
L5A
L5B
L6
Connection probability:
0.10
0.15
0.20
0.25
0.05
Fig. 12.5 Connectivity patterns inside one column. Examples of shapes of excitatory neurons
in different layers. Arrows on the left indicate connection probabilities between excitatory neu-
rons across layers. Arrows on the right show connection probabilities between excitatory neurons
within a given layer. Data from a barrel column in the somatosensory cortex of the mouse. After
Lefort et al. (2009).
at least in layer 4, clearly separated. Neurons are connected vertically across layers so
that, in this part of cortex, cortical columns are exceptionally well identiﬁable. Because
of the barrel-shaped subregions in layer 4, this part of the somatosensory cortex is called
the barrel cortex (Woosley and Van der Loos, 1970).
Neurons in different layers of a barrel cortex column have various shapes and form
connections with each other with different probabilities (Lefort et al., 2009), indicat-
ing that excitatory neurons in the column do not form a homogeneous population; see
Fig. 12.5. However, if we increase the resolution (i.e., a less "coarse-grained" model) to
that of a single layer in one barrel cortex column, then it might be possible to consider
all excitatory neurons inside one layer as a rather homogeneous population.
12.1.3 Distributed assemblies
The concept of cortical columns suggests that localized populations of neurons can be
grouped together into populations, where each population (e.g., the excitatory neurons in
layer 4) can be considered as a homogeneous group of neurons with similar intrinsic prop-
erties and similar receptive ﬁelds. However, the mathematical notion of a population does
not require that neurons need to form local groups to qualify as a homogeneous population.
Donald Hebb (1949) introduced the notion of neuronal assemblies, i.e., groups of cells
which get activated together so as to represent a mental concept such as the preparation of
a movement of the right arm toward the left. An assembly can be a group of neurons which

12.2 Identical neurons: a mathematical abstraction
297
are distributed across one or several brain areas. Hence, an assembly is not necessarily
a local group of neurons. Despite the fact that neurons belonging to one assembly can
be widely distributed, we can think of all neurons belonging to the assembly as a homo-
geneous population of neurons that is activated whenever the corresponding mental concept
is evoked. Importantly, such an assignment of a neuron to a population is not ﬁxed, but
can depend on the stimulus. We will return to the concept of distributed assemblies in
Chapter 17 when we discuss associative memories and the Hopﬁeld model.
12.2 Identical neurons: a mathematical abstraction
As discussed in the previous section, there exist many brain regions where neurons are
organized in populations of cells with similar properties. Prominent examples are columns
in the somatosensory and visual cortex (Mountcastle, 1957; Hubel and Wiesel, 1962) and
pools of motor neurons (Kandel et al., 2000). Given the large number of neurons within
such a column or pool it is sensible to describe the mean activity of the neuronal population
rather than the spiking of individual neurons.
The deﬁnition of population activity has already been introduced earlier, but is repeated
here for convenience. In a population of N neurons, we calculate the proportion of active
neurons by counting the number of spikes nact(t;t + Δt) in a small time interval Δt and
dividing by N. Further division by Δt yields the population activity
A(t) = limΔt→0
1
Δt
nact(t;t +Δt)
N
= 1
N
N
∑
j=1∑
f
δ(t −t f
j ),
(12.1)
where δ denotes the Dirac δ-function. The double sum runs over all ﬁring times t f
j of all
neurons in the population. In other words the activity A is deﬁned by a population average.
Even though the activity has units of a rate and indeed is often called the population rate,
the population activity is quite different from the concept of a mean ﬁring rate deﬁned by
temporal averaging in a single neuron; see Section 7.2.
Theories of population dynamics, sometimes called "neural mass models," have a long
tradition (Knight, 1972; Wilson and Cowan, 1972, 1973; Amari, 1974; Abbott and van
Vreeswijk, 1993; Gerstner and van Hemmen, 1992; Treves, 1993; Amit and Brunel, 1997b;
Brunel and Hakim, 1999; Fusi and Mattia, 1999; Brunel, 2000; Gerstner, 2000; Nykamp
and Tranchina, 2000; Omurtag et al., 2000). Their aim is to predict the temporal evolution
of the population activity A(t) in large and homogeneous populations of spiking neurons.
Why do we restrict ourselves to large populations? If we repeatedly conduct the same
experiment on a population of, say, one hundred potentially noisy neurons, the observed
activity A(t) deﬁned in Eq. (12.1) will vary from one trial to the next. Therefore we cannot
expect a population theory to predict the activity measurements in a single trial. Rather all
population activity equations that we discuss in this chapter predict the expected activity.
For a large and homogeneous network, the observable activity is very close to the expected

298
Neuronal populations
activity. For the sake of notational simplicity, we do not distinguish the observed activity
from its expectation value and in what follows we denote the expected activity by A(t).
Why do we focus on homogeneous populations? Intuitively, we cannot expect to predict
the activity of a population where each neuron receives a different input and has a different,
and potentially unknown, set of parameters. However, if all neurons in a population have
roughly the same parameters and receive roughly the same input, all neurons are more
or less exchangeable and there is a realistic chance that, based on the knowledge of the
parameters of a typical neuron in the population, we would be able to predict the activity
of the population as a whole. The notion of a homogeneous network will be clariﬁed in
the following subsection. In Section 12.2.2 we will ask whether the requirements of homo-
geneous populations can be relaxed so as to include some degree of heterogeneity within a
population.
12.2.1 Homogeneous networks
We study a large and homogeneous population of neurons. By homogeneous we mean
that (i) all neurons 1 ≤i ≤N are identical; (ii) all neurons receive the same external input
Iext
i
(t) = Iext(t); and (iii) the interaction strength wi j for the connection between any pair j,i
of pre- and postsynaptic neurons is "statistically uniform." The notion will be made precise
in Section 12.3, but for the moment we can think of connections inside the population as
being either absent or "roughly the same," wi j ≈w0, where w0 is a parameter. For w0 = 0 all
neurons are independent; a value w0 > 0 (w0 < 0) implies excitatory (inhibitory) coupling.
Not all neurons need to be coupled with each other; connections can, for example, be
chosen randomly (see Section 12.3 below).
Example: Homogeneous population of integrate-and-ﬁre neurons
In the case of leaky integrate-and-ﬁre neurons, encountered in Chapters 1 and 5 (Sec-
tion 5.1), the dynamics are
τm
d
dt ui = −ui +RIi(t)
for ui < ϑ
(12.2)
combined with a reset condition: if ui ≥ϑ then integration restarts at ur. A homogeneous
network implies that all neurons have the same input resistance R, the same membrane
time constant τm, as well as identical thresholds ϑ and reset values ur. Note that we have
shifted the voltage scale such that the resting potential is urest = 0, which is only possible
if all neurons also have the same resting potential.
We assume that a neuron is coupled to all others as well as to itself with coupling
strength wi j = w0. The input current Ii in Eq. (12.2) takes care of both the external drive
and synaptic coupling
Ii =
N
∑
j=1∑
f
wi jα(t −t f
j )+Iext(t).
(12.3)

12.2 Identical neurons: a mathematical abstraction
299
Here we have assumed that each input spike generates a postsynaptic current with some
generic time course α(t −t f
j ). The sum on the right-hand side of Eq. (12.3) runs over
all ﬁring times of all neurons. Because of the homogeneous all-to-all coupling, the total
input current is identical for all neurons. To see this, we insert wi j = w0 and use the
deﬁnition of the population activity, Eq. (12.1). We ﬁnd a total input current,
I(t) = w0 N
 ∞
0 α(s)A(t −s)ds+Iext(t),
(12.4)
which is independent of the neuronal index i. Thus, the input current at time t depends
on the past population activity and is the same for all neurons.
As an aside we note that for conductance-based synaptic input, the total input current
would depend on the neuronal membrane potential which is different from one neuron
to the next.
12.2.2 Heterogeneous networks
Our deﬁnition of a homogeneous network relied on three conditions: (i) identical param-
eters for all neurons; (ii) identical external input to all neurons; (iii) statistically homo-
geneous connectivity within the network. We may wonder whether all three of these are
required or whether we can relax our conditions to a certain degree (Tsodyks et al., 1993;
Chow, 1998). Potential connectivity schemes will be explored in Section 12.3. Here we
focus on the ﬁrst two conditions.
Let us suppose that all N neurons in the population receive the same input I, considered
to be constant for the moment, but parameters vary slightly between one neuron and the
next. Because of the difference in parameters, the stationary ﬁring rate νi = gθi(I) of neuron
i is different from that of another neuron j. The index θi refers to the set of parameters of
neuron i. The mean ﬁring rate averaged across the population is ⟨ν⟩= ∑i νi/N.
Under the condition that, ﬁrst, the ﬁring rate is a smooth function of the parameters and,
second, that the differences between parameters of one neuron and the next are small, we
can linearize the function g around the mean parameter value ¯θ and ﬁnd for the mean ﬁring
rate averaged across the population
⟨ν⟩= g ¯θ(I),
(12.5)
where we neglected terms (d2gθ/dθ 2)(θi−¯θ)2 as well as all higher-order terms. Eq. (12.5)
can be phrased as saying that the mean ﬁring rate across a heterogeneous network is
equal to the ﬁring rate of the "typical" neuron in the network, i.e., the one with the mean
parameters.
However, strong heterogeneity may cause effects that are not well described by the
above averaging procedure. For example, suppose that the network contains two subgroups
of neurons, each of size N/2, one with parameters θ1 and the other with parameters
θ2. Suppose that the gain function takes a ﬁxed value ν = ν0 whenever the parameters

300
Neuronal populations
are smaller than ˆθ and has some arbitrary dependence ν = gθ(I) > ν0 for θ > ˆθ. If
¯θ = (θ1 + θ2)/2 < ˆθ, then Eq. (12.5) would predict a mean ﬁring rate of ν0 averaged
across the population, which is not correct. The problem can be solved if we split the
population into two populations, one containing all neurons with parameters θ1 and the
other containing all neurons with parameters θ2. In other words, a strongly heterogeneous
population should be split until (nearly) homogeneous groups remain.
The same argument also applies to a population of N neurons with identical parameters,
but different inputs Ii. If the differences in the input are small and neuronal output is a
continuous function of the input, then we can hope to treat the slight differences in input
by a perturbation theory around the homogeneous network, i.e., a generalization of the
Taylor expansion used in the previous subsection. If the differences in the input are large,
for example, if only a third of the group is strongly stimulated, then the best approach is
to split the population into two smaller ones. The ﬁrst group contains all those that are
stimulated, and the second group all the other ones.
12.3 Connectivity schemes
The real connectivity between cortical neurons of different types and different layers, or
within groups of neurons of the same type and the same layer, is still partially unknown,
because experimental data is limited. At most, some plausible estimates of connection
probabilities exist. In some cases the connection probability is considered distance-
dependent, in other experimental estimates it is considered uniform in the restricted neigh-
borhood of a cortical column.
In simulations of spiking neurons, there are a few coupling schemes that are frequently
adopted (Fig. 12.6). Most of these assume random connectivity within and between pop-
ulations. In what follows we discuss these schemes with a special focus on the scaling
behavior induced by each choice of coupling scheme. Here, scaling behavior refers to a
change in the number N of neurons that participate in the population.
An understanding of the scaling behavior is important not only for simulations, but also
for the mathematical analysis of the network behavior. However, it should be kept in mind
that real populations of neurons have a ﬁxed size because, for example, the number of
neurons in a given cortical column is given and, at least in adulthood, does not change
dramatically from one day to the next. Typical numbers, counted in one column of mouse
somatosensory cortex (barrel cortex, C2), are 5750 excitatory and 750 inhibitory neurons
(Lefort et al., 2009). Thus numbers are ﬁnite and considerations of the behavior for the
number N going to inﬁnity are of little relevance to biology.
We note that numbers are even smaller if we break them down per layer. The estimated
mean (± standard error of the mean) number of excitatory neurons in each layer (L1 to
L6) are as follows: L2, 546 ± 49; L3, 1145 ± 132; L4, 1656 ± 83; L5A, 454 ± 46; L5B,
641 ± 50; L6, 1288 ± 84; and for inhibitory neurons: L1, 26 ± 8; L2, 107 ± 7; L3, 123 ±
19; L4, 140 ± 9; L5A, 90 ± 14; L5B, 131 ± 6; L6, 127 ± 9 (Lefort et al., 2009).

12.3 Connectivity schemes
301
(a)
(b)
(c)
Fig. 12.6 Coupling schemes. (a) Full connectivity: Top: A network of 9 neurons with all-to-all cou-
pling. The input links are shown for two representative neurons. Self-couplings are not indicated.
Bottom: The number of input links (indicated for one representative neuron) increases, if the size
of the network is doubled. (b) Random coupling with ﬁxed connection probability. In a network of
18 neurons (bottom) the number of input links is larger than in a network of 9 neurons (top). (c)
Random coupling with ﬁxed number of inputs. The number of links from presynaptic neurons (top:
input links to two representative neurons) does not change when the size of the network is increased
(bottom: input links to one representative neuron).
Example: Scaling of interaction strength in networks of different sizes
Suppose we simulate a fully connected network of 1000 noisy spiking neurons. Spikes
of each neuron in the population generate in all other neurons an inhibitory input current
of strength w < 0 which lasts for 20 ms. In addition to the inhibitory inputs, each neuron
also receives a ﬁxed constant current Iext
0
so that each neuron in the network ﬁres at 5 Hz.
Since each neuron receives input from itself and from 999 partner neurons, the total rate
of inhibitory input is 5 kHz. Because each input exerts an effect over 20 ms, a neuron is,
at each moment in time, under the inﬂuence of about 100 inhibitory inputs - generating
a total input I ≈100w+Iext
0 .
We now get access to a bigger computer which enables us to simulate a network
of 2000 neurons instead of 1000. In the new network each neuron therefore receives
inhibitory inputs at a rate of 10 kHz and is, at each moment in time, under the inﬂuence
of a total input current I ≈200w+Iext
0 . Scaling the synaptic weights w by a factor of 1
2
leads us back to the same total input as before.
Why should we be interested in changing the size of the network? As mentioned
before, in biology the network size is ﬁxed. An experimenter might tell us that the system
he studies contains 20 000 neurons, connected with each other with strength wi j = 1 (in
some arbitrary units) and connection probability of 10%. Running a simulation of the

302
Neuronal populations
(a)
(b)
Fig. 12.7 Simulation of a model network with a ﬁxed connection probability p = 0.1. (a) Top: Pop-
ulation activity A(t) averaged over all neurons in a network of 4000 excitatory and 1000 inhibitory
neurons. Bottom: Total input current Ii(t) into two randomly chosen neurons. (b) Same as (a), but
for a network with 8000 excitatory and 2000 inhibitory neurons. The synaptic weights have been
rescaled with a factor of 1
2 and a common input current Iext is given to all neurons to ensure that
the same population activity is obtained. All neurons are leaky integrate-and-ﬁre units with identical
parameters interacting by short current pulses.
full network of 20 000 neurons is possible, but will take a certain amount of time. We
may want to speed up the simulation by simulating a network of 4000 neurons instead.
The question arises whether we should increase the interaction strength in the smaller
network compared to the value wi j = 1 in the big network.
12.3.1 Full connectivity
The simplest coupling scheme is all-to-all connectivity within a population. All connec-
tions have the same strength. If we want to change the number N of neurons in the simula-
tion of a population, an appropriate scaling law is
wi j = J0
N .
(12.6)
This scaling law is a mathematical abstraction that enables us to formally take the limit of
N →∞while keeping ﬁxed the expected input that a neuron receives from its partners in
the population. In the limit of N →∞, the ﬂuctuations disappear and the expected input can
be considered as the actual input to any of the N neurons. Of course, real populations are
of ﬁnite size, so that some ﬂuctuations always remain. But as N increases the ﬂuctuations
decrease.
A slightly more intricate all-to-all coupling scheme is the following: weights wi j are
drawn from a Gaussian distribution with mean J0/N and standard deviation σ0/
√
N. In this
case, each neuron in the population sees a somewhat different input, so that ﬂuctuations of
the membrane potential are of the order σ0 even in the limit of large N (Faugeras et al.,
2009).

12.3 Connectivity schemes
303
12.3.2 Random coupling: ﬁxed coupling probability
Experimentally the probability p that a neuron inside a cortical column makes a functional
connection to another neuron in the same column is in the range of 10%, but varies across
layers; see Fig. 12.5.
In simulations, we can ﬁx a connection probability p and choose connections randomly
with probability p among all the possible N2 connections. In this case, the number of
presynaptic input links Cj to a postsynaptic neuron j has a mean value of ⟨Cj⟩= pN, but
ﬂuctuates between one neuron and the next with variance p(1−p)N.
Alternatively, we can take one model neuron j = 1,2,3,...,N after the other and choose
randomly C = pN presynaptic partners for it (each neuron can be picked only once as a
presynaptic partner for a given postsynaptic neuron j). In this case all neurons have, by
construction, the same number of input links C j = C. By an analogous selection scheme,
we could also ﬁx the number of output links to exactly pN as opposed to simply imposing
pN as the average value.
Whatever the exact scheme to construct random connectivity, the number of input con-
nections per neuron increases linearly with the size N of the population; see Fig. 12.6b. It
is therefore useful to scale the strength of the connections as
wi j = J0
C = J0
pN ,
(12.7)
so that the mean input to a typical neuron does not change if the number of model neurons
in the simulated population is increased. Since in a bigger network individual inputs have
smaller effects with the scaling according to Eq. (12.7), the amount of ﬂuctuation in the
input decreases with population size; compare Fig. 12.7.
12.3.3 Random coupling: ﬁxed number of presynaptic partners
The number of synapses onto the dendrites of a single pyramidal neuron is estimated to lie
in the range of a few thousand (Kandel et al., 2000). Thus, when one simulates networks
of a hundred thousand neurons or millions of neurons, a modeling approach based on a
ﬁxed connection probability in the range of 10% cannot be correct. Moreover, in an animal
participating in an experiment, not all neurons will be active at the same time. Rather
only a few subgroups will be active, the composition of which depends on the stimulation
conditions and the task. In other words, the number of inputs converging onto a single
neuron may be much smaller than a thousand.
We can construct a random network with a ﬁxed number C of inputs by the following
procedure. We pick one model neuron j = 1,2,3,...,N after the other and choose randomly
its C presynaptic partners; see Fig. 12.6c. Whenever the network size N is much bigger
than C, the inputs to a given neuron can be thought of as random samples from the current
network activity. No scaling of the connections with the population size N is necessary;
see Fig. 12.8.

304
Neuronal populations
(a)
(b)
Fig. 12.8 Simulation of a model network with a ﬁxed number of presynaptic partners (400 excitatory
and 100 inhibitory cells) for each postsynaptic neuron. (a) Top: Population activity A(t) averaged over
all neurons in a network of 4000 excitatory and 1000 inhibitory neurons. Bottom: Total input current
Ii(t) into two randomly chosen neurons. (b) Same as (a), but for a network with 8000 excitatory
and 2000 inhibitory neurons. The synaptic weights have not been rescaled. While the ﬂuctuations of
the population activity A(t) decrease compared to the smaller network (top), the mean and variance
of the synaptic input do not change with the size of the network (bottom). All neurons are leaky
integrate-and-ﬁre units with identical parameters interacting by current pulses; see Brunel (2000).
12.3.4 Balanced excitation and inhibition
In the simulations of Fig. 12.2, we have assumed a network of excitatory and inhibitory
neurons. In other words, our network consists of two interacting populations. The combi-
nation of one excitatory and one inhibitory population can be exploited for the scaling of
synaptic weights if the effects of excitation and inhibition are "balanced."
In the discussion of scaling in the previous subsections, it was mentioned that a ﬁxed
connection probability of p and a scaling of weights wi j = J0/(pN) leads to a mean neu-
ronal input current that is insensitive to the size of the simulation; however, ﬂuctuations
decrease with increasing N. Is there a possibility of working with a ﬁxed connection prob-
ability p and yet control the size of the ﬂuctuations while changing N?
In a network of two populations, one excitatory and one inhibitory, it is possible to adjust
parameters such that the mean input current into a typical neuron vanishes. The condition
is that the total amount of excitation and inhibition cancel each other, so that excitation
and inhibition are "balanced." The resulting network is called a balanced network or a
population with balanced excitation and inhibition (van Vreeswijk and Sompolinsky, 1996;
Vogels et al., 2011).
If the network has balanced excitation and inhibition the mean input current to a typical
neuron is automatically zero and we do not have to apply a weight rescaling scheme to
control the mean. Instead, we can scale synaptic weights so as to control speciﬁcally the
amount of ﬂuctuation of the input current around zero. An appropriate choice is
wi j = J0
√
C
=
J0
√pN .
(12.8)
With this choice, a change in the size of the network hardly affects the mean and vari-
ance of the input current into a typical neuron; see Fig. 12.9. Note that in simulations of

12.3 Connectivity schemes
305
(a)
(b)
Fig. 12.9 Simulation of a model network with balanced excitation and inhibition and ﬁxed con-
nectivity p = 0.1. (a) Top: Population activity A(t) averaged over all neurons in a network of 4000
excitatory and 1000 inhibitory neurons. Bottom: Total input current Ii(t) into two randomly cho-
sen neurons. (b) Same as (a), but for a network with 8000 excitatory and 2000 inhibitory neurons.
The synaptic weights have been rescaled by a factor 1/
√
2 and the common constant input has been
adjusted. All neurons are leaky integrate-and-ﬁre units with identical parameters coupled interacting
by short current pulses.
networks of integrate-and-ﬁre neurons, the mean input current to the model neurons is in
practice often controlled, and adjusted, through a common constant input to all neurons.
In Figs. 12.7-12.9 we simply report the main effects of network size on the population
activity and synaptic currents; the analysis of the observed phenomena will be postponed
to Section 12.4.
12.3.5 Interacting populations
In the previous subsections we considered two populations, one of them excitatory and the
other one inhibitory. Let us generalize the arguments to a network consisting of several
populations; see Fig. 12.10. It is convenient to visualize the neurons as being arranged
in spatially separate pools, but this is not necessary. All neurons could, for example, be
physically localized in the same column of the visual cortex, but of three different types:
excitatory, fast-spiking inhibitory, and non-fast-spiking interneurons.
We assume that neurons are homogeneous within each pool. The activity of neurons in
pool n is
An(t) = 1
Nn ∑
j∈Γn∑
f
δ(t −t f
j ),
(12.9)
where Nn is the number of neurons in pool n and Γn denotes the set of neurons that belong
to pool n. We assume that each neuron i in pool n receives input from all neurons j in pool
m with strength wi j = Jnm/Nm; see Fig. 12.10. The time course αi j(s) caused by a spike of
a presynaptic neuron j may depend on the synapse type, i.e., a connection from a neuron in
pool m to a neuron in pool n, but not on the identity of the two neurons. The input current
to a neuron i in group Γn is generated by the spikes of all neurons in the network,
Ii,n = ∑
j ∑
f
wi j αi j(t −t f
j )

306
Neuronal populations
Ak
Am
An
(a)
Nn
Nn
Nm
Jnn
Jmn
Jnm
Gm
Gn
(b)
Fig. 12.10 Several interacting populations of neurons. (a) A neuron in population Γk is driven by the
population activity Am and An of other groups, as well as by the activity Ak of its own population. (b)
All neurons in group Γn are coupled with synaptic efﬁcacy wij = Jnn/Nn. Each pair of neurons i, j
with the presynaptic j in groups Γm and the postsynaptic neuron i in Γn is coupled via wij = Jnm/Nm.
= ∑
m
Jnm
 ∞
0 αnm(s) ∑
j∈Γm∑
f
δ(t −t f
j −s)
Nm
ds,
(12.10)
where αnm(t −t f
j ) denotes the time course of a postsynaptic current caused by spike ﬁring
at time t f
j of the presynaptic neuron j which is part of population m. We use Eq. (12.9) to
replace the sum on the right-hand side of Eq. (12.10) and obtain
In = ∑
m
Jnm
 ∞
0 α(s)Am(t −s)ds.
(12.11)
We have dropped the index i since the input current is the same for all neurons in pool n.
Thus, we conclude that the interaction between neurons of different pools can be sum-
marized by the population activity A(t) of the respective pools. Note that Eq. (12.11) is a
straightforward generalization of Eq. (12.4) and could have been "guessed" immediately;
external input Iext could be added as in Eq. (12.4).
12.3.6 Distance-dependent connectivity
The cortex is a rather thin sheet of cells. Cortical columns extend vertically across the
sheet. As we have seen before, the connection probability within a column depends on the
layer where pre- and postsynaptic neurons are located. In addition to this vertical connec-
tivity, neurons make many horizontal connections to neurons in other, cortical columns
in the same, but also in other, areas of the brain. Within the same brain area the proba-
bility of making a connection is often modeled as distance dependent. Note that distance
dependence is a rather coarse feature, because the actual connectivity depends also on the
function of the pre- and postsynaptic cell. In the primary visual area, for example, it has
been found that pyramidal neurons with a preferred orientation for horizontal bars are more
likely to make connections to other columns with a similar preferred orientation (Angelucci
and Bressloff, 2006).

12.3 Connectivity schemes
307
(a)
(b)
Fig. 12.11 Distance-dependent connectivity. (a) Random coupling where the probability of making
a connection falls off with distance. Incoming connections to a single selected neuron are shown.
(b) Full connectivity in a local neighborhood, but the connection strength falls off as a function of
distance. Incoming connections to a single selected neuron are strong (thick solid arrow among close
neighbors), weak (dashed) or non-existent (for distant neurons).
For models of distance-dependent connectivity it is necessary to assign to each model
neuron i a location x(i) on the two-dimensional cortical sheet. Two different algorithmic
procedures can be used to assign distance-dependent connectivity (Fig. 12.11). The ﬁrst
one assumes full connectivity with a strength wi j which falls off with distance
wi j = w(|x(i)−x( j)|),
(12.12)
where x(i) and x( j) denote the location of post- and presynaptic neurons, respectively, and
w is a function into the real numbers. For convenience, one may assume ﬁnite support so
that w vanishes for distances |x(i)−x( j)| > d.
The second alternative is to give all connections the same weight, but to assume that the
probability P of forming a connection depends on the distance
Prob(wi j = 1) = P(|x(i)−x( j)|),
(12.13)
where x(i) and x( j) denote the location of post- and presynaptic neurons, respectively and
P is a function into the interval [0,1].
Example: Expected number of connections
Let us assume that the density of cortical neurons at location y is ρ(y). The expected
number of connections that a single neuron i located at position x(i) receives is then
Ci =
 P(|x(i)−y|)ρ(y)dy. If the density is constant, ρ(y) = ρ0, then the expected num-
ber C of input synapses is the same for all neurons and controlled by the integral of the
connection probability, i.e., Ci = ρ0
 P(|x(i)−y|)dy.
12.3.7 Spatial continuum limit (*)
The physical location of a neuron in a population often reﬂects the task of a neuron. In
the auditory system, for example, neurons are organized along an axis that reﬂects the

308
Neuronal populations
nd
(n+1)d
md
(m +1)d
Nm=ρd  
d
w(nd,md) 
Fig. 12.12 In a spatially continuous ensemble of neurons, the number of neurons in a segment of
size d is N = ρ d. The efﬁcacy wij between two neurons depends on their location. The coupling
strength between a presynaptic neuron j at position x(j) ≈md and a postsynaptic neuron i at location
x(i) ≈nd is wij ≈w(nd,md).
neurons' preferred frequency. A neuron at one end of the axis will respond maximally to
low-frequency tones; a neuron at the other end to high frequencies. As we move along the
axis the preferred frequency changes gradually. In the visual cortex, the preferred orien-
tation changes gradually as one moves along the cortical sheet. For neurons organized in
a spatially extended multi-dimensional network, a description by discrete pools does not
seem appropriate. We will indicate in this section that a transition from discrete pools to a
continuous population is possible. Here we give a short heuristic motivation of the equa-
tions. A thorough derivation along a slightly different line of arguments will be performed
in Chapter 18.
To keep the notation simple we consider a population of neurons that extends along
a one-dimensional axis; see Fig. 12.12. We assume that the interaction between a pair
of neurons i, j depends only on their location x or y on the line. If the location of the
presynaptic neuron is y and that of the postsynaptic neuron is x, then wi j = w(x,y). In other
words we assume full, but spatially dependent, connectivity and neglect potential random
components in the connectivity pattern.
In order to use the notion of population activity as deﬁned in Eq. (12.11), we start by
discretizing space in segments of size d. The number of neurons in the interval [nd,(n +
1)d] is Nn = ρ d where ρ is the spatial density. Neurons in that interval form the group
Γn. We now change our notation with respect to the discrete population and replace the
subscript m in the population activity Am with the spatial position of the neurons in that
group
Am(t) −→A(md,t) = A(y,t).
(12.14)
Since the efﬁcacy of a pair of neurons with i ∈Γn and j ∈Γm is by deﬁnition wi j = Jnm/Nm
with Nm = ρ d, we have Jnm = ρ d w(nd,md). We use this in Eq. (12.11) and ﬁnd for the
input current
I(nd,t) = ρ∑
m
d w(nd,md)
 ∞
0 α(s)A(md,t −s)ds,
(12.15)

12.4 From microscopic to macroscopic
309
i 
(a)
i 
(b)
Fig. 12.13
The essence of a mean-ﬁeld argument. (a) A fully connected population of neurons
(not all connections are shown). An arbitrary neuron in the network is marked as i. (b) Neuron i has
been pulled out of the network to show that it receives input spikes from the whole population. Hence
it is driven by the population activity A(t). The same is true for all other neurons.
where α(s) describes the time course of the postsynaptic current caused by spike ﬁring in
one of the presynaptic neurons. For d →0, the summation on the right-hand side can be
replaced by an integral and we arrive at
I(x,t) = ρ

w(x,y)
 ∞
0 α(s)A(y,t −s)dsdy,
(12.16)
which is the ﬁnal result. To rephrase Eq. (12.16) in words, the input to neurons at location
x depends on the spatial distribution of the population activity convolved with the spatial
coupling ﬁlter w(x,y) and the temporal ﬁlter α(s). The population activity A(y,t −s)Δs is
the number of spikes in a short interval Δs summed across neurons in the neighborhood
around y normalized by the number of neurons in that neighborhood.
12.4 From microscopic to macroscopic
In this section we will give a ﬁrst example of how to make the transition from the properties
of single spiking neurons to the population activity in a homogeneous group of neurons.
We focus here on stationary activity.
In order to understand the dynamic response of a population of neurons to a chang-
ing stimulus, and to analyze the stability of the dynamics with respect to oscillations or
perturbations, we will need further mathematical tools to be developed in the next two
chapters. As we have see in Chapters 13 and 14, the dynamics depends, apart from the
coupling, also on the speciﬁc choice of neuron model. However, if we want to predict the
level of stationary activity in a large network of neurons, i.e., if we do not worry about the
temporal aspects of population activity, then knowledge of the single-neuron gain function
( f-I curve, or frequency-current relation) is completely sufﬁcient to predict the population
activity.
The basic argument is as follows (Fig. 12.13). In a homogeneous population, each

310
Neuronal populations
A(t)
N=5
A(t)
N=10
A(t)
N=100
A0
A0
A0
t
Fig. 12.14 Asynchronous ﬁring. The empirical population activity A(t), deﬁned as an average over
the spikes across a group of N neurons, can be plotted after smoothing spikes with a ﬁlter γ(s)
(here the ﬁlter is exponential). In the state of stationary asynchronous activity, the ﬁltered population
activity converges toward a constant value A0 if the size N of the group is increased (top: N = 5;
middle N = 10; bottom N = 100).
neuron receives input from many others, either from the same population, or from other
populations, or both. Thus, a single neuron takes as its input a large (and in the case of
a fully connected network even a complete) sample of the momentary population activity
A(t). This has been made explicit in Eq. (12.4) for a single population and in Eq. (12.11)
for multiple populations. To keep the arguments simple, in what follows we focus on a sin-
gle fully connected population. In a homogeneous population, no neuron is different from
any other one, so all neurons in the network receive the same input.
Moreover, under the assumption of stationary network activity, the neurons can be char-
acterized by a constant mean ﬁring rate. In this case, the population activity A(t) must
be directly related to the constant single-neuron ﬁring rate ν. We show in Section 12.4.2
that, in a homogeneous population, the two are in fact equal: A(t) = ν. We emphasize that
the argument sketched here and in the next subsections is completely independent of the
choice of neuron model and holds for detailed biophysical models of the Hodgkin-Huxley
type just as well as for an adaptive exponential integrate-and-ﬁre model or a spike response
model with escape noise. The argument for the stationary activity will now be made more
precise.
12.4.1 Stationary activity and asynchronous ﬁring
We deﬁne asynchronous ﬁring of a neuronal population as a macroscopic ﬁring state with
constant activity A(t) = A0. In this section we show that in a homogeneous population such
asynchronous ﬁring states exist and derive the value A0 from the properties of a single neu-
ron. In fact, we shall see that the only relevant single-neuron property is its gain function,
i.e., its mean ﬁring rate as a function of input. More speciﬁcally, we will show that the
knowledge of the gain function g(I0) of a single neuron and the coupling parameter J0 is
sufﬁcient to determine the activity A0 during asynchronous ﬁring.
At ﬁrst glance it might look absurd to search for a constant activity A(t) = A0, because
the population activity has been deﬁned in Eq. (12.1) as a sum over δ-functions. Empir-
ically the population activity is determined as the spike count across the population in a

12.4 From microscopic to macroscopic
311
ﬁnite time interval Δt or, more generally, after smoothing the δ-functions of the spikes
with some ﬁlter. If the ﬁlter is kept ﬁxed, while the population size is increased, the popu-
lation activity in the stationary state of asynchronous ﬁring approaches the constant value
A0 (Fig. 12.14). This argument will be made more precise below.
12.4.2 Stationary activity as single-neuron ﬁring rate
The population activity A0 is equal to the mean ﬁring rate νi of a single neuron in the
population. This result follows from a trivial counting argument and can best be explained
by a simple example. Suppose that in a homogeneous population of N = 1000 neurons
we observe over a time T = 10 s a total number of 25 000 spikes. Under the assumption
of stationary activity A(t) = A0 the total number of spikes is A0 N T so that the population
ﬁring rate is A0 = 2.5 Hz. Since all 1000 neurons are identical and receive the same input,
the total number of 25 000 spikes corresponds to 25 spikes per neuron, so that the ﬁring
rate (spike count divided by measurement time) of a single neuron i is νi = 2.5 Hz. Thus
A0 = νi.
More generally, the assumption of stationarity implies that averaging over time yields,
for each single neuron, a good estimate of the ﬁring rate ν0. The assumption of homogene-
ity implies that all neurons in the population have the same parameters and are statistically
indistinguishable. Therefore a spatial average across the population and the temporal aver-
age give the same result:
A0 = νi ,
(12.17)
where the index i refers to the ﬁring rate of a single, but arbitrary neuron.
For an inﬁnitely large population, Eq. (12.17) gives a formula to predict the population
activity in the stationary state. However, real populations have a ﬁnite size N and each
neuron in the population ﬁres at moments determined by its intrinsic dynamics and possibly
some intrinsic noise. The population activity A(t) has been deﬁned in Eq. (12.1) as an
empirically observable quantity. In a ﬁnite population, the empirical activity ﬂuctuates and
we can, with the above arguments, only predict its expectation value
⟨A0⟩= νi .
(12.18)
The neuron models discussed in Parts I and II enable us to calculate the mean ﬁring rate νi
for a stationary input, characterized by a mean I0 and, potentially, ﬂuctuations or noise of
amplitude σ. The mean ﬁring rate is given by the gain function
νi = gσ(I0),
(12.19)
where the subscript σ is intended to remind the reader that the shape of the gain func-
tion depends on the level of noise. Thus, considering the pair of equations (12.18) and
(12.19), we may conclude that the expected population activity in the stationary state can
be predicted from the properties of single neurons.

312
Neuronal populations
Example: Theory vs. simulation, expectation vs. observation
How can we compare the population activity ⟨A0⟩calculated in Eq. (12.18) with sim-
ulation results? How can we check whether a population is in a stationary state of asyn-
chronous ﬁring? In a simulation of a population containing a ﬁnite number N of spiking
neurons, the observed activity ﬂuctuates. Formally, the (observable) activity A(t) has
been deﬁned in Eq. (12.1) as a sum over δ-functions. The activity ⟨A0⟩predicted by
the theory is the expectation value of the observed activity. Mathematically speaking,
the observed activity A converges for N →∞in the weak topology to its expectation
value. More practically this implies that we should convolve the observed activity with
a continuous test function γ(s) before comparing with A0. We take a function γ with the
normalization
 smax
0
γ(s)ds = 1. For the sake of simplicity we assume furthermore that γ
has ﬁnite support so that γ(s) = 0 for s < 0 or s > smax. We deﬁne
A(t) =
 smax
0
γ(s)A(t −s)ds.
(12.20)
The ﬁring is asynchronous if the averaged ﬂuctuations ⟨|A(t) −A0|2⟩decrease with
increasing N; see Fig. 12.14.
To keep the notation light, we normally write simply A(t) here, even in places where
it would be more precise to write ⟨A(t)⟩(the expected population activity at time t, cal-
culated by theory) or A(t) (the ﬁltered population activity, derived from empirical mea-
surement in a simulation or experiment). Only in places where the distinction between
A, A, and ⟨A⟩is crucial do we use the explicit notation with bars or angle brackets.
12.4.3 Activity of a fully connected network
The gain function of a neuron is the ﬁring rate ν as a function of its input current I. In the
previous subsection, we have seen that the ﬁring rate is equivalent to the expected value of
the population activity A0 in the state of asynchronous ﬁring. We thus have
⟨A0⟩= gσ(I).
(12.21)
The gain function in the absence of any noise (ﬂuctuation amplitude σ = 0) will be denoted
by g0.
Recall that the total input I to a neuron of a fully connected population consists of the
external input Iext(t) and a component that is due to the interaction of the neurons within
the population. We copy Eq. (12.4) to have the explicit expression of the input current
I(t) = w0 N
 ∞
0 α(s)A(t −s)ds+Iext(t).
(12.22)
Since the overall strength of the interaction is set by w0, we can impose a normalization
 ∞
0 α(s)ds = 1. We now exploit the assumption of stationarity and set
 ∞
0 α(s)A(t −s)ds =
A0. The left-hand side is the ﬁltered observed quantity which is in reality never exactly

12.4 From microscopic to macroscopic
313
A0
I0
Fig. 12.15 Graphical solution for the ﬁxed point A0 of the activity in a population of spiking neurons.
The intersection of the gain function A0 = g0(I0) (solid line) with the straight line A0 = [I0 −Iext
0 ]/J0
(dotted) gives the value of the activity A0. Depending on the parameters, several solutions may coexist
(dashed line).
constant, but if the number N of neurons in the network is sufﬁciently large, we do not
have to worry about small ﬂuctuations around A0. Note that α here plays the role of the
test function introduced in the previous example.
Therefore, the assumption of stationary activity A0 combined with the assumption of
constant external input Iext(t) = Iext
0
yields a constant total driving current
I0 = w0 N A0 +Iext
0 .
(12.23)
Together with Eq. (12.21) we arrive at an implicit equation for the population activity A0,
A0 = g0

J0 A0 +Iext
0

,
(12.24)
where g0 is the noise-free gain function of single neurons and J0 = w0 N. In words, the
population activity in a homogeneous network of neurons with all-to-all connectivity can
be calculated if we know the single-neuron gain function g0 and the coupling strength J0.
This is the central result of this section, which is independent of any speciﬁc assumption
about the neuron model.
A graphical solution of Eq. (12.24) is indicated in Fig. 12.15 where two functions are
plotted: ﬁrst, the mean ﬁring rate ν = g0(I0) as a function of the input I0 (i.e., the gain
function); second, the population activity A0 as a function of the total input I0 (i.e., A0 =
[I0 −Iext
0 ]/J0; see Eq. (12.23)). The intersections of the two functions yield ﬁxed points of
the activity A0.
As an aside we note that the graphical construction is identical to that of the Curie-Weiss
theory of ferromagnetism which can be found in any physics textbook. More generally, the
structure of the equations corresponds to the mean-ﬁeld solution of a system with feedback.
As shown in Fig. 12.15, several solutions may coexist. We cannot conclude from the ﬁgure
whether one or several solutions are stable. In fact, it is possible that all solutions are unsta-
ble. In the last case, the network leaves the state of asynchronous ﬁring and evolves toward

314
Neuronal populations
an oscillatory state. The stability analysis of the asynchronous state requires equations for
the population dynamics, which will be discussed in Chapters 13 and 14.
The parameter J0 introduced above in Eq. (12.24) implies, at least implicitly, a scaling
of weights wi j = J0/N - as suggested earlier during the discussion of fully connected
networks; see Eq. (12.6). The scaling with 1/N enables us to consider the limit of a large
number of neurons: if we keep J0 ﬁxed, the equation remains the same, even if N increases.
Because ﬂuctuations of the observed population activity A(t) around A0 decrease as N
increases, Eq. (12.24) becomes exact in the limit of N →∞.
Example: Leaky integrate-and-ﬁre model with diffusive noise
We consider a large and fully connected network of identical leaky integrate-and-ﬁre
neurons with homogeneous coupling wi j = J0/N and normalized postsynaptic currents
(
 ∞
0 α(s)ds = 1). In the state of asynchronous ﬁring, the total input current driving a
typical neuron of the network is then
I0 = Iext
0 +J0 A0 .
(12.25)
In addition, each neuron receives individual diffusive noise of variance σ2 that could
represent spike arrival from other populations. The single-neuron gain function (Siegert,
1951) in the presence of diffusive noise has already been stated in Chapter 8; see
Eq. (8.54). We use the formula of the gain function to calculate the population activity
A0 = gσ(I0) =

τm
√π

ϑ−RI0
σ
ur−RI0
σ
du exp

u2
[1+erf(u)]
 −1
,
(12.26)
where σ with units of voltage measures the amplitude of the noise. The ﬁxed points
for the population activity are once more determined by the intersections of these two
functions; see Fig. 12.16.
12.4.4 Activity of a randomly connected network
In the preceding subsections we have studied the stationary state of a large population of
neurons for a given noise level. In Fig. 12.16 the noise was modeled explicitly as diffusive
noise and can be interpreted as the effect of stochastic spike arrival from other populations
or some intrinsic noise source inside each neuron. In other words, noise was added explic-
itly to the model while the input current Ii(t) to neuron i arising from other neurons in the
population was constant and the same for all neurons: Ii = I0.
In a randomly connected network (and similarly in a fully connected network of ﬁnite
size), the summed synaptic input current arising from other neurons in the population is,
however, not constant but ﬂuctuates around a mean value I0, even if the population is in a
stationary state of asynchronous activity. In this subsection, we discuss how to mathemati-
cally treat the additional noise arising from the network.

12.4 From microscopic to macroscopic
315
−1
0
1
2
I0
0
0.1
0.2
A [kHz]
Fig. 12.16 Graphical solution for the ﬁxed point A0 in the case of a fully connected network
of leaky integrate-and-ﬁre neurons. The solid lines show the single-neuron ﬁring rate as a func-
tion of the constant input current I0 for four different noise levels, namely, σ = 1.0,σ = 0.5,
σ = 0.1,σ = 0.0 (from top to bottom). The intersection of the gain function with the dashed line
with slope 1/J0 gives solutions for the stationary activity A0 in a population with excitatory coupling
J0. Other parameters: ϑ = 1, R = 1, τ = 10 ms.
We assume that the network is in a stationary state where each neuron ﬁres stochastically,
independently, and at a constant rate ν, so that the ﬁring of different neurons exhibits only
chance coincidences. Suppose that we have a randomly connected network of N neurons
where each neuron receives input from Cpre presynaptic partners. All weights are set equal
to wi j = w.
We are going to determine the ﬁring rate ν = A0 of a typical neuron in the network self-
consistently as follows. If all neurons ﬁre at a rate ν then the mean input current to neuron
i generated by its Cpre presynaptic partners is
⟨I0⟩= Cpre qwν +Iext
0 ,
(12.27)
where q =
 ∞
0 α(s)ds denotes the integral over the postsynaptic current and can be inter-
preted as the total electric charge delivered by a single input spike; see Section 8.2.
The input current is not constant but ﬂuctuates with a variance σ2
I given by
σ2
I = Cpre w2 q2 ν ,
(12.28)
where q2 =
 ∞
0 α2(s)ds; see Section 8.2.
Thus, if neurons ﬁre at constant rate ν, we know the mean input current and its variance.
In order to close the argument we use the single-neuron gain function
ν = gσ(I0),
(12.29)
which is supposed to be known for arbitrary noise levels σI. If we insert the mean I0 from
Eq. (12.27) and its standard deviation σI from Eq. (12.28), we arrive at an implicit equation
for the ﬁring rate ν which we need to solve numerically. The mean population activity is
then ⟨A0⟩= ν.

316
Neuronal populations
We emphasize that the above argument does not require any speciﬁc neuron model.
In fact, it holds for biophysical neuron models of the Hodgkin-Huxley type as well as
for integrate-and-ﬁre models. The advantage of a leaky integrate-and-ﬁre model is that an
explicit mathematical formula for the gain function gσ(I0) is available. An example will
be given below. But we can use Eqs. (12.27)-(12.29) just as well for a homogeneous pop-
ulation of biophysical neuron models. The only difference is that we have to numerically
determine the single-neuron gain function gσ(I0) for different noise levels (with noise of
the appropriate autocorrelation) before starting to solve the network equations.
Note also that the above argument is not restricted to a network consisting of a single
population. It can be extended to several interacting populations. In this case, the expres-
sions for the mean and variance of the input current contain contributions from the other
populations, as well as from the self-interaction in the network. An example with interact-
ing excitatory and inhibitory populations is given below.
The arguments that have been developed above for networks with a ﬁxed number of
presynaptic partners Cpre can also be generalized to networks with asymmetric random
connectivity of ﬁxed connection probability p and synaptic scaling wi j = J0/
√
N (Amari,
1972; Sompolinksy et al., 1988; Cessac et al., 1994; van Vreeswijk and Sompolinsky,
1996; Ben Arous and Guionnet, 1995).
Brunel network: excitatory and inhibitory populations
The self-consistency argument will now be applied to the case of two interacting popu-
lations, an excitatory population with NE neurons and an inhibitory population with NI
neurons. The neurons in both populations are modeled by leaky integrate-and-ﬁre neurons.
For the sake of convenience, we set the resting potential to zero (urest = 0). We have seen
in Chapter 8 that leaky integrate-and-ﬁre neurons with diffusive noise generate spike trains
with a broad distribution of interspike intervals when they are driven in the subthreshold
regime. We will use this observation to construct a self-consistent solution for the station-
ary states of asynchronous ﬁring.
We assume that excitatory and inhibitory neurons have the same parameters ϑ, τm, R,
and ur. In addition, all neurons are driven by a common external current Iext. Each neuron
in the population receives CE synapses from excitatory neurons with weight wE > 0 and
CI synapses from inhibitory neurons with weight wI < 0. If an input spike arrives at the
synapses of neuron i from a presynaptic neuron j, its membrane potential changes by an
amount ΔuE = wE qR/τm if j is excitatory and ΔuI = ΔuE wI/wE if j is inhibitory. Here q
has units of electric charge. We set
γ = CI
CE
and
g = −wI
wE
= −ΔuI
ΔuE
.
(12.30)
Since excitatory and inhibitory neurons receive the same number of input connections
in our model, we assume that they ﬁre with a common ﬁring rate ν. The total input current

12.4 From microscopic to macroscopic
317
generated by the external current and by the lateral couplings is
I0 = Iext +q ∑
j
ν j wj
= Iext
0 +qν wE CE [1−γ g].
(12.31)
Because each input spike causes a jump of the membrane potential, it is convenient to
measure the noise strength by the variance σ2
u of the membrane potential (as opposed to
the variance σ2
I of the input). With the deﬁnitions of Chapter 8, we set σ2
u = 0.5σ2 where,
from Eq. (8.42),
σ2 = ∑
j
ν j τ (Δu2
j)
= ν τ (ΔuE)2CE [1+γ g2].
(12.32)
The stationary ﬁring rate A0 of the population with mean input I0 and variance σ is copied
from Eq. (12.26) and repeated here for convenience
A0 = ν = gσ(I0) = 1
τm

√π

ϑ−RI0
σ
ur−RI0
σ
exp

x2
[1+erf(x)] dx
 −1
.
(12.33)
In a stationary state we must have A0 = ν. To get the value of A0 we must therefore solve
Eqs. (12.31)-(12.33) simultaneously for ν and σ. Since the gain function, i.e., the ﬁring
rate as a function of the input I0, depends on the noise level σ, a simple graphical solution
as in Fig. 12.15 is no longer possible. Numerical solutions of Eqs. (12.31)-(12.33) have
been obtained by Amit and Brunel (1997a,b). For a mixed graphical-numerical approach
see Mascaro and Amit (1999).
Below we give some examples of how to construct self-consistent solutions. For conve-
nience we always set ϑ = 1, q = 1, R = 1 and τm = 10 ms and work with a unit-free current
I →h. Our aim is to ﬁnd connectivity parameters such that the mean input to each neuron
is h = 0.8 and its variance σ = 0.2.
Figure 12.17a shows that h0 = 0.8 and σ = 0.2 correspond to a ﬁring rate of A0 = ν ≈
16 Hz. We set ΔuE = 0.025, i.e., 40 simultaneous spikes are necessary to make a neuron
ﬁre. Inhibition has the same strength wI = −wE so that g = 1. We constrain our search
to solutions with CE = CI so that γ = 1. Thus, on the average, excitation and inhibition
balance each other. To get an average input potential of h0 = 0.8 we therefore need a
constant driving current Iext = 0.8.
To arrive at σ = 0.2 we solve Eq. (12.32) for CE and ﬁnd CE = CI = 200. Thus for this
choice of the parameters the network generates enough noise to allow a stationary solution
of asynchronous ﬁring at 16 Hz.
Note that, for the same parameters, the inactive state where all neurons are silent is also
a solution. Using the methods discussed in this section we cannot say anything about the
stability of these states. For the stability analysis see Chapter 13.

318
Neuronal populations
0
0.5
1
h0
0
0.01
0.02
0.03
0.04
A [kHz]
(a)
−0.5
0
0.5
1
h0
0
0.01
0.02
0.03
0.04
(b)
A [kHz]
Fig. 12.17 (a) Mean activity of a population of integrate-and-ﬁre neurons with diffusive noise ampli-
tude of σ = 0.2 as a function of h0 = RI0. For h0 = 0.8 the population rate is ν ≈16 Hz (dotted line).
(b) Mean activity of a population of integrate-and-ﬁre neurons with diffusive noise of σ = 0.54 as
a function of h0 = RI0. For h0 = 0.2 the population rate is ν = 8 Hz (dotted line). The dashed line
shows A0 = [h0 −hext
0 ]/Jeff with an effective coupling Jeff < 0.
Example: Inhibition dominated network
About 80-90% of the neurons in the cerebral cortex are excitatory and the remaining
10-20% inhibitory. Let us suppose that we have NE = 8000 excitatory and NI = 2000
inhibitory neurons in a cortical column. We assume random connectivity with a con-
nection probability of 10% and take CE = 800, CI = 200 so that γ = 1/4. As before,
spikes arriving at excitatory synapses cause a voltage jump ΔuE = 0.025, i.e., an action
potential can be triggered by the simultaneous arrival of 40 presynaptic spikes at excita-
tory synapses. If neurons are driven in the regime close to threshold, inhibition is rather
strong and we take ΔuI = −0.125 so that g = 5. Even though we have fewer inhibitory
than excitatory neurons, the mean feedback is then dominated by inhibition since γ g > 1.
We search for a consistent solution of Eqs. (12.31)-(12.33) with a spontaneous activity
of ν = 8 Hz.
Given the above parameters, the variance is σ ≈0.54; see Eq. (12.32). The gain func-
tion of integrate-and-ﬁre neurons gives us for ν = 8 Hz a corresponding total potential of
h0 ≈0.2; see Fig. 12.17b. To attain h0 we have to apply an external stimulus hext
0 = RIext
which is slightly larger than h0 since the net effect of the lateral coupling is inhibitory.
Let us introduce the effective coupling Jeff = τCE ΔuE (1 −γ g). Using the above para-
meters we ﬁnd from Eq. (12.31) that hext
0 = h0 −Jeff A0 ≈0.6.
The external input could, of course, be provided by (stochastic) spike arrival from
other columns in the same or other areas of the brain. In this case Eq. (12.31) is to be
replaced by
h0 = τm ν ΔuE CE [1−γ g] +τm νextΔuextCext ,
(12.34)
with Cext the number of connections that a neuron receives from neurons outside the
population, Δuext their typical coupling strength characterized by the amplitude of the

12.4 From microscopic to macroscopic
319
voltage jump, and νext their spike arrival rate (Amit and Brunel, 1997a,b). Owing
to the extra stochasticity in the input, the variance σ2
u of the membrane voltage is
larger
σ 2
u = 0.5σ2 = 0.5τm ν (ΔuE)2CE [1+γ g2]+0.5τm νext(Δuext)2Cext.
(12.35)
The equations (12.33), (12.34) and (12.35) can be solved numerically (Amit and Brunel,
1997a,b). The analysis of the stability of the solution is slightly more involved (Brunel
and Hakim, 1999; Brunel, 2000), and will be considered in Chapter 13.
Example: Vogels-Abbott network
The structure of the network studied by Vogels and Abbott (Vogels and Abbott, 2005,
2009; Brette et al., 2007) is the same as that for the Brunel network: excitatory and
inhibitory model neurons have the same parameters and are connected with the same
probability p within and across the two sub-populations. Therefore inhibitory and exci-
tatory neurons ﬁre with the same mean ﬁring rate (see Section 12.4.4) and with hardly
any correlations above chance level (Fig. 12.18). The two main differences to the Brunel
network are: (i) the choice of random connectivity in the Vogels-Abbott network does
not preserve the number of presynaptic partners per neuron so that some neurons receive
more and others less than pN connections; (ii) neurons in the Vogels-Abbott network
communicate with each other by conductance-based synapses. A spike ﬁred at time t f
j
causes a change in conductance
τg
dg
dt = −g+τgΔg∑
f
δ(t −t f
j ).
(12.36)
Thus, a synaptic input causes for t > t f
j a contribution to the conductance g(t) = Δg
exp[−(t −t f
j )/τg]. The neurons are leaky integrate-and-ﬁre units.
As will be discussed in more detail in Section 13.6.3, the dominant effect of
conductance-based input is a decrease of the effective membrane time constant. In other
words, if we consider a network of leaky integrate-and-ﬁre neurons (with resting poten-
tial urest = 0), we may use again the Siegert formula of Eq. (12.26)
A0 = gσ(I0) =

τeff(I0,σ)√π

ϑ−RI0
σ
ur−RI0
σ
du exp

u2
[1+erf(u)]
 −1
(12.37)
in order to calculate the population activity A0. The main difference to the current-based
model is that the mean input current I0 and the ﬂuctuations σ of the membrane voltage
now also enter into the time constant τeff. The effective membrane time constant τeff in
simulations of conductance-based integrate-and-ﬁre neurons is sometimes four or ﬁve
times shorter than the raw membrane time constant τm (Destexhe et al., 2003; Vogels
and Abbott, 2005, 2009).

320
Neuronal populations
(a)
Correlation
(b)
Fig. 12.18 Pairwise correlation of neurons in the Vogels-Abbott network. (a) Excess probability
of observing a spike in a neuron i at time t and a spike in neuron j at time t′ for various time
lags t −t′, after subtraction of chance coincidences. Normalization such that two identical spike
trains would give a value of 1 at zero time lag. (b) As in (a), but averaged across 171 randomly
chosen pairs. The pairwise correlations are extremely small in this randomly connected network of
8000 excitatory and 2000 inhibitory neurons with connection probability p = 0.02 and conductance-
based synapses; see Vogels et al. (2011) for details. The mean ﬁring rate is A0 = 5 Hz.
The Siegert formula holds in the limit of short synaptic time constants (τE →0 and
τI →0). The assumption of short time constants for the conductances is necessary,
because the Siegert formula is valid for white noise, corresponding to short pulses. How-
ever, the gain function of integrate-and-ﬁre neurons for colored diffusive noise can also
be determined (Fourcaud and Brunel, 2002); see Section 13.6.4.
12.4.5 Apparent stochasticity and chaos in a deterministic network
In this section we discuss how a network of deterministic neurons with ﬁxed random con-
nectivity can generate its own noise. In particular, we will focus on spontaneous activ-
ity and argue that there exist stationary states of asynchronous ﬁring at low ﬁring rates
which have broad distributions of interspike intervals (Fig. 12.19) even though individual
neurons are deterministic. The arguments made here have tacitly been used throughout
Section 12.4.
Van Vreeswijk and Sompolinsky (1996, 1998) used a network of binary neurons to de-
monstrate broad interval distribution in deterministic networks. Amit and Brunel (1997a,b)
were the ﬁrst to analyze a network of integrate-and-ﬁre neurons with ﬁxed random connec-
tivity. While they allowed for an additional ﬂuctuating input current, the major part of the
ﬂuctuations were in fact generated by the network itself. The theory of randomly connected
integrate-and-ﬁre neurons has been further developed by Brunel and Hakim (1999). In a
later study, Brunel (2000) conﬁrmed that asynchronous highly irregular ﬁring can be a sta-
ble solution of the network dynamics in a completely deterministic network consisting of
excitatory and inhibitory integrate-and-ﬁre neurons. Work of Tim Vogels and Larry Abbott
has shown that asynchronous activity at low ﬁring rates can indeed be observed reliably

12.4 From microscopic to macroscopic
321
(a)
(b)
Fig. 12.19 Interspike interval distributions in the Vogels-Abbott network. (a) Interspike interval
distribution of a randomly chosen neuron. Note the long tail of the distribution. The width of the
distribution can be characterized by a coefﬁcient of variation of CV = 1.9. (b) Distribution of the CV
index across all 10 000 neurons of the network. Bin width of horizontal axis is 0.01.
in networks of leaky integrate-and-ﬁre neurons with random coupling via conductance-
based synapses (Vogels and Abbott, 2005, 2009; Brette et al., 2007). The analysis of ran-
domly connected networks of integrate-and-ﬁre neurons (Brunel, 2000) is closely related
to earlier theories for random nets of formal analog or binary neurons (Amari, 1972, 1974,
1977; Kree and Zippelius, 1991; N¨utzel, 1991; Crisanti and Sompolinsky, 1988; Cessac
et al., 1994). However, the reset of neurons after each spike can be the cause of additional
instabilities that have been absent in these earlier networks with analog or binary neurons.
Random connectivity of the network plays a central role in the arguments. We focus on
randomness with a ﬁxed number C of presynaptic partners. Sparse connectivity means that
the ratio
δ = C
N ≪1
(12.38)
is a small number. Formally, we may take the limit as N →∞while keeping C ﬁxed. As
a consequence of the sparse random network connectivity two neurons i and j share only
a small number of common inputs. In the limit of C/N →0 the probability that neurons
i and j have a common presynaptic neuron vanishes. Thus, if the presynaptic neurons ﬁre
stochastically, then the input spike trains that arrive at neuron i and j are independent
(Derrida et al., 1987; Kree and Zippelius, 1991). In that case, the input of neurons i
and j can be described as an uncorrelated stochastic spike arrival which in turn can be
approximated by a diffusive noise model; see Chapter 8. Therefore, in a large and suitably
constructed random network, correlations between spiking neurons can be arbitrarily low
(Renart et al., 2010); see Fig. 12.18.
Note that this is in stark contrast to a fully connected network of ﬁnite size where neurons
receive highly correlated input, but the correlations are completely described by the time
course of the population activity.

322
Neuronal populations
12.5 Summary
Neurons do not work in isolation, but are embedded in networks of neurons with similar
properties. Such networks of similar neurons can be organized as distributed assemblies
or as local pools of neurons. Groups of neurons with similar properties can be approxi-
mated as homogeneous or weakly heterogeneous populations of neurons. In mathematical
models, the connectivity within the population is typically all-to-all or random.
The population activity is deﬁned as the number of spikes ﬁred in a short instant of time,
averaged across the population. Since each neuron in a population receives input from
many others (from the same and/or from other populations) its total input at each moment
in time depends on the activity of the presynaptic population(s). Hence the population
activity A(t) controls the mean drive of a postsynaptic neuron.
If the population in a self-connected network is in a state of stationary activity, the
expected value ⟨A0⟩of the population activity can be determined self-consistently. To do
so, we approximate the mean drive of a neuron by ⟨A0⟩and exploit that the ﬁring rate of
the population must be equal to that of a single neuron. In the stationary state of asyn-
chronous activity the population activity is therefore fully determined by the gain function
of a single neuron (i.e., its frequency-current curve) and the strength of feedback connec-
tions. This result, which is an example of a (stationary) mean-ﬁeld theory, is independent
of any neuron model. The mean-ﬁeld solution is exact for a fully connected network in the
limit of a large number of neurons (N →∞), and a good approximation for large randomly
connected networks.
The assumption of a stationary state is, of course, a strong limitation. In reality, the
activity of populations in the brain responds to external input and may also show non-trivial
intrinsic activity changes. In other words, the population activity is in most situations time-
dependent. The mathematical description of the dynamics of the population activity is the
topic of the next three chapters.
Literature
The development of population equations, also called "neural mass" equations, had a ﬁrst
boom around 1972 with several papers by different researchers (Wilson and Cowan, 1972;
Knight, 1972; Amari, 1972). Equations very similar to the population equations have some-
times also been used as effective rate model neurons (Grossberg, 1973). The transition from
stationary activity to dynamics of population in the early papers is often ad hoc (Wilson
and Cowan, 1972).
The study of randomly connected networks has a long tradition in the mathematical
sciences. Random networks of formal neurons have been studied by numerous researchers
(e.g., Amari 1972, 1974, 1977; Sompolinksy et al. 1988; Cessac et al. 1994; van Vreeswijk
and Sompolinsky 1996, 1998), and a mathematically precise formulation of mean-ﬁeld
theories for random nets is possible (Faugeras et al., 2009).
The theory for randomly connected integrate-and-ﬁre neurons (Amit and Brunel, 1997a;

12.5 Summary
323
Brunel and Hakim, 1999; Brunel, 2000; Renart et al., 2010) builds on earlier studies of for-
mal random networks. The Siegert formula for the gain function of a leaky integrate-and-
ﬁre model with diffusive noise appears in several classic papers (Siegert, 1951; Amit and
Brunel, 1997a; Brunel and Hakim, 1999; Brunel, 2000). In arbitrarily connected integrate-
and-ﬁre networks, the dynamics is highly complex (Cessac, 2008).
Exercises
1. Fully connected network. Assume a fully connected network of N Poisson neurons with ﬁring
rate νi(t) = g(Ii(t)) > 0. Each neuron sends its output spikes to all other neurons as well as back
to itself. When a spike arrives at the synapse from a presynaptic neuron j to where a postsynaptic
neuron i is, it generates a postsynaptic current
Isyn
i
= wij exp[−(t −t f
j )/τs]
for t > t f
j ,
(12.39)
where t f
j is the moment when the presynaptic neuron j ﬁred a spike and τs is the synaptic time
constant.
(a) Assume that each neuron in the network ﬁres at the same rate ν. Calculate the mean and
the variance of the input current to neuron i.
Hint: Use the methods of Chapter 8.
(b) Assume that all weights are of equal weight wij = J0/N. Show that the mean input to
neuron i is independent of N and that the variance decreases with N.
(c) Evaluate the mean and variance under the assumption that the neuron receives 4000 inputs
at a rate of 5 Hz. The synaptic time constant is 5 ms and J0 = 1 μA.
2. Stochastically connected network. Consider a network analogous to that discussed in the pre-
vious exercise, but with a synaptic coupling current
Isyn
i
= wij
 1
τ1

exp[−(t −t f
j )/τ1]−
 1
τ2

exp[−(t −t f
j )/τ2]

for t > t f
j ,
(12.40)
which contains both an excitatory and an inhibitory component.
(a) Calculate the mean synaptic current and its variance assuming arbitrary coupling weights
wij. How do the mean and variance depend upon the number of neurons N?
(b) Assume that the weights have a value J0/
√
N. How do the mean and variance of the synap-
tic input current scale as a function of N?
3. Mean-ﬁeld model. Consider a network of N neurons with all-to-all connectivity and scaled
synaptic weights wij = J0/N. The transfer function (rate as a function of input potential) is piece-
wise linear:
f = g(h) = h−h1
h2 −h1
for h1 ≤h ≤h2 .
(12.41)
The rate vanishes for h < h1 and is constant f = 1 (in units of the maximal rate) for h > h2.
The dynamics of the input potential hi of a neuron i are given by
τ dhi
dt = −hi +RIi(t),
(12.42)
with
I(t) = Iext +∑
j
wijα(t −t f
j ).
(12.43)
(a) Find graphically the ﬁxed points of the population activity in the network with connections
as described above.
(b) Determine the solutions analytically.

324
Neuronal populations
4. Mean ﬁeld in a network of two populations. We study a network of excitatory and inhibitory
neurons. Each excitatory neuron has, in the stationary state, a ﬁring rate
e = f(I) = γ I
for I > 0
and f(I) = 0 otherwise.
(12.44)
Inhibitory neurons have a ﬁring rate
s = g(I) = I2
for I > 0
and g(I) = 0 otherwise.
(12.45)
Assume that we have a large network of N excitatory and N inhibitory neurons, where N ≫1.
The input to an excitatory neuron i is
Ii(t) = I0 +
N
∑
k=1
w
N ek −
N
∑
n=1
1
N sn,
(12.46)
where ek is the rate of excitatory neuron k and sn the rate of inhibitory neuron n. The input to an
inhibitory neuron n is
Ii(t) =
N
∑
k=1
w
N ek.
(12.47)
(a) Give the analytical solution for the steady state of the network. If there are several
solutions, indicate the stability of each of these.
Hint: Introduce the parameter A = ∑N
k=1
1
N ek for the excitatory population activity; express
the activity of the inhibitory population by A and insert the result into the excitatory equation.
(b) Solve graphically for the stationary state of the activity in the network, for two qualitatively
different regimes which you choose. Free parameters are the coupling strength w and the external
input I.

13
Continuity equation and the Fokker-Planck approach
In the previous chapter, the notion of a homogeneous population of neurons was intro-
duced. Neurons within the population can be independent, fully connected, or randomly
connected, but they should all have identical, or at least similar, parameters and all neu-
rons should receive similar input. For such a homogeneous population of neurons, it is
possible to predict the population activity in the stationary state of asynchronous ﬁring
(Section 12.4). While the arguments we made in the previous chapter are general and do
not rely on any speciﬁc neuron model, they are unfortunately restricted to the stationary
state.
In a realistic situation, neurons in the brain receive time-dependent input. Humans change
their direction of gaze spontaneously two or three times per second. After each gaze
change, a new image impinges on the retina and is transmitted to the visual cortex. Audi-
tory stimuli such as music or trafﬁc noise have a rich intrinsic temporal structure. If humans
explore the texture of a surface which by itself is static, they move their ﬁngers so as to
actively create temporal structure in the touch perception. If we think back to our last
holiday, we recall sequences of events rather than static memory items. When we type a
message on a keyboard, we move our ﬁngers in a rapid pattern. In none of these situations,
is stationary brain activity a likely candidate to represent our thoughts and perceptions.
Indeed, EEG (electroencephalography) recordings from the surface of the human scalp, as
well as multi-unit activity recorded from the cortex of animals, indicate that the activity of
the brain exhibits a rich temporal structure.
In this chapter, we present a formulation of population activity equations that can account
for the temporal aspects of population dynamics. It is based on the notion of mem-
brane potential densities for which a continuity equation is derived (Section 13.1). In order
to illustrate the approach, we consider a population of neurons receiving stochastically
arriving spikes (Sections 13.2 and 13.3). For an explicit solution of the equations, we ﬁrst
focus on coupled populations of leaky integrate-and-ﬁre neurons (Sections 13.4), but the
mathematical approach can be generalized to arbitrary nonlinear integrate-and-ﬁre neu-
rons (Section 13.5) and generalized integrate-and-ﬁre neurons with adaptation (Section
13.6).
Before we turn to neurons with adaptation, we focus on one-dimensional, but potentially
nonlinear integrate-and-ﬁre neurons. Knowledge of the momentary membrane potential

326
Continuity equation and the Fokker-Planck approach
and the input is sufﬁcient to predict the future evolution of a single integrate-and-ﬁre neu-
ron. In a large population of neurons, the momentary state of the population as a whole
can therefore be characterized by the momentary distribution of membrane potentials. The
evolution of this distribution over time is summarized by the continuity equation which is
introduced now.
13.1 Continuity equation
In a population of neurons, each neuron may be in a different internal state. In this section
we derive partial differential equations that describe how the distribution of internal states
evolves as a function of time. We start in Section 13.1.1 with a population of integrate-and-
ﬁre neurons. Since the state of an integrate-and-ﬁre neuron is characterized by its mem-
brane potential, we describe the dynamics of the population as the evolution of membrane
potential densities.
The population activity, A(t), was introduced in Chapter 7 as the fraction of neurons that
ﬁre at time t in a ﬁnite population. In this chapter and the next, the population activity is
the expected population activity A(t) ≡⟨A(t)⟩. Since A(t) is self-averaging, it can also be
said that we consider the limit of large populations. The ﬁnite-size effects will be discussed
in Section 14.6.
The formulation of the dynamics of a population of integrate-and-ﬁre neurons on the
level of membrane potential densities has been developed by Abbott and van Vreeswijk
(1993), Brunel and Hakim (1999), Fusi and Mattia (1999), Nykamp and Tranchina (2000),
Brunel (2000), and Omurtag et al. (2000). The closely related formulation in terms of
refractory densities has been studied by Wilson and Cowan (1972), Gerstner and van Hem-
men (1992), Bauer and Pawelzik (1993), and Gerstner (2000). Generalized density equa-
tions have been discussed by Knight (2000) and Fourcaud and Brunel (2002).
13.1.1 Distribution of membrane potentials
We study a homogeneous population of integrate-and-ﬁre neurons. The internal state of a
neuron i is determined by its membrane potential which changes according to
τm
d
dt ui = f(ui)+RIi(t)
for ui < θreset .
(13.1)
Here R is the input resistance, τm = RC the membrane time constant, and Ii(t) the total
input (external driving current and synaptic input). If ui ≥θreset the membrane potential
is reset to ui = ur < θreset. Here f(ui) is an arbitrary function of u; see Eq. (5.2). For
f(ui) = −(ui −urest) the equation reduces to the standard leaky integrate-and-ﬁre model.
For the moment we keep the treatment general and restrict it to the leaky integrate-and-ﬁre
model only later.
In a population of N integrate-and-ﬁre neurons, we may ask how many of the neurons

13.1 Continuity equation
327
have at time t a given membrane potential. As N →∞the fraction of neurons i with mem-
brane potential u0 < ui(t) ≤u0 +Δu is
lim
N→∞
neurons with u0 < ui(t) ≤u0 +Δu
N

=
 u0+Δu
u0
p(u,t)du,
(13.2)
where p(u,t) is the membrane potential density; see Chapter 8. The integral over this den-
sity remains constant over time, i.e.,
 θreset
−∞
p(u,t)du = 1.
(13.3)
The normalization to unity expresses the fact that all neurons have a membrane potential
below or equal to the threshold.
The aim of this section is to describe the evolution of the density p(u,t) as a function of
time. As we shall see, the equation that describes the dynamics of p(u,t) is nearly identical
to that of a single integrate-and-ﬁre neuron with diffusive noise; see Eqs. (8.40) and (8.41).
13.1.2 Flux and continuity equation
Let us consider the portion of neurons with a membrane potential between u0 and u1,
n(u0;u1)
N
=
 u1
u0
p(u′,t)du′ .
(13.4)
The fraction of neurons with u0 < u < u1 increases if neurons enter from below through the
boundary u0 or from above through the boundary u1; see Fig. 13.1. Since there are many
neurons in the population, we expect that in each short time interval Δt, many trajectories
cross one of the boundaries. The ﬂux J(u,t) is the net fraction of trajectories per unit time
that crosses the value u. A positive ﬂux J(u,t) > 0 is deﬁned as a ﬂux toward increasing
values of u. In other words, in a ﬁnite population of N neurons, the quantity N J(u0,t)Δt
describes the number of trajectories that in the interval Δt cross the boundary u0 from
below, minus the number of trajectories crossing u0 from above. Note that u0 here is an
arbitrary value that we chose as the lower bound of the integral in Eq. (13.4) and as such
has no physical meaning for the neuron model.
Since trajectories cannot simply end, a change in the number n(u0;u1) of trajectories in
the interval u0 < u < u1 can be traced back to the ﬂux of trajectories in and out of that
interval. We therefore have the conservation law
∂
∂t
 u1
u0
p(u′,t)du′ = J(u0,t)−J(u1,t).
(13.5)
Taking the derivative with respect to the upper boundary u1 and changing the name of the
variable from u1 to u yields the continuity equation,
∂
∂t p(u,t) = −∂
∂uJ(u,t)
for u ̸= ur and u ̸= θreset ,
(13.6)

328
Continuity equation and the Fokker-Planck approach
u
t
u0
u1
J(u1,t)
J(u0,t)
Fig. 13.1 The number of trajectories in the interval [u0,u1] changes if one of the trajectories crosses
the boundary u0 or u1. For a large number of neurons this fact is described by the continuity equation;
see Eq. (13.6). Schematic ﬁgure where only three trajectories are shown.
which expresses the conservation of the number of trajectories. In integrate-and-ﬁre mod-
els, however, there are two special voltage values, ur and θreset, where the number of tra-
jectories is not conserved, because of the ﬁre-and-reset mechanism.
Since neurons that have ﬁred start a new trajectory at ur, we have a "source of new
trajectories" at u = ur, i.e., new trajectories appear in the interval [ur −ε,ur +ε] that have
not entered the interval through one of the borders. Adding a term A(t)δ(u −ur) on the
right-hand side of (13.6) accounts for this source of trajectories. The trajectories that appear
at ur disappear at θreset, so that we have
∂
∂t p(u,t) = −∂
∂uJ(u,t)+A(t)δ(u−ur)−A(t)δ(u−θreset).
(13.7)
The density p(u,t) vanishes for all values u > θreset.
The population activity A(t) is, by deﬁnition, the fraction of neurons that ﬁre, i.e., those
that pass through the threshold. Therefore we ﬁnd
A(t) = J(θreset,t).
(13.8)
Equations (13.7) and (13.8) describe the evolution of the the membrane potential densities
and the resulting population activity as a function of time. We now specify the neuron
model so as to have an explicit expression for the ﬂux.
13.2 Stochastic spike arrival
We consider the ﬂux J(u,t) in a homogeneous population of integrate-and-ﬁre neurons
with voltage equation (13.1). We assume that all neurons in the population receive the
same driving current Iext. In addition each neuron receives independent background input
in the form of stochastic spike arrival. We allow for different types of synapses. An input
spike at a synapse of type k causes a jump of the membrane potential by an amount wk.
For example, k = 1 could refer to weak excitatory synapses with jump size w1 > 0; k = 2
to strong excitatory synapses w2 > w1; and k = 3 to inhibitory synapses with w3 < 0.
The effective spike arrival rate (summed over all synapses of the same type k) is denoted

13.2 Stochastic spike arrival
329
u0
u
t
}Wk
Jjump(u0  ,t)
(a)
u0
u
t
Jdrift (u0,t)
(b)
Fig. 13.2 (a) All trajectory that are less than wk below u0 cross u0 upon spike arrival. (b) The drift
Jdrift(u0,t) depends on the density of the trajectories and on the slope with which the trajectories
cross the boundary u0.
as νk. While the mean spike arrival rates νk(t) are identical for all neurons, we assume that
the actual input spike trains at different neurons and different synapses are independent.
In a simulation, spike arrival at different neurons is generated by independent Poisson
processes with a common spike arrival rate νk(t) for synapse type k.
Whereas spike arrivals cause a jump of the membrane potential, a ﬁnite input current
Iext(t) generates a smooth drift of the membrane potential trajectories. In such a network,
the ﬂux J(u,t) across a reference potential u0 can therefore be generated in two different
ways: through a "jump" or a "drift" of trajectories. We separate the two contributions to
the ﬂux into Jjump and Jdrift
J(u0,t) = Jdrift(u0,t)+Jjump(u0,t),
(13.9)
and treat each of these in turn.
13.2.1 Jumps of membrane potential due to stochastic spike arrival
To evaluate Jjump, let us consider an excitatory input wk > 0. All neurons that have a mem-
brane potential ui with u0 −wk < ui ≤u0 will jump across the reference potential u0 upon
spike arrival at a synapse of type k; see Fig. 13.2a. Since at each neuron spikes arrive
stochastically, we cannot predict with certainty whether a single neuron receives a spike
around time t or not. But because the Poisson rate νk of spike arrival at synapses of type k
is the same for each neuron, while the actual spike trains are independent for different neu-
rons, the total (expected) ﬂux, or probability current, caused by input spikes at all synapses
can be calculated as
Jjump(u0,t) = ∑
k
νk
 u0
u0−wk
p(u,t)du.
(13.10)
If the number of neurons is large, the actual ﬂux is very close to the expected ﬂux given in
Eq. (13.10).

330
Continuity equation and the Fokker-Planck approach
13.2.2 Drift of membrane potential
The drift ﬂux Jdrift(u0,t) through the reference potential u0 is given by the density p(u0,t)
at the potential u0 times the momentary "velocity" du/dt; see Fig. 13.2b. Therefore
Jdrift(u0,t) = du
dt

u0
p(u0,t) = 1
τm
[ f(u0)+RIext(t)] p(u0,t),
(13.11)
where f(u0) is the nonlinearity of the the integrate-and-ﬁre model in Eq. (13.1). Note that
synaptic δ-current pulses cause a jump of the membrane potential and therefore contribute
only to Jjump (see Section 13.2.1), but not to the drift ﬂux considered here. Current pulses
of ﬁnite duration, however, should be included in Iext(t) in Eq. (13.11).
Example: Leaky integrate-and-ﬁre neurons
With f(u) = −(u−urest) we have for leaky integrate-and-ﬁre neurons a drift-induced
ﬂux
Jdrift(u0,t) = 1
τm
[−u0 +urest +RIext(t)] p(u0,t).
(13.12)
13.2.3 Population activity
A positive ﬂux through the threshold θreset yields the population activity A(t). Since the
ﬂux has components from the drift and from the jumps, the total ﬂux at the threshold is
A(t) = 1
τm
[ f(θreset)+RIext(t)] p(θreset,t)+∑
k
νk
 θreset
θreset−wk
p(u,t)du.
(13.13)
Since the probability density vanishes for u > θreset, the sum over the synapses k can be
restricted to all excitatory synapses.
If we insert the explicit form of the ﬂux that we derived in Eqs. (13.10) and (13.11) into
the continuity equation (13.7), we arrive at the density equation for the membrane potential
of integrate-and-ﬁre neurons
∂
∂t p(u,t) = −1
τm
∂
∂u

f(u)+RIext(t)

p(u,t)

+∑
k
νk(t) [p(u−wk,t)−p(u,t)]
(13.14)
+A(t)δ(u−ur)−A(t)δ(u−θreset).
The ﬁrst two terms on the right-hand side describe the continuous drift, the third term the
jumps caused by stochastic spike arrival, and the last two terms take care of the reset.
Because of the ﬁring condition, we have p(u,t) = 0 for u > θreset.
Equations (13.13) and (13.14) can be used to predict the population activity A(t) in a
population of integrate-and-ﬁre neurons stimulated by an arbitrary common input Iext(t).

13.2 Stochastic spike arrival
331
A
A(t)
100
50
A(t) [Hz]
A 
0
50
t [ms]
100
ν (t) [kHz]
0
0
1
2
(a)
−65
−55 0
50
100
0
0.1
0.2
0.3
0.4
u [mv]
t [ms]
p(u,t)
(b)
Fig. 13.3 Solution of the membrane potential density equation for time dependent input. The input
is sinusoidal with a period of 100 ms. (a) Population activity A(t) (thick solid line; left vertical
scale) in response to excitatory and inhibitory spikes arriving with modulated ﬁring rates (thin solid
and dashed lines, respectively; right vertical scale). (b) The membrane population density p(u,t)
as a function of voltage and time during one period of the periodic stimulation. Adapted from
Nykamp and Tranchina (2000) with kind permission from Springer Science and Business Media.
For a numerical implementation of Eq. (13.6) we refer the reader to the literature (Nykamp
and Tranchina, 2000; Omurtag et al., 2000).
Example: Transient response of population activity
The population of 10 000 uncoupled leaky integrate-and-ﬁre neurons simulated by
Nykamp and Tranchina (2000) receives stochastic spike arrivals at excitatory and
inhibitory synapses at rate νE(t) and νI(t), respectively. Each input spike causes a volt-
age jump of amplitude w. The raw jump size is drawn from some distribution and then
multiplied with the difference between the synaptic reversal potential and value of the
membrane potential just before spike arrival, so as to approximate the effect of conduc-
tance based synapses. The average jump size in the simulation was about 0.5 mV at exci-
tatory synapses and −0.33 mV at inhibitory synapses (Nykamp and Tranchina, 2000).
The input rates are periodically modulated with frequency f = 10 Hz
νE/I(t) = ¯νE/I [1+sin(2π f t)],
(13.15)
with ¯νE = 2 kHz and ¯νI = 1 kHz. Integration of the population equations (13.13) and
(13.14) yields a population activity A(t) that responds strongly during the rising phase
of the input, well before the excitatory input reaches its maximum; see Fig. 13.3a.
We compare the solution of the population activity equations with the explicit sim-
ulation of 10 000 uncoupled neurons. The simulated population activity of the ﬁnite
network (Fig. 13.4a) is well approximated by the predicted activity A(t) which becomes
correct if the number of neurons goes to inﬁnity. The density equations also predict the
voltage distribution at each moment in time (Fig. 13.3b). The empirical histogram of
voltages in a ﬁnite population of 10 000 neurons (Fig. 13.4b) is close to the smooth
voltage distribution predicted by the theory.

332
Continuity equation and the Fokker-Planck approach
0
20
40
60
80
100
0
20
40
60
80
100
120
(a)
(b)
t [ms] 
A [Hz]
−70
−60
0
0.1
0.2
p(u,t)
u [mV]
Fig. 13.4 Comparison of theory and simulation. (a) Population ﬁring rate A(t) as a function of time
in a simulation of 100 neurons (gray histogram bars) compared to the prediction by the theory (solid
line) while the population receives periodically modulated excitatory and inhibitory conductance
input with period T = 100 ms. (b) Histogram of voltage distribution (gray horizontal bars) at t0 =
20 ms in a population of 1000 neurons compared to the solution p(u,t0) of the density equation
during the periodic stimulation. Adapted from Nykamp and Tranchina (2000) with kind permission
from Springer Science and Business Media.
13.2.4 Single neuron versus population of neurons
Equation (13.14), which describes the dynamics of p(u,t) in a population of integrate-and-
ﬁre neurons, is nearly identical to that of a single integrate-and-ﬁre neuron with stochastic
spike arrival; see Eq. (8.40). Apart from the fact that we have formulated the problem here
for arbitrary nonlinear integrate-and-ﬁre models, there are three subtle differences.
First, while p(u,t) was introduced in Chapter 8 as probability density for the membrane
potential of a single neuron, it is now interpreted as the density of membrane potentials in
a large population of uncoupled neurons.
Second, the normalization is different. In Chapter 8, we considered a single neuron
which was initialized at time ˆt at a voltage ur. For t > ˆt, the integrated density
 θreset
−∞
p(u,t)
du ≤1 was interpreted as the probability that the neuron under consideration has not yet
ﬁred since its last spike at ˆt. The value of the integral therefore decreases over time. In the
present treatment of a population of neurons, a neuron remains part of the population even
if it ﬁres. Thus the integral over the density remains constant over time; see Eq. (13.3).
Third, the fraction of neurons that "ﬂow" across threshold per unit of time is the
(expected value of) the population activity A(t). Thus, the population activity has a nat-
ural interpretation in terms of the ﬂux J(θreset,t).
13.3 Fokker-Planck equation
The equation for the membrane potential density in a population of integrate-and-ﬁre neu-
rons (see Eq. (13.14) in the previous section) can, in the limit of small jump amplitudes wk,
be approximated by a diffusion equation. To show this, we expand the right-hand side of
Eq. (13.14) into a Taylor series up to second order in wk. The result is the Fokker-Planck

13.3 Fokker-Planck equation
333
equation,
τm
∂
∂t p(u,t) = −∂
∂u

f(u)+RIext(t)+τm∑
k
νk(t)wk

p(u,t)
 
+ 1
2

τm∑
k
νk(t)w2
k

∂2
∂u2 p(u,t)
(13.16)
+τm A(t)δ(u−ur)−τm A(t)δ(u−θreset)+O(w3
k).
The term with the second derivative describes a "diffusion" in terms of the membrane
potential.
It is convenient to deﬁne the total "drive" in voltage units as
μ(t) = RIext(t)+τm∑
k
νk(t)wk
(13.17)
and the amount of diffusive noise (again in voltage units) as
σ2(t) = τm∑
k
νk(t)w2
k .
(13.18)
The ﬁring threshold acts as an absorbing boundary so that the density at threshold van-
ishes:
p(θreset,t) = 0.
(13.19)
The boundary condition p(θreset,t) = 0 arises from the mathematical limiting process: We
consider that all weights go to zero, wk →0, while the total drive μ and the amount of dif-
fusive noise remains constant. This is only possible if we have at least two different types
of synapse (excitatory and inhibitory) and we increase the rate of both while decreasing
the weights of synapses. In other words, the spike arrival rates at the synapses go to inﬁnity
so that the "shot noise" generated by spike arrivals turns into a white Gaussian distributed
noise. Any neuron with a membrane potential just below the threshold would then imme-
diately ﬁre because of the noise. Therefore the density at the threshold has to be zero. This
argument is no longer valid if spike arrival rates are ﬁnite, or if synapses react slowly so
that the noise is colored (see Section 13.6.4 below).
In order to calculate the ﬂux through the reset threshold we expand Eq. (13.13) in wk
about u = θreset and obtain
A(t) = −σ2(t)
2τm
∂p(u,t)
∂u

u=θreset
,
(13.20)
Eqs. (13.16)-(13.20), together with the normalization (13.3), deﬁne the dynamics of a
homogeneous population of integrate-and-ﬁre neurons with "diffusive" noise. For a more
detailed discussion of the diffusion limit see Chapter 8, in particular Eqs. (8.41) and (8.43).

334
Continuity equation and the Fokker-Planck approach
Example: Flux in the diffusion limit
If we compare the continuity equation (13.7) with the explicit form of the Fokker-
Planck equation (13.16), we can identify the ﬂux caused by stochastic spike arrival and
external current in the diffusion limit
Jdiff(u,t) = f(u)+ μ(t)
τm
p(u,t)−1
2
σ2(t)
τm
∂
∂u p(u,t).
(13.21)
We emphasize that stochastic spike arrival contributes to the mean drive μ(t) =
RIext(t)+τm ∑k νk(t)wk as well as to the diffusive noise σ2(t) = τm ∑k νk(t)w2
k.
13.3.1 Stationary solution for leaky integrate-and-ﬁre neurons (*)
The stationary distribution p(u) of the membrane potential is of particular interest, since
it is experimentally accessible (Calvin and Stevens, 1968; Destexhe et al., 2003; Crochet
and Petersen, 2006). We now derive the stationary solution p(u,t) ≡p(u) of the Fokker-
Planck equation (13.16) for a population of leaky integrate-and-ﬁre neurons. Neurons are
described by Eq. (13.1) with f(u) = −u, i.e., the voltage scale is shifted so that the equi-
librium potential is at zero. For leaky integrate-and-ﬁre neurons, the reset threshold is the
same as the rheobase ﬁring threshold and will be denoted by ϑ = θreset = ϑrh.
We assume that the total input h0 = RIext + τm ∑k νk wk is constant. In the stationary
state, the temporal derivative on the left-hand side of Eq. (13.16) vanishes. The terms on
the right-hand side can be transformed so that the stationary Fokker-Planck equation reads
(for u < ϑ)
0 = −∂
∂uJ(u)+A0 δ(u−ur),
(13.22)
where A0 is the population activity (or mean ﬁring rate) in the stationary state and
J(u) = −u+h0
τm
p(u)−1
2
σ2
τm
∂
∂u p(u)
(13.23)
is the total ﬂux; see Eqs. (13.6) and (13.21). The meaning of Eq. (13.22) is that the ﬂux
is constant except at u = ur where it jumps by an amount A0. Similarly, the boundary
condition p(ϑ,t) = 0 implies a second discontinuity of the ﬂux at u = ϑ.
With the results from Chapter 8 in mind, we expect that the stationary solution approaches
a Gaussian distribution for u →−∞. In fact, we can check easily that for any constant c1
p(u) = c1
σ exp

−(u−h0)2
σ2

for u ≤ur
(13.24)
is a solution of Eq. (13.22) with ﬂux J(u) = 0. However, for u > ur a simple Gaussian
distribution cannot be a solution since it does not respect the boundary condition p(ϑ) = 0.

13.4 Networks of leaky integrate-and-ﬁre neurons
335
Nevertheless, we can make an educated guess and try a modiﬁed Gaussian (Giorno et al.,
1992; Brunel and Hakim, 1999)
p(u) = c2
σ2 exp

−(u−h0)2
σ2

·
 ϑ
u exp
(x−h0)2
σ2

dx
for ur < u ≤ϑ ,
(13.25)
with some constant c2. We have written the above expression as a product of two terms. The
ﬁrst factor on the right-hand side is a standard Gaussian while the second factor guarantees
that p(u) →0 for u →ϑ. If we insert Eq. (13.25) in (13.22) we can check that it is indeed
a solution. The constant c2 is proportional to the ﬂux,
c2 = 2τm J(u)
for ur < u ≤ϑ .
(13.26)
The solution deﬁned by Eqs. (13.24) and (13.25) must be continuous at u = ur. Hence
c1 = c2
σ
 ϑ
ur
exp
(x−h0)2
σ2

dx.
(13.27)
Finally, the constant c2 is determined by the normalization condition (13.3). We use
Eqs. (13.24), (13.25), and (13.27) in (13.3) and ﬁnd
1
c2
=
 ur
−∞
 ϑ
ur
f(x,u)dxdu+
 ϑ
ur
 ϑ
u
f(x,u)dxdu =
 ϑ
ur
 x
−∞f(x,u)dudx,
(13.28)
with
f(x,u) = 1
σ2 exp

−(u−h0)2
σ2

exp
(x−h0)2
σ2

.
(13.29)
Figure 13.5b shows the resulting stationary density p(u) for different noise amplitudes.
The activity A0 is identical to the ﬂux J(u) between ur and ϑ and therefore proportional
to the constant c2; see Eq. (13.26). If we express the integral over u in Eq. (13.28) in terms
of the error function, erf(x) =
2
√π
 x
0 exp(−u2)du, we obtain
A−1
0
= τm
√π

ϑ−h0
σ
ur−h0
σ
exp

x2
[1+erf(x)] dx,
(13.30)
which is identical to the Siegert formula (Siegert, 1951) of the single-neuron ﬁring rate
[see Eq. (8.54) or (12.26)] that we used previously in Chapters 8 and 12. An alternative
formulation (see Exercises) of the remaining integral in Eq. (13.30) is also possible (Brunel
and Hakim, 1999).
13.4 Networks of leaky integrate-and-ﬁre neurons
In the previous section, the formalism of membrane potential densities was applied to a
single population driven by spikes arriving at some rate νk at the synapse of type k, where
k = 1,...,K. In a population that is coupled to itself, the spikes that drive a given neuron

336
Continuity equation and the Fokker-Planck approach
t [ms]
−0.5
0
0.5
1
u
0
20
40
60
80
(a)
0
2
4
6
p(u)
−0.5
0
0.5
1
u
(b)
h0
−1
0
1
2
0
0.1
0.2
(c)
A [kHz]
Fig. 13.5 (a) Membrane potential trajectories of ﬁve neurons (R = 1 and τm = 10 ms) driven by a
constant background current I0 = 0.8 and stochastic background input with ν+ = ν−= 0.8 kHz and
w± = ±0.05. These parameters correspond to h0 = 0.8 and σ = 0.2 in the diffusive noise model.
(b) Stationary membrane potential distribution in the diffusion limit for σ = 0.2 (solid line), σ =
0.1 (short-dashed line), and σ = 0.5 (long-dashed line). (Threshold ϑ = 1.) (c) Mean activity of a
population of integrate-and-ﬁre neurons with diffusive noise as a function of h0 for four different
noise levels: (from top to bottom) σ = 1.0,σ = 0.5,σ = 0.2 (solid line), σ = 0.1,σ = 0.0.
are, at least partially, generated within the same population. For a homogeneous population
with self-coupling the feedback is then proportional to the population activity A(t); see
Chapter 12.
We now formulate the interaction between several coupled populations using the Fokker-
Planck equation for the membrane potential density (Section 13.4.1) and apply it subse-
quently to the special cases of a population of excitatory integrate-and-ﬁre neurons inter-
acting with a population of inhibitory ones (Section 13.4.2).
13.4.1 Multiple populations
We consider multiple populations k = 1,...,K. The population with index k contains Nk
neurons and its activity is denoted by Ak. We recall that Nk Ak(t)Δt is the total number of
spikes emitted by population k in a short interval Δt.
Let us suppose that population k sends its spikes to another population n. If each neuron
in population n receives input from all neurons in k the total spike arrival rate from pop-
ulation k is therefore νk(t) = Nk Ak(t) ("full connectivity"). If each neuron in population
n receives connections only from a subset of Cnk randomly chosen neurons of population
k, then the total spike arrival rate is νk(t) = Cnk Ak(t) ("random connectivity" with a con-
nection probability pnk = Cnk/Nk from population k to population n). We assume that all
connections from k to n have the same weight wnk and that spike arrival from population k
can be approximated by a Poisson process with rate νk(t).
For each population n = 1,...,K we write down a Fokker-Planck equation analogous
to Eq. (13.16). Neurons are leaky integrate-and-ﬁre neurons. Within a population n, all
neurons have the same parameters τn, Rn, un
r, and in particular the same ﬁring threshold
ϑn. For population n the Fokker-Planck equation for the evolution of membrane potential

13.4 Networks of leaky integrate-and-ﬁre neurons
337
A1(t)
A3(t)
A5(t)
A2(t)
A4(t)
 
 
w11
w13
w31  
w14  
w41  
w42  
w24
w52 
w25
w22  
(a)
wEE
wEI
wIE
wII
AE(t)
(b)
Aext(t)
AI(t)
Fig. 13.6 Interacting populations. (a) Five populations interact via their population activities Ak. The
parameter wnk gives the synaptic weight of a connection from a presynaptic neuron in population k
to a postsynaptic neuron in population n. Not all populations are coupled with each other. (b) Brunel
network: an excitatory population of leaky integrate-and-ﬁre neurons is coupled to itself and to an
inhibitory population. Neurons in both populations receive also external input from a third population
with population activity Aext = νext described as a homogeneous Poisson process.
densities is then
τn
∂
∂t pn(u,t) = −∂
∂u

−u+Rn Iext
n (t)+τn∑
k
CnkAk(t)wnk

pn(u,t)
 
+ 1
2

τn∑
k
CnkAk(t)w2
nk

∂2
∂u2 pn(u,t)
(13.31)
+τn An(t)δ(u−un
r)−τn An(t)δ(u−ϑn).
The population activity An is the ﬂux through the threshold (see Eq. (13.20)), which gives
in our case
An(t) = −1
2

∑
k
CnkAk(t)w2
nk
 ∂pn(u,t)
∂u

u=ϑn
.
(13.32)
Thus populations interact with each other via the variable Ak(t); see Fig. 13.6.
Example: Background input
Sometimes it is useful to focus on a single population, coupled to itself, and
replace the input arising from other populations by background input. For example,
we may focus on population n = 1, which is modeled by Eq. (13.31), but use as the
inputs Ak spikes generated by a homogeneous or inhomogeneous Poisson process with
rate Ak = νk.

338
Continuity equation and the Fokker-Planck approach
Example: Full coupling and random coupling
Full coupling can be retrieved by setting Cnk = Nk and wnk = Jnk/Nk. In this case the
amount of diffusive noise in population n,
σ2
n(t) = τn

∑
k
CnkAk(t)w2
nk

,
(13.33)
decreases with increasing population size σ2
n ∝1/Nk.
13.4.2 Synchrony, oscillations, and irregularity
In Chapter 12 we have already discussed the stationary state of the population activity in a
population coupled to itself. With the methods discussed in Chapter 12 we were, however,
unable to study the stability of the stationary state; nor were we able to make any prediction
about potential time-dependent solutions.
We now give a more complete characterization of a network of leaky integrate-and-
ﬁre neurons consisting of two populations: a population of NE excitatory neurons coupled
to a population with NI = NE/4 inhibitory neurons (Brunel, 2000). The structure of the
network is shown in Fig. 13.6b. Each neuron (be it excitatory or inhibitory) receives CE
connections from the excitatory population, each with weight wEE = wIE = w0; it also
receives CI = CE/4 connections from the inhibitory population (wEI = wII = −gw0) and
furthermore CE connections from an external population (weight wEE) with neurons that
ﬁre at a ﬁxed rate νext. Each spike causes, after a delay of Δ = 1.5 ms a voltage jump of
w0 = 0.1 mV and the threshold is 20 mV above resting potential. Note that each neuron
receives four times as many excitatory than inhibitory inputs so that the total amount of
inhibition balances excitation if inhibition is four times stronger (g = 4), but the relative
strength g is kept as a free parameter. Also note that, in contrast to Chapter 12, the weight
here has units of voltage and directly gives the amplitude of the voltage jump: w0 = ΔuE.
The population can be in a state of asynchronous irregular activity (AI), where neurons
in the population ﬁre at different times ("asynchronous" ﬁring) and the distribution of
interspike intervals is fairly broad ("irregular" ﬁring of individual neurons); see Fig. 13.7b.
This is the state that corresponds to the considerations of stationary activity in Chapter 12.
However, with a slight change of parameters, the same network can also be in a state of
fast synchronous regular (SR) oscillations. It is characterized by periodic oscillations of
the population activity and a sharply peaked interval distribution of individual neurons.
The network can also be in the state of synchronous irregular ﬁring (SI) either with fast (SI
fast) or with slow (SI slow) oscillations of the population activity. The oscillatory temporal
structure emerges despite the fact that the input has a constant spike arrival rate. It can be
traced back to an instability of the asynchronous ﬁring regime toward oscillatory activity.
With the mathematical approach of the Fokker-Planck equations, it is possible to
determine the instabilities analytically. The mathematical approach will be presented in

13.4 Networks of leaky integrate-and-ﬁre neurons
339
4
0
0
Input
4
(a)
SR
SI 
fast
SI slow
AI
Q
8
2
g
I 
SI slow
AI
SR
SI fast 
0.2
2.0
A(t)
Neuron #
Neuron #
0.1
0.1
A(t)
0
0
0
0
(b)
Fig. 13.7 Population of pulse-coupled leaky integrate-and-ﬁre neurons (Brunel network). (a) Phase
diagram of the Brunel network. The population activity can be in a state of asynchronous irregular
(AI), synchronous regular (SR) or synchronous irregular (SI) activity. The horizontal axis indicates
the relative importance of inhibition (g = 4 corresponds to balance between excitation and inhibition).
The vertical axis is the amount of external input each neuron receives. Input I = 1 corresponds to
a mean input just sufﬁcient to reach the neuronal ﬁring threshold (in the absence of recurrent input
from the network). Stability of the asynchronous irregular ﬁring state (AI) breaks down at the dashed
or solid lines and can lead to synchronous regular (SR), or synchronous irregular (SI, either fast
or slow) activity, or to a near-quiescent state (Q); redrawn after Brunel (2000). (b) Typical time
course of the population activity A(t) (bottom part of each subgraph, units in kHz) and associated
spike patterns (50 randomly chosen neurons are plotted along the vertical axis in the top part of
each subgraph; each dot indicates a spike) in different ﬁring regimes. "SI fast" refers to fast and
regular oscillations, but individual neurons ﬁre irregularly with intervals at random multiples of the
oscillation period. Horizontal black bar: 50 ms. Simulation of 10 000 excitatory and 2500 inhibitory
neurons with connection probability p = 0.1. Each spike causes, after a delay of Δ = 1.5 ms a voltage
jump of 0.1 mV; distance from equilibrium potential to the threshold is 20 mV; absolute refractory
period 2 ms; membrane time constant 20 ms. Parameters are top left: g = 3, input = 2 (SR); top right:
g = 6, input = 4 (SI fast); bottom left: g = 5, input = 2 (AI) bottom right g = 4.5, input = 0.9 (SI slow).
Adapted from Brunel (2000) with kind permission from Springer Science and Business Media.
Section 13.5.2, but Fig. 13.7a already shows the result. Stability of a stationary state of
asynchronous ﬁring is most easily achieved in the regime where inhibition dominates exci-
tation. Since each neuron receives four times as many excitatory as inhibitory inputs, inhi-
bition must be at least four times as strong (g > 4) as excitation. In order to get nonzero
activity despite the strong inhibition, the external input alone must be sufﬁcient to make the
neurons ﬁre. "Input = 1" corresponds to an average external input just sufﬁcient to reach
the ﬁring threshold, without additional input from the network.
Consider now the regime of strong inhibition (g > 4) and strong input, say spikes from
the external source arrive at a rate leading to a mean input of amplitude 4. To understand
how the network can run into an instability, let us consider the following intuitive argument.
Suppose a momentary ﬂuctuation leads to an increase in the total amount of activity in the

340
Continuity equation and the Fokker-Planck approach
excitatory population. This causes, after a transmission delay Δ, an increase in inhibition
and, after a further delay Δ, a suppression of excitation. If this feedback loop is strong
enough, an oscillation with period 4Δ may appear, leading to fast-frequency ("SI fast")
oscillations (Brunel, 2000).
If the external input is, on its own, not sufﬁcient to keep the network going ("input < 1"),
then a similar small ﬂuctuation may eventually turn the network from a self-activated state
into a quiescent state where the only activity is that caused by external input. It then needs
another ﬂuctuation (caused by variations of spike arrivals from the external source) to
kick it back into a short burst of activity (Brunel, 2000). This leads to slow irregular but
synchronous bursts of ﬁring ("SI slow").
Finally, if inhibition is globally weak compared to excitation (g < 4), then the population
is in a state of high activity where each neuron ﬁres close to its maximal rate (set by the
inverse of an absolute refractory period). This high-activity state is unstable compared to
fast but regular oscillations ("SR"). Typically, the population can split up into two or more
subgroups, the number of which depends on the transmission delay (Brunel, 2000; Gerstner
and van Hemmen, 1993).
Example: Analysis of the Brunel network
All neurons have the same parameters, so that we can assume that they all ﬁre at
the same time-dependent ﬁring rate ν(t) = A(t). We assume that the network is large
N ≫CE, so that it is unlikely that neurons share a large fraction of presynaptic neurons;
therefore inputs can be considered as uncorrelated, except for the trivial correlations
induced by their common modulation of the ﬁring rate A(t).
The mean input at time t to a neuron in either the excitatory or the inhibitory popula-
tion is (in voltage units)
μ(t) = τm w0CE [1−g/4]A(t −Δ) +τm w0CE νext,
(13.34)
and the input also generates diffusive noise (in voltage units) of strength
σ2(t) = τm w2
0CE[(1+g2/4)A(t −Δ)+νext].
(13.35)
The mean and σ2 are inserted in the Fokker-Planck equation (see Eq. 13.31)
τm
∂
∂t p(u,t) = −∂
∂u {[−u+ μ(t)] p(u,t)}
+ 1
2 σ2(t) ∂2
∂u2 p(u,t)
(13.36)
+τm A(t)δ(u−ur)−τm A(t)δ(u−ϑ)+O(w3
k).
The main difference to the stationary solution considered in Section 13.3.1 and
Chapter 12 is that mean input and noise amplitude are kept time-dependent.
We ﬁrst solve to ﬁnd the stationary solution of the Fokker-Planck equation, denoted
as p0(u) and activity A0. This step is completely analogous to the calculation in
Section 13.3.1.

13.5 Networks of nonlinear integrate-and-ﬁre neurons
341
In order to analyze the stability of the stationary solution, we search for solutions of
the form A(t) = A0 + A1 eλt cos(ω t) (for details, see Section 13.5.2). Parameter com-
binations that lead to a value λ > 0 indicate an instability of the stationary state of
asynchronous ﬁring for a network with this set of parameters.
Figure 13.7a indicates that there is a broad regime of stability of the asynchronous
irregular ﬁring state (AI). This holds even if the network is completely deterministic
(Brunel, 2000) and driven by a constant input I0 (i.e., we set νext = 0 in the noise term,
Eq. (13.35), and replace spike arrivals by a constant current RIext
0
= w0CE νext in Eq.
(13.34).
Stability of the stationary state of asynchronous irregular activity is most easily
achieved if the network is in the regime where inhibition slightly dominates excitation
and external input is sufﬁcient to drive neurons to the threshold. This is called the "inhi-
bition dominating" regime. The range of parameters where asynchronous ﬁring is stable
can, however, be increased into the range of dominant excitation, if delays are not ﬁxed
at D = 1.5 ms, but drawn from the range 0 < D < 3 ms. Finite size effects can also be
taken into account (Brunel, 2000).
13.5 Networks of nonlinear integrate-and-ﬁre neurons
In Chapter 5 it was shown that nonlinear integrate-and-ﬁre neurons such as the exponen-
tial integrate-and-ﬁre model provide an excellent approximation to the dynamics of single
neurons, much better than the standard leaky integrate-and-ﬁre model. This section indi-
cates how the Fokker-Planck approach can be used to analyze networks of such nonlinear
integrate-and-ﬁre models.
We determine, for arbitrary nonlinear integrate-and-ﬁre models driven by a diffusive
input with constant mean μ = RI0 and noise σ2, the distribution of membrane potentials
p0(u) as well as the linear response of the population activity
A(t) = A0 +A1(t) = A0 +
 ∞
0 G(s)I1(t −s)ds
(13.37)
to a drive μ(t) = R[I0+I1(t)] (Richardson, 2007). As explained in Section 13.4, knowledge
of p0 is sufﬁcient to predict, for coupled populations of integrate-and-ﬁre neurons, the
activity A0 in the stationary state of asynchronous ﬁring. Moreover, we shall see that the
ﬁlter G(s) contains all the information needed to analyze the stability of the stationary state
of asynchronous ﬁring. In this section we focus on one-dimensional nonlinear integrate-
and-ﬁre models, and add adaptation later on, in Section 13.6.
13.5.1 Steady-state population activity
We consider a population of nonlinear integrate-and-ﬁre models in the diffusion limit. We
start with the continuity equation (13.7)

342
Continuity equation and the Fokker-Planck approach
∂
∂t p(u,t) = −∂
∂uJ(u,t)+A(t)δ(u−ur)−A(t)δ(u−θreset).
(13.38)
In the stationary state, the membrane potential density does not depend on time, p(u,t) =
p0(u), so that the left-hand side of (13.38) vanishes. Eq. (13.38) therefore simpliﬁes to
∂
∂uJ(u,t) = A(t)δ(u−ur)−A(t)δ(u−θreset).
(13.39)
Therefore the ﬂux takes a constant value, except at two values: at the numerical threshold
θreset, at which the membrane potential is reset; and at the potential ur, to which the reset
occurs. The ﬂux vanishes for u > θreset and for u < ur. For ur < u < θreset the constant value
J(u,t) = c > 0 still needs to be determined.
A neuron in the population under consideration is driven by the action potentials emitted
by presynaptic neurons from the same or other populations. For stochastic spike arrivals at
rate νk, where each spike causes a jump of the voltage by an amount wk, the contributions
to the ﬂux have been determined in Eqs. (13.10) and (13.11). In the diffusion limit the ﬂux
according to Eq. (13.21) is
J(u,t) = 1
τm

f(u)+ μ(t)−1
2σ2(t) ∂
∂u

p(u,t).
(13.40)
In the stationary state, we have p(u,t) = p0(u) and J(u,t) = c for ur < u < θreset. (For u < ur
we have J(u,t) = 0.) Hence Eq. (13.40) simpliﬁes to a ﬁrst-order differential equation
dp0(u)
du
= 2τm
σ2
 f(u)+ μ
τm
p0(u)−c

.
(13.41)
The differential equation (13.41) can be integrated numerically starting at the upper bound
u = θreset with initial condition p0(θreset) = 0 and dp0/du|θreset = −1 = −2cτm/σ2. When
the integration passes u = ur the constant switches from c to zero. The integration is
stopped at a lower bound ulow when p0 has approached zero. The exact value of the lower
bound is of little importance.
At the end of the integration, the surface under the voltage distribution
 θreset
ulow p0(u)du =
1, which determines the constant c and therefore the ﬁring rate A0 in the stationary state.
Example: Exponential integrate-and-ﬁre model
The exponential integrate-and-ﬁre model (Fourcaud-Trocme et al., 2003) as deﬁned
in Eq. (5.6) is characterized by the differential equation
τ d
dt u = −(u−urest)+ΔT exp
u−ϑrh
ΔT

+ μ ,
(13.42)
where μ is the total drive in units of the membrane potential. The result of the numerical
integration of Eqs. (13.39) and (13.41) depends critically on the relative value of the
reset potential, the driving potential μ with respect to the reset ur, and the rheobase ﬁring

13.5 Networks of nonlinear integrate-and-ﬁre neurons
343
qreset
u (mV)
0
p 0 (u)
0.1
p0 (u)
0
-80
-40
Case (ii)
ur
vrh
Case (i)
(a)
u [mV]
c
Case (ii)
Case (i)
A0 [Hz]  
20
40
0
s = 6 mV
s = 2 mV
s = 0 mV
-70
-60
-50
-40
m [mV]
60
(b)
Fig. 13.8 Exponential integrate-and-ﬁre neurons. (a) The stationary membrane potential density
p0(u) in the regime of low noise and superthreshold drive (case (i): σ = 2 mV, μ = −45 mV >
ϑrh = −53 mV > ur = −60 mV) and in the regime of high noise and subthreshold drive (case (ii):
σ = 6 mV, μ = ur = −60 mV < ϑrh = −53 mV). Note that the exact value of the numerical ﬁring
threshold (θreset = 0 mV) is irrelevant because the membrane p0(u) is, for all potentials above −30
mV, very small. (b) The stationary population ﬁring rate A0 = gσ(I0) as a function of the total drive
μ = RI0 of the population, in the regimes of high noise (solid line, σ = 6 mV), low noise (dashed
line, σ = 2 mV), and in the absence of noise (dotted, σ = 0). The two cases depicted in (a) are
marked by open and solid symbols. Adapted from Richardson (2007).
threshold ϑrh, as well as on the level σ of diffusive noise. Two representative scenarios
are shown in Fig. 13.8a. Case (i) has very little noise (σ = 2 mV) and the total drive
(μ = −45 mV) is above the rheobase ﬁring threshold (ϑrh = −53 mV). In this case, the
membrane potential density a few millivolts below the reset potential (ur = −60 mV) is
negligible. Because of the strong drive, the model neuron model is in the superthreshold
regime (see Section 8.3) and ﬁres regularly with a rate of about 44 Hz.
Case (ii) is different, because it has a larger amount of noise (σ = 6 mV) and a neg-
ligible drive of μ = ur = −60 mV. Therefore, the distribution of membrane potentials
is broad, with a maximum at ur, and ﬁring is noise driven and occurs at a low rate of
5.6 Hz.
For both noise levels, the frequency-current curve A0 = ν = gσ(I0) is shown in Fig.
13.8b, as a function of the total drive μ = RI. We emphasize that for very strong
superthreshold drive, the population ﬁring rate A0 of noisy neurons is lower than that
of noise-free neurons.
13.5.2 Response to modulated input (*)
So far we have restricted the discussion to a constant input I0. We now add a small periodic
perturbation
I(t) = I0 +ε cos(ω t),
(13.43)

344
Continuity equation and the Fokker-Planck approach
where ω = 2π/T; the parameter T denotes the period of the modulation. We expect the
periodic drive to lead to a small periodic change in the population activity
A(t) = A0 +A1(ω) cos(ω t +φA(ω)).
(13.44)
Our aim is to calculate the complex number ˆG that characterizes the linear response or
"gain" at frequency ω
ˆG(ω) = A1(ω)
ε
eiφA(ω) .
(13.45)
The result for a population of exponential integrate-and-ﬁre neurons is shown in Fig. 13.9.
Once we have found the gain ˆG for arbitrary frequencies ω, an inverse Fourier transform
of ˆG gives the linear ﬁlter G(s). The linear response of the population activity A(t) =
A0 +ΔA(t) to an arbitrary input current I(t) = I0 +ΔI(t) is
ΔA(t) =
 ∞
0 G(s)ΔI(t −s)ds.
(13.46)
A linear response is a valid description if the change is small:
ΔA(t) ≪A(t).
(13.47)
In our case of periodic stimulation, the amplitude of the input current is scaled by ε. We
are free to choose ε small enough to fulﬁll condition (13.47).
The small periodic drive at frequency ω leads to a small periodic change in the density
of membrane potentials
p(u,t) = p0(u)+ p1(u) cos(ω t +φp(u)),
(13.48)
which has a phase lead (φp > 0) or lag (φp < 0) with respect to the periodic drive. We
assume that the modulation amplitude in the input current ε is small so that p1(u) ≪p0(u)
for most values of u. We say that the change is at most of "order ε."
Similarly to the membrane potential density, the ﬂux J(u,t) will also exhibit a small
perturbation of order ε. For the exponential integrate-and-ﬁre model of Eq. (13.42) with
urest = 0 the ﬂux is (see Eq. (13.40))
J(u,t) =
−u+RI(t)
τm
+ ΔT
τm
exp
u−ϑrh
ΔT

−σ2(t)
2τm
∂
∂u

p(u,t) = Q(u,t) p(u,t),
(13.49)
where we have introduced on the right-hand side a linear operator Q that comprises all
the terms inside the square brackets. The stationary state that we analyzed in the previous
subsection under the assumption of constant input I(t) = I0 has a ﬂux J0(u) = Q0(u) p0(u).
In the presence of the periodic perturbation, the ﬂux is
J(u,t) = J0(u)+J1(u)cos(ωt +φJ(u))
(13.50)
with
J1(u)cos(ωt +φJ(u)) = Q0(u) p1(u)cos(ωt +φp(u))+Q1(u,t) p0(u)+0order(ε2),
(13.51)

13.5 Networks of nonlinear integrate-and-ﬁre neurons
345
Case (i)
Case (ii) 
A1(w )
A1(w)
f (w )
f(w)
30
-60
0
15
2
1
0
0
-30
-30
-60
-90
-120
0
10
5
w = 2p /T  [Hz]
w = 2p/T  [Hz]
10-1 100
101
102
103
104
10-1 100
101
102
103
104
(a)
120
-120
-60
0
180
60
0
-30
-60
-90
-120
f(w)
f(w)
w = 2p/T  [Hz]
w = 2p/T  [Hz]
10-1 100
101
102
103
104
10-1 100
101
102
103
104
0
3
2
1
4
0
3
2
1
4
A1(w)
Case (i)
Case (ii) 
A1(w)
(b)
Fig. 13.9 Frequency response of a population of exponential integrate-and-ﬁre neurons, with param-
eter settings as in Fig. 13.8. Solid line: theoretical Dashed line: analytical prediction for high fre-
quencies. (a) Case (i): The population response A1(ω) (top) to a periodic stimulation of frequency
ω = 2π/T in the situation of low noise (σ = 2 mV) shows a resonance at the population ﬁring rate
A0 = 44 Hz. The phase shift φ(ω) for low noise (bottom) approaches −45◦for high frequencies.
Case (ii): The population response A1(ω) for high noise (σ = 6 mV, population ﬁring rate A0 = 5.6
Hz) has no resonance (top) and the phase shift φ(ω) approaches −90◦(bottom). The combination of
amplitude and phase A1(ω)exp(iφ(ω)) deﬁnes the complex frequency-dependent gain factor ˆG(ω)
in response to modulation of the input current. (b) Gain factor Gσ for a modulation of the noise
strength σ2(t) while the input current is constant. Case (i): low noise. Case (ii): high noise. (a) and
(b) adapted from Richardson (2007). © 2007 The American Physical Society.
where Q1(u,t) = ε R cos(ω t)/τm is the change of the operator Q to order ε. Note that the
ﬂux through the threshold θreset gives the periodic modulation of the population activity.
We insert our variables A, p,J into the differential equation (13.38) and ﬁnd that the
stationary terms with subscript zero cancel each other, as should be the case, and only the
terms with subscript "1" survive. To simplify the notation, it is convenient to switch from
real to complex numbers and include the phase in the deﬁnition of A1, p1(u),J1(u), for
example, ˆA1 = A1 exp(iφA); the hat indicates the complex number. If we take the Fourier
transform over time, Eq. (13.38) becomes
−∂
∂u
ˆJ1(u) = iω ˆp1(u)+ ˆA1 [δ(u−θreset)−δ(u−ur)].
(13.52)
Before we proceed further, let us have a closer look at Eqs. (13.51) and (13.52). We high-
light three aspects (Richardson, 2007). The ﬁrst observation is that we have, quite arbi-
trarily, normalized the membrane potential density to an integral of unity. We could have
chosen, with equal rights, a normalization to the total number N of neurons in the popu-
lation. Then the ﬂux on the left-hand side of Eq. (13.52) would be enlarged by a factor of
N, but so would the membrane potential density and the population activity, which appear
on the right-hand side. We could also multiply both sides of the equation by any other
(complex) number. As a consequence, we can, for example, try to solve Eq. (13.52) for a
population activity modulation ˆA1 = 1 and take care of the correct normalization only later.

346
Continuity equation and the Fokker-Planck approach
The second observation is that the ﬂux J1 in Eq. (13.51) can be quite naturally separated
into two components. The ﬁrst contribution to the ﬂux is proportional to the perturbation
p1 of the membrane potential density. The second component is caused by the direct action
of the external current Q1(u,t) = ε R cos(ω t)/τm. We will exploit this separability of the
ﬂux later.
The third observation is that, for the case of exponential integrate-and-ﬁre neurons, the
explicit expression for the operators Q0 and Q1 can be inserted into Eq. (13.51), which
yields a ﬁrst-order differential equation
∂
∂u ˆp1(u) = 2
σ2

−u+RI0 +ΔT exp
u−ϑrh
ΔT

ˆp1(u)+ 2Rε
σ2 p0(u)−2τm
σ2 ˆJ1(u).
(13.53)
We therefore have two ﬁrst-order differential equations (13.52) and (13.53) which are cou-
pled to each other. In order to solve the two equations, we now exploit our second obser-
vation and split the ﬂux into two components. We drop the hats on J1, p1,A1 to lighten the
notation.
(i) A "free" component Jfree
1
(u) describes the ﬂux that would occur in the absence of
external drive (ε = 0), but in the presence of a periodically modulated population activity
A1. Intuitively, the distribution of the membrane potential density pfree
1
(u) and the ﬂux Jfree
1
must exhibit some periodic "breathing pattern" to enable the periodic modulation of the
ﬂux through the threshold of strength ˆA1. We ﬁnd the "free" component by integrating Eq.
(13.53) with ε = 0 in parallel with Eq. (13.52) with parameter A1 = 1 (i.e., the periodic
ﬂow through threshold is of unit strength). The integration starts at the initial condition
p1(θreset) = 0 and Jfree
1
(θreset) = A1 = 1 and continues toward decreasing voltage values.
Integration stops at a lower bound ulow which we place at an arbitrarily large negative value.
(ii) A "driven" component Jε
1 accounts for the fact that the periodic modulation is in
fact caused by the input. We impose for the "driven" component that the modulation of
the ﬂux through threshold vanishes: A1 = 0. We can therefore ﬁnd the "driven" component
by integrating Eq. (13.53) with a ﬁnite ε > 0 in parallel with Eq. (13.52) with parameter
A1 = 0 starting at the initial condition p1(θreset) = 0 and Jε
1(θreset) = A1 = 0 and integrating
toward decreasing voltage values. As before, integration stops at a lower bound ulow which
we can shift to arbitrarily large negative values.
Finally we add the two solutions together: any combination of parameters a1,a2 for the
total ﬂux a1 Jfree
1
(u)+a2 Jε
1(u) and the total density a1 pfree
1
(u)+a2 pε
1(u) will solve the pair
of differential equations (13.53) and (13.52). Which one is the right combination?
The total ﬂux must vanish at large negative values. Therefore we require a boundary
condition
0 = J(ulow) = a1 Jfree
1
(ulow)+a2 Jε
1(ulow).
(13.54)
We recall that Jε
1(u) is proportional to the drive ε. Furthermore, the initial condition was
chosen such that Jfree
1
(θreset) yields a population response A1 = 1 so that, in the combined
solution, the factor a1 is the population response!

13.6 Neuronal adaptation and synaptic conductance
347
We are interested in the "gain factor" at stimulation frequency ω. We started this section
by applying a periodic stimulus of strength ε and observing, at the same periodic frequency,
a modulation of strength A1. The gain factor is deﬁned as ˆG(ω) = A1/ε. With the above
arguments the gain factor is (Richardson, 2007)
ˆG(ω) = a1
ε = −a2
ε
Jε
1(ulow)
Jfree
1
(ulow) .
(13.55)
The gain factor ˆG(ω) has an amplitude | ˆG(ω)| and a phase φG. Amplitude and phase of
the gain factor of a population of exponential integrate-and-ﬁre neurons are plotted in Fig.
13.9a.
The same numerical integration scheme that starts at the numerical threshold θreset and
integrates downward with appropriate initial conditions can also be applied to other, linear
as well as nonlinear, neuron models. Furthermore, with the same scheme it is also pos-
sible to calculate the gain factor Gσ in response to a modulation of the variance σ2(t)
(Fig. 13.9b), or the response Gϑ to periodic modulation of model parameters such as the
rheobase threshold ϑrh (Richardson, 2007). For earlier results on Gσ see also Brunel and
Hakim (1999), Lindner and Schimansky-Geier (2001) and Silberberg et al. (2004).
13.6 Neuronal adaptation and synaptic conductance
In the previous section we analyzed a population of exponential integrate-and-ﬁre neurons
driven by diffusive noise with mean μ(t) and strength σ(t). At ﬁrst glance, the results
might seem of limited relevance and several concerns may be raised.
(i) What happens if we replace the one-dimensional exponential integrate-and-ﬁre model
by a neuron model with adaptation?
(ii) What happens if neurons are embedded into a network with coupling within and
between several populations?
(iii) What happens if neurons don't receive synaptic current pulses that lead to a jump
of the membrane potential but rather, more realistically, conductance-based input?
(iv) What happens if the input noise is not "white" but colored?
All of these questions can be answered and will be answered in this section. In fact,
all questions relate to the same, bigger picture: suppose we would like to simulate a large
network consisting of K populations. In each population, neurons are described by a multi-
dimensional integrate-and-ﬁre model, similar to the adaptive integrate-and-ﬁre models of
Chapter 6.
The set of equations (6.1) and (6.2) that controls the dynamics of a single neuron i is
repeated here for convenience
τm
dui
dt = f(ui)−R ∑
k
wk,i +RIi(t),
(13.56)
τk
dwk,i
dt
= ak (u−urest)−wk,i +bkτk∑
t f
δ(t −t f
i ),
(13.57)

348
Continuity equation and the Fokker-Planck approach
where f(u) = −(u−urest)+ΔT exp[(u−ϑrh)/ΔT] is the nonlinear spike generation mech-
anism of the exponential integrate-and-ﬁre model. The voltage equation (13.56) is comple-
mented by a set of adaptation variables wk,i which are coupled to the voltage and the spike
ﬁring via Eq. (13.57). The ﬁrst of the above questions concerns the treatment of these slow
adaptation variables in the Fokker-Planck framework.
In a network with a more realistic synapse model, the input current Ii of neuron i is
generated as a conductance change, caused by the spike ﬁrings of other neurons j
Ii(t) = ∑
j ∑
f
gi j(t −t f
j )(ui −Esyn
i j ),
(13.58)
where gi j(s) for s > 0 describes the time course of the conductance change and Esyn
i j
is the
reversal potential of the synapse from j to i. Question (ii) concerns the fact that the spike
ﬁrings are generated by the network dynamics, rather than by a Poisson process. Questions
(iii) and (iv) focus on the aspects of conductance (rather than current) input and temporal
extension of the conductance pulses.
Let us now discuss each of the four points in turn.
13.6.1 Adaptation currents
To keep the treatment simple, we consider the adaptive exponential integrate-and-ﬁre model
(AdEx) with a single adaptation current (see Eq. (6.3)). We drop the neuron index i, and
consider, just as in the previous sections, that the stochastic spike arrival can be modeled
by a mean μ(t) = R⟨I(t)⟩plus a white-noise term ξ
τm
du
dt = −(u−urest)+ΔT exp
u−ϑrh
ΔT

−Rw+ μ(t)+ξ(t),
(13.59)
τw
dw
dt = a(u−urest)−w+bτw∑
t f
δ(t −t f ).
(13.60)
The stochastic input drives the neuron into a regime where the voltage ﬂuctuates and the
neuron occasionally emits a spike. Let us now assume that the input is stationary, i.e.,
the mean and variance of the input are constant. Suppose furthermore that the time con-
stant τw of the adaptation variable w is larger than the membrane time constant and that
the increase of w during spike ﬁring is small: b ≪1. In this case, the ﬂuctuations of
the adaptation variable w around its mean value ⟨w⟩are small. Therefore, for the solu-
tion of the membrane potential density equations p0(u) the adaptation variable can be
approximated by a constant w0 = ⟨w⟩(Richardson et al., 2003; Gigante et al., 2007). This
separation-of-time-scales approach can also be extended to calculate the steady-state rate
and time-dependent response for neurons with biophysically detailed voltage-gated cur-
rents (Richardson, 2009).
13.6.2 Embedding in a network
Embedding the model neurons into a network consisting of several populations proceeds
along the same line of argument as in Section 13.4 or Chapter 12.

13.6 Neuronal adaptation and synaptic conductance
349
The mean input μ(t) to neuron i arriving at time t from population k is proportional to
its activity Ak(t). Similarly, the contribution of population k to the variance σ2 of the input
to neuron i is also proportional to Ak(t); see Eq. (13.31). The stationary states and their
stability in a network of adaptive model neurons can therefore be analyzed as follows.
(i) Determine the stationary state A0 self-consistently. To do so, we use the gain function
gσ(I0) for our neuron model of choice, where the mean current I0 = μ/R and the noise level
σ depend on the activity A0. The gain function gσ(I0) of adaptive nonlinear integrate-and-
ﬁre neurons can be found using the methods discussed above.
(ii) Determine the response to periodic modulation of input current and input variance,
ˆGμ(ω) and ˆGσ(ω), respectively, using the methods discussed above.
(iii) Use the inverse Fourier transform to ﬁnd the linear response ﬁlters Gμ(s) and Gσ(s)
that describes the population activity with respect to small perturbations of the input current
ΔI(t) and to small perturbations in the noise amplitude σ(t)
A(t) = A0 +
 ∞
0 Gμ(s)ΔI(t −s)ds+
 ∞
0 Gσ(s)Δσ(t −s)ds.
(13.61)
(iv) Exploit the fact that the current I(t) and its ﬂuctuations σ(t) in a network with
self-coupling, Eq. (13.31), are proportional to the current activity A(t). If we set ΔA(t) =
A(t)−A0(t) we therefore have for the case of a single population feeding its activity back
to itself
ΔA(t) =
 ∞
0 [Jμ Gμ(s)+Jσ Gσ(s)]ΔA(t −s)ds,
(13.62)
where the constants Jμ and Jσ depend on the coupling parameters.
(v) Search for solutions ΔA(t) = ε exp[λ(ω)t]cos(ωt). The stationary state of asyn-
chronous ﬁring with activity A0 is unstable if there exists a frequency for which λ(ω) > 0.
The arguments in steps (i) to (v) do not rely on the assumption of current-based synapses.
In fact, as we shall see now, conductance-based synapses can be, in the stationary state, well
approximated by an equivalent current-based scheme.
13.6.3 Conductance input vs. current input
Throughout this chapter we assumed that spike ﬁring by a presynaptic neuron j at time t f
j
generates in the postsynaptic neuron i an excitatory or inhibitory postsynaptic current pulse
wi j δ(t −t f
j ). However, synaptic input is more accurately described as a change in conduc-
tance g(t −t f
j ), rather than as current injection (Destexhe et al., 2003). As mentioned in
Eq. (13.58), a time-dependent synaptic conductance leads to a total synaptic current into
neuron i
Ii(t) =∑
j ∑
f
wi jgi j(t −t f
j )(ui(t)−Esyn),
(13.63)
which depends on the momentary difference between the reversal potential Esyn and the
membrane potential ui(t) of the postsynaptic neuron. A spike ﬁred by a presynaptic neuron

350
Continuity equation and the Fokker-Planck approach
j at time t f
j can therefore have a bigger or smaller effect, depending on the state of the
postsynaptic neuron; see Chapter 3.
Nevertheless we will now show that, in the state of stationary asynchronous activ-
ity, conductance-based input can be approximated by an effective current input (Lansky
and Lanska, 1987; Richardson, 2004; Richardson and Gerstner, 2005; Wolff and Lindner,
2011). The main effect of conductance-based input is that the membrane time constant of
the stochastically driven neuron is shorter than the "raw" passive membrane time constant
(Bernander et al., 1991; Destexhe et al., 2003).
To keep the arguments transparent, we consider NE excitatory and NI inhibitory leaky
integrate-and-ﬁre neurons in the subthreshold regime
Cdu
dt = −gL (u−EL)−gE(t)(u−EE)−gI(t)(u−EI),
(13.64)
where C is the membrane capacity, gL the leak conductance and EL,EE,EI are the reversal
potentials for leak, excitation, and inhibition, respectively. We assume that input spikes at
excitatory synapses lead to an increased conductance
gE(t) = ΔgE ∑
j ∑
f
exp[−(t −t f
j )/τE]Θ(t −t f
j )
(13.65)
with amplitude ΔgE and decay time constant τE. The Heaviside step function Θ assures
causality in time. The sum over j runs over all excitatory synapses. Input spikes at inhibitory
synapses have a similar effect, but with jump amplitude ΔgI and decay time constant τI.
We assume that excitatory and inhibitory input spikes arrive with a total rate νE and νI,
respectively. For example, in a population of excitatory and inhibitory neurons the total
excitatory rate to neuron i would be the number of excitatory presynaptic partners CE of
neuron i times the typical ﬁring rate of a single excitatory neuron.
Using the methods from Chapter 8 we can calculate the mean excitatory conductance
gE,0 = ΔgE νE τE ,
(13.66)
where νE is the total spike arrival rate at excitatory synapses, and analogously for the mean
inhibitory conductance. The variance of the conductance is
σ2
E = 0.5(ΔgE)2 νE τE.
(13.67)
The mathematical analysis of conductance input proceeds in two steps. First, we write
the conductance as the mean gE,0 plus a ﬂuctuating component gE, f (t) = gE(t)−gE,0. This
turns Eq. (13.64) into a new equation
Cdu
dt = −g0 (u−μ)−gE, f (t)(u−EE)−gI, f (t),(u−EI),
(13.68)
with a total conductance g0 = gL +gE,0 +gI,0 and an input-dependent equilibrium potential
μ = gL EL +gE,0 EE +gI,0 EI
g0
.
(13.69)
We emphasize that Eq. (13.68) looks just like the original equation (13.64). The major dif-
ferences are, however, that the dynamics in Eq. (13.64) is characterized by a raw

13.6 Neuronal adaptation and synaptic conductance
351
membrane time constant C/gL whereas Eq. (13.68) is controlled by an effective membrane
time constant
τeff = C
g0
=
C
gL +gE,0 +gI,0
,
(13.70)
and a mean depolarization μ which acts as an effective equilibrium potential (Johannesma,
1968).
In the second step we compare the momentary voltage u(t) with the effective equilibrium
potential μ. The ﬂuctuating part of the conductance in Eq. (13.68) can therefore be written
as
gE, f (t)(u−EE) = gE, f (t)(μ −EE)+gE, f (t)(u−μ),
(13.71)
and similarly for the inhibitory conductance. The second term on the right-hand side of
Eq. (13.71) is small compared to the ﬁrst term and needs to be dropped to arrive at a
consistent diffusion approximation (Richardson and Gerstner, 2005). The ﬁrst term on the
right-hand side of Eq. (13.71) does not depend on the membrane potential and can therefore
be interpreted as the summed effects of postsynaptic current pulses. Thus, in the station-
ary state, a conductance-based synapse model is well approximated by a current-based
model of synaptic input. However, we need to use the effective membrane time constant
τeff introduced above in Eq. (13.70) in the voltage equation.
Example: Response to conductance-modulating input
Suppose we have a population of uncoupled exponential integrate-and-ﬁre neurons.
Using the methods discussed above in Section 13.5, we can calculate the linear response
G(s) of the population to a short conductance pulse gE(t) at an excitatory synapse (Fig.
13.10). The response to some arbitrary time-dependent conductance input can then be
predicted by convolving the conductance change with the ﬁlter response. The Fourier
transform of the ﬁlter predicts the response to sinusoidal conductance modulation with
period T (Fig. 13.10).
13.6.4 Colored noise (*)
In the previous subsection, we replaced synaptic conductance pulses by current input. If
the time constants τE and τI of excitatory and inhibitory synapses are sufﬁciently short, we
may approximate stochastic spike arrivals by white noise. Some synapse types, such as the
NMDA component of excitatory synapses, are, however, rather slow (see Chapter 3). As a
result of this, a spike that has arrived at an NMDA synapse at time t0 generates a ﬂuctuation
of the input current that persists for tens of milliseconds. Thus the ﬂuctuations in the input
exhibit temporal correlations, a situation that is termed colored noise, as opposed to white
noise; see Chapter 8. Colored noise represents the temporal smoothing caused by slow
synapses in a compact form.

352
Continuity equation and the Fokker-Planck approach
0
4
2
6
0
-90
-180
-270
2
1
0
-270
-240
-210
-180
-150
Case (i)
Case (ii) 
A1(w)
A1(w )
f(w)
f(w )
w = 2p /T  [Hz]
w = 2p /T  [Hz]
10-1 100
101
102
103
104
10-1 100
101
102
103
104
Fig. 13.10 Conductance input. Frequency response of the population of exponential integrate-
and-ﬁre neurons as in Fig. 13.9, but to conductance modulation. For high frequencies, the
phase slowly approaches a lag of 270◦which can be interpreted as a phase advance of 90◦.
Solid line: numerical solution. Dashed line: analytical high-frequency response; cases (i) and
(ii) correspond to low noise and high noise, respectively. Adapted from Richardson (2007).
© (2007) The American Physical Society.
There are two different approaches to colored noise in the membrane potential density
equations.
The ﬁrst approach is to approximate colored noise by white noise and replace the tem-
poral smoothing by a broad distribution of delays. To keep the treatment transparent, let
us assume a current-based description of synaptic input. The mean input to a neuron i in
population n arising from other populations k is
Ii(t) = ∑
k
Cnkwnk
 ∞
0 αnk(s)Ak(t −s)ds,
(13.72)
where Cnk is the number of presynaptic partner neurons in population k, wnk is the typical
weight of a connection from k to a neuron in population n and αnk(s) is the time course
of a synaptic current pulse caused by a spike ﬁred in population k at s = 0. Suppose Cnk
is a large number, say Cnk = 1000, but the population k itself is at least 10 times larger
(e.g., Nk = 10 000) so that the connectivity Cnk/Nk ≪1. We now replace the broad current
pulses α(s) by short pulses qδ(s −Δ) where δ denotes the Dirac δ-function and q =
 ∞
0 α(s)ds and Δ > 0 is a transmission delay. For each of the Cnk connections we randomly
draw the delay Δ from a distribution p(Δ) = α(Δ)/q. Because of the low connectivity, we
may assume that the ﬁring of different neurons is uncorrelated. The mean input current
Ii(t) to neuron i is then given again by Eq. (13.72), with ﬂuctuations around the mean
that are approximately white, because each spike arrival causes only a momentary current
pulse. The broad distribution of delays stabilizes the stationary state of asynchronous ﬁring
(Brunel, 2000).
The second approach consists in an explicit model of the synaptic current variables. To
keep the treatment transparent and minimize the number of indices, we focus on a single
population coupled to itself and suppose that the synaptic current pulses are exponential
α(s) = (q/τq) exp(−s/τq). The driving current of a neuron i in a population n arising from

13.7 Summary
353
spikes of the same population is then described by the differential equation
dIi
dt = −Ii
τq
+Cnn wnn
q
τq
An(t),
(13.73)
which we can verify by taking the temporal derivative of Eq. (13.72). As before the popula-
tion activity An(t) can be decomposed into a mean μ(t) (which is the same for all neurons)
and a ﬂuctuating part ξi(t) with white-noise characteristics:
dIi
dt = −Ii
τq
+ μ(t)+ξi(t).
(13.74)
However, Eq. (13.74) does not lead directly to spike ﬁring but needs to be combined with
the differential equation for the voltage
τm
dui
dt = f(ui)+RIi(t),
(13.75)
and the reset condition: if u = θreset then u = ur. Since we now have two coupled dif-
ferential equations, the momentary state of a population of N neurons is described by a
two-dimensional density p(u,I).
We recall that, in the case of white noise, the membrane potential density at thresh-
old vanishes. The main insight for the mathematical treatment of the membrane potential
density equations in two dimensions is that the density at threshold p(θreset,I(t)) is ﬁnite,
whenever the momentary slope of the voltage du/dt ∝RI(t) + f(θreset) is positive (Four-
caud and Brunel, 2002).
13.7 Summary
The momentary state of a population of one-dimensional integrate-and-and ﬁre neurons
can be characterized by the membrane potential density p(u,t). The continuity equation
describes the evolution of p(u,t) over time. In the special case that neurons in the pop-
ulation receive many inputs that each cause a small change of the membrane potential,
the continuity equation has the form of a Fokker-Planck equation. Several populations of
integrate-and-ﬁre neurons interact via the population activity A(t), which is identiﬁed with
the ﬂux across the threshold.
The stationary state of the Fokker-Planck equation and the stability of the stationary
solution can be calculated by a mix of analytical and numerical methods, be it for a popu-
lation of independent or interconnected neurons. The mathematical and numerical methods
developed for membrane potential density equations apply to leaky as well as to arbitrary
nonlinear one-dimensional integrate-and-ﬁre models. A slow adaptation variable such as
in the adaptive exponential integrate-and-ﬁre model can be treated as quasi-stationary in
the proximity of the stationary solution. Conductance input can be approximated by an
equivalent current-based model.

354
Continuity equation and the Fokker-Planck approach
Literature
The formulation of the dynamics of a population of integrate-and-ﬁre neurons on the
level of membrane potential densities has been developed by Abbott and van Vreeswijk
(1993), Brunel and Hakim (1999), Fusi and Mattia (1999), Nykamp and Tranchina (2000),
Omurtag et al. (2000), and Knight (2000), but the Fokker-Planck equation has been used
much earlier for the probabilistic description of a single neuron driven by stochastic spike
arrivals (Johannesma, 1968; Capocelli and Ricciardi, 1971; Ricciardi, 1976). The classic
application of the Fokker-Planck approach to a network of excitatory and inhibitory leaky
integrate-and-ﬁre neurons is Brunel (2000). For the general theory of Fokker-Planck equa-
tions see Risken (1984).
Efﬁcient numerical solutions of the Fokker-Planck equation, for both stationary input
and periodic input, have been developed by M. J. E. Richardson (2007, 2009). These
methods can be used to ﬁnd activity in networks of nonlinear integrate-and-ﬁre models,
and also of generalized neuron models with slow spike-triggered currents or conductances
(Richardson, 2009). For the treatment of colored noise, see Fourcaud and Brunel (2002).
Exercises
1. Diffusion limit in the quadratic integrate-and-ﬁre model. Consider a population of quadratic
integrate-and-ﬁre models. Assume that spikes from external sources arrive at excitatory and
inhibitory synapses stochastically, and independently for different neurons, at a rate νE(t) and
νI(t), respectively.
(a) Write down the membrane potential density equations assuming that each spike causes a
voltage jump by an amount ±Δu.
(b) Take the diffusion limit so as to arrive at a Fokker-Planck equation.
2. Voltage distribution of the quadratic integrate-and-ﬁre model. Find the stationary solution of
the membrane potential distribution for the quadratic integrate-and-ﬁre model with white diffu-
sive noise.
3. Non-leaky integrate-and-ﬁre model. Consider a non-leaky integrate-and-ﬁre model subject to
stochastic spike arrival
du
dt = 1
C I(t) = q
C ∑
f
δ(t −t f ),
(13.76)
where q is the charge that each spike puts on the membrane and the spike arrival rate is constant
and equal to ν. At u = ϑ = 1 the membrane potential is reset to u = ur = 0.
(a) Formulate the continuity equation for the membrane potential density equation.
(b) Make the diffusion approximation.
(c) Solve for the stationary membrane potential density distribution under the assumption that
the ﬂux through ur vanishes.
4. Linear response. A population is driven by a current I0 + I1(t). The response of the population
is described by
A(t) = A0 +A1(t) = A0 +
 ∞
0 G(s)I1(t −s)ds,
(13.77)
where G is called the linear response ﬁlter.

13.7 Summary
355
(a) Take the Fourier transformation and show that the convolution with the ﬁlter G turns into
a simple multiplication:
ˆA1(ω) = ˆG(ω) ˆI1(ω),
(13.78)
where the hats denote the Fourier transformed variable.
Hint: Replace G(s) in Eq. (13.77) by a causal ﬁlter Gc(s) = 0 for s ≤0 and Gc(s) = G(s) for
s > 0, extend the lower integral bound to −∞, and apply standard rules for Fourier transforms.
(b) The squared quantity |ˆI1(ω)|2 is the power of the input at frequency ω. What is the power
| ˆA1(ω)|2 of the population activity at frequency ω?
(c) Assume that the ﬁlter is given by G(s) = exp[−(s −Δ)/τg] for s > Δ and zero otherwise.
Calculate ˆG(ω).
(d) Assume that the input current has a power spectrum |ˆI1(ω)|2 = (c/ω) with c > 0 for
ω > ω0 and zero otherwise.
What is the power spectrum of the population activity with a linear ﬁlter as in (iii)?
5. Stability of stationary state. The response of the population is described by
A(t) = A0 +A1(t) = A0 +
 ∞
0 G(s)I1(t −s)ds,
(13.79)
where G is the linear response ﬁlter. Set G(s) = exp[−(s−Δg)/τg] for s > Δg and zero otherwise.
Assume that the input arises due to self-coupling with the population:
I1(t) =
 ∞
0 α(s)A1(t −s)ds.
(13.80)
Set α(s) = (α0/τα) exp[−(s−Δα)/τα] for s > Δα and zero otherwise.
(a) Search for solutions A1(t) ∝exp[λ(ω)t]cos(ωt). The stationary state A0 is stable if λ < 0
for all frequencies ω.
(b) Analyze the critical solutions λ = 0 as a function of the delays ΔG and Δα and the feedback
strength α0.
6. Conductance input. Consider NE excitatory and NI inhibitory leaky integrate-and-ﬁre neurons
in the subthreshold regime
C du
dt = −gL (u−EL)−gE(t)(u−EE)−gI(t)(u−EI),
(13.81)
where C is the membrane capacity, gL the leak conductance and EL,EE,EI are the reversal poten-
tials for leak, excitation, and inhibition, respectively. Assume that input spikes at excitatory arrive
at a rate νE and lead to a conductance change
gE(t) = ΔgE ∑
j ∑
f
exp[−(t −t f
j )/τE]
for t > t f
j
(13.82)
(and zero otherwise) with amplitude ΔgE and decay time constant τE. A similar expression holds
for inhibition with ΔgI = 2ΔgE and τI = τE/2. Spike arrival rates are identical νI = νE.
(a) Determine the mean potential μ.
(b) Introduce
αE(t −t f
j ) = aE exp[−(t −t f
j )/τE]Θ(t −t f
j )(μ −EE)
(13.83)
and an analogous expression for inhibitory input currents αI.
Show that the membrane with conductance-based synapses Eq. (13.81) can be approximated
by a model with current-based synapses
τeff
du
dt = −(u−EL)+ ∑
j∈NE∑
f
αE(t −t f
j )+ ∑
j∈NI∑
f
αI(t −t f
j ),
(13.84)

356
Continuity equation and the Fokker-Planck approach
where EL is the leak potential deﬁned earlier in Eq. (13.81). Determine aE,aI and τeff. What are
the terms that are neglected in this approximation? Why are they small?
(c) Assume that the reversal potential for inhibition and leak are the same EI = EL. What is
the mean potential μ in this case? How does inhibitory input manifest itself? What would change
if you replaced inhibition by a constant current that sets the mean membrane potential (in the
presence of the same amount of excitation as before) to μ?
7. Firing rate of leaky integrate-and-ﬁre neurons in the Brunel-Hakim formulation.
Show that the Siegert formula of Eq. (13.30) can be also written in the form (Brunel and
Hakim, 1999)
1
A0 τm
= 2
 ∞
0 due−u2 e2y2u −e2y1u
u

(13.85)
with y2 = (ϑ −h0)/σ and y1 = (ur −h0)/σ.
Hint: Use the deﬁnition of the error function erf given above Eq. (13.30).

14
Quasi-renewal theory and the integral-equation
approach
In the previous chapter it was shown that an approach based on membrane potential den-
sities can be used to analyze the dynamics of networks of integrate-and-ﬁre neurons. For
neuron models that include biophysical phenomena such as refractoriness and adaptation
on multiple time scales, however, the resulting system of partial differential equations is
situated in more than two dimensions and therefore difﬁcult to solve analytically; even the
numerical integration of partial differential equations in high dimensions is slow. To cope
with these difﬁculties, we now indicate an alternative approach to describing the popula-
tion activity in networks of model neurons. The central concept is expressed as an integral
equation of the population activity.
The advantage of the integral equation approach is four-fold. First, the approach works
for a broad spectrum of neuron models, such as the Spike Response Model with escape
noise and other Generalized Linear Models (see Chapter 9) for which parameters can be
directly extracted from experiments (see Chapter 11). Second, it is easy to assign an intu-
itive interpretation to the quantities that show up in the integral equation. For example, the
interspike interval distribution plays a central role. Third, an approximative mathematical
treatment of adaptation is possible not only for the stationary population activity, but also
for the case of arbitrary time-dependent solutions. Fourth, the integral equations provide
a natural basis for the transition to classical "rate equations," which will be discussed in
Chapter 15.
In Section 14.1, we derive, starting from a small set of assumptions, an integral equation
for the population activity. The essential idea of the mathematical formulation is to remain
at the macroscopic level as much as possible, without reference to a speciﬁc model of
neuronal dynamics. Knowledge of the interval distribution PI(t|ˆt) for arbitrary input I(t) is
enough to formulate the population equations.
For didactic purposes, we begin by treating neurons without adaptation. In this case,
the internal state of the neurons depends solely on the input and on the time since the
last spike. The formulation of the macroscopic integral equation exploits the concepts of a
time-dependent version of renewal theory that we have already encountered in Chapter 7.
In the presence of adaptation, however, the state of the neuron depends not only on the
last spike, but also on all the previous spike times. But since the refractoriness caused by

358
The integral-equation approach
the last spike dominates over the effects of earlier spikes we can approximate the interval
distribution for adaptive neurons by a "quasi-renewal" theory.
A theory for networks consisting of several interacting populations of spiking neurons is
formulated in Section 14.2. To analyze the stability of stationary solutions of asynchronous
ﬁring with population activity A0 in connected networks of integrate-and-ﬁre neurons, we
need to know the linear response ﬁlter. The linearization of the integral equations under the
assumption of a small perturbation is presented in Section 14.3.
The integral equation of Section 14.1 is exact in the limit of a large number of neurons
and can be interpreted as a solution to partial differential equations analogous to those of
the previous chapter. Section 14.4, which is slightly more technical, presents the relation
of the integral equation to an approach by membrane potential density equations.
Section 14.5 describes in detail how we can formulate integral equations for adaptive
neurons. Finally, Section 14.6 contains variants of the theory that are applicable to popula-
tions of a ﬁnite number of neurons.
14.1 Population activity equations
The interval distribution PI(t|ˆt), which has already been introduced in Chapter 7, plays a
central role in the formulation of the population equation. Before we formulate the evolu-
tion of the population activity A(t) in terms of this interval distribution PI(t|ˆt), we specify
some necessary assumptions. Two key assumptions are that the population is homoge-
neous and contains non-adaptive neurons so that we can work in the framework of a time-
dependent renewal theory. These assumptions will eventually be relaxed in Section 14.1.4
where we extend the theory to the case of a population of adaptive neurons and in Section
14.6 where we treat populations of ﬁnite size.
14.1.1 Assumptions of time-dependent renewal theory
To formulate a ﬁrst version of an integral equation for a population of neurons, we start
in the framework of time-dependent renewal theory (Chapter 7). To do so, we have to
assume the state of a neuron i at time t to be completely described by (i) its last ﬁring time
ˆti; (ii) the input I(t′) it received for times t′ < t; (iii) the characteristics of potential noise
sources, be it noise in the input, noise in the neuronal parameters, or noise in the output.
Are these assumptions overly restrictive or can we still place an interesting and rich
set of neuron models in the class of models consistent with assumptions (i)-(iii) of time-
dependent renewal theory?
The state of a single-variable integrate-and-ﬁre neuron i, for example one of the nonlin-
ear integrate-and-ﬁre models of Chapter 5, is completely characterized by its momentary
membrane potential ui(t). After ﬁring at a time ˆti, the membrane potential is reset, so that all
information that arrived before the ﬁring is "forgotten." Integration continues with u = ur.
Therefore knowledge of the last ﬁring time ˆti and the input current I(t′) for ˆti < t′ ≤t is suf-
ﬁcient to predict the momentary state of neuron i at time t and therefore (for a deterministic

14.1 Population activity equations
359
model) its next ﬁring time. If the integrate-and-ﬁre model is furthermore subject to noise
in the form of stochastic spike arrivals of known rate (but unknown spike arrival times), we
will not be able to predict the neuron's exact ﬁring time. Instead we are interested in the
probability density
PI(t|ˆti)
(14.1)
that the next spike occurs around time t given that the last spike was at time ˆti and the
neuron was subject to an input I(t′) for t′ ≤t. In practice, it might be difﬁcult to write
down an exact analytical formula for PI(t|ˆti) for noise models corresponding to stochastic
spike arrival or diffusive noise (see Chapter 8), but the quantity PI(t|ˆti) is still well deﬁned.
We call PI(t|ˆti) the generalized interval distribution (see Chapter 9).
For several other noise models, there exist explicit mathematical expressions for PI(t|ˆti).
Consider, for example, integrate-and-ﬁre models with slow noise in the parameters, deﬁned
as follows. After each ﬁring time, the value ur for the reset or the value τm of the membrane
time constant is drawn from a predeﬁned distribution. Between two resets, the membrane
potential evolves deterministically. As a consequence, the distribution PI(t|ˆti) of the next
ﬁring time can be predicted from the distribution of parameters and the deterministic solu-
tion of the threshold crossing equations (Gerstner, 2000). Such a model of slow noise in
the parameters can also be considered as an approximation to a heterogeneous popula-
tion of neurons where different neurons in the population have slightly different, but ﬁxed,
parameters.
Another tractable noise model is the "escape noise" model, which is also the basis for
the Generalized Linear Models of spiking neurons already discussed in Chapter 9. The
short-term memory approximation SRM0 of the Spike Response Model with escape noise
(see Eq. (9.19)) is a prime example of a model that ﬁts into the framework of renewal
theory speciﬁed by assumptions (i)-(iii).
The escape noise model can be used in combination with any linear or nonlinear integrate-
and-ﬁre model. For a suitable choice of the escape function f it provides also an excellent
approximation to diffusive noise in the input; see Section 9.4. An example of how to for-
mulate a nonlinear integrate-and-ﬁre model with escape noise is given below.
The major limitation of time-dependent renewal theory is that, for the moment, we need
to exclude adaptation effects, because the momentary state of adaptive neurons depends
not only on the last ﬁring time (and the input in the past) but also on the ﬁring times
of earlier spikes. Section 14.1.4 shows that adaptation can be included by extending the
renewal theory to a quasi-renewal theory. The treatment of adaptive neurons is important
because most cortical neurons exhibit adaptation (Chapter 6).
Example: Escape noise in integrate-and-ﬁre models
Consider an arbitrary (linear or nonlinear) integrate-and-ﬁre model with refractori-
ness. The neuron has ﬁred its last spike at ˆt and enters thereafter an absolute refractory

360
The integral-equation approach
period of time Δabs. Integration of the differential equation of the membrane potential u,
τ d
dt u = f(u)+R(u)I(t),
(14.2)
restarts at time ˆt + Δabs with initial condition ur. The input current I(t) can have an
arbitrary temporal structure.
In the absence of noise, the neuron would emit its next spike at the moment when the
membrane potential reaches the numerical threshold θ reset. In the presence of escape
noise, the neuron ﬁres in each short time interval Δt →0, a spike with probability
PF(t;t +Δt) = ρ(t)Δt where
ρ(t) = f(u(t)−θ reset, ˙u(t))
(14.3)
is the escape rate which typically depends on the distance between the membrane poten-
tial and the threshold, and potentially also on the derivative ˙u = (du/dt) of the membrane
potential; see Section 9.4.
Knowledge of the input I(t′) for t′ > ˆt + Δabs is sufﬁcient to calculate the membrane
potential u(t) by integration of Eq. (14.2). The time course of u(t) is inserted into Eq.
(14.3) to get the instantaneous rate or ﬁring "hazard" ρ(t) for all t > ˆt + Δabs. By deﬁ-
nition, the instantaneous rate vanishes during the absolute refractory time: ρ(t) = 0 for
ˆt < t < ˆt + Δabs. With this notation, we can use the results of Chapter 7 to arrive at the
generalized interval distribution
PI(t|ˆt) = ρ(t) exp

−
 t
ˆt ρ(t′)dt′

.
(14.4)
Note that, in order to keep notation light, we simply write ρ(t) instead of the more
explicit ρ(t|ˆt,I(t′)) which would emphasize that the hazard depends on the last ﬁring
time ˆt and the input I(t′) for ˆt < t′ ≤t; for the derivation of Eq. 14.4, see also Eq. (7.28).
14.1.2 Integral equations for non-adaptive neurons
The integral equation (Gerstner, 1995, 2000; Wilson and Cowan, 1972) for activity dynam-
ics with time-dependent renewal theory states that the activity at time t depends on the
fraction of active neurons at earlier times ˆt multiplied by the probability of observing a
spike at t given a spike at ˆt:
A(t) =
 t
−∞PI(t|ˆt)A(ˆt)dˆt .
(14.5)
Equation (14.5) is easy to understand. The kernel PI(t|ˆt) is the probability density that the
next spike of a neuron, which is under the inﬂuence of an input I, occurs at time t given that
its last spike was at ˆt. The number of neurons which have ﬁred at ˆt is proportional to A(ˆt)
and the integral runs over all times in the past. The interval distribution PI(t|ˆt) depends
on the total input (both the external input and the synaptic input from other neurons in
the population). For an unconnected population, I(t) corresponds to the external drive.

14.1 Population activity equations
361
For connected neurons, I(t) is the sum of the external input and the recurrent input from
other neurons in the population; the case of connected neurons will be further analyzed in
Section 14.2.
We emphasize that A(t) on the left-hand side of Eq. (14.5) is the expected activity at
time t, while A(ˆt) on the right-hand side is the observed activity in the past. In the limit of
the number N of neurons in the population going to inﬁnity, the fraction of neurons that
actually ﬁre in a short time Δt is the same as its expected value A(t)Δt. Therefore, Eq.
(14.5) becomes exact in the limit of N →∞, so that we can use the same symbol for A(t)
on both sides of the equation. Finite-size effects are discussed in Section 14.6.
We conclude this section with some ﬁnal remarks on the form of Eq. (14.5). First, we
observe that we can multiply the activity value A on both sides of the equation with a
constant c and introduce a new variable A′ = cA. If A(t) solves the equation, then A′(t) will
solve it as well. Thus, Eq. (14.5) cannot predict the correct normalization of the activity A.
This reﬂects the fact that, instead of deﬁning the activity by a spike count divided by the
number N of neurons, we could have chosen to work directly with the spike count per unit
of time or any other normalization. The proper normalization consistent with our deﬁnition
of the population activity A(t) is derived below in Section 14.1.3.
Second, even though Eq. (14.5) is linear in the variable A, it is in fact a highly nonlinear
equation in the drive, because the kernel PI(t|ˆt) depends nonlinearly on the input I(t).
However, numerical implementations of the integral equations lead to rapid schemes that
predict the population activity in response to changing input, even in the highly nonlinear
regime when strong input transiently synchronizes neurons in the population (Fig. 14.1).
Example: Leaky integrate-and-ﬁre neurons with escape noise
Using appropriate numerical schemes, the integral equation can be used to predict the
activity in a homogeneous population of integrate-and-ﬁre neurons subject to a time-
dependent input. In each time step, the fraction of neurons that ﬁre is calculated as
A(t)Δt using (14.5). The value of A(t) then becomes part of the observed history and
we can evaluate the fraction of neurons in the next time step t + Δt. For the sake of the
implementation, the integral over the past can be truncated at some suitable lower bound
(see Section 14.1.5). The numerical integration of Eq. (14.5) predicts well the activity
pattern observed in a simulation of 4000 independent leaky integrate-and-ﬁre neurons
with exponential escape noise (Fig. 14.1).
14.1.3 Normalization and derivation of the integral equation
To derive Eq. (14.5), we recall that PI(t|ˆt) is the probability density that a neuron ﬁres at
time t given its last spike at ˆt and an input I(t′) for t′ ≤t. Integration of the probability
density over time
 t
ˆt PI(s|ˆt)ds gives the probability that a neuron which has ﬁred at ˆt ﬁres
its next spike at some arbitrary time between ˆt and t. Just as in Chapter 7, we can deﬁne a

362
The integral-equation approach
0
50
100
150
200
t [ms]
0.00
0.05
0.10
A [kHz]
(a)
0.15
(b)
0
50
100
150
200
t [ms]
−100
0
100
I [pA]
Fig. 14.1 Population activity A(t) (top) in a population of leaky integrate-and-ﬁre neurons with
escape noise in response to a time-dependent input (bottom). After a strong step, neurons in the
population synchronize, which leads to a transient oscillation. The numerical solution of the integral
equation is compared with a simulation of 4000 neurons.
survival probability,
SI(t|ˆt) = 1−
 t
ˆt PI(s|ˆt)ds,
(14.6)
i.e., the probability that a neuron which has ﬁred its last spike at ˆt "survives" without ﬁring
up to time t.
We now return to the homogeneous population of neurons in the limit of N →∞and
assume that the ﬁring of different neurons at time t is independent, given that we know the
history (the input and last spike) of each neuron. The technical term for such a situation is
"conditional independence." We consider the network state at time t and label all neurons
by their last ﬁring time ˆt. The proportion of neurons at time t which have ﬁred their last
spike between t0 and t1 < t (and have not ﬁred since) is expected to be
number of neurons at t with last spike in [t0,t1]
total number of neurons

=
 t1
t0
SI(t|ˆt)A(ˆt)dˆt.
(14.7)
For an interpretation of the integral on the right-hand side of Eq. (14.7), we recall that
A(ˆt)dˆt is the fraction of neurons that have ﬁred in the interval [ˆt, ˆt +Δˆt]. Of these a fraction
SI(t|ˆt) are expected to survive from ˆt to t without ﬁring. Thus among the neurons that we
observe at time t the proportion of neurons that have ﬁred their last spike between t0 and t1
is expected to be
 t1
t0 SI(t|ˆt)A(ˆt)dˆt; see Fig. 14.2.
Finally, we use the fact that the total number of neurons remains constant. All neurons
have ﬁred at some point in the past.1 Thus, if we extend the lower bound t0 of the integral on
the right-hand side of Eq. 14.7 to −∞and the upper bound to t, the left-hand side becomes
1Neurons which have never ﬁred before are assigned a formal ﬁring time ˆt = −∞.

14.1 Population activity equations
363
^
^
A(t) Dt
A(t)
^
SI (t| t )
t^
t+D t
^
^
t1
t
t0
Fig. 14.2 Derivation of the population equation in discretized time. Of the NA(ˆt)Δˆt neurons that
have ﬁred between ˆt and ˆt +Δˆt, a fraction SI(t|ˆt) is expected to "survive" up to time t without ﬁring
another spike. Thus (with t1 = ˆt0 + kmaxΔˆt) the Riemann sum ∑kmax
k=0 S(t|t0 + kΔˆt)A(t0 + kΔˆt)Δˆt ≈
 t1
t0 SI(t|ˆt)A(ˆt)dˆt gives the expected fraction of neurons at time t that have ﬁred their last spike
between t0 and t1.
equal to one,
1 =
 t
−∞SI(t|ˆt)A(ˆt)dˆt,
(14.8)
because all N neurons have ﬁred their last spike in the interval [−∞,t]. Since the number
of neurons remains constant, the normalization of Eq. 14.8 must hold at arbitrary times t.
Eq. (14.8) is an implicit equation for the population activity A and the starting point for the
discussions in this and the following chapters.
Since Eq. (14.8) is rather abstract, we will put it into a form that is easier to grasp
intuitively. To do so, we take the derivative of Eq. (14.8) with respect to t. We ﬁnd
0 = SI(t|t)A(t)+
 t
−∞
∂SI(t|ˆt)
∂t
A(ˆt)dˆt.
(14.9)
We now use PI(t|ˆt) = −∂
∂t SI(t|ˆt) and SI(t|t) = 1, which is a direct consequence of Eq.
(14.6). This yields the activity dynamics of Eq. (14.5).
We repeat an important remark concerning the normalization of the activity. Since Eq.
(14.5) is deﬁned as the derivative of Eq. (14.8), the integration constant on the left-hand
side of Eq. (14.8) is lost. This is most easily seen for constant activity A(t) = A0. In this
case the variable A0 can be eliminated on both sides of Eq. (14.5) so that it yields the trivial
statement that the interval distribution is normalized to unity. Equation (14.5) is therefore
invariant under a rescaling of the activity A0 →cA0 with any constant c, as mentioned
earlier. To get the correct normalization of the activity we have to return to Eq. (14.8).
Example: Absolute refractoriness and the Wilson-Cowan integral equation
Let us consider a population of Poisson neurons with an absolute refractory period
Δabs. A neuron that is not refractory ﬁres stochastically with a rate f[h(t)] where
h(t) =
 ∞
0 κ(s)I(t −s)ds is the total input potential caused by an external driving current
or synaptic input from other neurons. After ﬁring, a neuron is inactive during a time

364
The integral-equation approach
Δabs. The population activity of a homogeneous group of Poisson neurons with absolute
refractoriness is (Wilson and Cowan, 1972)
A(t) = f[h(t)]

1−
 t
t−Δabs A(t′)dt′

.
(14.10)
Eq. (14.10) represents a special case of Eqs. (14.5) and (14.8) (see Exercises).
The Wilson-Cowan integral equation (14.10) has a simple interpretation. Neurons
stimulated by a total postsynaptic potential h(t) ﬁre with an instantaneous rate f[h(t)].
If there were no refractoriness, we would expect a population activity A(t) = f[h(t)].
However, not all neurons may ﬁre, since some of the neurons are in the absolute refrac-
tory period. The fraction of neurons that participate in ﬁring is 1−
 t
t−Δabs A(t′)dt′, which
explains the factor in curly brackets.
The function f in Eq. (14.10) was introduced here as the stochastic intensity of an
inhomogeneous Poisson process describing neurons in a homogeneous population. In
this interpretation, Eq. (14.10) is the exact equation for the population activity of neurons
with absolute refractoriness in the limit of N →∞. In their original paper, Wilson and
Cowan motivated the function f by a distribution of threshold values in an inhomoge-
neous population. In this case, the population equation (14.10) is only an approximation
since correlations are neglected (Wilson and Cowan, 1972).
For constant input potential, h(t) = h0 = I0
 ∞
0 κ(s)I(t −s)ds, the population activity
has a stationary solution (see Fig. 14.3)
A0 =
f(h0)
1+Δabs f(h0) = g(h0).
(14.11)
For the last equality sign we have used the deﬁnition of the gain function of Poisson
neurons with absolute refractoriness in Eq. (7.50). Equation (14.11) tells us that in a
homogeneous population of neurons the population activity in a stationary state is equal
to the ﬁring rate of individual neurons, as expected from the discussion in Chapter 12.
Sometimes the stationary solution from Eq. (14.11) is also used in the case of time-
dependent input. However, the expression A0(t) = g(h(t)) [with g from Eq. (14.11)] does
not correctly reﬂect the transients that are seen in the solution of the integral equation
(14.10); see Fig. 14.3b and Chapter 15.
14.1.4 Integral equation for adaptive neurons
The integral equations presented so far are restricted to non-adapting neurons, because
we assumed that the knowledge of the input and of the last ﬁring time was sufﬁcient to
characterize the state of a neuron. For adapting neurons, however, the whole spiking history
can shape the interspike interval distribution. In this section we extend the integral equation
(14.5) to the case of adapting neurons.
For an isolated adaptive neuron in the presence of noise, the probability density of ﬁring
around time t will, in general, depend on its past ﬁring times ˆtn < ˆtn−1 ··· < ˆt2 < ˆt1 = ˆt < t

14.1 Population activity equations
365
0.0
0.1
0.2
0.3
g [kHz]
−4.0
2.0
4.0
h
0.0
−2.0
(a)
(b)
80
90
100
110
120
t [ms] 
0.0
0.1
0.2
0.3
A [kHz]
Fig. 14.3 Wilson-Cowan model. (a) Stationary activity calculated from the gain function A0 = g(h)
of Poisson neurons with absolute refractoriness of Δabs = 4 ms; see Eq. (14.11). (b) The response of
the population activity to an abrupt change of the input current shows an oscillatory behavior (solid
line) in the approach to the new stationary state. The oscillations are absent in a quasi-stationary
approximation A0(t) = g(h(t)) where the stationary solution from Eq. (14.11) is applied to explain
time-dependent behavior (dashed line). The input potential vanishes for t0 < 100 ms and is h(t) =
1−exp[−(t −t0)/τm] for t > t0 with τm = 4 ms. The exponential escape rate f(h) = τ−1
0
exp[β(h−
ϑ)] with ϑ = 1, τ0 = 1 ms, and β = 2. No lateral coupling (w0 = 0).
where ˆt = ˆt1 denotes the most recent spike time. The central insight is that, in a population
of neurons, we can approximate the past ﬁring times by the population activity A(ˆt) in the
past. Indeed, the probability of one of the neurons having a past spike time ˆtk = t′ in the
interval ˆt < t′ < ˆt +Δt is A(ˆt)Δt.
Just as in the time-dependent renewal theory, we will treat the most recent spike ˆt1 = ˆt
of each neuron explicitly. For all spikes ˆtk with k ≥2 we approximate the actual spike-train
history of an individual by the average history as summarized in the population activity
A(t). Let PI,A(t|ˆt) be the probability of observing a spike at time t given the last spike
at time ˆt, the input current and the activity history A(t) until time t; then we can rewrite
Eq. (14.5) in a form suitable for adaptive neurons
A(t) =
 t
−∞PI,A(t|ˆt)A(ˆt)dˆt.
(14.12)
In Section 14.5 we explain the methods to describe populations of adaptive neurons in
more detail. Appropriate numerical schemes (Section 14.1.5) make it possible to describe
the response of a population of adaptive neurons to arbitrary time-dependent input; see Fig.
14.4.
14.1.5 Numerical methods for integral equations (*)
Integral equations can be solved numerically. However, the type of equation we face in Eq.
(14.5) or Eq. (14.12) cannot be cast in the typical Volterra or Fredholm forms for which
efﬁcient numerical methods have been extensively studied (Linz, 1985; Atkinson, 1997).
In what follows, we describe a method that can be used to solve Eq. (14.5), Eq. (14.12) or

366
The integral-equation approach
A [Hz]
t [s]
Fig. 14.4 Population of adaptive neurons. Middle: The solution (black solid line) of the integral
equation for adaptive neurons (14.12) is compared with the population activity during a simulation
of 25 000 model neurons (thick gray line). Model neurons are Generalized Linear Models of spiking
neurons with parameters from cortical cells; see Chapter 11. Top: Error (theory minus simulations) in
the prediction of the population activity. Bottom: Driving stimulus h(t) =
 ∞
0 exp(−s/τm)I(t −s)ds
in arbitrary units. Threshold in the limit of deterministic neurons located at h = 0 so that h < 0
indicates the subthreshold regime. Modiﬁed from Naud and Gerstner (2012a).
Eq. (14.8), but we take as an example the quasi-renewal equivalent of Eq. (14.8)
1 =
 t
−∞SI,A(t|ˆt)A(ˆt)dˆt.
(14.13)
To derive a numerical algorithm, we proceed in three steps: ﬁrst, truncation of the inte-
gral in Eq. (14.13) at some lower bound; second, the discretization of this integral; and,
third, the discretization of the integral deﬁning the survivor function. Here we will use the
rectangle rule for the discretization of every integral. Note that adaptive quadratures or
Monte-Carlo methods could present more efﬁcient alternatives.
The ﬁrst step is the truncation. The probability of surviving a very long time is essentially
zero. Let τc be a period of time such that the survivor SI,A(t|t −τc) is very small. Then, we
can truncate the inﬁnite integral in (14.13)
1 =
 t
t−τc
SI,A(t|ˆt)A(ˆt)dˆt.
(14.14)
Next, we proceed to discretize the integral on small bins of size Δt. Let m(t) be the vector
made up of the fraction of neurons at t with last spike within ˆt and ˆt + Δt. This deﬁnition
means that the kth element is m(t)
k = S(t|t −kΔt)A(t −kΔt)Δt. The element with k = 0 is
then the momentary population activity in the time step starting at time t, m(t)
0 = AtΔt, since

14.2 Recurrent networks and interacting populations
367
S(t|t) = 1. Therefore we arrive at
AtΔt = 1−
K
∑
k=1
m(t)
k .
(14.15)
Finally, we discretize the integral deﬁning the survival function to obtain m(t)
k as a func-
tion m(t−Δt)
k
. Because of S(t|ˆt) = exp[−
 t
ˆt ρ(t′|ˆt)dt′] = exp[−
 t
t−Δt ρ(t′|ˆt)dt′]S(t −Δt|ˆt), we
ﬁnd for sufﬁciently small time steps
m(t)
k = m(t−Δt)
k−1
exp[−ρ(t|t −kΔt)Δt]
for
k ≥1.
(14.16)
Note that we work in a moving coordinate because the index k always counts time steps
backward starting from the present time t. Therefore m(t)
k
and m(t−Δt)
k−1
refer to the same
group of neurons, i.e., those that have ﬁred their last spike around time ˆt = t −kΔt =
(t −Δt)−(k −1)(Δt)). Equation (14.16) indicates that the number of neurons that survive
from ˆt up to t decreases in each time step by an exponential factor. In Eq. (14.16), ρ(t|t′)
can be either the renewal conditional intensity of a non-adaptive neuron model (e.g., Eq.
(14.3)) or the effective "quasi-renewal" intensity of adaptive neurons (see Section 14.5).
Together, Eqs. (14.15) and (14.16) can be used to solve At iteratively.
14.2 Recurrent networks and interacting populations
The integral equation (14.5) derived in the previous section can be applied to interacting
populations of connected neurons. In Section 14.2.1 we present the mathematical frame-
work of the integral equations so as to describe several populations that interact with each
other.
Using the methods discussed in Chapter 12, we can ﬁnd the activity A0 of a recurrent
network in the regime of stationary asynchronous ﬁring (Section 14.2.2). Using the linear
response ﬁlter, which will be derived in Section 14.3, the stability of the solutions can
further be analyzed for different levels of noise and arbitrary delays (Section 14.2.3).
14.2.1 Several populations and networks with self-interaction
In Section 14.1 we discussed a single homogeneous population of N neurons. The formal-
ism of integral equations introduced there can readily be adapted to several populations
with recurrent interactions within and across populations.
We consider a coupled network of spiking neurons of the renewal type, such as nonlinear
(or leaky) integrate-and-ﬁre neurons with escape noise or a Spike Response Model SRM0.
Neurons within a population have the same set of parameters whereas neurons of different
populations can have different parameters. The activity of population k is described by Eq.
(14.5)
Ak(t) =
 t
−∞PIk(t|ˆt)Ak(ˆt)dˆt ,
(14.17)

368
The integral-equation approach
0
50
100
150
200
t [ms]
0
100
A [Hz]
(a)
50
(b)
0
50
100
150
200
t [ms]
0.05
0.10
A [kHz]
0.00
Fig. 14.5 Asynchronous ﬁring. For a sufﬁcient amount of noise, the population activity in a network
of coupled spiking neurons with constant external input approaches a stationary value A0. (a) The
population activity of 1000 neurons has been ﬁltered with a time window of 1 ms duration. (b) Same
parameters as before, but the size of the population has been increased to N = 4000. Fluctuations
decrease with N and approach the value of A0 = 50 Hz predicted by theory.
where PIk(t|ˆt) is the input-dependent interval distribution of population k. The input to
population k is
Ik(t) = ∑
n
Nn wkn
 ∞
0 αkn(s)An(t −s)ds+Iext
k
.
(14.18)
Here Nn is the number of neurons in the presynaptic population n, wkn is the strength of a
synaptic connection of a neuron in population n to a neuron in population k, and αkn the
time course of the postsynaptic current into a neuron in population k, caused by spike ﬁring
of a neuron in population n. Conductance-based synapses are treated in the current-based
approximation (see Section 13.6.3). Connections can be excitatory or inhibitory, depending
on the choice of wkn. Because the overall strength of the connection is incorporated in wkn,
we can, without loss of generality, assume a normalization
 ∞
0 αkn(s)ds = 1.
The noise level of each neuron in population k is ﬁxed to a value of σk. The choice of
noise is arbitrary. If our aim is to mimic stochastic spike arrivals in randomly connected
networks by an escape rate, a suitable choice of escape function has been given in Chapter
9. In practice this implies that noise in the input to a neuron is effectively described and
replaced by escape noise in its output.
In the following we assume a fully connected network with interaction strength wkn =
Jkn/Nn; see Chapter 12. If the theory is applied to a random network where each neuron
in population k has a ﬁxed number of presynaptic partners Ckn in population n, we can use
the same theory, except that (i) we use wkn = Jkn/Ckn; and (ii) we increase the noise level
σ in the escape rate function so as to mimic the additional noise caused by stochastic spike
arrival; see Section 9.4.
14.2.2 Stationary states and ﬁxed points of activity
We are interested in the value Ak(t) = Ak,0 of the population activity in the stationary
state of asynchronous ﬁring. We recall from Chapter 12 that stationary activity means
that the expected value of the population activity is constant whereas in a simulation the
actual value A(t) always ﬂuctuates (Fig. 14.5). To lighten the notation, we consider a single

14.2 Recurrent networks and interacting populations
369
population k with self-interaction wkk = J0/Nk and drop the index k subsequently. The input
from other populations is summarized as a constant external input Iext. According to our
assumptions, all neurons in the population have the same parameters and can be described
by time-dependent renewal theory. The level of noise is indicated by an index σ.
A stationary state of asynchronous ﬁring requires that the total input I0 is constant (or at
least stationary). In Chapter 12, we have seen that the population activity A0 in the state of
asynchronous ﬁring is given by the single-neuron ﬁring rate ν = gσ(I0). We thus have
A0 = ν = gσ(I0).
(14.19)
Given constant activity A0 of the population and constant external input Iext
0 , the total
input I0 to each neuron is constant. From Eq. (14.18) we ﬁnd the total input to a neuron in
population k
I0 = Iext
0 +J0
 ∞
0 α(s)A0(t −s)ds = Iext
0 +J0 A0.
(14.20)
Equations (14.19) and (14.20) together yield the following equation for the population
activity A0
A0 = gσ(J0A0 +Iext
0 ).
(14.21)
This result agrees with the general result found in Chapter 12 for the stationary state in a
network with self-coupling. Solutions can be found graphically (Fig. 14.6) using the same
method as in Chapter 12.
The advantage of the integral equation approach is two-fold. First, for the integral equa-
tions we have transparent mathematical tools to analyze the stability of the stationary solu-
tion, as shown in Section 14.2.3.
Second, we can write down the gain function gσ(I) and an expression for A0 in a com-
pact form, as will be shown now. Because the input is constant, the state of each neuron
depends only on the time since the last spike t −ˆt. We are thus in the situation of stationary
renewal theory. Therefore, the survivor function and the interval distribution cannot depend
explicitly upon the absolute time, but only on the time difference s = t −ˆt. Hence we set
SI(ˆt +s|ˆt) →S0(s),
(14.22)
PI(ˆt +s|ˆt) →P0(s).
(14.23)
The value of the stationary activity A0 now follows directly from the normalization Equa-
tion (14.8),
1 = A0
 ∞
0 S0(s)ds.
(14.24)
We use d
dsS0(s) = −P0(s) and integrate by parts
1 = A0
 ∞
0 sP0(s)ds = A0⟨T⟩,
(14.25)
where the last equality follows from the deﬁnition of the mean interspike interval

370
The integral-equation approach
(a)
(b)
Fig. 14.6 Gain function and stationary activity in a population of SRM neurons with exponential
escape noise. (a) Gain function (single neuron ﬁring frequency ν as a function of constant current I0)
for neurons with refractoriness given by Eq. (14.29). (b) Self-consistent solution for the population
activity A(t) = A0 in a recurrent network of SRM neurons coupled to itself with strength J0. Neurons
are characterized by the same gain function as in part (a) of the ﬁgure.
(see Chapter 9). Hence
A0 =
1
 ∞
0 S0(s)ds =
1
⟨T⟩= ν .
(14.26)
The result has an intuitively appealing interpretation: if everything is constant, then averag-
ing over time (for a single neuron) is the same as averaging over a population of identical
neurons; see the discussion in Chapter 12.
Example: Population of SRM neurons with escape noise
Consider a population of SRM0 neurons with exponential escape noise and membrane
potential
u(t) = η(t −ˆt)+
 ∞
0 κ(s)I(t −s)ds = η(t −ˆt)+h(t).
(14.27)
We assume that the input current is constant so that h(t) = h0 = RI0 with R =
 ∞
0 κ(s)ds. With exponential escape noise, the hazard function (Chapter 9) is ρ(t −ˆt) =
ρ0 exp[β(h0 +η(t −ˆt))] and the gain function is given by Eq. (14.26)
A0 =
 ∞
0 dx exp

−
 x
0 ρ0eβ[h0+η(s)]ds
−1
= gσ(I0)
(14.28)
where σ = 1/β indicates the level of noise.
We now set β = 1 and consider a speciﬁc choice of η that includes absolute and
relative refractoriness
η(t) =
⎧
⎨
⎩
−∞
if t < Δabs
ln

1−e−(t−Δabs)/τ
otherwise.
(14.29)

14.2 Recurrent networks and interacting populations
371
With this choice of η it is possible to calculate the gain function in terms of the incom-
plete gamma function γ(a,x) =
 x
0 ta−1e−tdt.
A0 = gσ(I0) =

Δabs + τγ(r,r)
rre−r
−1
,
(14.30)
where r = τρ0eh0 (see Exercises). The result is shown in Fig. 14.6a.
If the population of neurons is coupled to itself with synapses w0 = J0/N, the sta-
tionary value of asynchronous activity can be found graphically by plotting on the same
graph A0 = gσ(I0) and
A0 = [I0 −Iext
0 ]/J0 ,
(14.31)
which follows from Eq. (14.20); see Fig. 14.6b.
14.2.3 Oscillations and stability of the stationary state (*)
In the previous subsection we assumed that the network is in a state of asynchronous ﬁring.
In this section, we study whether asynchronous ﬁring can indeed be a stable state of a fully
connected population of spiking neurons - or whether the connectivity drives the network
toward oscillations. For the sake of simplicity, we restrict the analysis to SRM0 neurons;
the same methods can, however, be applied to integrate-and-ﬁre neurons or spiking neurons
formulated in the framework of Generalized Linear Models.
For SRM0 neurons (see Chapter 9), the membrane potential is given by
ui(t) = η(t −ˆti)+h(t),
(14.32)
where η(t −ˆti) is the effect of the last ﬁring of neuron i (i.e., the spike-afterpotential) and
h(t) is the total postsynaptic potential caused by presynaptic ﬁring. If all presynaptic spikes
are generated within the homogeneous population under consideration, we have
h(t) = ∑
j
wi j∑
f
ε0(t −t f
j ) = J0
 ∞
0 ε0(s)A(t −s)ds.
(14.33)
Here ε0(t −t f
j ) is the time course of the postsynaptic potential generated by a spike of
neuron j at time t f
j and wi j = J0/N is the strength of lateral coupling within the popula-
tion. The second equality sign follows from the deﬁnition of the population activity, i.e.,
A(t) = N−1 ∑j ∑f δ(t −t f
j ); see Chapter 12. For the sake of simplicity, we have assumed
in Eq. (14.33) that there is no external input.
The state of asynchronous ﬁring corresponds to a ﬁxed point A(t) = A0 of the population
activity. We have already seen in the previous subsection as well as in Chapter 12 how the
ﬁxed point A0 can be determined either numerically or graphically. To analyze its stability
we assume that for t > 0 the activity is subject to a small perturbation,
A(t) = A0 +A1 eiωt+λt
(14.34)

372
The integral-equation approach
with A1 ≪A0. This perturbation in the activity induces a perturbation in the input potential,
h(t) = h0 +h1 eiωt+λt .
(14.35)
The perturbation of the potential causes some neurons to ﬁre earlier (when the change in
h is positive) and others to ﬁre later (whenever the change is negative). The perturbation
may therefore build up (λ > 0, the asynchronous state is unstable) or decay back to zero
(λ < 0, the asynchronous state is stable). At the transition between the region of stability
and instability the amplitude of the perturbation remains constant (λ = 0, marginal stability
of the asynchronous state). These transition points, deﬁned by λ = 0, are determined now.
We start from the population integral equation A(t) =
 t
−∞PI(t|ˆt)A(ˆt)dˆt that was intro-
duced in Section 14.1. Here PI(t|ˆt) is the input-dependent interval distribution, i.e., the
probability density of emitting a spike at time t given that the last spike occurred at time ˆt.
The linearized response of the population activity to a small change ΔI in the input can,
under general smoothness assumptions, always be written in the form
A(t) = A0 +
 ∞
0 G(s)ΔI(t −s)ds,
(14.36)
where G(s) is the linear response ﬁlter in the time domain. The Fourier transform ˆG(ω) is
the frequency-dependent gain function. The explicit form of the ﬁlter will be derived in the
framework of the integral equations in Section 14.3.
Instead of thinking of a stimulation by an input current ΔI(t), it is more convenient to
work with the input potential h(t) =
 ∞
0 κ(s)I(t −s)ds, because the neuron model equations
have been deﬁned on the level of the potential; see Eq. (14.32). We use ΔA(t) = A1 eiωt+λt
and Δh(t) = h1 eiωt+λt in Eq. (14.36) and search for the critical value λ = 0 where the stable
solution turns into an unstable one. After cancellation of a common factor A1 exp(iωt) the
result can be written in the form
1 = J0
ˆG(ω) ˆε(ω)
ˆκ(ω)
= Sf (ω) exp[iΦ(ω)].
(14.37)
Here, ˆκ(ω) and ˆε(ω) are the Fourier transform of the membrane kernel κ(s) and the time
course of the postsynaptic potential ε0(s) caused by an input spike, respectively. Typically,
κ(s) = (R/τm) exp(−s/τm) where τm is the membrane time constant. If the synaptic input
is a short current pulse of unit charge, ε0 and κ are identical, but we would also like to
include the case of synaptic input currents with arbitrary time dependence and therefore
keep separate symbols for ε0 and κ. The second equality sign deﬁnes the real-valued func-
tions Sf (ω) and Φ(ω).
Equation (14.37) is thus equivalent to
S f (ω) = 1
and
Φ(ω) mod 2π = 0.
(14.38)
Solutions of Eq. (14.38) yield bifurcation points where the asynchronous ﬁring state loses
its stability toward an oscillation with frequency ω.
We have written Eq. (14.38) as a combination of two requirements, i.e., an amplitude

14.2 Recurrent networks and interacting populations
373
condition Sf (ω) = 1 and a phase condition Φ(ω) mod 2π = 0. Let us discuss the general
structure of the two conditions. First, if Sf (ω) ≤1 for all frequencies ω, an oscillatory
perturbation cannot build up. All oscillations decay and the state of asynchronous ﬁring
is stable. We conclude from Eq. (14.37) that by increasing the absolute value |J0| of the
coupling constant, it is always possible to increase Sf (ω). The amplitude condition can
thus be met if the excitatory or inhibitory feedback from other neurons in the population
is sufﬁciently strong. Second, for a bifurcation to occur we need in addition that the phase
condition is met. Loosely speaking, the phase condition implies that the feedback from
other neurons in the network must arrive just in time to keep the oscillation going. Thus
the axonal signal transmission time and the rise time of the postsynaptic potential play a
critical role during oscillatory activity (Abbott and van Vreeswijk, 1993; Gerstner and van
Hemmen, 1993; Treves, 1993; Tsodyks et al., 1993; Gerstner, 1995; Brunel and Hakim,
1999; Brunel, 2000; Gerstner, 2000).
Example: Slow noise and phase diagram of instabilities
Let us apply the above results to leaky integrate-and-ﬁre neurons with slow noise
in the parameters. After each spike the neuron is reset to a value ur which is drawn
from a Gaussian distribution with mean ¯ur and width σr ≪[ϑ −¯ur]. After the reset, the
membrane potential evolves deterministically according to
τm
du
dt = −u+RI(t).
(14.39)
The next ﬁring occurs if the membrane potential hits the threshold ϑ.
We assume that neurons are part of a large population N →∞which is in a state
of asynchronous ﬁring with activity A0. In this case, each neuron receives a constant
input I0. For constant input, a neuron which was reset to a value ¯ur will ﬁre again after
a period T0. Because of the noisy reset with σr ≪[ϑ −¯ur], the interval distribution is
approximately a Gaussian centered at T0. We denote the standard deviation of the interval
distribution by σ. The stationary population activity is simply A0 = 1/T0. The width of
the Gaussian interval distribution σ is linearly related to σr with a proportionality factor
that represents the (inverse of the) slope of the membrane potential at the ﬁring threshold
(Gerstner, 2000).
In order to analyze the stability of the stationary state, we have to specify the time
course of the excitatory or inhibitory postsynaptic potential ε0. For the sake of simplicity
we choose a delayed alpha function,
ε0(s) = s−Δax
τ2
exp

−s−Δax
τ

Θ(s−Δax).
(14.40)
The Fourier transform of ε has an amplitude |ˆε(ω)| = (1 + ω2 τ2)−1 and a phase
|ψ(ω)| = ω Δax + 2arctan(ω τ). Note that a change in the delay Δax affects only the
phase of the Fourier transform and not the amplitude.

374
The integral-equation approach
Figure 14.7 shows S f deﬁned in the second equality sign of Eq. (14.37) as a function
of ω T0. Since Sf = 1 is a necessary condition for a bifurcation, it is apparent that bifur-
cations can occur only for frequencies ω ≈ωn = n2π/T0 with integer n where T0 = 1/A0
is the typical interspike interval. We also see that higher harmonics are only relevant for
low levels of noise. At a high noise level, however, the asynchronous state is stable even
with respect to perturbations at ω ≈ω1.
A bifurcation at ω ≈ω1 implies that the period of the perturbation is identical to the
ﬁring period of individual neurons. Higher harmonics correspond to instabilities of the
asynchronous state toward cluster states (Golomb et al., 1992; Gerstner and van Hem-
men, 1993; Ernst et al., 1995; Golomb and Rinzel, 1994; Brunel, 2000): each neuron
ﬁres with a mean period of T0, but the population of neurons splits up in several groups
that ﬁre alternately so that the overall activity oscillates several times faster. In terms
of the terminology introduced in Chapter 13, the network is in the synchronous regular
(SR) state of fast oscillations.
Figure 14.7 illustrates the amplitude condition for the solution of Eq. (14.38). The
numerical solutions of the full equation (14.38) for different values of the delay Δax and
different levels of the noise σ are shown in the bifurcation diagram of Fig. 14.8. The
insets show simulations that illustrate the behavior of the network at certain combina-
tions of transmission delay and noise level.
Let us consider, for example, a network with transmission delay Δax = 2 ms, corre-
sponding to an x-value of Δax/T0 = 0.25 in Fig. 14.8. The phase diagram predicts that,
at a noise level of σ = 0.5 ms, the network is in a state of asynchronous ﬁring. The
simulation shown in the inset in the upper right-hand corner conﬁrms that the activity
ﬂuctuates around a constant value of A0 = 1/T0 = 0.125 kHz.
If the noise level of the network is signiﬁcantly reduced, the system crosses the short-
dashed line. This line is the boundary at which the constant activity state becomes unsta-
ble with respect to an oscillation with ω ≈3(2π/T0). Accordingly, a network simulation
with a noise level of σ = 0.1 exhibits an oscillation of the population activity with period
T osc ≈T0/3 ≈2.6 ms.
Keeping the noise level constant but reducing the transmission delay corresponds to a
horizontal move across the phase diagram in Fig. 14.8. At some point, the system crosses
the solid line that marks the transition to an instability with frequency ω1 = 2π/T0.
Again, this is conﬁrmed by a simulation shown in the inset in the upper left corner. If
we now decrease the noise level, the oscillation becomes even more pronounced (bot-
tom left).
In the limit of low noise, the asynchronous network state is unstable for virtually all
values of the delay. The region of the phase diagram in Fig. 14.8 around Δax/T0 ≈0.1,
which looks stable, hides instabilities with respect to the higher harmonics ω6 and ω5,
which are not shown. We emphasize that the speciﬁc location of the stability borders
depends on the form of the postsynaptic response function ε. The qualitative features of
the phase diagram in Fig. 14.8 are generic and hold for all kinds of response kernels.

14.3 Linear response to time-dependent input
375
Sf
wT0 / 2p
Fig. 14.7 Amplitude condition for instabilities in the asynchronous state. The amplitude S f is plot-
ted as a function of the normalized frequency ω T0 for two different values of the noise: σ = 1 ms
(solid line) and σ = 0.1 ms (dashed line). Instabilities of the asynchronous ﬁring state are possible
at frequencies where S f > 1. For low noise S f crosses unity (broken horizontal line) at frequencies
ω ≈ωn = n2π/T0. For σ = 1 ms there is a single instability region for ω T0 ≈1. For the plot we
have set T0 = 2τ.
What happens if the excitatory interaction is replaced by inhibitory coupling? A
change in the sign of the interaction corresponds to a phase shift of π. For each harmonic,
the region along the delay axis where the asynchronous state is unstable for excitatory
coupling (see Fig. 14.8) becomes stable for inhibition and vice versa. In other words, we
simply have to shift the instability tongues for each harmonic frequency ωn = 2nπ/T0
horizontally by half the period of the harmonic, i.e., Δ/T0 = 1/(2n). Apart from that the
pattern remains the same.
14.3 Linear response to time-dependent input
We consider a homogeneous population of independent neurons. All neurons receive the
same time-dependent input current I(t) which varies about the mean I0. For constant input
I0 the population would ﬁre at an activity A0 which we can derive from the neuronal gain
function. We require that the variations of the input
I(t) = I0 +ΔI(t)
(14.41)
are small enough for the population activity to stay close to the value A0
A(t) = A0 +ΔA(t),
(14.42)
with |ΔA| ≪A0.
In that case, we may expand the right-hand side of the population equation A(t) =
 t
−∞PI(t|ˆt)A(ˆt)dˆt into a Taylor series about A0 to linear order in ΔA. In this section, we
want to show that for spiking neuron models (either integrate-and-ﬁre or SRM0 neurons)
the linearized population equation can be written in the form
ΔA(t) =
 t
−∞P0(t −ˆt)ΔA(ˆt)dˆt +A0
d
dt
 ∞
0 L (x)Δh(t −x)dx,
(14.43)

376
The integral-equation approach
940
960
980
1000
t [ms]
0
1
2
3
A(t) [kHz]
940
960
980
1000
t [ms]
0
1
2
3
A(t) [kHz]
940
960
980
1000
t [ms]
0
1
2
3
A(t) [kHz]
940
960
980
1000
t [ms]
0
1
2
3
A(t) [kHz]
0.0
0.2
0.4
0.6
0.8
1.0
D/T0
0.0
0.2
0.4
0.6
0.8
1.0
s [ms]
Fig. 14.8 Stability diagram (center) for the state of asynchronous ﬁring in a network of SRM0 neu-
rons with reset noise as a function of the noise level (y-axis) and the delay Δax (x-axis). The noise
level is characterized by the standard deviation σISI of the interspike-interval distribution divided by
the mean interval T0. The diagram shows the borders of the stability region with respect to ω1,...,ω4.
For high values of noise, the asynchronous ﬁring state is always stable. If the noise is reduced, the
asynchronous state becomes unstable with respect to an oscillation either with frequency ω1 (solid
border lines), or ω2 (long-dashed border lines), ω3 (short-dashed border lines), or ω4 (long-short-
dashed border lines). Four insets show typical patterns of the activity as a function of time taken
from a simulation with N = 1000 neurons. Parameters are σISI = 0.5 ms and Δax = 0.2 ms (top left);
σISI = 0.5 ms and Δax = 2.0 ms (top right); σISI = 0.1 ms and Δax = 0.2 ms (bottom left); σISI = 0.1
ms and Δax = 2.0 ms (bottom right). Neuronal parameters are J0 = 1 and τ = 4 ms. The threshold ϑ
was adjusted so that the mean interspike interval is T0 = 2τ = 8 ms. Adapted from Gerstner (2000).

14.3 Linear response to time-dependent input
377
where P0(t −ˆt) is the interval distribution for constant input I0, L (x) is a real-valued
function that plays the role of an integral kernel, and
Δh(t) =
 ∞
0 κ(s)ΔI(t −s)ds
(14.44)
is the input potential generated by the time-dependent part of the input current. The ﬁrst
term of the right-hand side of Eq. (14.43) takes into account that previous perturbations
ΔA(ˆt) with ˆt < t have an after-effect one interspike interval later. The second term describes
the immediate response to a change in the input potential. If we want to understand the
response of the population to an input current ΔI(t), we need to know the characteristics
of the kernel L (x). The main task of this section is therefore the calculation of L (x) to be
performed in Section 14.3.1.
The linearization of the integral equation (Gerstner, 2000) is analogous to the lineariza-
tion of the membrane potential density equations (Brunel and Hakim, 1999) that was pre-
sented in Chapter 13. In order to arrive at the standard formula for the linear response,
A(t) = A0 +
 ∞
0 G(s)ΔI(t −s)ds,
(14.45)
we insert Eq. (14.44) into Eq. (14.43) and take the Fourier transform. For ω ̸= 0 we ﬁnd
ˆA(ω) = iω A0
ˆ
L (ω) ˆκ(ω)
1−ˆP(ω)
ˆI(ω) = ˆG(ω) ˆI(ω).
(14.46)
Hats denote transformed quantities, i.e., ˆκ(ω) =
 κ0(s) exp(−iω s)ds is the Fourier trans-
form of the response kernel; ˆP(ω) is the Fourier transform of the interval distribution
P0(t −ˆt); and
ˆ
L (ω) is the transform of the kernel L . Note that for ω ̸= 0 we have
ˆA(ω) =
ˆ
(ΔA)(ω) and I(ω) = ˆ
(ΔI)(ω) since A0 and I0 are constant.
The frequency-dependent gain ˆG(ω) describes the linear response of the population
activity to a periodic input current ˆI(ω). The linear response ﬁlter G(s) in the time domain
is found by inverse Fourier transform
G(s) = 1
2π
 ∞
−∞
ˆG(ω)e+iω sdω .
(14.47)
A0 is the mean rate for constant drive I0. The ﬁlter G plays an important role for the analysis
of the stability of the stationary state in recurrent networks (Section 14.2).
Example: Leaky integrate-and-ﬁre with escape noise
The frequency-dependent gain ˆG depends on the ﬁlter L (s), which in turns depends
on the width of the interval distribution P0(s) (Fig. 14.9b and a, respectively). In
Fig. 14.9c we have plotted the signal gain ˆG(ω) for integrate-and-ﬁre neurons with
escape noise at different noise levels. At low noise, the signal gain exhibits resonances at
the frequency that corresponds to the inverse of the mean interval and multiples thereof.
Increasing the noise level, however, lowers the signal gain of the system. For high noise

378
The integral-equation approach
P0[s]
20
s [ms]
10
0
0.2
0.4
0.6
(a)
0
(b)
0.0
5.0
10.0
x [ms]
0.0
25.0
L IF
0
0.0
1.0
(c)
|G|(f) 
2
4
6
f [1/<T>]
Fig. 14.9 Response properties of a population of leaky integrate-and-ﬁre neurons with escape noise.
(a) Interval distribution for three different noise levels. The escape rate has been taken as piecewise
linear ρ = ρ0 [u −ϑ]Θ(u −ϑ). The value of the bias current I0 has been adjusted so that the mean
interval is always ⟨T⟩= 8 ms. (b) The corresponding kernel L IF(x). The dip in the kernel around
x = ⟨T⟩is typical for integrate-and-ﬁre neurons. (c) Frequency-dependent gain |G(f)| = | ˆG(ω =
2π f)|. Low noise (short-dashed line): the sharply peaked interval distribution (standard deviation
0.75 ms) and rapid fall-off of kernel L lead to a linear response gain ˆG with strong resonances
at multiples of the intrinsic ﬁring frequency 1/⟨T⟩. High noise (long-dashed line): the broad inter-
val distribution (standard deviation 4 ms) and broad kernel L suppress resonances in the frequency
dependent gain. Medium noise (solid line): a single resonance for an interval distribution with stan-
dard deviation 2 ms. Adapted from Gerstner (2000).
(long-dashed line in Fig. 14.9c) the signal gain at 1000 Hz is ten times lower than the
gain at zero frequency. The cut-off frequency depends on the noise level. The gain at
zero frequency corresponds to the slope of the gain function gσ(I0) and changes with
the level of noise.
14.3.1 Derivation of the linear response ﬁlter (*)
In order to derive the linearized response ΔA of the population activity to a change in the
input we start from the conservation law,
1 =
 t
−∞SI(t | ˆt)A(ˆt)dˆt ;
(14.48)
compare Eq. (14.8). As we have seen in Section 14.1 the population equation (14.5) can be
obtained by taking the derivative of Eq. (14.8) with respect to t, i.e.,
0 = d
dt
 t
−∞SI(t | ˆt)A(ˆt)dˆt .
(14.49)
For constant input I0, the population activity has a constant value A0. We consider a small
perturbation of the stationary state, A(t) = A0 +ΔA(t), that is caused by a small change in
the input current, ΔI(t). The time-dependent input generates a total postsynaptic potential,
h(t) = h0 +Δh(t, ˆt) where h0 is the postsynaptic potential for constant input I0 and
Δh(t, ˆt) =
 b(ˆt)
0
κ(s)ΔI(t −s)ds
(14.50)

14.3 Linear response to time-dependent input
379
is the change of the postsynaptic potential generated by ΔI. Note that we keep the nota-
tion general and include a dependence upon the last ﬁring time ˆt. For leaky integrate-and-
ﬁre neurons, we set b(ˆt) = t −ˆt whereas for SRM0 neurons we set b(ˆt) = ∞. We expand
Eq. (14.49) to linear order in ΔA and Δh and ﬁnd
0 = d
dt
 t
−∞S0(t −ˆt)ΔA(ˆt)dˆt
+A0
d
dt
 t
−∞ds
 t
−∞dˆt Δh(s, ˆt) ∂SI(t | ˆt)
∂Δh(s, ˆt)

Δh=0

.
(14.51)
We have used the notation S0(t −ˆt) = SI0(t | ˆt) for the survivor function of the asynchronous
ﬁring state. To take the derivative of the ﬁrst term in Eq. (14.51) we use dS0(s)/ds = −P0(s)
and S0(0) = 1. This yields
ΔA(t) =
 t
−∞P0(t −ˆt)ΔA(ˆt)dˆt
−A0
d
dt
 t
−∞ds
 t
−∞dˆt Δh(s, ˆt) ∂SI(t | ˆt)
∂Δh(s, ˆt)

Δh=0

.
(14.52)
We note that the ﬁrst term on the right-hand side of Eq. (14.52) has the same form as
the population integral equation (14.5), except that P0 is the interval distribution in the
stationary state of asynchronous ﬁring.
To make some progress in the treatment of the second term on the right-hand side of
Eq. (14.52), we now restrict the choice of neuron model and focus on either SRM0 or
integrate-and-ﬁre neurons.
(i) For SRM0 neurons, we may drop the ˆt dependence of the potential and set Δh(t, ˆt) =
Δh(t) where Δh is the input potential caused by the time-dependent current ΔI; compare
Eqs. (14.44) and (14.50). This allows us to pull the variable Δh(s) in front of the integral
over ˆt and write Eq. (14.52) in the form
ΔA(t) =
 t
−∞P0(t −ˆt)ΔA(ˆt)dˆt +A0
d
dt
 ∞
0 L (x)Δh(t −x)dx,
(14.53)
with a kernel
L (x) = −
 ∞
x dξ
∂S(ξ|0)
∂Δh(ξ −x) ≡L SRM(x).
(14.54)
(ii) For leaky integrate-and-ﬁre neurons we set Δh(t, ˆt) = Δh(t)−Δh(ˆt) exp[−(t −ˆt)/τ],
because of the reinitialization of the membrane potential after the reset (Gerstner, 2000).
After some rearrangements of the terms, Eq. (14.52) becomes identical to Eq. (14.53) with
a kernel
L (x) = −
 ∞
x dξ
∂S(ξ|0)
∂Δh(ξ −x) +
 x
0 dξ e−ξ/τ ∂S(x|0)
∂Δh(ξ) ≡L IF(x).
(14.55)
Let us discuss Eq. (14.53). The ﬁrst term on the right-hand side of Eq. (14.53) is of the
same form as the dynamic equation (14.5) and describes how perturbations ΔA(ˆt) in the

380
The integral-equation approach
0
50
100
s [ms]
0
0.1
P0 (s)
(a)
0
50
100
x [ms]
0
0.01
0.02
0.03
LSRM
(b)
Fig. 14.10 Interval distribution (a) and the kernel L SRM(x) (b) for SRM0 neurons with escape noise.
The escape rate has been taken as piecewise linear ρ = ρ0 [u−ϑ]Θ(u−ϑ). For low noise (solid lines
in (a) and (b)) the interval distribution is sharply peaked and the kernel L SRM has a small width. For
high noise (dashed line) both the interval distribution and the kernel L SRM are broad. The value of
the bias current I0 has been adjusted so that the mean interval is always 40 ms. The kernel has been
normalized to
 ∞
0 L (x)dx = 1.
past inﬂuence the present activity ΔA(t). The second term gives an additional contribution
which is proportional to the derivative of a ﬁltered version of the potential Δh.
We see from Fig. 14.10 that the width of the kernel L depends on the noise level. For
low noise, it is signiﬁcantly sharper than for high noise.
Example: The kernel L (x) for escape noise (*)
In the escape noise model, the survivor function is given by
SI(t | ˆt) = exp

−
 t
ˆt f[η(t′ −ˆt)+h(t′, ˆt)]dt′

,
(14.56)
where f[u] is the instantaneous escape rate across the noisy threshold; see Chapter 7. We
write h(t, ˆt) = h0(t −ˆt)+Δh(t, ˆt). Taking the derivative with respect to Δh yields
∂SI(t | ˆt)
∂Δh(s, ˆt)

Δh=0
= −Θ(s−ˆt)Θ(t −s) f ′[η(s−ˆt)+h0(s−ˆt)]S0(t −ˆt),
(14.57)
where S0(t −ˆt) = Sh0(t | ˆt) and f ′ = df(u)/du. For SRM0 neurons, we have h0(t −ˆt) ≡h0
and Δh(t, ˆt) = Δh(t), independent of ˆt. The kernel L is therefore
L SRM(t −s) = Θ(t −s)
 s
−∞dˆt f ′[η(s−ˆt)+h0]S0(t −ˆt).
(14.58)
Example: Absolute refractoriness (*)
Absolute refractoriness is deﬁned by a refractory kernel η(s) = −∞for 0 < s < δ abs
and zero otherwise. We take an arbitrary escape rate f(u) ≥0. The only condition on f is

14.4 Density equations vs. integral equations
381
that the escape rate goes rapidly to zero for voltages far below threshold: limu→−∞f(u) =
0 = limu→−∞f ′(u).
This yields f[η(t −ˆt)+h0] = f(h0)Θ(t −ˆt −δ abs) and hence
f ′[η(t −ˆt)+h0] = f ′(h0)Θ(t −ˆt −δ abs).
(14.59)
The survivor function S0(s) is unity for s < δ abs and decays as exp[−f(h0)(s −δ abs)]
for s > δ abs. Integration of Eq. (14.58) yields
L (t −t1) = Θ(t −t1) f ′(h0)
f(h0) exp[−f(h0)(t −t1)].
(14.60)
As we have seen in Section 14.1, absolute refractoriness leads to the Wilson-Cowan
integral equation (14.10). Thus L deﬁned in (14.60) is the kernel relating to Eq. (14.10).
It could have been derived directly from the linearization of the Wilson-Cowan integral
equation (see Exercises). We note that it is a low-pass ﬁlter with cut-off frequency f(h0),
which depends on the input potential h0.
14.4 Density equations vs. integral equations
In this section we relate the integral equation (14.5) to the membrane potential density
approach for integrate-and-ﬁre neurons that we discussed in Chapter 13. The two
approaches are closely related. For noise-free neurons driven by a constant suprathreshold
stimulus, the two mathematical formulations are, in fact, equivalent and related by a sim-
ple change of variables. Even for noisy neurons with subthreshold stimulation, the two
approaches are comparable. Both methods are linear in the densities and amenable to
efﬁcient numerical implementations. The formal mathematical relation between the two
approaches is shown in Section 14.4.3.
We use Section 14.4.1 to introduce a "refractory density" which is analogous to the
membrane potential density that we saw in Chapter 13. In particular, the dynamics of
refractory density variables follow a continuity equation. The solution of the continuity
equation (14.4.2) transforms the partial differential equation into the integral equations
that we saw in Section 14.1.
14.4.1 Refractory densities
In this section we develop a density formalism for spike response neurons, similar to the
membrane potential density approach for integrate-and-ﬁre neurons that we discussed in
Chapter 13. The main difference is that we replace the membrane potential density p(u,t)
by a refractory density q(r,t), to be introduced below.
We study a homogeneous population of neurons with escape noise. The neuron model
should be consistent with time-dependent renewal theory. In this case, we can write the
membrane potential of a neuron i in general form as
ui(t, ˆt) = η(t −ˆti)+h(t, ˆti).
(14.61)

382
The integral-equation approach
For example, a nonlinear integrate-and-ﬁre model which has ﬁred the last time at ˆti and
follows a differential equation ˙u(t) = [ f(u) + RI(t)] has for t > ˆti a potential ui(t, ˆti) =
h(t, ˆti) = ur +
 t
ˆti ˙u(t′)dt′ and η = 0. An SRM0 neuron has a potential ui(t, ˆt) = η(t −ˆti)+
h(t) with an arbitrary spike-afterpotential η(t −ˆti) and an input potential h.
The notation in Eq. (14.61) emphasizes the importance of the last ﬁring time ˆt. We
denote the refractory state of a neuron by the variable
r = t −ˆt ≥0,
(14.62)
i.e., by the time that has passed since the last spike. If we know r and the total input
current in the past, we can calculate the membrane potential, u(t) = η(r) + h(t,t −r).
Given the importance of the refractory variable r, we may wonder how many neurons
in the population have a refractory state between r0 and r0 + Δr. For a large population
(N →∞) the fraction of neurons with a momentary value of r in the interval [r0,r0 +Δr] is
given by
lim
N→∞
neurons with r0 < r(t) ≤r0 +Δr
N

=
 r0+Δr
r0
q(r,t)dr,
(14.63)
where q(r,t) is the refractory density. The aim of this section is to describe the dynamics
of a population of SRM neurons by the evolution of q(r,t).
We start from the continuity equation (see Chapter 13),
∂
∂t q(r,t) = −∂
∂rJrefr(r,t),
(14.64)
where we have introduced the ﬂux Jrefr along the axis of the refractory variable r. As long
as the neuron does not ﬁre, the variable r = t −ˆt increases at a speed of dr/dt = 1. The ﬂux
is the density q times the velocity, hence
Jrefr(r,t) = q(r,t) dr
dt = q(r,t).
(14.65)
The continuity equation (14.64) expresses the fact that, as long as a neuron does not ﬁre, its
trajectories r(t) can neither start nor end. On the other hand, if a neuron ﬁres, the trajectory
stops at the current value of r and "reappears" at r = 0. In the escape rate formalism, the
instantaneous ﬁring rate of a neuron with refractory variable r is given by the hazard
ρ(t|t −r) = f[η(r)+h(t|t −r)].
(14.66)
If we multiply the hazard (14.66) with the density q(r,t), we get the loss per unit of time,
Jloss = −ρ(t|t −r)q(r,t).
(14.67)
The total number of trajectories that disappear at time t due to ﬁring is equal to the popu-
lation activity, i.e.,
A(t) =
 ∞
0 ρ(t|t −r)q(r,t)dr.
(14.68)
The loss (14.67) has to be added as a "sink" term on the right-hand side of the continuity
equation, while the activity A(t) acts as a source at r = 0. The full dynamics is

14.4 Density equations vs. integral equations
383
∂
∂t q(r,t) = −
 ∂
∂rq(r,t)

−ρ(t|t −r)q(r,t)+δ(r)A(t).
(14.69)
This partial differential equation is the analog of the Fokker-Planck equation (13.16) for
the membrane potential density of integrate-and-ﬁre neurons. The relation between the two
equations will be discussed in Section 14.4.3.
Equation (14.69) can be integrated analytically and rewritten in the form of an integral
equation for the population activity. The mathematical details of the integration will be
presented below. The ﬁnal result is
A(t) =
 t
−∞PI(t|ˆt)A(ˆt)dˆt ,
(14.70)
where
PI(t|ˆt) = ρ(t|ˆt) exp

−
 t
ˆt ρ(t′|ˆt)dt′

(14.71)
is the interval distribution of neurons with escape noise; see Eq. (7.28). Thus, neurons
that have ﬁred their last spike at time ˆt contribute with weight PI(t|ˆt) to the activity at
time T. Integral equations of the form (14.70) are the starting point for the formal theory
of population activity presented in Section 14.1.
14.4.2 From refractory densities to the integral equation (*)
All neurons that have ﬁred together at time ˆt form a group that moves along the r-axis at
constant speed. To solve Eq. (14.69) we turn to a frame of reference that moves along with
the group. We replace the variable r by t −r ≡ˆt and deﬁne a new density
Q(ˆt,t) = q(t −ˆt,t),
(14.72)
with ˆt ≤t. The total derivative of Q with respect to t is
d
dt Q(ˆt,t) = ∂
∂r q(r,t)|r=t−ˆt
dr
dt + ∂
∂t q(r,t)|r=t−ˆt
(14.73)
with dr/dt = 1. We insert Eq. (14.69) on the right-hand side of (14.73) and obtain for t > ˆt
d
dt Q(ˆt,t) = −ρ(t|ˆt)Q(ˆt,t).
(14.74)
The partial differential equation (14.69) has thus been transformed into an ordinary differ-
ential equation that is solved by
Q(ˆt,t) = Q(ˆt,t0) exp

−
 t
t0
ρ(t′|ˆt)dt′

,
(14.75)
where Q(ˆt,t0) is the initial condition, which is still to be ﬁxed.
From the deﬁnition of the refractory density q(r,t) we conclude that q(0,t) is the pro-
portion of neurons at time t that have just ﬁred, i.e., q(0,t) = A(t) or, in terms of the new
refractory density, Q(t,t) = A(t). We can thus ﬁx the initial condition in Eq. (14.75) at
t0 = ˆt and ﬁnd
Q(ˆt,t) = A(ˆt) exp

−
 t
ˆt ρ(t′|ˆt)dt′

.
(14.76)

384
The integral-equation approach
t
^
^t
r = t -t
J
u(t,t)ˆ
u
(a)
r
0
u
Q(t,t - r)
p(u,t)
(b)
u(t,t)ˆ
Fig. 14.11 (a) In a noise-free (nonlinear) integrate-and-ﬁre neuron we deﬁne a refractory variable
r = t −ˆt and write the trajectory as u(t, ˆt). (b) The membrane potential density p(u,t) at time t is
plotted to the left as a function of the membrane potential u (vertical axis). The fraction of neurons
p(u,t)Δu with membrane potentials around u (gray shaded area) is proportional to the refractory
density Q(t, ˆt)Δˆt (shaded area at the bottom).
On the other hand, from (14.68) we have
A(t) =
 t
−∞ρ(t|ˆt)Q(ˆt,t)dˆt .
(14.77)
If we insert (14.76) into (14.77), we ﬁnd
A(t) =
 t
−∞ρ(t|ˆt) exp

−
 t
ˆt ρ(t′|ˆt)dt′

A(ˆt)dˆt,
(14.78)
which is the population equation (14.70) mentioned above. It has been derived from refrac-
tory densities in Gerstner and van Hemmen (1992) and similarly in the appendix of the
papers by Wilson and Cowan (1972). If we insert Eq. (14.76) into the normalization con-
dition 1 =
 t
−∞Q(ˆt,t)dˆt we arrive at
1 =
 t
−∞exp

−
 t
ˆt ρ(t′|ˆt)dt′

A(ˆt)dˆt .
(14.79)
Both the population equation (14.78) and the normalization condition (14.79) play an
important role in the general theory outlined in Section 14.1.
For a numerical implementation of population dynamics, it is more convenient to take
a step back from the integral equations to the iterative updates that describe the survival
Q(ˆt,t) of the group of neurons that has ﬁred the last time at time ˆt. In other words, efﬁcient
numerical implementation schemes work directly on the level of the density equations
(14.74). A simple discretization scheme for numerical implementations has been discussed
above in Section 14.1.5.

14.4 Density equations vs. integral equations
385
14.4.3 From refractory densities to membrane potential densities (*)
In this section we want to show the formal relation between the dynamics of p(u,t) and
the evolution of the refractory densities q(r,t). We focus on a population of nonlinear or
leaky integrate-and-ﬁre neurons with escape noise. For a known time-dependent input we
can calculate the membrane potential u(t, ˆt) where the notation with ˆt highlights that, in
addition to external input, we also need to know the last ﬁring time (and the reset value ur)
in order to predict the voltage at time t. We require that the input is constant or only weakly
modulated so that the trajectory is increasing monotonously (∂u/∂t > 0).
To stay concrete, we focus on leaky integrate-and-ﬁre neuron for which the membrane
potential is
u(t, ˆt) = ur exp

−t −ˆt
τm

+ R
τm
 t
ˆt exp

−t −t′
τm

I(t′)dt′.
(14.80)
Knowledge of u(t, ˆt) can be used to deﬁne a transformation from voltage to refractory vari-
ables: u ←→r = t −ˆt; see Fig. 14.11a. It turns out that the ﬁnal equations are even simpler
if we take ˆt instead of r as our new variable. We therefore consider the transformation
u −→ˆt.
Before we start, we calculate the derivatives of Eq. (14.80). The derivative with respect to
t yields ∂u/∂t = [−u+RI(t)]/τm as expected for integrate-and-ﬁre neurons. According to
our assumption, ∂u/∂t > 0 or RI(t) > u (for all neurons in the population). The derivative
with respect to ˆt is
−∂u
∂ˆt = RI(t)−ur
τm
exp

−t −ˆt
τm

= F(t, ˆt) > 0,
(14.81)
where the function F is deﬁned by Eq. (14.81).
The densities in the variable ˆt are denoted as Q(ˆt,t). From Q(ˆt,t)|dˆt| = p(u,t)|du| we
have
Q(ˆt,t) = p[u(t, ˆt),t]F(t, ˆt).
(14.82)
We now want to show that the differential equation for the density Q(ˆt,t) that we derived
in (14.74),
∂
∂t Q(ˆt,t) = −ρ(t|ˆt)Q(ˆt,t),
for ˆt < t ,
(14.83)
is equivalent to the partial differential equation for the membrane potential densities. If we
insert Eq. (14.82) into Eq. (14.83) we ﬁnd
∂p
∂u
∂u
∂t F + ∂p
∂t F + p ∂F
∂t = −ρ pF .
(14.84)
For the linear integrate-and-ﬁre neuron and I(t) = const. we have ∂F/∂t = −F/τm. Fur-
thermore, according to our assumption of monotonously increasing trajectories, we have
F ̸= 0. Thus we can divide (14.84) by F and rewrite Eq. (14.84) in the form
∂p(u,t)
∂t
= −∂
∂u
−u+RI(t)
τm
p(u,t)

−f(u−ϑ) p(u,t),
for ur < u < ϑ ,
(14.85)

386
The integral-equation approach
A
I
A
(a)
(b)
]
]
[
[
[ ]
[
]
[
]
Fig. 14.12 Population of adaptive neurons in response to a step stimulus. The results from quasi-
renewal theory are compared to a direct simulation of 25 000 neurons with parameters optimized for
cortical cells. (a) The solution of the integral equation Eqs. (14.86) and (14.96) for the population
activity (thin black line) is overlaid on the population activity calculated by simulating 25 000 SRM
neurons with parameters capturing properties of cortical cells (see Chapter 11). The dotted line,
which gives the solution of the integral equation of non-adapting neurons (time-dependent renewal
theory, Eq. (14.5)), indicates that adaptation makes a major contribution to the observed population
activity. (b) Comparing adapted activity A∞from simulations (squares, error bars correspond to one
standard deviation) to predictions from renewal (dotted line) and quasi-renewal (black line) theory.
Modiﬁed from Naud and Gerstner (2012a).
where we have used the deﬁnition of the hazard via the escape function ρ(t|ˆt) = f[u(t, ˆt)−
ϑ] and the deﬁnition of the reset potential ur = η0. If we compare Eq. (14.85) with the
Fokker-Planck equation (13.16), we see that the main difference is the treatment of the
noise. For noise-free integrate-and-ﬁre neurons (i.e., ρ(t|ˆt) = 0 for u ̸= ϑ) the equation
(13.16) for the membrane potential densities is therefore equivalent to the density equation
∂Q(ˆt,t)/∂t = 0; see Eq. (14.83).
14.5 Adaptation in population equations
The integral equations presented so far apply only to neurons whose state does not depend
on the spiking history, except on the most recent spike. Cortical neurons, however, show
pronounced adaptation, as discussed in Chapter 11. Since time-dependent renewal theory
cannot account for adaptation, the predicted population activity does not match the one
observed in simulations; see Fig. 14.12.
As indicated in Eq. (14.12), the intuitions that have led to the integral equation (14.5) of
time-dependent renewal theory, are still applicable, but the interval distribution must take
into account the past history.
Let PI,A(t|ˆt) be, again, the probability of observing a spike at time t given the last spike at
time ˆt, the input current and the activity history A(t) until time t; then the integral equation

14.5 Adaptation in population equations
387
for adapting neurons is Eq. (14.12), which we recall here for convenience
A(t) =
 t
−∞PI,A(t|ˆt)A(ˆt)dˆt.
(14.86)
In this section, we develop the methods necessary to describe adapting neuron populations.
First we present the systematic derivation of the integral equation Eq. (14.86). Then, in Sec-
tion 14.5.2 we describe the event-based moment expansion which provides a framework
for approximating PI,A(t|ˆt).
14.5.1 Quasi-renewal theory (*)
Chapter 12 discussed the concept of a homogeneous population. We have seen that the
activity of a homogeneous population of uncorrelated neurons can be seen as an average
of the spike trains across the population, A(t) = ⟨S(t)⟩N where the subscript N denotes an
average across the N neurons. Because neurons are stochastic, all neurons have different
spiking histories. Accordingly, an average over a population is equivalent to an average
over all possible past spike trains,
A(t) = ⟨ρ(t|S)⟩S,
(14.87)
where ρ(t|S) is the hazard (or instantaneous ﬁring rate) at time t given the previous spikes
in the spike-train S(t) and the average ⟨·⟩S is over all spike-train histories. In other words,
A(t) can be calculated as the expected activity averaged over all possible spike train histo-
ries, whereas ρ(t|S) gives the stochastic intensity of generating a spike around time t given
the speciﬁc history summarized by the past spike train S (Naud and Gerstner, 2012a).
The spike train S consists of a series of spikes ˆt1, ˆt2, ... , ˆtn. To average over all possible
spike trains requires that we consider spike trains made of n = 0 to ∞spikes. Moreover, for
a given number n of spikes, all possible time sequences of the n spikes must be considered.
This average takes the form of a path integral (Feynman et al., 2010) where the path here
is the spike trains. Therefore, the average in Eq. (14.87) is
A(t) =
∞
∑
n=0
 t
−∞
 ˆt1
−∞...
 ˆtn−1
−∞ρ(t|ˆt1, ˆt2,..., ˆtn)P(ˆt1, ˆt2,...)dˆtn...dˆt1.
(14.88)
We emphasize that in Eq. (14.88) the spikes are ordered counting backward in time; there-
fore ˆt1 is the most recent spike so that t > ˆt1 > ˆt2 > ··· > ˆtn.
Each spike train can occur with a probability entirely deﬁned by the hazard function
P(ˆt1, ˆt2,..., ˆtn) =

∏
ˆti∈Sn
ρ(ˆti|Sn)

e−
 t
−∞ρ(x|Sn)dx.
(14.89)
The equality follows from the product of two probabilities: the probabilities of observ-
ing the spikes at the times ˆt given the rest of the history (the hazard function) and the
probability of not spiking between each of the spikes (the survivor function). Again, it

388
The integral-equation approach
is a generalization of the quantities seen in Chapters 7 and 9. Writing the complete path
integral, we have
A(t) =ρ(t)e−
 t
−∞ρ(x)dx +
∞
∑
n=1
 t
−∞
 ˆt1
−∞...
 ˆtn−1
−∞

e−
 t
ˆt1 ρ(x|ˆt1,...,ˆtn)dxρ(t|ˆt1,..., ˆtn)

×ρ(ˆt1|ˆt2,..., ˆtn)ρ(ˆt2|ˆt3,..., ˆtn)...ρ(ˆtn)e
−
 ˆt1
ˆt2 ρ(x|ˆt2,...,ˆtn)dx−...−
 ˆtn
−∞ρ(x)dxdˆtn...dˆt2dˆt1.
(14.90)
The case with zero spikes in the past (the ﬁrst term on the right-hand-side of Eq. (14.90))
can be neglected, because we can always formally assign a ﬁring time at ˆt = −∞to neurons
that have not ﬁred in the recent past. We now focus on the factor enclosed in square brackets
on the right-hand side of Eq. (14.90). This factor resembles PI(t|ˆt). In fact, if, for a moment,
we made a renewal assumption, the most recent spike were the only one that mattered. This
would imply that we could set ρ(t|ˆt1,..., ˆtn) = ρ(t|ˆt) inside the square brackets (where
ˆt = ˆt1 is the most recent spike) and shift the factor enclosed by square brackets in front of
the n−1 integral over ˆt2, ˆt3,..., ˆtn. In this case, the factor in square brackets would become
exactly PI(t|ˆt). The remaining integrals over the n −1 variables can be recognized as the
average of ρ(ˆt1|S) over the possible histories, i.e., A(ˆt1). Therefore the renewal assumption
leads back to Eq. (14.5), as it should.
In quasi-renewal theory, instead of assuming ρ(t|S) = ρ(t|ˆt1) we assume that
⟨ρ(t|S)⟩≈⟨ρ(t|ˆt1,S′)⟩S′,
(14.91)
where S′ is made of all the spikes in S but ˆt1. This assumption is reasonable given the
following two observations in real neurons. First, the strong effect of the most recent spike
needs to be considered explicitly. Second, the rest of the spiking history only introduces a
self-inhibition that is similar for all neurons in the population and that depends only on the
expected distribution of spikes in the past (Naud and Gerstner, 2012a). The approximation
(14.91) is not appropriate for intrinsically bursting neurons, but should apply well to other
cell types (fast-spiking, non-fast-spiking, adapting, delayed, ...). If we insert Eq. (14.91)
into the terms inside the square brackets of Eq. (14.90), we can deﬁne the interspike interval
distribution
PI,A(t|ˆt) = ⟨ρ(t|ˆt,S′)⟩S′ exp

−
 t
ˆt ⟨ρ(x|ˆt,S′)⟩S′dx

,
(14.92)
such that Eq. (14.90) becomes Eq. (14.86).
14.5.2 Event-based moment expansion (*)
The development in the previous subsection is general and does not rely on a speciﬁc neu-
ron model nor on a speciﬁc noise model. In this section, we now introduce approximation
methods that are valid for the broad class of Generalized Linear Models of spiking neurons
with exponential escape noise, for example the Spike Response Model (see Chapter 9).
The aim is to ﬁnd theoretical expressions for PI,A(t|ˆt) according to quasi-renewal theory

14.5 Adaptation in population equations
389
(Eq. (14.92)). In particular we need to evaluate the average of the likelihood over the past
history ⟨ρ(t|ˆt1,S′)⟩S′.
We recall the SRM model with exponential escape noise (Chapter 9). The instantaneous
stochastic intensity at time t, given the spike history, is
ρ(t|S) = ρ exp
!
h(t)+ ∑
ˆtk∈S
η(t −ˆtk)
"
= ρeh(t)+[η∗S](t).
(14.93)
Here, h(t) =
 ∞
0 κ(s)I(t −s)ds is the input potential, η(s) describes the spike-afterpotential
introduced by each spike and u(t) = h(t)+∑ˆtk∈S η(t −ˆtk) is the total membrane potential.
The standard formulation of exponential escape noise, ρ(t) = f(u(t)−ϑ) = ρ0 exp[β (u(t)−
ϑ)], contains two extra parameters (ϑ for the threshold and 1/β for the noise level), but
we can rescale the voltage and rate units so as to include the parameters β and ϑ in the
deﬁnition of u and ρ, respectively. The time course of η and κ and the parameter ¯ρ can be
optimized so as to describe the ﬁring behavior of cortical neurons; see Chapter 11.
In the model deﬁned by Eq. (14.93), all the history dependence is contained in a fac-
tor, eη∗S, which can be factorized into the contribution from the last spike and that of all
previous spikes,
⟨ρ(t|I, ˆt,S′)⟩S′ = ρeh(t)+η(t−ˆt)⟨e[η∗S′](t)⟩S′.
(14.94)
In order to evaluate the expected values on the right-hand side of Eq. (14.92), we need to
calculate the quantity MS[η] = ⟨eη∗S⟩S.
MS is called a moment-generating functional because the functional derivative with
respect to η(t) and evaluated at η(t) = 0 yields the moments of S: δMS
δη [η = 0] = ⟨S(t)⟩,
δ 2MS
δη2 [η = 0] = ⟨S(t)S(t′)⟩, ... . Explicit formulas for the moment-generating functional are
known (van Kampen, 1992). One of the expansion schemes unfolds in terms of the corre-
lation functions gk(t1,t2,...,tk) and provides a useful framework for the approximation of
our functional at hand.
We have already seen two examples of such correlation functions in various chapters of
the book. The ﬁrst term is simply the population activity g1(t1) = ⟨S(t1)⟩= A(t1), i.e., the
expectation value or "mean" of the spike count in a short interval Δt →0. The second term
in the expansion scheme is the second-order correlation function which we encountered
in Chapter 7 in the context of autocorrelation and the noise spectrum. There, the quantity
C0
ii(s) is the stationary version of the slightly more general time-dependent correlation term
g2(t1,t2) = ⟨S(t1)S(t2)⟩−⟨S(t1)⟩⟨S(t2)⟩. Higher orders would follow the same pattern (van
Kampen, 1992), but they will play no role in what follows.
Using the moment expansion, the expected value in Eq. (14.94) becomes
⟨e[η∗S′](t)⟩S′ = exp
!
∞
∑
m=1
1
m!
 ˆt
−∞

eη(t−s1) −1
	
...

eη(t−sm) −1
	
gm(s1,...,sm)ds1...dsm
"
.
(14.95)
We call the expansion the event-based moment expansion. As a physical rule of thumb, the

390
The integral-equation approach
contribution of terms m ≥2 in Eq. (14.95) decreases rapidly with increasing m, whenever
the events (i.e., spike times at times t and t′) are weakly coupled. For the purpose of Eq.
(14.92), we can effectively ignore all second- and higher-order correlations and keep only
the term with m = 1. This gives
⟨ρ(t|ˆt,S′)⟩S′ = ρeh(t)+η(t−ˆt)+
 ˆt
−∞(eη(t−z)−1)A(z)dz.
(14.96)
Eq. (14.96) can be used as an excellent approximation in the survivor function as well as
in the formula for the interval distribution PI,A(t|ˆt) in Eq. (14.92). Used within the integral
equation (14.12) it gives an implicit description of the population activity for inﬁnite an
population of adapting neurons.
14.6 Heterogeneity and ﬁnite size
Neuronal populations in biology are neither completely homogeneous nor inﬁnitely large.
In order to treat heterogeneity in local neuronal parameters, the variability of a parameter
between one neuron and the next is often replaced by slow noise in the parameters. For
example, a population of integrate-and-ﬁre neurons where the reset value ur is different
for each neuron is replaced by a population where the reset values are randomly chosen
after each ﬁring (and not only once at the beginning). Such a model of slow noise in
the parameters has been discussed in the example of Section 14.3. The replacement of
heterogeneity by slow noise neglects, however, correlations that would be present in a
truly heterogeneous model. To replace a heterogeneous model by a noisy version of a
homogeneous model is somewhat ad hoc, but common practice in the literature.
The second question is whether we relax the condition of a large network. For N →∞
the population activity shows no ﬂuctuations and this fact has been used for the deriva-
tion of the population equation. For systems of ﬁnite size ﬂuctuations are important since
they limit the amount of information that can be transmitted by the population activ-
ity. For a population without internal coupling (J0 = 0), ﬂuctuations can be calculated
directly from the interval distribution PI(t |ˆt) if the population consists of neurons that can
be described by renewal theory; see Chapter 9. For networks with recurrent connections,
several attempts toward a description of the ﬂuctuations have been made (Spiridon et al.,
1998; Meyer and van Vreeswijk, 2002; Lindner et al., 2005). Here we present a different
approach.
If we consider a network with a ﬁnite number N of neurons, the integral equation
(14.5), which describes the evolution of the population activity A(t) in terms of the input-
dependent interval distribution PI(t|ˆt), should be written more carefully with expectation
signs,
⟨A(t)⟩=
 t
−∞PI(t|ˆt)A(ˆt)dˆt
(14.97)
so as to emphasize that the left-hand side is the expected population activity at time t, given
the observed population activity at earlier times ˆt. In other words N ⟨A(t)⟩Δt = N⟨m0(t)⟩is

14.6 Heterogeneity and ﬁnite size
391
the expected number of spikes to occur in a short interval Δt. Here we have deﬁned m0(t)
as the fraction of neurons that ﬁre in a time step Δt, just as in Section 14.1.5. Given the
past input for t′ < t (which is the same for all the N neurons in the group), the ﬁring of
the neurons is independent in the next time step ("conditional independence"). Therefore
in the limit of N →∞the observed variable m0(t) approaches ⟨m0(t)⟩and we can drop the
expectation signs.
For ﬁnite N, the variable m0(t) ﬂuctuates around ⟨m0(t)⟩. To determine these ﬂuctua-
tions, we assume that N is large, but ﬁnite. For ﬁnite N the population activity A(t) can be
written in the form of a "noisy" integral equation
A(t) = ⟨A(t)⟩+σ(t)ξ(t) =
 t
−∞ρnoise(t|ˆt)Snoise
I
(t|ˆt)A(ˆt)dˆt,
(14.98)
where ξ(t) is a Gaussian colored noise, A(ˆt) is the observed activity in the past, Snoise
I
(t|ˆt)
is the fraction of neurons that have survived up to time t after a last spike at time ˆt, and
ρ(t|ˆt)noise is the stochastic intensity of that group of neurons. Starting from discrete time
steps, and then taking the continuum limit, it is possible to determine the amplitude of the
ﬂuctuations as σ(t) =

⟨A(t)⟩/N. Equation (14.98) can be used to evaluate the correla-
tions ⟨A(t)A(t′)⟩, in coupled networks of ﬁnite size (Deger et al., 2013).
14.6.1 Finite number of neurons (*)
For the development of the arguments, it is convenient to work in discrete time. We use
the formalism developed in Section 14.1.5. We introduce the variable mN
k (t) = N m(t)
k
to
denote the number of neurons that have ﬁred in the interval [t −kΔt,t −(k −1)Δt] and
have "survived" up to time t without ﬁring again. With this deﬁnition, mN
0 (t) = N A(t)Δt
denotes the number of neurons that ﬁre in the time step from t to t +Δt.
We start with the normalization condition in the quasi-renewal equivalent of Eq. (14.8)
and multiply both sides by the number of neurons
N =
 t
−∞SI,A(t|ˆt)N A(ˆt)dˆt.
(14.99)
This normalization must hold at any moment in time, therefore
mN
0 (t) = N −
K
∑
k=1
mN
k (t),
(14.100)
where K is chosen big enough so that all neurons have ﬁred at least once in the last K time
bins.
In order to determine the value of mN
k (t) for k ≥2, we focus on the group of neurons that
has ﬁred at time ˆt ≈t −(k −1)Δt. The number of neurons that have "survived" up to time
t −Δt without emitting a further spike is mN
k−1(t −Δt). In the time step starting at time t,
all of these neurons have the same stochastic intensity ρ(t|ˆt) and ﬁre independently with
probability pF(t|ˆt) = 1 −exp[−ρ(t|ˆt)Δt]. In a ﬁnite-N discrete-time update scheme, the

392
The integral-equation approach
actual number of neurons nk(t) of neurons that ﬁre in time step t is therefore drawn from
the binomial distribution
P(nk) =
!
[mN
k−1(t −Δt)]!
[nk]![mN
k−1(t −Δt)−nk]!
"
[pF(t|ˆt)]nk [1−pF(t|ˆt)]mN
k−1(t−Δt)−nk.
(14.101)
In the time step starting at time t, the number of neurons that have last ﬁred at ˆt is therefore
(for k ≥2)
mN
k (t) = mN
k−1(t −Δt)−nk(t).
(14.102)
Because of the shifting time frame used for the index k, neurons that are at time t −Δt in
group (k−1) will be at time t in group k, except those that ﬁred in the previous time step -
and this is expressed in Eq. (14.102). Note that mN
k (t) is the actual number of neurons
remaining in the group of neurons that ﬁred the last spike at ˆt. Its expected value is
⟨mN
k (t)⟩= mN
k−1(t −Δt) exp[−ρ(t|t −kΔt)Δt]
for k > 1
(14.103)
as already discussed in Eq. (14.16). In the limit N →∞, the actual value will approach the
expectation value, but for ﬁnite N the actual value ﬂuctuates. The ﬁnite-N update scheme
in discrete time is given by the iteration of Eqs. (14.102) and (14.100).
To arrive at an equation in continuous time, two further steps are needed. First, the
binomial distribution in Eq. (14.101) is approximated by a Gaussian distribution with the
same mean and variance. Second, we take the limit of Δt to zero and keep track of terms
to order 1/N but not 1/N2,1/N3,.... The result is Eq. (14.98). Note that for an uncoupled
network of N neurons in the stationary case, ﬂuctuations can also be directly calculated
from the interval distribution as discussed in Chapter 7. The advantage of the approach
presented here is that it works also for coupled networks.
14.7 Summary
Relating the microscopic level of single neurons to the macroscopic level of neuronal popu-
lations, the integral equation approach offers an interpretation of neuronal activity in terms
of the interspike interval distribution. The integral approach can be related to partial dif-
ferential equations. The formulation of partial differential equations with refractory den-
sities exhibits a close formal relation with the membrane potential density equations of
Chapter 13. In a direct comparison of the two theories, the ﬁrst one developed in Chap-
ter 13, the second here, it turns out that the integral equation approach is particularly useful
in modeling populations of neurons that have multiple intrinsic time scales in refractori-
ness, synapses, or adaptation and escape noise as the model of stochasticity.
Population equations can be formulated for several coupled populations. At the steady
state, the population can be in a state of asynchronous and irregular ﬁring, but the stability
of these solutions against emergence of oscillations needs to be checked. Stability can be
analyzed using the linearization of the integral equations around a stationary state.

14.7 Summary
393
Heterogeneity in the population can be treated as slow noise in the parameters and ﬁnite
size effects can be analyzed and included in the numerical integration scheme.
Literature
The original paper of Wilson and Cowan (1972) can be recommended as the classical ref-
erence for population equations. The paper contains the integral equation for neurons with
absolute refractoriness as well as, in the appendix, the case of relative refractoriness. Note,
however, that the paper is most often cited for a differential equation for an "ad hoc" rate
model that does not correctly reﬂect the dynamics of neurons with absolute refractoriness.
It is worth while also consulting the papers of Knight (1972) and Amari (1972) that each
take a somewhat different approach toward a derivation of population activity equations.
The presentation of the integral equations for time-dependent renewal theory (Eqs. (14.5)
and (14.8)) in this chapter follows the general arguments developed in Gerstner (1995,
2000) emphasizing that the equations do not rely on any speciﬁc noise model. The same
integral equations can also be found in the appendix of Wilson and Cowan (1972) as an
approximation to a model with heterogeneity in the ﬁring thresholds and have been derived
by integration of the partial differential equations for refractory densities with escape noise
in Gerstner and van Hemmen (1992). The integral approach for adaptive neurons and the
approximation scheme based on the moment-generating function were introduced in Naud
and Gerstner (2012a).
The linearization of the integral equation can be found in Gerstner (2000) and Gerstner
and van Hemmen (1993). The model of slow noise in the parameters is taken from Gerstner
(2000). The escape noise model - which turns out to be particularly convenient for the
integral equation approach - is intimately linked to the noise model of Generalized Linear
Models, as discussed in Chapter 9, where references to the literature are given.
Exercises
1. Integral equation of neurons with absolute refractory period
(a) Apply the population equation (14.5) to SRM neurons with escape noise which have an abso-
lute refractory period
η(t) =

−∞
if
t < Δabs
0
otherwise.
(14.104)
(b) Introduce the normalization condition Eq. (14.8) so as to arrive at the Wilson-Cowan integral
equation (14.10).
(c) Use Eq. (14.8) to show that the mean interspike interval of neurons ﬁring stochastically with
a rate f(h0) is
A−1
0
= Δabs + f(h0)−1,
(14.105)
where h0 is a constant input potential.

394
The integral-equation approach
2. Gain function of SRM neurons. Consider SRM neurons with escape noise such that the hazard
function is given by ρ(s) = ρeh+η(s) with η(s) = ln

1−e−s/τ
.
(a) Show that the survivor function in the asynchronous state is
S0(t) = exp

−rt
τ +r(1−e−t/τ)
	
,
(14.106)
where r = τρeh.
(b) Using your results in (a), ﬁnd the gain function A0 = g(h0) for neurons.
Hint: Remember that the mean ﬁring rate for ﬁxed h0 is the inverse of the mean interval. You will
have to use the lower incomplete gamma function γ(a,x) =
 x
0 ta−1e−tdt.
(c) Suppose that you have SRM0 neurons with an absolute and a relative refractory period as in
Eq. (14.29). Calculate A0 using your result from (b) and compare with Eq. (14.30).
3. Linearization of the Wilson-Cowan integral equation. The aim is to ﬁnd the frequency-
dependent gain ˆG(ω) for a population of neurons with absolute refractoriness.
(a) Start from the Wilson-Cowan integral equation and linearize around a stationary state A0.
(b) Start with the ﬁlter in Eq. (14.60) and derive directly the ﬁlter ˆG.
4. Slow noise in the parameters. Consider a population of leaky integrate-and-ﬁre neurons with
time constant τm and resistance R, driven by a constant superthreshold input I0. After each ﬁring,
the membrane potential is reset to ur, which is chosen randomly from a distribution P(ur) with
mean ⟨ur⟩.
(a) Calculate the interspike interval T0 for a neuron i which was reset at time t0 to a value
ui(t0) = ⟨ur⟩and that of another neuron j which was reset at t0 to uj(t0) = ⟨ur⟩+Δu.
(b) Suppose a Gaussian distribution of reset values with standard deviation σr. Show that the
standard deviation σISI of the interval distribution is σISI = σr/ ˙u(T0) where ˙u(T0) is the derivative
of the membrane potential at the moment of threshold crossing.
5. Linear response ﬁlter with step-function escape rate. Consider f(u) = ρ Θ(u−ϑ), i.e., a step-
function escape rate. For ρ →∞neurons ﬁre immediately as soon as u(t) > ϑ and we are back to
a noise-free sharp threshold. For ﬁnite ρ, neurons respond stochastically with time constant ρ−1.
The neuron mode is an SRM0 with arbitrary refractoriness η(t −ˆt) driven by a constant input
h0 and a time-dependent component h1(t). The total membrane potential at time t is u(t) =
η(t −ˆt)+h0 +h1(t) where h1(t) =
 ∞
0 exp(−s/τm)I1(t −s)ds.
(i) Show that the kernel L (x) for neurons with step-function escape rate is an exponential func-
tion.
Hint: Denote by T0 the time between the last ﬁring time ˆt and the formal threshold crossing, T0 =
min{s|η(s)+h0 = ϑ}. The derivative of f is a δ-function in time. Use a short-hand notation
η′ = dη(s)
ds |s=T0 and exploit Eq. (14.58).
(ii) Calculate the linear ﬁlter G(s) and the response to an input current I1(t).

15
Fast transients and rate models
The mathematical formalism necessary for a correct description of the population activity
A(t) in homogeneous networks of neurons is relatively involved - as we have seen in Chap-
ters 13 and 14. However, the population activity A0 in a stationary state of asynchronous
ﬁring can simply be predicted by the neuronal gain function gσ(I) of isolated neurons; see
Chapter 12. It is therefore tempting to extend the results that are valid in the stationary state
to the case of time-dependent input. Let us write
A(t) = F(h(t)),
(15.1)
where F is the gain function expressed with the input potential h(t) as an argument, as
opposed to input current. We choose a different symbol, because the units of the argument
are different, but the relation of F(h) to the normal frequency-current curve is simply
F(h) = gσ(h/R) where gσ(I0) is the single-neuron gain function for constant input I0 at
some noise level σ and R the membrane resistance.
The input potential h in the argument on the right-hand side of Eq. (15.1) is the contri-
bution to the membrane potential that is caused by the input
h(t) = R
τm
 ∞
0 e−s
τm I(t −s)ds,
(15.2)
where τm is the membrane time constant. Eq. (15.2) can also be written in the form of a
differential equation
τm
dh(t)
dt
= −h+RI(t).
(15.3)
Integration of Eq. (15.3) with initial conditions h(−∞) = 0 in the far past leads back to Eq.
(15.2) so that the two formulations are equivalent.
By construction, Eqs. (15.1) and (15.2) predict the correct population activity for a con-
stant mean input I0. From Eq. (15.2) we have h0 = RI0 so that Eq. (15.1) yields the sta-
tionary activity A0 = F(h0) = gσ(I0), as it should.
The question arises whether the rate model deﬁned by Eqs. (15.1) and (15.2) (or, equiv-
alently, by Eqs. (15.1) and (15.3)) is also a valid description for time-dependent stimuli.
In other words, we ask whether the stationary solution of the population activity can be

396
Fast transients and rate models
(a)
0
200
400
600
800
1000
Neuron #
0
50
100
150
200
250
t [ms]
0
5
10
15
20
25
30
A [Hz]
t ON=100ms 
(b)
Fig. 15.1 Transients and rate models. All neurons receive the same step current stimulus at time
tON = 100 ms. A randomly connected network of 8000 excitatory and 2000 inhibitory neurons
exhibits an abrupt response to the change in the input. (a) The spike trains of 1000 excitatory neurons
are shown. Vertical bands of greater spike density are short periods of high activity as shown in the
population activity A to the right. Scale bars are 200 ms and 10 Hz. (b) The population activity A(t)
exhibits fast transients (full line). In a Standard Rate Model with population activity A(t) = F(h(t)),
the new stationary state is approached on the time scale deﬁned by the membrane time constant τm
(here τm = 4 ms, dotted line). The response to the input switch at t0 = 200 ms is therefore compara-
tively slow.
extended to a "quasi-stationary" rate model of the population activity. To answer this ques-
tion we focus in this chapter on the special case of step stimuli. Strong step stimuli cause a
transient response, which can be abrupt in networks of spiking neurons (Fig. 15.1a), but is
systematically smooth and slow in the rate model deﬁned above (Fig. 15.1b).
Therefore the question arises whether the "normal" case for neurons in vivo is that of an
abrupt and fast response (which would be absent in the rate model), or that of a smooth and
slow response as predicted by the rate model. To answer this question, we start in Section
15.1 by taking a closer look at experimental data.
In Section 15.2 we use modeling approaches to give an answer to the question of whether
the response to a step stimulus is fast or slow. As we shall see, the response of generalized
integrate-and-ﬁre models to a step input can be rapid, if the step is either strong and the
noise level is low or if the noise is slow, i.e., not white. However, if the noise is white
and the noise level is high, the response to the step input is slow. In this case the rate
model deﬁned above in Eqs. (15.1) and (15.2) provides an excellent approximation to the
population dynamics.

15.1 How fast are population responses?
397
L2/3
L4
L5
L6
(a)
L2/3
L5
L6
L4
(b)
Fig. 15.2 Response of auditory neurons across different layers to short stimuli. (a) Left: Schematic
drawing of an electrode with 32 sites overlayed on top of stained cortical tissue in order to show that
the electrode crosses all cortical layers. Right: Spike responses of multiple neurons to a short click
stimulus (solid arrows) and during spontaneous activity (open arrows). Horizontal scale bar: 500 ms.
(b) Responses to a tone sustained during the shaded period. Solid circles indicate estimated peak
of response. Scale bar: 50 ms. Neuron recordings in (a) and (b) are from primary auditory cortex.
Figures adapted from Sakata and Harris (2009) with permission from Elsevier.
Finally, in Section 15.3, we discuss several variants of rate models. We emphasize that
all of the rate models discussed in this section are intended to describe the response of a
population of neurons to a changing input - as opposed to rate models for single neurons.
However, it is also possible to reinterpret a population model as a rate model of a single
stochastically ﬁring neuron. Indeed, the single-neuron PSTH accumulated over 200 repe-
titions of the same time-dependent stimulus is identical to the population activity of 200
neurons in a single trial.
15.1 How fast are population responses?
Simultaneous measurements from many neurons in vivo with spike-time resolution are
difﬁcult. Fig. 15.2 shows two examples of simultaneous recordings across different layers
in the primary auditory cortex. Each of the 32 recording sites is able to pick up activity of
several neurons (Fig. 15.2a). The group of recorded neurons in layer 4 responds to a short
tone stimulus with a delay of about 15 ms (Fig. 15.2b); the neurons in other layers follow
shortly thereafter. Based on several such experiments, we may conclude that population
activity in layer 4 exhibits an initial sharp peak less than 20 ms after stimulus onset (Sakata
and Harris, 2009). Unfortunately, the number of neurons that are recorded simultaneously
in one layer is limited so that an interpretation in terms of population activity is difﬁcult;
nevertheless, the data suggests that transients can be fast and reliable on the time scale of
10 ms.

398
Fast transients and rate models
0.5
1.0
-50
50
0
t [ms]
Scaled firing rate
0.0
0
200
f [Hz]
100
0
0
40
f [Hz]
t [ms]
t [ms]
0
100
Fig. 15.3 Transient response of neurons in the visual cortex. At t = 0 a high-contrast grating is
ﬂashed on a gray screen. Top left: A neuron in visual cortex V1 of a behaving monkey responds with
a sharp onset after a latency of 27 ms, as shown by the PSTH. Bottom left: Another neuron in V1
responds after a latency of 99 ms. Right: PSTHs of 73 neurons in V1 (solid line) and of 183 neurons
in V4 (dashed line) were normalized to an amplitude of 1.0 and onsets were aligned at half the peak
value (horizontal and vertical solid lines) and ﬁnally averaged. The rise time of the averaged PSTH
is less than 10 ms. After the ﬁrst peak, the ﬁring rate drops off rapidly; adapted from Marsalek et al.
(1997).
Alternatively, one can attempt to study population activity across many experiments with
single-neuron recordings. Neurons in visual cortex V1 and V4 respond reliably to the onset
of spatial gratings (Fig. 15.3), as seen in the PSTH accumulated over several repetitions of
the stimulus presentation (Marsalek et al., 1997). However, different neurons have different
delays. If the PSTHs from many neurons are aligned onto the moment of the sharp rise
of the PSTH response, then the resulting population activity exhibits an extremely sharp
and abrupt onset peak, followed by a rapid decrease (Marsalek et al., 1997). However, if
the responses of different cells were aligned on the moment of stimulus onset, then the
population response would look slower, which is not surprising given that the recordings
do not come from a single homogeneous population.
In an in vitro preparation, the same step current input can be repeatedly given to the
same neuron. In order to mimic additional stochastic spike arrivals that would be present
in vivo, during each repetition a different realization of a noisy current can be added to
the step current. Fig. 15.4 shows the response of pyramidal neurons in cortical layer 2/3
to such noisy step inputs, averaged over 12 different cells. The population activity in Fig.
15.4a exhibits a rapid transient, followed by a strongly damped oscillation (Tchumatchenko
et al., 2011). As we shall see in the following sections, the oscillatory component indicates

15.2 Fast transients vs. slow transients in models
399
300 ms 
A(t)
I(t)
A(t)
[Hz]
8
0
40 ms 
h(t)
(a)
0
10
A [Hz]
2.5Hz
1 ms 
(b)
0.0
0.2
0.4
0.6
0.8
1.0
t[s]
−20
0
20
I [pA]
−
Fig. 15.4 Response of pyramidal cells in vitro to step input. (a) The PSTH response of pyramidal
cells in cortical layers 2 and 3 averaged across 12 cells gives an estimate of the population activity
A(t). The step current (I(t), bottom) generates an input potential h(t) which responds much slower
than the population activity A(t). Right: Zoom into A(t). Vertical dashed line indicates stimulus
onset. Adapted from Tchumatchenko et al. (2011). (b) Experimental data from Tchumatchenko et al.
(2011) are compared with the numerical integration of the integral equations for adaptive neurons
(see Section 14.5). The input current is shown below.
that the noise level of the stochastic input component was chosen fairly low. For low noise,
those neurons that ﬁre together at stimulus onset enter together into a state of refractoriness
and ﬁre again after a time corresponding to the mean interspike interval. We can therefore
conclude that populations of neurons in vitro exhibit, in the regime of low noise, a sharp
transient, indicating a very fast response to step current input.
The theory of population activity (Fig. 15.4b) enables us to understand the responses
found in the experiments, as we shall see in the next section.
15.2 Fast transients vs. slow transients in models
Populations of model neurons can exhibit fast abrupt responses or slow responses to a step
current input. To predict whether the response is fast or slow, knowledge of the type and
magnitude of noise turns out to be more critical than the details of the neuron model.

400
Fast transients and rate models
0.0
0.2
0.4
A [kHz] 
(a)
180
200
220
I,h [a.u]
0.0
0.1
0.2
t [ms]
0.0
0.2
A [kHz]
0.4
(b)
180
200
220
I,h [a.u]
0.0
0.1
0.2
t [ms]
Fig. 15.5 The response is rapid for low noise or slow noise. Response of the population activity
(top) to the step current I(t) (bottom) and the input potential h(t) caused by the step at t = 100 ms.
(a) Leaky integrate-and-ﬁre neurons at a very low noise level. Solid line: simulation of a population of
1000 neurons without coupling, all receiving the same step input. Dashed line: numerical integration
of the integral equation (14.5) of time-dependent renewal theory in the low-noise limit; see Chapter
14. (b) Slow noise. Transients for SRM0 neurons with noisy reset in response to the same step
current. The results of a simulation of 1000 SRM0-neurons (solid line) are compared with a numerical
integration (dashed line) of the integral equation; see Eq. (14.5). The instantaneous response is typical
for "slow" noise models. Bottom: Step current input I (solid line) and input potential h(t) (dashed
line). Note that the population responds instantaneously to the input switch at t0 = 100 ms even
though the membrane potential responds only slowly; taken from Gerstner (2000).
15.2.1 Fast transients for low noise or "slow" noise
A homogeneous population of independent leaky integrate-and-ﬁre neurons with a low
level of noise exhibits a sharp transient after the onset of a step current as shown in Fig.
15.5a. The onset transiently synchronizes a subgroup of neurons. Since all the neurons
are of the same type and have the same parameters, the synchronized subgroup ﬁres again
some time later, such that the population activity oscillates with a period corresponding to
the interspike interval of single neurons.
The oscillation is suppressed, and neurons desynchronize, if the population is heteroge-
neous or, for a homogeneous population, if neurons have slow noise in the parameters (Fig.
15.5b). The abrupt onset, however, remains, so that the transient after a switch in the input
is extremely fast.
We can conclude that fast transients occur in a population of leaky integrate-and-ﬁre
neurons:
(i) at a low noise level and strong step current stimulation;
(ii) at a high level of "slow" noise, for example, slow variations in the parameters of the
neurons or heterogeneity across the group of neurons.

15.2 Fast transients vs. slow transients in models
401
In the ﬁrst case, the onset triggers oscillations, while in the second case the oscillations
are suppressed. The rapid transients in spiking models without noise or with slow noise
have been reported by several researchers (Knight, 1972; Gerstner, 2000; Brunel et al.,
2001; Moreno-Bote and Parga, 2004).
Note that the time course of the response in the simulations with slow noise in Fig. 15.5b
is reminiscent of the neuronal responses measured in the visual cortex; see Fig. 15.3. In
particular, we ﬁnd in the simulations that the rapid onset is followed by a decay of the
activity immediately thereafter. This indicates that the decay of the activity is due to the
reset or, more generally, to refractoriness after ﬁring, and not due to adaptation or input
from inhibitory neurons.
Whereas the low-noise result is independent of the speciﬁc noise model, the results for
high noise depend on the characteristics of the noise. We analyze in Sections 15.2.2 and
15.2.3 the response to step currents for two different noise models. We start with escape
noise and turn thereafter to diffusive noise. Before we do so, let us discuss a concrete
example of slow noise.
Example: Fast transients with noise in parameters
We consider a population of SRM0 neurons with noise in the duration of the absolute
refractoriness. The membrane potential is u(t) = ηr(t −ˆt)+h(t) where h(t) is the input
potential and
ηr(s) =
 −c
for
0 < s ≤Δabs +r
η0(s−Δabs −r)
for
s > Δabs +r.
The constant c is large enough to prevent ﬁring during absolute refractoriness. After
each spike the reset variable r is chosen independently from a Gaussian distribution
Gσ(r) with variance σr ≪Δabs. This is an example of a "slow" noise model, because a
new value of the stochastic variable r is chosen only once per interspike interval. The
approach of the neuron to the threshold is noise-free.
A neuron which was reset at time ˆt with a value r ﬁres again after an interval T(ˆt,r)
which is deﬁned by the next threshold crossing u(t) = ϑ. The interval distribution of the
noisy reset model is
PI(t|ˆt) =
 ∞
−∞drδ[t −ˆt −T(ˆt,r)]Gσ(r).
(15.4)
The population equation (14.5) from Chapter 14 is thus
A(t) =
 t
−∞dˆt
 ∞
−∞drδ[t −ˆt −T(ˆt,r)]Gσ(r)A(ˆt).
(15.5)
A neuron that has been reset at time ˆt with value r behaves identically to a noise-free
neuron that has ﬁred its last spike at ˆt + r. In particular we have the relation T(ˆt,r) =
r+T0(ˆt +r) where T0(t′) is the next interspike interval of a noiseless neuron (r = 0) that

402
Fast transients and rate models
has ﬁred its last spike at t′. The integration over ˆt in Eq. (15.5) can therefore be done and
yields
A(t) =

1+ h′
η′
  ∞
−∞drGσ(r)A[t −Tb(t)−r],
(15.6)
where Tb(t) is the backward interval, i.e., the distance to the previous spike for a noise-
less neuron (r = 0) that ﬁres at time t. The factor [1+(h′/η′)] arises due to the integra-
tion over the δ-function. We use the short-hand h′ for the derivative dh(t)/dt and η′ for
dη0(T(ˆt,0))/dt. We remind the reader that the interval T(ˆt,r) is deﬁned by the thresh-
old condition u(t) = ϑ which gives, more explicitly, ηr(T(ˆt,r))+h(ˆt +T(ˆt,r)) = ϑ (see
Exercises).
We can interpret Eq. (15.6) as follows.
(i) The activity at time t is proportional to the activity A(t −Tb(t)) one interspike
interval earlier.
(ii) Compared to A(t −Tb(t)), the activity is smoother, because interspike intervals
vary across different neurons in the population, which gives rise to an integration over
the Gaussian Gσ.
(iii) Most importantly, compared to the activity A(t −Tb(t)) one interspike interval
earlier, the activity at time t is increased by a factor [1+ h′
η′ ]. This factor is proportional
to the derivative of the input potential as opposed to the potential itself. As we can
see from Eq. (15.3), the derivative of h is discontinuous at the moment when the step
current switches. Therefore, the response of the population activity A(t) to a step current
is instantaneous and exhibits an abrupt change, as conﬁrmed by the simulation of Fig.
15.5b. We emphasize that the mathematical arguments that lead to Eq. (15.6) require
neither an assumption of small input steps nor a linearization of the population dynamics,
but are applicable to arbitrary time-dependent and strong inputs.
15.2.2 Populations of neurons with escape noise
For neurons with escape noise, the level of noise determines whether transients are sharp
and fast or smooth and slow. For low noise the response to a step current is fast (Fig. 15.6a)
whereas for a high noise level the response is slow and follows the time course of the
input potential h(t) (Fig. 15.6b). Analogous results hold for a large class of generalized
integrate-and-ﬁre models with escape noise, including SRMs and leaky integrate-and-ﬁre
models (Gerstner, 2000).
To analyze the response to step current inputs, we assume that the step amplitude ΔI
of the input is small so that the population activity A(t) after the step can be considered
as a small perturbation of the asynchronous ﬁring state with activity A0 before the step.
With these assumptions, we can use the linearized population activity equations (14.43)
that were derived in Section 14.3. For the sake of convenience we copy the equation here
ΔA(t) =
 t
−∞P0(t −ˆt)ΔA(ˆt)dˆt +A0
d
dt
 ∞
0 L (x)Δh(t −x)dx.
(15.7)

15.2 Fast transients vs. slow transients in models
403
(a)
80
90
100
110
120
t [ms]
0.0
0.2
0.4
A [kHz]
(b)
80
90
100
110
120
t [ms]
0.0
0.2
0.4
A [kHz]
Fig. 15.6 Escape noise. Response of a network of 1000 SRM0 neurons with exponential escape
noise to step current input. The input is switched at t = 100 ms. Simulations (ﬂuctuating solid line)
are compared to the numerical integration of the integral equation (14.5) (thick dashed line). (a) For
low noise the transition is comparatively sharp. (b) For high noise the response to the change in the
input is smooth and slow.
We recall that P0(t −ˆt) is the interval distribution for constant input I0 before the step;
L (x) is a real-valued function that plays the role of an integral kernel; and
Δh(t) =
 t−t0
0
R
τm
e−s
τm ΔI ds = RΔI

1−exp

−t −t0
τm

for t > t0
(15.8)
is the input potential generated by step input of amplitude ΔI, switched on at time t0.
The ﬁrst term on the right-hand side of Eq. (15.7) describes that perturbations ΔA(ˆt) in
the past (ˆt < t) have an after-effect about one interspike interval later. Thus, if the switch
in the input at time t0 has caused a momentary increase of the population activity A(t), then
the ﬁrst peak in A around t0 can generate a second, slightly broader, peak one interspike
interval later - exactly as seen in the experimental data of Fig. 15.4a. If the second peak is
again prominent, it can cause a further peak one period later, so that the population activity
passes through a phase of transient oscillations; see Fig. 15.6a. The oscillation decays
rapidly, however, if the noise level is high, because a high noise level corresponds to a
broad interspike interval distribution P0(t −ˆt) so that successive peaks are "smeared out."
Thus, the ﬁrst term on the right-hand side of Eq. (15.7) explains the potential "ringing"
of the population activity after a momentary synchronization of neurons around time t0; it
does not, however, predict whether the transient at time t0 is sharp or not.
It is the second term on the right-hand side of Eq. (15.7) which predicts the immediate
response to a change in the input potential Δh. In what follows, we are mainly interested in
the initial phase of the transient, i.e., 0 < t −t0 ≪T where T = 1/A0 is the mean interspike
interval. During the initial phase of the transient, the ﬁrst term on the right-hand side of
Eq. (15.7) does not contribute, since ΔA(ˆt) = 0 for ˆt < t0. Therefore, Eq. (15.7) reduces to
ΔA(t) = A0
d
dt
 t−t0
0
L (s)Δh(t −s)ds,
for t −t0 ≪T .
(15.9)
In the upper bound of the integral we have exploited that Δh =0 for t < t0.

404
Fast transients and rate models
If we want to understand the response of the population to an input current ΔI(t), we
need to know the characteristics of the kernel L (x). The explicit form of the ﬁlter L (x)
has been derived in Section 14.3. Here we summarize the main results that are necessary
to understand the transient response of the population activity to a step current input.
(i) In the low-noise limit, the kernel L (x) can be approximated by a Dirac δ-function.
The dynamics of the population activity ΔA has therefore a term proportional to the
derivative of the input potential; see Eq. (15.9). This result implies a fast response ΔA to
any change in the input. In particular, for step current input, the response in the low-noise
limit is discontinuous at the moment of the step.
(ii) For a large amount of escape noise, the kernel L (x) is broad. This implies that the
dynamics of the population activity is proportional to the input potential h rather than to
its derivative. Therefore the response to a step input is slow and consistent with that of a
rate model, A(t) = F(h(t)).
A summary of the mathematical results for the ﬁlter L (x) is given in Table 15.1. The
formulas for leaky integrate-and-ﬁre models differ slightly from those for SRM0, because
of the different treatment of the reset.
Example: Slow response for large escape noise
To understand how the slow response to a step at time t0 arises, we focus on the right-
hand side of Eq. (15.9) and approximate the kernel L (x) by a small constant c over
the interval 0 < x < 1/c. For t −t0 < 1/c (and as before t −t0 ≪T), the integral then
simpliﬁes to
 ∞
0 L (s)Δh(t −s)ds ≈c
 t
t0 Δh(t′)dt′ ; i.e., a simple integral over the input
potential.
In front of the integral on the right-hand side of Eq. (15.9) we see the temporal
derivate. The derivate undoes the integration so that
ΔA(t) ∝Δh(t).
(15.10)
This implies that the response to a change in the input is as slow as the input potential
and controlled by the membrane time constant.
15.2.3 Populations of neurons with diffusive noise
Simulation results for a population of integrate-and-ﬁre neurons with diffusive noise are
similar to those reported for escape noise. For a small to medium amount of diffusive
noise, the transient is fairly sharp and followed by a damped oscillation (Fig. 15.7a). For
a large amount of noise, the oscillation is suppressed and the response of the population
activity A(t) is slower (Fig. 15.7b).
In the discussion of escape noise in the preceding section, we saw that the response to a

15.2 Fast transients vs. slow transients in models
405
Deﬁnition
L SRM(x) =
−
 ∞
x dξ
∂S(ξ|0)
∂Δh(ξ−x)
L IF(x) =
L SRM(x)+
 x
0 dξ e−ξ/τ ∂S(x|0)
∂Δh(ξ)
No noise
L SRM
0
(x) =
δ(x)/η′
L IF
0 (x) =

δ(x)−δ(x−T0)e−T0/τ
/u′
Escape noise
L SRM(x) =
 ∞
x dξ f ′[u(ξ −x)]S0(ξ)
L IF(x) =
L SRM(x)−S0(x)
 x
0 dξ e−ξ/τ f ′[u(ξ)]
Reset noise
L SRM(x) =
δ(x)/η′
L IF(x) =

δ(x)−Gσ(x−T0)e−T0/τ
/u′
Table 15.1 The kernel L (x) that appears in Eq. (15.7) is given each time for
integrate-and-ﬁre neurons and SRM0 neurons (upper index IF and SRM, respectively).
Top row: The general case ("Deﬁnition"). Second row: Deterministic neuron model
without noise. Third row: Neuron model with escape noise. Bottom: Neuron model with
slow noise in the form of "reset noise," where the value of the reset has a small jitter.
S0(s) is the survivor function in the asynchronous state and Gσ a normalized Gaussian
with width σ. Primes denote derivatives with respect to the argument.
step input is fast if the population activity reﬂects the derivative h′ of the input potential.
To understand when and how the derivative h′ can play a role with diffusive noise, it is
convenient to consider for a moment not a step current input but a current pulse. According
to Eq. (15.3), a current pulse I(t) = qδ(t −t0) which deposits at time t0 a charge q causes
a discontinuous jump of the input potential
Δh(t) =
 0
for
t ≤t0,
Rq/τm
for
t > t0 .
(15.11)
The central idea of the following arguments is shown schematically in Fig. 15.8. Accord-
ing to Eq. (15.11), all membrane potential trajectories jump at time t0 by the amount
Δu = Rq/τm. The distribution of membrane potentials across the different neurons in the
population, just before t0, is described by p(u). The step increase in the membrane poten-
tial kicks all neurons i with membrane potential ui in the range ϑ −Δu < ui < ϑ instanta-
neously across the threshold which generates an activity pulse
ΔA(t0) ∝NF(t0)
N
δ(t −t0),
(15.12)
where NF(t0)/N =
 ϑ
ϑ−Δu p(u)du is the fraction of neurons that ﬁre because of the input

406
Fast transients and rate models
(a)
80
90
100
110
120
t [ms]
0.0
0.2
0.4
A [kHz]
(b)
80
90
100
110
120
t [ms]
0.0
0.2
0.4
A [kHz]
Fig. 15.7 Diffusive noise. Response of a network of 1000 integrate-and-ﬁre neurons with diffusive
noise to step current input. Simulations (ﬂuctuating solid line) are compared to a numerical integra-
tion of the density equations (thick dashed line). (a) For low noise and a big (superthreshold) current
step the response is rapid. (b) For high noise and a small current step the response is slower and does
not exhibit oscillations.
current pulse. The Dirac δ-pulse in the activity indicates that ΔA(t) is proportional to the
derivative h′ of the input potential of Eq. (15.11). A population response proportional to h′
is the signature of an immediate response to step currents.
The above argument assumes that the jump size is ﬁnite. The linearization of the mem-
brane potential density equations (see Chapter 13) corresponds to the limit where the jump
size goes to zero. Two different situations may occur, which are visualized in Figs. 15.8a
and b. Let us start with the situation depicted in Fig. 15.8b. As the jump size Δu goes to
zero, the fraction of neurons that ﬁre (i.e., the shaded area under the curve of p(u)) remains
proportional to Δu. Therefore, even in the limit of Δu to zero the linearized population equa-
tions predict a rapid response component. The fast response component is proportional to
p(ϑ), i.e., to the density of the membrane potential at the threshold. For colored noise, the
density at threshold is ﬁnite. Therefore, for colored noise, the response is fast (Fig. 15.9),
even after linearization of the equations of the population dynamics (Brunel et al., 2001;
Fourcaud and Brunel, 2002).
For diffusive noise with white-noise characteristics, however, the membrane potential
density vanishes at the threshold. The area under the curve therefore has the shape of a
triangle (Fig. 15.8a) and is proportional to (Δu)2. In the limit as Δu tends to zero, a lin-
earization of the equation thus predicts that the response loses its instantaneous component
(Brunel and Hakim, 1999; Lindner and Schimansky-Geier, 2001; Richardson, 2007).
The linearization of the membrane potential density equations leads to the linear response
ﬁlter G(s). The Fourier transform of G is the frequency-dependent gain ˆG(ω); see Chapter
13. After linearization of the population activity equations, the question of fast or slow
response to a step input is equivalent to the question of the high-frequency behavior of
ˆG(ω). Table 15.2 summarizes the main results from the literature. A cut-off frequency pro-
portional to 1/τm implies that the dynamics of the population activity is "slow" and roughly
follows the input potential. Exponential integrate-and-ﬁre neurons, which we identiﬁed in

15.2 Fast transients vs. slow transients in models
407
p(u)
I(t)
I(t)
u
u
A(t)
t
(a)
I(t)
(b)
p(u)
I(t)
u
A(t)
t
Fig. 15.8 Transients in a population of neurons with diffusive noise. (a) Rapid response to strong
stimuli. A population of neurons (top left) is characterized by its distribution of membrane potentials
(below left). Four representative trajectories are shown (right). In the stationary state of asynchronous
ﬁring, the population activity A(t) ﬂuctuates about a constant value A0. Bottom right: If all neurons
receive a common current pulse at time t0, the membrane potential jumps by a small amount Δu.
Therefore, all neurons with a membrane potential just below threshold (shaded area below p(u)) ﬁre
synchronously at time t0, which gives rise to an instantaneous peak in A(t). With white diffusive
noise, the density p(u) vanishes at the threshold ϑ. Therefore, the amplitude of the peak vanishes
quadratically as the charge deposited by the current pulse decreases. (b) Rapid response to strong
and weak stimuli. Same as in (a), except that the noise is slow, either slow noise in the parameters or
colored diffusive noise. In this case, the area under the curve and therefore the amplitude of the peak
in A(t) vanishes linearly with the charge delivered by the current pulse. This gives rise to a rapid
linear response. Schematic ﬁgure.
Chapter 5 as a good model of cortical neurons, are always slow in this sense. If there is no
cut-off, the population activity can respond rapidly. With this deﬁnition, leaky integrate-
and-ﬁre neurons respond rapidly to a change in the input variance σ2 of the diffusive
noise (Lindner and Schimansky-Geier, 2001; Silberberg et al., 2004; Richardson, 2007). A
cut-off proportional to 1/√τm means that the response of a population of leaky integrate-
and-ﬁre neurons to a step is slightly faster than that of the membrane potential but must
still be considered as "fairly slow" (Brunel and Hakim, 1999).
We close with a conundrum: Why is the linear response of the leaky integrate-and-ﬁre
model fairly slow for all noise levels, yet the noise-free response that we have seen in Fig.
15.5a is fast? We emphasize that the linearization of the noise-free population equations
does indeed predict a fast response, because, if there is no noise, the membrane poten-
tial density at the threshold is ﬁnite. However, already for a very small amount of white
diffusive noise, the formal membrane potential density at the threshold vanishes, so that
the linearized population equations predict a slow response. This is, however, to a certain
degree an artifact of the diffusion approximation. For a small amount of diffusive noise, the
layer below ϑ over which the membrane potential density drops from its maximum to zero
becomes very thin. For any ﬁnite spike arrival rate and ﬁnite EPSP size in the background
input or ﬁnite signal amplitude ΔI, the immediate response is strong and fast - as seen from
the general arguments in Fig. 15.8.

408
Fast transients and rate models
GI(ω)
Gσ(ω)
Gg(ω)
LIF
A0 R
σ
1
√ωτm
A0 1
σ2

1+
ϑ−h0
σ√ωτm
	
A0 1
g0
ϑ−h0
σ√ωτm
EIF
A0 R
ΔT
1
ωτm
A0
1
(ΔT )2
1
ωτm
A0 1
g0
1
ωτm log(ωτm)
Table 15.2 High-frequency response in the presence of diffusive noise. The
frequency-dependent gain of leaky integrate-and-ﬁre neurons (LIF) and exponential
integrate-and-ﬁre neurons (EIF) in response to a periodic modulation of the input current
GI, of the noise variance Gσ, or of the input conductance Gg. The neurons are subject to
diffusive noise and described by the Fokker-Planck equation; see Chapter 13. The
response Gσ of the LIF to modulations in the noise level is rapid, since it approaches a
ﬁnite value for ω →∞. The response GI or Gg of the LIF to changes in input current or
input conductance is fairly slow, since it decays at high frequencies with 1/√ωτm. The
response of the EIF is always slow (decay with 1/ωτm) whatever the type of input.
Parameters denote the input resistance R, membrane time constant τm, noise level σ0,
population activity in the stationary state A0, and slope factor ΔT of the exponential
integrate-and-ﬁre model (see Chapter 5). The table (adapted from Richardson (2007))
summarizes mathematical results of various sources (Brunel and Hakim, 1999; Lindner
and Schimansky-Geier, 2001; Fourcaud and Brunel, 2005; Richardson, 2007).
15.3 Rate models
The gain function F(h) of rate models can always be chosen such that, for constant input
h0 = RI0, the population activity A0 = F(h0) in the stationary state of asynchronous ﬁring
is correctly described. The dynamic equations that describe the approach to the stationary
state in a rate model are, however, to a certain degree ad hoc. This means that the analysis
of transients as well as the stability analysis in recurrent networks will, in general, give
different results in rate models than in spiking neuron models.
15.3.1 Rate models have slow transients
In Section 15.2 we saw that spiking neuron models with a large amount of escape noise
exhibit a population activity A(t) that follows the input potential h(t). In this case, it is
therefore reasonable to deﬁne a rate model A(t) = F(h(t)) in which the momentary activity
A(t) reﬂects the momentary input potential h(t). An example is Eq. (15.1), which corre-
sponds to a "quasi-stationary" treatment of the population activity, because the transform
F is identical to the stationary gain function, except for a change in the units of the argu-
ment, as discussed in the text after Eq. (15.1). A similar argument can also be made for

15.3 Rate models
409
A
10ms
A(t) [Hz]
I(t)
(a)
 
(b)
10ms
A(t) [Hz]
I(t)
Fig. 15.9 Slow (colored) diffusive noise versus white diffusive noise. A population of integrate-
and- ﬁre models with a time constant of τm = 20 ms was simulated and responses to a step stimulus
reported in time bins of 1 ms. (a) Colored noise with a ﬁltering time constant τs = 10 ms leads to an
abrupt, instantaneous response. (b) White noise leads to a smoothly increasing, fairly slow response.
Figures adapted from Brunel et al. (2001). Copyright (2001) The American Physical Society.
exponential integrate-and-ﬁre neurons with diffusive noise, as we shall see later in this
section.
If we insert Eq. (15.2) into Eq. (15.1) we obtain
A(t) = F[h(t)] = F
 R
τm
 ∞
0 exp

−s
τm

I(t −s)ds

.
(15.13)
Eq. (15.13) makes explicit that the population activity in the rate model reﬂects a low-pass
ﬁltered version of the input current. The transient response to a step in the input current is
therefore slow.
Since differential equations are more convenient than integrals, we rewrite the input
potential in the form of Eq. (15.3), which we repeat here for convenience
τm
dh(t)
dt
= −h+RI(t).
(15.14)
The input potential h(t) resulting from the integration of Eq. (15.14) is to be inserted into
the function F to arrive at the population activity A(t) = F[h(t)]. Note that the input current
I(t) in Eq. (15.14) can arise from external sources, from other populations or from recurrent
activity in the network itself.
Example: Wilson-Cowan differential equation
Sometimes one ﬁnds in the literature rate models of the form
τA
d ¯A(t)
dt
= −¯A(t)+F(h(t)),
(15.15)

410
Fast transients and rate models
which have an additional time constant τA. Therefore the transient response to a step in
the input would be even slower than that of the rate model in Eq. (15.13).
In the derivation of Wilson and Cowan (1973) the time constant τA arises from time-
averaging over the "raw" activity variable with a sliding window of duration τA. Thus,
even if the "raw" activity has sharp transients, the time-averaged variable ¯A(t) in Eq.
(15.15) is smooth. In the theory of Wilson and Cowan, the differential equation for the
population activity takes the form (Wilson and Cowan, 1972, 1973)
τA
d ¯A(t)
dt
= −¯A(t)+(1−Δabs)F(h(t))
(15.16)
so as to account for absolute refractoriness of duration Δabs; see the integral equation
(14.10) in Chapter 14. F has a sigmoidal shape. The input potential h(t) comprises input
from the same population as well as from other populations.
Since there is no reason to introduce the additional low-pass ﬁlter with time constant
τA, we advise against the use of the model deﬁned in Eqs. (15.15) or (15.16). However,
we may set
τm
dA(t)
dt
= −A(t)+gσ(I(t)),
(15.17)
where I(t) is the input current (as opposed to the input potential). The current can be
attributed to input from other populations or from recurrent coupling within the popula-
tion. The low-pass ﬁlter in Eq. (15.17) replaces the low-pass ﬁlter in Eq. (15.14) so that
the two rate models are equivalent after an appropriate rescaling of the input, even for
complex networks (Miller and Fumarola, 2012); see also Exercises.
15.3.2 Networks of rate models
Let us consider a network consisting of K populations. Each population contains a homo-
geneous population of neurons. The input into population k arising from other populations
n and from recurrent coupling within the population is described as
Ik(t) = ∑
n
Ckn wkn
 ∞
0 α(s)An(t −s)ds.
(15.18)
Here An(t) is the activity of population n and Ckn is the number of presynaptic neu-
rons in population n that are connected to a typical neuron in population k; the time
course and strength of synaptic connections are described by α and wkn, respectively; see
Chapter 12.
We describe the dynamics of the input potential hk of population k with the differential
equation (15.14) and use for each population the quasi-stationary rate model An(t) = Fn(hn)
where Fn is the gain function of the neurons in population n. The ﬁnal result is
τm
dhk(t)
dt
= −hk +R ∑
n
Ckn wkn
 ∞
0 α(s)Fn(hn(t −s))ds.
(15.19)

15.3 Rate models
411
Eq. (15.19) is the starting point for some of the models in Part IV of this book.
Example: Population with self-coupling
If we have a single population, we can drop the indices in Eq. (15.19) so as to arrive at
τm
dh(t)
dt
= −h+J0
 ∞
0 α(s)F(h(t −s))ds,
(15.20)
where J is the strength of the feedback. Thus, a single population with self-coupling
is described by a single differential equation for the input potential h. The population
activity is simply A(t) = F(h(t)).
Stationary states are found as discussed in Chapter 12. If there are three ﬁxed points,
the middle one is unstable while the other two (at low and high activity) are stable under
the dynamics (15.20). The ﬁxed points calculated from Eq. (15.20) are correct. However,
stability under the dynamics (15.20) does not guarantee stability of the original network
of spiking neurons. Indeed, as we have seen in Chapters 13 and 14, the ﬁxed points of
high and low activity may lose stability with respect to oscillations, even in a single
homogeneous population. The rate dynamics of Eq. (15.20) cannot correctly account for
these oscillations. In fact, for instantaneous synaptic current pulses α(s) = qδ(s), where
δ denotes the Dirac δ-function, Eq. (15.20) reduces to a one-dimensional differential
equation which can never give rise to oscillatory solutions.
15.3.3 Linear-Nonlinear-Poisson and improved transients
To improve the description of transients, we start from Eq. (15.13), but insert an arbitrary
ﬁlter κ,
A(t) = F(h(t)) = F
 ∞
0 κ(s)I(t −s)ds

.
(15.21)
Equation (15.21) is called the Linear-Nonlinear-Poisson (LNP) model (Chichilnisky 2001;
Simoncelli et al. 2004). It is also called a cascade model because it can be interpreted as
a sequence of three processing steps. First, input is ﬁltered with an arbitrary linear ﬁlter
κ, which yields the input potential h. Second, the result is passed through a nonlinearity
F. Third, in case of a single neuron, spikes are generated by an inhomogeneous Poisson
process with rate F(h(t)). Since, in our model of a homogeneous population, we have
many similar neurons, we drop the third step and interpret the rate F(h(t)) directly as the
population activity.
For κ(s) = (R/τm)exp(−s/τm) we are back at Eq. (15.13). The question arises whether
we can make a better choice of the ﬁlter κ than a simple low-pass with the membrane
time constant τm. In Chapter 11 it was shown how an optimal ﬁlter κ can be determined
experimentally by reverse correlation techniques.
Here we are interested in deriving the optimal ﬁlter from the complete population dynam-
ics. The LNP model in Eq. (15.21) is an approximation of the population dynamics that

412
Fast transients and rate models
is more correctly described by the Fokker-Planck equations in Chapter 13 or by the inte-
gral equation of time-dependent renewal theory in Chapter 14. Let us recall that, in both
approaches, we can linearize the population equations around a stationary state of asyn-
chronous ﬁring A0 which is obtained with a mean input I0 at some noise level σ. The
linearization of the population dynamics about A0 yields a ﬁlter GI(s). We use this ﬁlter,
and arrive at a variant of Eq. (15.21)
A(t) = ˜F
 ∞
0 GI(s)I(t −s)ds

,
(15.22)
where ˜F(x) = gσ(x/c) is a scaled version of the frequency-current curve gσ(I) and c =
 ∞
0 GI(s)ds a constant which matches the slope of the gain function at the reference point
for the linearization (Ostojic and Brunel, 2011). Models with this, or similar, choices of ˜F
describe transient peaks in the population activity surprisingly well (see, e.g., Herrmann
and Gerstner, 2001; Aviel and Gerstner, 2006; Ostojic and Brunel, 2011). Rate models
based on Eq. (15.22) can also be used to describe coupled populations. Stability of a sta-
tionary state A0 is correctly described by Eq. (15.22), if the ﬁlter GI(s) in the argument on
the right-hand-side reﬂects the linearization of the full population dynamics around A0, but
not if the ﬁlter is derived by linearization around some other value of the activity.
Example: Effective rate model for exponential integrate-and-ﬁre neurons
We denote the stationary gain function of exponential integrate-and-ﬁre neurons by
gσ(I) and the linear ﬁlter arising from linearization around a stationary activity A0 by
GI(s). For exponential integrate-and-ﬁre neurons GI(s) has the high-frequency behavior
of a low-pass ﬁlter that varies as A0
R
ΔT τm
1
ω ; see Table 15.2.
We recall that the Fourier transform of an exponential ﬁlter also yields a high-
frequency behavior that varies as 1/ω with the inverse ﬁlter time constant as cut-off fre-
quency. This suggests that, for the exponential integrate-and-ﬁre model, we can approx-
imate the time course of GI(s) as an exponential ﬁlter with an effective time constant
τeff ∝τm/A0. This leads back to Eq. (15.22), but with an exponential ﬁlter G(s). Hence,
we are now nearly back to Eq. (15.13), except that the time constant of the exponential
is different.
We now switch from the frequency current curve gσ(I) to the equivalent description
of the gain function F(h) = gσ(h/R) where the argument of F has units of a potential.
It is convenient to implement the exponential ﬁlter in the form of a differential equation
for the effective input potential (Ostojic and Brunel, 2011)
τeff(t)dh
dt = −h+RI(t),
(15.23)
with an effective time constant
τeff(t) = τm
ΔT F′
A0(t) ,
(15.24)

15.3 Rate models
413
100
200
300
400
500
0
100
0
200
t [ms]
A [Hz]
50
−50
0
I [a.u.] 
0
100
200
300
400
500
t [ms]
Fig. 15.10 Population of exponential integrate-and-ﬁre neurons. The population activity A(t) arising
from a explicit simulation of N model neurons (black solid line) can be approximated by a rate
model with effective time constant τeff(t) (gray overlaid). The stimulation is shown in the bottom
panel. Figure adapted from (Ostojic and Brunel, 2011).
where A0(t) is the activity averaged over one or a few previous time steps and F′ =
dF/dh is the derivative of the gain function at an appropriately chosen reference point
h0, so that F(h0) ≈⟨A0(t)⟩is the long-term average of the activity.
In each time step, we update the input using Eq. (15.23) and calculate the activity
as A(t) = F(h(t)) with F(h) = gσ(h/R). Such a rate model gives an excellent approx-
imation of the activity in a population of exponential integrate-and-ﬁre neurons (Fig.
15.10). Note that fast transients are well described, because the effective time constant
is shortened as soon as the population activity increases.
15.3.4 Adaptation
So far we have focused on the initial transient after a step in the input current. After the
initial transient, however, follows a second, much slower phase of adaptation during which
the population response decreases, even if the stimulation is kept constant. For single neu-
rons, adaptation has been discussed in Chapter 6.
In a population of neurons, adaptation can be described as an effective decrease in the
input potential. If a population of non-adaptive neurons has an activity described by the
gain function A(t) = F(h(t)), then the population rate model for adaptive neurons is
A(t) = F(h(t)−a(t)),
(15.25)
where a(t) describes the amount of adaptation that neurons have accumulated, and
τa(A)da
dt = a∞(A)−a,
(15.26)
where a∞(A) is the asymptotic level of adaptation that is attained if the population continu-

414
Fast transients and rate models
ously ﬁres at a constant rate A. The asymptotic level is approached with a time constant τa.
Eqs. (15.25) and (15.26) are a simpliﬁed version of the phenomenological model proposed
in Benda and Herz (2003).
Example: Effective adaptation ﬁlter
Suppose that a∞(A) = cA is linear in the population activity with a constant c > 0 and
τa(A) = τa is independent of A. Then Eq. (15.26) can be integrated and yields a(t) =
 ∞
0 γ(s)A(t −s)ds with a ﬁlter γ(s) = (c/τa) exp(−s/τa). We insert the result in Eq.
(15.25) and ﬁnd
A(t) = F

h(t)−
 ∞
0 γ(s)A(t −s)ds

.
(15.27)
Equation (15.27) nicely describes the adaptation process but it misses, like other rate
models, the sharp initial transient, and potential transient oscillation, caused by the syn-
chronization of the population at the moment of the step (Naud and Gerstner, 2012a).
15.4 Summary
The population activity of spiking neuron models responds to a big and rapid change in
the input current much faster than the input potential. The response of the input potential
is characterized by the membrane time constant τm and therefore exhibits the properties
of a low-pass ﬁlter. In an asynchronously ﬁring population of neurons, however, there
are always a few neurons with membrane potential just below the threshold. These neu-
rons respond quasi-instantaneously to a step in the input current, despite the fact that the
input potential, i.e., the contribution to the membrane potential that is caused by the input,
responds slowly.
The details of the response depend on the neuron model as well as on the amplitude
of the signal and the type of noise. With slow noise as the dominant noise source, model
neurons respond quickly and reliably to a step input. For white noise, the picture is more
complicated.
For Spike Response Model neurons with escape noise, the speed of the response depends
on the noise level. While the response is fast for low noise, it is as slow as the membrane
potential in the limit of high noise.
For a large amount of diffusive white noise and a small amplitude of the input signal, the
choice of neuron model plays an important role. Leaky integrate-and-ﬁre models respond
fairly slowly, but faster than the input potential. The response of exponential integrate-and-
ﬁre models follows that of the effective membrane potential, but the effective membrane
time constant depends on the population activity.
The fact that spiking neuron models in the high-noise limit respond slowly can be used
to derive rate models for the population activity. Such rate models are the basis for the
analysis of cognitive dynamics in Part IV of the book. Nevertheless, it should be kept in

15.4 Summary
415
mind that standard rate models miss the rapid transients that a population of spiking models
exhibits in response to signals that are strong compared to the level of noise.
Literature
The rapid transients in spiking models without noise or with slow noise have been reported
by several researchers, probably ﬁrst by Knight (1972) and have later been rediscovered
several times (Gerstner, 2000; Brunel et al., 2001; Moreno-Bote and Parga, 2004).
The analysis of transients in the escape rate has been performed in Gerstner (2000),
where the limits of high noise and low noise are also discussed. For the linearization of the
membrane potential density equations and analysis of transient behavior in neuron models
with diffusive noise see Brunel and Hakim (1999); Lindner and Schimansky-Geier (2001);
Fourcaud and Brunel (2005); and Richardson (2007). Experimental data on transients in
the linearized regime can be found in Silberberg et al. (2004) and Tchumatchenko et al.
(2011).
Simoncelli et al. (2004) give an authoritative summary of LNP models. How general-
ized integrate-and-ﬁre models can be mapped to LNP models has been discussed in Aviel
and Gerstner (2006) and Ostojic and Brunel (2011). An excellent overview of the central
concepts of rate models with adaptation can be found in Benda and Herz (2003).
Exercises
1. Population of noise-free neurons
(a) Show that for noise-free neurons the population activity equation yields
A(t) =
1
1+T ′(ˆt) A(ˆt),
(15.28)
where T(ˆt) is the interspike interval of a neuron that has ﬁred its last spike at time ˆt, and the
prime denotes the derivative.
Hints: In the limit of no noise, the input-dependent interval distribution PI(t | ˆt) reduces to a Dirac
δ-function, i.e.,
PI(t | ˆt) = δ[t −ˆt −T(ˆt)],
(15.29)
where T(ˆt) is given implicitly by the threshold condition
T(ˆt) = min{(t −ˆt)|u(t) = ϑ; ˙u > 0, t > ˆt}.
(15.30)
Recall from the rules for δ-functions that
 b
a δ[ f(x)]g(x)dx =
g(x0)
| f ′(x0)| ,
(15.31)
if f has a single zero-crossing f (x0) = 0 in the interval a < x0 < b with f ′(x0) ̸= 0.
(b) Assume SRM0 neurons with u(t) = η(t −ˆt)+h(t). Show that
A(t) = h′(t)
η′T) A(ˆt).
(15.32)

416
Fast transients and rate models
Hint: Use the results from (a).
(c) An input current of amplitue I1 is switched on at time t = 0. Assume an input potential h(t) = h0
for t < 0 and h(t) = (R/τ)
 t
0 exp(−s/τ)I1 for t > 0. Show that the transient of the population
activity after the step at t = 0 is instantaneous, despite the fact that the input potential responds
slowly.
2. LNP and frequency-current curve. Around Eq. (15.22), it was argued that a model
A(t) = ˆF
 ∞
0 GI(s)I(t −s)ds

(15.33)
with a choice ˆF(x) = gσ(x/[
 ∞
0 GI(s)ds]) is optimal. The aim is to make the notion of optimality
more precise.
(a) Show that for constant, but arbitrary, input I0, Eq. (15.33) leads to A0 = gσ(I0), consistent
with the general results of Chapter 12.
(b) Suppose that GI(s) is the linearization of the population activity equations around A0 which
is achieved for a constant input I0. Show that linearization of Eq. (15.33) leads to ΔA(t) =
 ∞
0 G(s)ΔI(t −s)ds.
Hint: Recall that the response at zero frequency, ˆG(0) =
 ∞
0 G(s)ds, is related to the slope of the
gain function.
(c) Interpret the results from (a) and (b) and explain the range of validity of the model deﬁned
in Eq. (15.33). What can happen if the input varies about a mean I1 ̸= I0? What happens if the
variations around I0 are big?
3. Leaky integrate-and-ﬁre with white diffusive noise. According to the results given in Table 15.2,
the linear ﬁlter GI(s) of leaky integrate-and-ﬁre neurons has a high-frequency behavior ˜GI(ω) =
A0 R
σ
1
√ωτm .
(a) Calculate the response to a step current input.
Hint: Use ΔA(t) =
 ∞
0 G(s)ΔI(t −s)ds. Insert the step current, take the Fourier transform, per-
form the multiplication in frequency space, and ﬁnish with the inverse Fourier transform.
(b) Compare with the simulation results in Fig. 15.9b.
4. Rate model for a population of exponential integrate-and-ﬁre with white diffusive noise.
The aim is to derive the effective time constant given in Eq. (15.24) which characterizes a popu-
lation of exponential integrate-and-ﬁre neurons.
(a) Write A(t) = F[h(t)]. Linearize about a reference value A0 = F(h0) and prove that dA/dt =
F′ dh/dt.
(b) Assume that Eq. (15.23) holds with the unknown time constant τeff. Assume periodic stimu-
lation I(t) = I0 +ΔI exp(iωt) with a high frequency ω. This will lead to a periodic perturbation
ΔA exp[i(ωt +φ)]. Find the ratio c(ω) = ΔA/ΔI.
(c) Match the high-frequency behavior of c(ω) to ˜GI(ω) so as to ﬁnd the time constant τeff.
Hint: Recall from Table 15.2 that the linear ﬁlter GI(s) of the exponential integrate-and-ﬁre neu-
rons has a high-frequency behavior ˜GI(ω) = A0 R
ΔT
1
ωτm .
5. Equivalence of rate models. We use the rate model deﬁned in Eqs. (15.1) and (15.3) with R = 1
in order to describe coupled populations
τm
dhi
dt = −hi +Ii +∑
k
wikF(hk).
(15.34)
Compare this model to another rate model
τm
dAi
dt = −Ai +F
!
∑
k
wikAk + ˆIi
"
.
(15.35)
Show that Eq. (15.35) implies Eq. (15.34) under the assumption that I = ˆI +τmdˆI/dt.
Hint: Set hi = ∑k wikAk +I and take the derivative (Miller and Fumarola, 2012).

PART FOUR
DYNAMICS OF COGNITION


419
'Left'
'Right'
?
Decision making
Associative memory
'Hammer'
Cognitive science is an academic ﬁeld of research with its own questions, paradigms, and
models. The aim of Part IV is not to review the ﬁeld of cognitive science, but rather to show
by way of four examples how models of neuronal activity can be linked to fundamental
questions of cognition. To do so, we use the population rate equations resulting from the
mathematical developments of Part III and apply them to questions of cognition.
In Chapter 16 we describe the process of decision making using a network of interacting
neurons. Different neuronal populations, each one representing a different option, compete
with each other. The population with the highest activity eventually wins the competition,
suppresses the others, and determines the choice. The dynamics of decision making can be
visualized as a ball rolling down on one side rather than the other side of a hill.
Humans keep memories of important events of their life and can recall these events if
they receive appropriate cues or questions. Similarly, humans remember objects and tools,
such as a hammer, and can recognize these from noisy images. In Chapter 17, we describe
the recall of previously stored items using a model of associative memory. In this model,
neuronal assemblies of strongly connected neurons play an important role.
Human visual perception does not give rise to a precise photographic image of the envi-
ronment, but interprets and reconstructs the outside world based on the raw retinal image.
Many models of the visual cortex are formulated as ﬁeld models, which are reviewed in
Chapter 18 and discussed in relation to common visual illusions.
Finally, strong brain oscillations are related to many severe brain diseases. Understand-
ing the mechanisms that would allow suppression of brain oscillations could eventually
help patients, as discussed in Chapter 20.


16
Competing populations and decision making
We make multiple decisions in daily life. Should I cut across a busy street or take the
safer pedestrian underground path which causes a 2-minute detour? Should I say "Hello"
to the person I see on the other side of the street or move on? Should I spend money on a
simple and cheap bicycle which is less likely to be stolen, or on a faster, shiny, expensive
one? Which college should I choose after high school? Should I continue after college for
graduate studies and get a PhD? Some of these are small decisions of minor relevance, but
there are also important decisions that can inﬂuence the course of life for several years.
Decisions are most easily analyzed in the context of games. Small children already learn
in board games that they need to decide between several possibilities. A typical example is
shown in Fig. 16.1a. Would you advise a child to take the safe long path to the left, or the
shorter one with the risk of being reset to "Start"? What would you decide?
The situation depicted in the board game presents a choice between a safe and a risky
option. It is typical for decision problems that are empirically studied in the ﬁeld of neu-
roeconomics (Platt and Huettel, 2008; Rangel et al., 2008; Glimcher et al., 2008). Sup-
pose that you have a choice between winning 100 dollars with 100% probability or 200
Start
Goal
(a)
(b)
Fig. 16.1 Decision processes. (a) In a board game, your die shows the digit 4, and you have to move
the white token. The right path is shorter, but more risky, because the token has to restart if it ends
on one of the ﬂashed ﬁelds. How would you decide? (b) Perceptual decision making. Three vertical
bars are presented on a gray screen (four examples are shown): Is the central bar shifted left or right
compared to a perfectly symmetrical arrangement?

422
Competing populations and decision making
dollars with 50% probability, which option would you choose? Suppose you just received
200 dollars, but you now have the unfortunate choice between losing half of it (100 dollars)
with 100% probability or even all of it (200 dollars) with 50% probability, which option
would you choose? If the brain activity of a human subject is imaged, while he answers
these or similar monetary questions, the areas of highest activity associated with value,
risk, and loss can be identiﬁed, at the coarse resolution of brain regions (Platt and Huettel,
2008; Rangel et al., 2008).
In this chapter we work on a more microscopic level, i.e., that of neuronal activity dur-
ing decision making (Gold and Shadlen, 2007). Decision making requires (i) a suitable
representation of inputs and potential outcomes as well as of the values attached to the
options; (ii) a selection process that picks one of the options; and (iii) potentially also some
feedback that enables learning so as to achieve improved performance over several trials
(Rangel et al., 2008). Decision making involves different brain systems and has conscious
as well as unconscious aspects (Sanfey and Chang, 2008). Here, we focus on the dynamic
selection between different options in the context of perceptual decision making. There are
three reasons for this focus. First, measurements of neuronal activity of single neurons or
groups of neurons are available that indicate a correlation of neural activity with the choice
made during a decision. Second, these experimental measurements can be linked to neu-
ronal models of decision making. And, ﬁnally, the moment of the ﬁnal selection between
different choices lies at the heart of decision making.
In Section 16.1, we review some of the classic recordings of neural activity during deci-
sion making in monkeys (Gold and Shadlen, 2007). In Section 16.2, a model is presented
that describes the process of decision making as a competition between neuronal popu-
lations that share the same pool of inhibitory neurons (Wang, 2002). The mathematical
analysis of the dynamics in such a model of competition is outlined in Section 16.3. Alter-
native descriptions of decision making are presented in Section 16.4. We close the chapter
by situating models of decision making in the larger context of fundamental questions
related to the notion of "free will" (Section 16.5).
16.1 Perceptual decision making
Many perceptual phenomena can be formulated as a problem of decision making. In a
typical experiment of visual psychophysics, a subject observes a short ﬂash of three vertical
black bars on a gray background (Fig. 16.1b). Is the middle bar shifted to the left or to the
right compared to a symmetric arrangement of the three bars where it is exactly in the
center? If the shift is very small, or if the bars are presented with low contrast on a noisy
screen, the question is difﬁcult to answer. The subject who holds a button in each hand,
indicates his decision (left or right) by pressing the corresponding button. In other words,
he reports his perception as a decision.
In what follows, we focus on an experimental paradigm with visual random dot motion
stimuli used for the study of perceptual decision making in monkeys (Salzman et al., 1990;
Roitman and Shadlen, 2002; Gold and Shadlen, 2007). The stimulus consists of a random

16.1 Perceptual decision making
423
pattern of moving dots, where most, but not necessarily all, of the dots move coherently
in the same direction; see Fig. 16.2. Typically, two different directions of motion are used,
for example upward or downward. The monkey has been trained to indicate the perceived
motion direction by saccadic eye movements to one of two targets see Fig. 16.2b.
Note that, in contrast to the examples given at the beginning of this chapter, problems of
perceptual decision making typically have no direct monetary value or risk associated with
them. Normally we do not care whether a bar is shifted to the left or to the right, or whether
dots move upward or downward. Nevertheless, a correct perceptual decision might be life-
saving if a moving stripe pattern in the bush is correctly recognized as an approaching tiger
as opposed to a movement of the leaves in the wind.
16.1.1 Perception of motion
Neurons in the middle temporal visual area (MT, also called V5) are activated by large-
scale motion stimuli. The receptive ﬁeld of an MT neuron, i.e., the region of visual space
that is sensitive to motion stimuli, is considerably larger than that of a neuron in the primary
visual cortex; see Chapter 12. Different neurons in MT respond to different directions of
motion, but just as in other parts of the visual cortex, area MT has a columnar structure so
that clusters of neighboring neurons share receptive ﬁelds with a similar preferred direction
of motion (Albright et al., 1984).
At the beginning of a typical recording session with an extracellular electrode in MT
(Salzman et al., 1990), the location of the receptive ﬁeld and the preferred direction of
motion of a single neuron or cluster of neighboring neurons is determined by varying the
movement angle and the location of the random dot stimulus. Once the receptive properties
of the local MT neurons have been determined, only two different classes of stimuli are
used, i.e., dots moving coherently in the preferred direction of the recorded neuron, and
dots moving coherently in the opposite direction.
After each presentation of a random dot motion pattern, two targets are switched on,
one at a location in the direction of stimulus motion, the other one on the opposite side.
The monkey is trained to indicate the movement direction of the stimulus by a saccadic eye
movement to the corresponding target. After training, the perceptual decision between a dot
movement in the cell's preferred direction (P) or the null direction (N) is reliably performed
by the monkey if a noise-free stimulus is used where all dots move in the same direction.
However, the task becomes more difﬁcult if only a small fraction of dots move coherently
in one of the two directions while the rest of the dots move in a random direction. The
behavioral performance can be assessed with the psychometric function which represents
the percentage of saccades to the target P as a function of coherence, where coherence
indicates the fraction of coherently moving dots (Fig. 16.2b).
An electrode in MT can be used not only to record neural activity, but also to stimulate
a cluster of neurons in the neighborhood of the electrode. Since neighboring neurons have
similar preferred directions of motion, current injection into the electrode can bias the
perception of the monkey in favor of the neurons' preferred direction, even if the random

424
Competing populations and decision making
Firing rate
(a)
360
180
P
N
b [deg]
0
Coherence=0.66
P 
P 
N 
N 
Coherence=1.0
Coherence
(b)
1
0
-1
"P" reports [%]
100
50
0
Fig. 16.2 Random dot stimuli and perception of motion. (a) Top: A pattern of random dots moving in
direction β is presented on the screen. Different motion directions are tested. Bottom: The ﬁring rate
response of a neuron in area MT depends on the direction of motion β of the random dot stimulus.
The preferred direction is marked "P," the null direction "N" (schematic ﬁgure). (b) Top: In the ﬁrst
phase of each trial, the monkey ﬁxates on the star while a moving random dot stimulus is presented
inside the receptive ﬁeld (dashed circle) of a neuron. After visual stimulation is switched off, the
monkey indicates by eye movements to one of the two targets (solid black circles, marked P and N)
whether the perceived motion is in the direction "P" or "N." Bottom: The percentage of "P" reports
(vertical axis) is plotted as a function of the coherence (horizontal axis) of the stimulus (solid line).
If, during presentation of a random dot motion pattern, the MT column of neurons with preferred
direction "P" is electrically stimulated, the percentage of times the monkey reports a perception of
"P" is increased (dashed line). Coherence of 1 indicates that all points move in the P direction, while
coherence of 0.66 indicates that one third of the points move in a random direction. Coherence of −1
indicates coherent motion in the "N" direction; schematically redrawn after Salzman et al. (1990).
dot pattern has no or only a small amount of coherence (Fig. 16.2b). This indicates that
the perceptual decision of the monkey relies on the motion information represented in the
activity of MT neurons (Salzman et al., 1990).
While the monkey's perceptual decision is inﬂuenced by the manipulation of MT neu-
rons, this result does not imply that the decision itself is made in MT. It is likely to be made
at a later stage, in an area that uses the information of MT neurons.
16.1.2 Where is the decision taken?
The short answer is: we do not know. However, an interesting observation has been made
in the lateral intra-parietal (LIP) area during experiments of perceptual decision making
with moving random dot stimuli (Roitman and Shadlen, 2002).
Before discussing the experiment, we need to present a few facts about the properties of
LIP neurons. Area LIP is located in the visual processing stream between the primary
visual cortex and the frontal eye ﬁeld region involved in control of saccadic eye move-

16.1 Perceptual decision making
425
ments. Neurons in area LIP respond during the preparation of saccadic eye movements.
Different neurons in LIP have different receptive ﬁelds. The location of the receptive ﬁeld
corresponds to a potential target region of eye movements. In other words, a LIP neuron
responds just before a saccadic eye movement into its receptive ﬁeld occurs.
As in the previous subsection, monkeys in the experiment of Roitman and Shadlen are
trained to indicate the direction of a moving dot pattern by saccadic eye movements to
one of two visual targets. The ﬁrst target is located in the receptive ﬁeld of a LIP neuron.
Therefore, the recorded neuron is expected to respond whenever the monkey prepares a
movement to the ﬁrst target. The second target is located in the opposite direction. The
task is designed such that a random dot stimulus moving in the direction of the ﬁrst target
indicates that the monkey should make an eye movement toward it; the correct response to
a stimulus moving in the opposite direction is a saccade to the second target (Fig. 16.3a).
The difﬁculty of the task can be varied by changing the fraction of coherently moving
0.5 seconds
Rate [Hz]
Rate [Hz]
60
60
0
0
(a)
into RF 
away from
 RF
Firing rate [Hz] 
Time [ms] 
0 
-600     
Stimulus onset
Saccade onset
70
60
50
40
20
30
(b)
0
600
Fig. 16.3 (a) Neurons in the lateral intra-parietal (LIP) area have receptive ﬁelds (RF) that represent
potential targets of a saccade. A LIP neuron responds strongly just before the saccade, if the saccadic
movement is into its RF (left, dashed line surrounds region of interest), and is suppressed if the
movement is in the opposite direction, away from its RF (right). Monkeys observed random dot
motion stimuli and had been trained to report the direction of the stimulus by saccadic eye movements
either "into" or "away from" the RF of the recorded neuron. For histograms and spike raster, trials
were aligned to saccade onset (sac, vertical line). Filled triangles indicate onset of motion stimulus.
Responses were faster for stimuli with larger coherence (top row, coherence = 51.2%) than small
coherence (bottom row, coherence = 6.4%), and stronger for movements into the RF (left column)
than away from the RF (right column). (b) Firing rate response of LIP neurons (averaged over 54
neurons) aligned to stimulus onset (left part of graph) or saccade onset (right part of graph). The
stronger the coherence (thick solid line: coherence = 51.2%, other solid lines: 12.8% and 3.2%)
of a random dot motion stimulus initiating a saccade "into" the RF, the faster the rise of the initial
response of LIP neurons (left). However, whatever the coherence, the LIP neurons always reach the
same ﬁring rate, at the moment when a saccade into the RF starts (right). The neurons are suppressed,
if the monkey chooses the opposite saccadic target ("away from the RF," dashed lines, left and right).
Adapted from Roitman and Shadlen (2002).

426
Competing populations and decision making
dots. The behavioral reaction time of the monkey was measured as a function of stimulus
coherence. At the same time, the activity of neurons in LIP was recorded.
Roitman and Shadlen found that, during the presentation of the moving dot stimulus, the
activity of LIP neurons increased. The rate of increase after stimulus onset was higher for
stimuli with a large fraction of coherent points than for stimuli with little or no coherence.
Importantly, when the responses were averaged and aligned to the onset of the saccade, LIP
neurons always reached the same level of activity just before a saccade into their receptive
ﬁeld (Fig. 16.3b).
These ﬁndings are consistent with the idea that the decision to perform a saccade occurs
at the moment when LIP neurons reach a threshold value. For stimuli with a high degree of
coherence, the activity increases more rapidly, the threshold is reached earlier, and reaction
times are shorter than for stimuli with a low degree of coherence. Therefore, Roitman and
Shadlen suggest that "a threshold level of LIP activity appears to mark the completion of
the decision process" (Roitman and Shadlen, 2002).
16.2 Competition through common inhibition
The essential features of the experiments of Roitman and Shadlen (2002) can be described
by a simple model of decision making where neuronal populations compete with each other
through shared inhibition.
We consider a network of spiking neurons (Fig. 16.4) consisting of two excitatory pop-
ulations interacting with a common pool in inhibitory neurons (Y. Wang et al., 2002).
Within the two excitatory populations neurons are randomly connected with connection
weight wEE. Connections to and from the inhibitory populations have weights wIE and wEI,
respectively. Neuronal parameters and connection weights are adjusted such that, in the
absence of external input, all neurons exhibit spontaneous activity at low ﬁring rates. In
other words, the network is in a state of asynchronous irregular ﬁring.
Stimulation corresponds to a positive mean input into one or both groups of excita-
tory neurons. For example, for a description of the experiments of Roitman and Shadlen
discussed in the previous section, we can identify input into population 1 as indicating
)
(t
Ainh
Input "right" 
Input "left"
 
EE
w
EE
w
EI
w
EI
w
wIE
wIE
Fig. 16.4 Competition between neuronal
pools. Two populations of excitatory neurons
interact with a common pool of inhibitory
neurons. Input signals indicating movement
to the left are fed into population 1 with
activity AE,1(t). Each population of excita-
tory neurons makes excitatory connections of
strength wEE onto itself. The inhibitory popu-
lation receives input of strength wIE from the
two excitatory populations and sends back
inhibition of strength wEI.

16.2 Competition through common inhibition
427
coherent motion of the random dot pattern to the left whereas input into population 2 indi-
cates motion to the right (Fig. 16.4). Since the stimulus in the experiments has a random
component (e.g., the fraction of coherent dots is less than 100%), the input into each pop-
ulation is described as a mean plus some noise.
If the pattern has a high degree of coherence and moves to the left, the mean input to
population 1 is high. This induces a high activity AE,1 which in turn excites the inhibitory
population which transmits inhibition to both excitatory pools. However, only the stimu-
lated pool can overcome the inhibition so that the activity of the other excitatory population
is suppressed. Since, at most one of the two populations can be active at the same time,
the two populations are said to "compete" with each other. The competition is induced by
the shared inhibition. If the external stimulus favors one of the two populations, the pop-
ulation receiving the stronger stimulus "wins" the competition. In the absence of external
stimulation, or for a weak unbiased stimulus, both populations exhibit low activity.
To highlight the dynamics of competition, let us now focus on a strong, but unbiased
stimulus. Here, unbiased means that, after stimulus onset, both excitatory populations
receive an input of the same mean, but with a different realization of the noise (Fig. 16.5a).
Immediately after the onset of stimulation, both excitatory populations increase their ﬁring
rates. Soon afterward, however, one of the activities grows further at the expense of the
other one, which is suppressed. The population which develops a high activity is called
the "winner" of the competition. In the next section, we will show mathematically how the
shared inhibition induces a competition between the two excitatory populations.
Stimulus
AE,1
AE,2
AE,1
AE,2
20Hz 
(a)
Decision
"left"
Decision
"right"
0
10
20
30
40
0
10
20
30
40
AE,1  [Hz]
AE,2  [Hz]
(b)
Fig. 16.5 Competition between neuronal pools. (a) Top: Spiking activity of two populations in trial
1 (left) and trial 2 (right). Dots denote spikes. Average across the population gives the population
activities AE,1(t) and AE,2(t). During presentation of an unbiased stimulus (e.g., equal number of
points moving to the left and to the right), one of the excitatory population develops a high popula-
tion activity, while the other one is suppressed, indicating a spontaneous decision to the left (trial 1)
or to the right (trial 2). Bottom: An unbiased stimulus corresponds to an input to the left and right
populations of equal mean, but different realizations of noise. (b) The dynamics of population activ-
ities AE,1(t),AE,2(t) can be visualized in the phase plane. In the absence of stimulation, the activity
of both excitatory populations exhibits a low ﬁring rate of less than 5 Hz (circle). Upon stimulation,
the dynamics converge either to the region corresponding to "decision left" (characterized by high
values of AE,1) or to "decision right" (characterized by high values of AE,2). Adapted from Wang
et al. (2002).

428
Competing populations and decision making
16.3 Dynamics of decision making
In this section, we present a mathematical analysis of decision making in models of inter-
acting populations. We start in Section 16.3.1 with the rate equations for a model with three
populations, two excitatory ones which interact with a common inhibitory population. In
Section 16.3.2, the rate model with three populations is reduced to a simpliﬁed system
described by two differential equations. The ﬁxed points of the two-dimensional dynami-
cal system are analyzed in the phase plane (Section 16.3.3) for several situations relevant
to experiments on decision making. Finally, in Section 16.3.4 the formalism of competition
through shared inhibition is generalized to the case of K competing populations.
16.3.1 Model with three populations
In order to analyze the model of Fig. 16.4, we use the rate equations of Chapter 15 and
formulate for each of the three interacting populations a differential equation for the input
potential. Let
AE,k = gE(hE,k)
(16.1)
denote the population activity of an excitatory population k driven by an input potential
hE,k. Similarly, Ainh = ginh(hinh) is the activity of the inhibitory population under the inﬂu-
ence of the input potential hinh. Here gE and ginh are the gain functions of excitatory and
inhibitory neurons, respectively. The input potentials evolve according to
τE
dhE,1
dt
=−hE,1 +wEE gE(hE,1)+wEI ginh(hinh)+RI1 ,
(16.2)
τE
dhE,2
dt
=−hE,2 +wEE gE(hE,2)+wEI ginh(hinh)+RI2 ,
(16.3)
τinh
dhinh
dt
=−hinh +wIE gE(hE,1)+wIE gE(hE,2);
(16.4)
see Eqs. (15.3) and (15.1). Here wEE denotes the strength of recurrent coupling within each
of the excitatory populations and wEI the coupling from the inhibitory to the excitatory pop-
ulation of neurons. Inhibitory neurons are driven by the input from excitatory populations
via connections of strength wIE. We assume that inhibitory neurons have no self-coupling,
but feed their activity Ainh back to both excitatory populations with a negative coupling
coefﬁcient, wEI < 0. Note that the two excitatory populations are completely equivalent,
i.e., they contain neurons of the same type and the same coupling strength. However, the
two populations receive separate inputs, I1 and I2, respectively. We call an input "biased"
(i.e., favoring one of the two options represented by the excitatory populations) if I1 ̸= I2.
We emphasize that the only interaction between the two excitatory populations is indirect
via the shared inhibitory population.

16.3 Dynamics of decision making
429
AE,2(t)
Ainh(t)
Input "left"
 
Input "right"
-a
-a
w0
w0
wEI
wEI
wEI
wEI
AE,1(t)
(a)
−4
−2
0
2
4
hE,1
−4
−2
0
2
4
hE,2
˙h2 = 0
˙h1  = 0
˙h1 = 0
˙h2  = 0
(b)
Fig. 16.6 Effective inhibition. (a) Two populations of excitatory neurons interact with a common
pool of inhibitory neurons. The inhibitory population is replaced by an effective inhibitory coupling
of strength α between the two excitatory populations. In addition, both populations of excitatory
neurons make excitatory connections of strength w0 = wEE −α onto itself. (b) Phase plane analysis
in the absence of stimulation. The nullclines dhE,1/dt = 0 and dhE,2/dt = 0 are shown as a function
of hE,1 (horizontal axis) and hE,2 (vertical axis). There is a single crossing point corresponding to a
stable ﬁxed point close to hE,1 = hE,2 = 0. Arrows indicate the ﬂow toward the ﬁxed point.
16.3.2 Effective inhibition
The system of three differential equations (16.2)-(16.4) is still relatively complicated.
However, from Chapter 4 we know that for a two-dimensional system of equations we
can use the powerful mathematical tools of phase plane analysis. This is the main reason
why we now reduce the three equations to two.
To do so, we make two assumptions. First, we assume that the membrane time constant
of inhibition is shorter than that of excitation, τinh ≪τE. Formally, we consider the limit
of a separation of time scales τinh/τE →0. Therefore we can treat the dynamics of hinh in
Eq. (16.4) as instantaneous, so that the inhibitory potential is always at its ﬁxed point
hinh = wIE [gE(hE,1)+gE(hE,2)].
(16.5)
Is this assumption justiﬁed? Inhibitory neurons do indeed ﬁre at higher ﬁring rates than exci-
tatory ones and are in this sense "faster." However, this observation on its own does not imply
that the membrane time constants of excitatory and inhibitory neurons, respectively, would
differbyafactorof10ormore;infact,theydon't.Nevertheless,afocusontherawmembrane
time constant is also too limited in scope, since we should also take into account synaptic
processes. Excitatory synapses typically have an NMDA component with time constants in
the range of a hundred milliseconds or more, whereas inhibitory synapses are fast. We recall
from Chapter 15 that the rate equations that we use here are in any case highly simpliﬁed and
do not fully reﬂect the potentially much richer dynamics of neuronal populations.
Intuitively, the assumption of a separation of time scales implies that inhibition reacts
faster to a change in the input than excitation. In the following we simply assume the

430
Competing populations and decision making
separation of time scales between inhibition and excitation, because it enables a signiﬁcant
simpliﬁcation of the mathematical treatment. Essentially, it means that the variable hinh
can be removed from the system of three equations (16.2)-(16.4). Thus we drop Eq. (16.4)
and replace in Eqs. (16.2) and (16.3) the input potential hinh by the right-hand side of Eq.
(16.5).
The second assumption is not absolutely necessary, but it makes the remaining two
equations more transparent. The assumption concerns the shape of the gain function of
inhibitory neurons. We require a linear gain function and set
ginh(hinh) = γhinh ,
(16.6)
with a slope factor γ > 0. If we insert Eqs. (16.5) and (16.6) into (16.2) and (16.3) we arrive
at
τE
dhE,1
dt
=−hE,1 +(wEE −α)gE(hE,1)−α gE(hE,2)+RI1 ,
(16.7)
τE
dhE,2
dt
=−hE,2 +(wEE −α)gE(hE,2)−α gE(hE,1)+RI2 ,
(16.8)
where we have introduced a parameter α = −γ wEIwIE > 0. Thus, the model of three pop-
ulations has been replaced by a model with two excitatory populations that interact with
an effective inhibitory coupling of strength α; see Fig. 16.6a. Even though neurons make
either excitatory or inhibitory synapses, never both ("Dale's law"), the above derivation
shows that, under appropriate assumptions, there is a mathematically equivalent descrip-
tion where explicit inhibition by inhibitory neurons is replaced by effective inhibition
between excitatory neurons. The effective inhibitory coupling allows us to discuss com-
petition between neuronal groups in a transparent manner.
16.3.3 Phase plane analysis
The advantage of the reduced system with two differential equations (16.7) and (16.8) and
effective inhibition is that it can be studied using phase plane analysis; see Figs. 16.6b and
16.7.
In the absence of stimulation, there exists only a single ﬁxed point hE,1 = hE,2 ≈0,
corresponding to a small level of spontaneous activity (Fig. 16.6b).
If a stimulus I1 > 0 favors the ﬁrst population, the ﬁxed point moves to an asymmetric
position where population 1 exhibits much stronger activity AE,1 = g(hE,1) than population
2 (Fig. 16.7a). Note that, at the ﬁxed point, hE,2 ≪0. In other words, the effective interac-
tion between the two populations causes a strong inhibitory input potential to population 2.
This is a characteristic feature of a competitive network. If one of the populations exhibits
a strong activity, it inhibits activity of the others so that only the activity of a single win-
ning population "survives." This principle can also be applied to more than two interacting
populations, as we shall see in Section 16.3.4.
A particularly interesting situation arises with a strong but unbiased stimulus, as we have

16.3 Dynamics of decision making
431
−4
−2
0
2
4
hE,1
−4
−2
0
2
4
hE,2
˙h1 = 0
˙h2 = 0
(a)
−4
−2
0
2
4
hE,1
hE,2
−4
−2
0
2
4
˙h2 = 0
˙h1 = 0
(b)
Fig. 16.7 Phase plane analysis of the competition model during stimulation. (a) A strong stimulus
I1 > 0 = I2 gives rise to a single stable ﬁxed point, corresponding to high ﬁring rates AE,1 of the ﬁrst
population. This indicates a choice "left." The nullclines dhE,1/dt = 0 (solid line) and dhE,2/dt = 0
(solid line) are shown as a function of hE,1 (horizontal axis) and hE,2 (vertical axis). Arrows indicate
the ﬂow toward the ﬁxed point. A sample trajectory is indicated (thick line). (b) Phase plane analysis
with strong, but ambiguous stimulation I1 = I2 > 0. The symmetric ﬁxed point is unstable, and the
ﬂow converges to one of the two stable ﬁxed points. Two sample trajectories are shown.
already seen in the simulations of Fig. 16.5. The phase plane analysis of Fig. 16.7b shows
that, with a strong unbiased stimulus I1 = I2 ≫0, three ﬁxed points exist. The symmetric
ﬁxed point hE,1 = hE,2 is a saddle point and therefore unstable. The two other ﬁxed points
occur at equivalent positions symmetrically to the left and right of the diagonal. These are
the ﬁxed points that enforce a decision "left" or "right."
It depends on the initial conditions, or on tiny ﬂuctuations in the noise of the input,
whether the system ends up in the left or right ﬁxed point. If, before the onset of the
unbiased strong stimulation, the system was at the stable resting point close to hE,1 =
hE,2 ≈0, then the dynamics is ﬁrst attracted toward the saddle point, before it bends over
to either the left or right stable ﬁxed point (Fig. 16.7b). Thus, the phase plane analysis of
the two-dimensional system correctly reﬂects the dynamics observed in the simulations of
the model with populations of hundreds of spiking neurons (Fig. 16.5b).
16.3.4 Formal winner-take-all networks
The arguments that were developed above for the case of a binary choice between two
options can be generalized to a situation with K possible outcomes. Each outcome is repre-
sented by one population of excitatory neurons. Analogous to the arguments in Fig. 16.6a,
we work with an effective inhibition of strength α > 0 between the K pools of neurons and
with a self-interaction of strength w0 within each pool of neurons.
The activity of population k is then
Ak(t) = g(hk(t))
(16.9)

432
Competing populations and decision making
1( )
A t
Input
w0
( )
kI
t
1( )
I t
1
k
-a
...
...
(a)
2
A
Input
kI
2I
1
k
kA
Activity
-a
(b)
Fig. 16.8 Formal winner-take-all network. (a) Network architecture: each artiﬁcial neuron 1 ≤k ≤K
receives an input Ik. Each neuron has a positive feedback of magnitude w0 onto itself but inhibits with
strength α all other neurons. (b) In a pattern of ﬁxed inputs Ik > 0, 1 ≤k ≤K switched on at time t0,
the network converges to a state where only a single "winner" neuron is active, i.e., the one which
receives the strongest input.
with input potential
τ dhk
dt = −hk +w0 g(hk)−α ∑
j̸=k
gE(hj)+RIk,
(16.10)
where the sum runs over all neurons 1 ≤j ≤K, except neuron k. Note that we assume here a
network of interacting populations, but it is common to draw the network as an interaction
between formal units. Despite the fact that, in our interpretation, each unit represents a
whole population, the units are often called "artiﬁcial neurons;" see Fig. 16.8a. Winner-
take-all networks are a standard topic of artiﬁcial neural networks (Hertz et al., 1991;
Kohonen, 1984; Haykin, 1994).
For a suitable choice of coupling parameters w0 and α the network implements a com-
petition between artiﬁcial neurons, as highlighted in the following example.
Example: Competition
Consider a network of formal neurons described by activities Ak = [1+tanh(h−θ)]
Amax/2. We work in unit-free variables and set Amax = 1 and θ = 5. Thus, for an input
potential h = 0 the activity is nearly zero while for h = 10 it is close to 1. The input
potential, given by Eq. (16.10), contains contributions from external input as well as
contributions from recurrent interactions within the network.
Suppose that for all times t < t0 the external input vanishes, Ik = 0 for all k. Thus, at
time t0 the input potential hk and the activity Ak are negligible for all units k. Therefore
the interactions within the network are negligible as well.
At time t0 the input is switched on to a new ﬁxed value Ik which is different for each
neuron; see Fig. 16.8b. The activity of the neuron k which receives the strongest input
grows more rapidly than that of the others so that its activity also increases more rapidly.

16.4 Alternative decision models
433
E 
No decison
E 
A 
E 
A 
B 
No input
Biased input,
favors A
Unbiased strong 
input
x 
x 
x 
0 
+1
-1
0 
-1
(a)
x 
-1
0 
+1
x 
-1
0 
+1
x 
0 
A
h
A
h
A
h
B
h
B
h
A 
A 
B 
B 
A 
A 
No decision 
(b)
Fig. 16.9 Energy picture of decision making. (a) Decisions correspond to a ball rolling down an
energy landscape, plotted as a function of a formal decision variable x. A value of x = 0 indicates
that no decision is taken (top, no input), whereas a value of x = ±1 reﬂects a decision for options
A or B, respectively. An input favoring option A deforms and tilts the energy landscape so that the
minimum of the energy is in the neighborhood of x = 1 (middle). A strong but unbiased input creates
two energy minima corresponding to options A and B. Only one of the two options can be taken
by the rolling ball (bottom). (b) The corresponding phase plane diagram of the input potentials hA
(horizontal axis) and hB (vertical axis). Fixed points are indicated as solid (stable) or empty (saddle)
circles. The decision variable x moves along the axis (dashed gray line) perpendicular to the diagonal
(dashed black line) and is replotted again as a one-dimensional ﬂow on the right-hand side of the
ﬁgure.
The strong activity of neuron k inhibits the development of activity in the other neurons
so that, in the end, the neuron with the strongest input wins the competition and its
activity is the only one to survive.
16.4 Alternative decision models
In the previous two sections, we discussed decision models as the competitive interaction
between two or more populations of excitatory neurons. In this section we present two
different models of decision making, i.e., the energy picture in Section 16.4.1 and the drift-
diffusion model in Section 16.4.2. Both models are phenomenological concepts to describe
decision making. However, both models are also related to the phase diagram of the model
of two neuronal populations, encountered in Section 16.3.
16.4.1 The energy picture
Binary decisions can be visualized as a ball in a hilly energy landscape. Once the ball rolls
in a certain direction, a decision starts to form. The decision is ﬁnalized when the ball

434
Competing populations and decision making
approaches the energy minimum; see Fig. 16.9a. The decision variable x reﬂects a decision
for option A if it approaches a ﬁxed point in the neighborhood of x ≈1, and a decision for
option B for x ≈−1. If the variable x is trapped in a minimum close to x = 0, no decision
is taken.
The dynamics of the decision process can be formulated as gradient descent
dx
dt = −η dE
dx
(16.11)
with a positive constant η. In other words, in a short time step Δt, the decision variable
moves by an amount −ηΔt dE/dx. Thus, if the slope is positive, the movement is toward
the left. As a result, the movement is always downhill, so that the energy decreases along
the trajectory x(t). We can calculate the change of the energy along the trajectory:
dE(x(t))
dt
= dE
dx
dx
dt = −η
dE
dx
2
≤0.
(16.12)
Therefore the energy plays the role of a Liapunov function of the system, i.e., a quantity
that cannot increase along the trajectory of a dynamical system .
Interestingly, the energy picture can be related to the phase plane analysis of the two-
dimensional model that we encountered earlier in Figs. 16.6b and 16.7. The diagonal of
the phase plane plays the role of the boundary between the options A and B while the
variable x indicates the projection onto an axis orthogonal to the diagonal. Position x = 0
is the unbiased, undecided position on the diagonal; see Fig. 16.9. In the case of strong
unbiased input, the one-dimensional ﬂow diagram of the variable x presents a reasonable
summary of the ﬂow pattern in the two-dimensional system, because the saddle point in
the phase plane is attractive along the diagonal and is reached rapidly while the ﬂow in the
perpendicular direction is much slower (Wang et al., 2002; Bogacz et al., 2006; Wong and
Wang, 2006).
The above arguments regarding the Liapunov function of the network can be made more
precise and formulated as a general theorem (Cohen and Grossberg, 1983; Hopﬁeld, 1984).
We consider an arbitrary network of K neuronal populations 1 ≤j ≤K with population rate
Aj = g(h j) ≥0 where g is a gain function with derivative g′ > 0 and h follows the dynamics
τ dh j
dt = −h j +RIj +∑
k
wjkg(hk)
(16.13)
with ﬁxed inputs Ij. If the coupling is symmetric, i.e., wi j = wji, then the energy
E = −∑
i ∑
j
wi jAiA j −∑
i
Ai RIi +∑
i
 Ai
0
g−1(a)da
(16.14)
is a Liapunov function of the dynamics.
The proof follows by taking the derivative. We exploit the fact that wi j = w ji and apply

16.4 Alternative decision models
435
0
20
40
60
80
100
t[a.u.]
B
A
x[a.u.]
x0
tA
tB
Fig. 16.10 Drift-diffusion model. The decision variable x(t) starts from x0 and undergoes a biased
random walk toward one of the two thresholds, marked by horizontal dashed lines. In the ﬁrst trial
(thin solid line), the choice is option A and the reaction time indicated as tA. In another trial (thick
solid line) the trajectory hits, after a time tB the threshold for option B.
the chain rule dAi/dt = g′(hi)dhi/dt so as to ﬁnd
dE
dt =−∑
i

∑
j
wi jA j

g′(hi)dhi
dt −∑
i
RIi g′(hi)dhi
dt +∑
i
g−1(Ai)g′(hi)dhi
dt
=−τ∑
i
g′(hi)
dhi
dt
2
≤0.
(16.15)
In the second line we have used Eq. (16.13). Furthermore, since the neuronal gain function
stays below a biologically sustainable ﬁring rate g(x) ≤Amax, the energy is bounded from
below. Therefore the ﬂow of a symmetric network of interacting populations will always
converge to one of the stable ﬁxed points corresponding to an energy minimum, unless the
initial condition is chosen to lie on an unstable ﬁxed point, in which case the dynamics
stays there until it is perturbed by some input.
Example: Binary decision network revisited
The binary decision network of Eqs. (16.7) and (16.8) with effective inhibition α and
recurrent interactions w0 consists of two populations. Interactions are symmetric since
w12 = w21 = −α. Therefore the energy function
E = −w0[A2
1 +A2
2]+2αA1A2 −R[I1A1 +I2A2]+
 A1
0
g−1(x)dx+
 A2
0
g−1(y)dy
(16.16)
is a Liapunov function of the dynamics deﬁned in Eqs. (16.7) and (16.8). Since the
dynamics is bounded, there must be stable ﬁxed points.
16.4.2 Drift-diffusion model
The drift-diffusion model is a phenomenological model to describe choice preferences and
distributions of reaction times in binary decision making tasks (Ratcliff and Rouder, 1998).
At each trial of a decision experiment, a decision variable x is initialized at time t0 at a value

436
Competing populations and decision making
x(t0) = x0. Thereafter, the decision variable evolves according to
dx
dt = (IA −IB)+σξ(t)
(16.17)
where ξ(t) is Gaussian white noise of unit mean and variance σ2. An input IA > IB causes a
"drift" of the variable x toward positive values while the noise ξ leads to a "diffusion"-like
motion of the trajectory; hence the name "drift-diffusion model."
The reaction time is the time at which the variable x reaches one of two thresholds, ΘA
or ΘB, respectively (Fig. 16.10). For example tB, deﬁned by tB = min{t|x(t) = ΘB}, is the
reaction time in a trial where the choice falls on option B.
Parameters of the phenomenological drift-diffusion model are the values of thresholds
ΘA and ΘB, and the strength of the input IA −IB compared to that of the noise. The initial
condition x0 can be identical in all trials or chosen in each trial independently from a
small interval that reﬂects uncontrolled variations in the bias of the subject. The time t0 is
typically the moment when the subject receives the choice stimulus, but it is also possible to
start the drift-diffusion process a few milliseconds later so as to account for the propagation
delay from the sensors to the brain (Ratcliff and Rouder, 1998; Ratcliff and McKoon,
2008).
Example: Drift-diffusion model versus neuronal models
In the original formulation, the drift-diffusion model was used as a "black box," i.e., a
phenomenological model with parameters that can be ﬁtted to match the distribution of
reaction times and choice preferences to behavioral experiments. Interestingly, however,
variants of one-dimensional drift-diffusion models can be derived from the models of
neural populations with competitive interaction that we have discussed in earlier sections
of this chapter (Bogacz et al., 2006; Wong and Wang, 2006; Roxin and Ledberg, 2008).
The essential idea can be best explained in the energy picture; see Fig. 16.9. We assume
a small amount of noise. In the absence of input, the decision variable jitters around the
stable ﬁxed point x = 0. Its momentary value x ≈0 serves as an initial condition, once
the input is switched on. Suppose the input is strong but unbiased. Two new valleys
form around x ≈±1. However, in the neighborhood of x = 0 the landscape is ﬂat, so
that noise leads to a diffusive motion of the trajectory. A biased input IA > IB tilts the
energy landscape to the right which causes a corresponding drift term in the diffusion
process. The location where the slope of the valley becomes steep can be associated with
the threshold ΘA in the diffusion model.
16.5 Human decisions, determinism, and free will
In the previous section, we compared the process of decision making to a ball in
an energy landscape. However, as outlined in the introduction to this chapter, decision

16.5 Human decisions, determinism, and free will
437
Decision and movement
Preparation
x  a    r     h    q    e    f           y    t    u 
0
-3
-2
-1
Time [s]
g
1
(a)
(b)
Fig. 16.11 Decision processes and the notion of free will. (a) In a modern variant of the Libet exper-
iment (Libet, 1985), a subject lies in the fMRI-scanner while watching a rapid sequence of letters
(Soon et al., 2008) that appear at a rate of 2 Hz (top; horizontal axis shows time in seconds). The
subject spontaneously decides to move his left or right index ﬁnger and reports the letter he saw at
the moment when he felt the "urge to move" interpreted as the moment when he took a decision
(right; letter "g" deﬁnes time zero). However, already a few seconds earlier (e.g., when the letter "a"
was shown, left) the brain activity in frontal areas of the subject has a high correlation with his ﬁnal
decision; schematic ﬁgure, adapted from Soon et al. (2008) and Haggard (2008). (b) The decision
to move the left or right index ﬁnger is completely irrelevant, similar to a game where a decision
between two equivalent choices has to be made.
making incorporates a broad set of phenomena and processes (Rangel et al., 2008; Sanfey
and Chang, 2008). Here we sketch a link from the simpliﬁed model from decision making
to the bigger picture.
Adult humans in a state of normal health feel that they are in control of their actions:
"The street is too busy, therefore I decide to take the safer underground pathway"; "Because
there have been many accidents at this crossing, I decide to break early and be particularly
careful"; "I would rather prepare for the exams than go to the movies." We all know exam-
ples of consciously controlling our decisions and actions.
Voluntary control of actions can be understood in opposition to pure reﬂexes (Haggard,
2008). If the doctor hits the right spot on your knee, your foot moves without you intend-
ing it. If an object approaches your eyes from the front, you automatically move your head.
There are also cases where reﬂexes have been learned from experience. For example, dur-
ing your ﬁrst driving lessons you had to consciously control your foot in order to step on
the brakes when a red trafﬁc light appeared in front of your car. After years of experience,
you start to break even before you become aware of a conscious decision. Similarly, if you
are a good tennis player you will respond to a serve with an arm movement that was trained
so often that it has become as fast as a reﬂex. Nevertheless, you could decide to take back
control and try to inhibit your automatic response, if for some reason you want to disturb
your opponent. The feeling of voluntary control is what makes you feel responsible for the
things you do.
The movement of our arms and legs is controlled by muscles which in turn receive action
potentials from the brain via the spinal cord. The human cortex contains several areas

438
Competing populations and decision making
that are involved in voluntary actions. The question of where and how the brain controls
our decisions and represents our will has triggered the research ﬁeld of "neuroscience of
volition" (Haggard, 2008).
16.5.1 The Libet experiment
The classic experiment in the research ﬁeld of human volition was performed by Libet
(1985). In this experiment, subjects decide on their own when to move their right hand.
After each trial, subjects report when they felt the "urge to move," with respect to a rapidly
rotating hand of a clock. The reported "urge to move" is in fact about 200 ms earlier
than the actual movement. Most interestingly, however, electrical brain activity measured
by EEG recordings indicates that the brain exhibits signals of preparatory activity several
hundred milliseconds before the reported "urge to move." Thus, if we agree to interpret the
felt "urge to move" as the conscious decision to move the hand, then we must also accept
the fact that the brain has unconsciously prepared our decision.
A modern and debated variant of the Libet experiment is shown in Fig. 16.11a. The main
difference to the original Libet experiment (where the decision was limited to "move" or
"not move") is that subjects now hold two buttons, one in the left and the other in the right
hand (Soon et al., 2008). Subjects are free to decide when to move and press either of the
two buttons. While subjects perform the experiment, they watch a stream of letters at a rate
of two letters per second. At the end of each trial, they indicate at which letter they had
felt the "urge to move." The reported letter serves as a timing reference for the subsequent
analysis.
During the experiment, brain activity was recorded through functional magnetic reso-
nance imaging (fMRI). Using statistical pattern classiﬁcation techniques, the authors aimed
at predicting the ﬁnal response outcome (left or right) based on the activity patterns in local-
ized brain areas. If brain activity contained no cue about the ﬁnal decision, the prediction
would always be 50%. However, the authors found that activity patterns in fronto-polar cor-
tex 5 seconds before the reported "urge to move" allowed them to predict the ﬁnal choice
(left or right) with a precision of 55-60% (Soon et al., 2008) which is above chance but far
from a reliable prediction.
16.5.2 Relevant and irrelevant decisions - a critique
What, if anything, can we learn about decision making and volition from these and similar
experiments? In a naive interpretation, the results seem to suggest that the brain has taken
its own decision a long time before the subject becomes aware of it. As Wolfgang Prinz
puts it: "We don't do what we want, but we want what we do" (Prinz, 2004).
There is little doubt that our actions, plans, and wishes are represented in the brain. Our
childhood memories are stored in our brain; our knowledge of the world is memorized
in the brain; our values and priorities acquired through education, reading, understanding,

16.6 Summary
439
trial and error, or simply through being embedded in our culture, must also be stored in the
brain. Thus, a large fraction, if not all, of what we consider our conscious personality is
located in the brain.
Most actions where we care about our decision are relevant choices. The decision of
whether to take the risky shortcut across a busy street or the safer underground pathway
depends on what we have experienced in the past. Similarly, the decision in the board
game of Fig. 16.1a depends on the player's attitude toward risk, which has been formed
by previous experiences in similar situations. However, the decision task in the scientiﬁc
experiment of Libet (1985) or Soon et al. (2008) is a completely irrelevant one. Subjects
don't really care whether they move the left or right ﬁnger. The decision has nothing to
do with life-long experience or attitude toward risk. In cases like this one, any decision is
arbitrary and therefore easily inﬂuenced by noise. Think of the board game of Fig. 16.1a
and compare it with the situation in Fig. 16.11b. While the ﬁrst one asks for a decision
between a risky and a safe path, the second one poses an irrelevant choice. In the latter
case, we might, just for the sake of advancing the game, decide to go left, based on the
whim of the moment, but we know that right would do just as well.
Interestingly, even in the irrelevant situation of the experiment of Soon et al. (2008), the
predictive power of the brain activity ﬁve seconds before the conscious "urge to move" is
only in the range of 60%. Moreover, in a different experimental design, the subject could
"veto" at the last moment a previously prepared movement suggesting the possibility of
voluntary inhibition of actions that are only weakly predicted (Brass and Haggard, 2007).
Finally, there is also the problem of whether we can really identify a reported "urge to
move" with a precise moment of decision. If we take the picture of the ball in the energy
landscape, the ball starts to roll in a certain direction while still remaining in the ﬂat region.
But this does not yet imply a ﬁnal decision, because novel input could tilt the energy
landscape in the opposite direction.
16.6 Summary
Decisions are prepared and made in the brain so that numerous physiological correlates of
decision making can be found in the human and monkey cortex. The ﬁelds of cognitive neu-
roscience associated with these questions are called "neuroeconomics" and "neuroscience
of volition."
An inﬂuential computational model describes decision making as the competition of sev-
eral populations of excitatory neurons which share a common pool of inhibitory neurons.
Under suitable conditions, the explicit model of inhibitory neurons can be replaced by an
effective inhibitory coupling between excitatory populations. In a rate model, the compet-
itive interactions between two excitatory populations can be understood using phase plane
analysis. Equivalently, the decision process can be described as downward motion in an
energy landscape which plays the role of a Liapunov function. The energy picture is valid
for any rate model where all units of the network are coupled by symmetric interactions.
The drift-diffusion model, which has been used in the past as a black-box model for

440
Competing populations and decision making
reaction time distributions and choice preferences, can, under appropriate assumptions, be
related to a rate model of competitively interacting populations of neurons.
Literature
There are several accessible introductions to the problem of decision making in neuro-
economics (Platt and Huettel, 2008; Rangel et al., 2008; Glimcher et al., 2008). The
neurophysiological correlates of decision making are reviewed in Gold and Shadlen (2007),
Romo and Salinas (2003) and Deco et al. (2009, 2010).
The competitive model of decision making that we presented in this chapter is discussed
in Y. Wang et al. (2002) and Wong and Wang (2006), but competitive interaction through
inhibition is a much older topic in the ﬁeld of computational neuroscience and artiﬁcial
neural networks (Grossberg, 1969; Kohonen, 1984; Hertz et al., 1991; Haykin, 1994).
Competitive models of spiking neurons with shared inhibition have also been applied to
other tasks of perceptual decision making, (see e.g., Machens et al., 2005).
Energy as a Liapunov function for rate models of neurons has been introduced by Cohen
and Grossberg (1983). In the context of associative memories (to be discussed in the next
chapter) energy functions have been used for binary neuron models by Hopﬁeld (1982)
and for rate models by Hopﬁeld (1984).
Drift-diffusion models have been reviewed by Ratcliff and Rouder (1998) and Ratcliff
and McKoon (2008). The relation of drift-diffusion models to neuronal decision models
has been discussed by Bogacz et al. (2006) and Wong and Wang (2006) and has been
worked out in the general case by Roxin and Ledberg (2008).
A highly recommended overview of neuroscience around the questions of volition is
given by Haggard (2008), who reviews both the original Libet experiment (Libet, 1985)
and its modern variants. The fMRI study of Soon et al. (2008) is also accessible to the
non-specialized reader.
Exercises
1. Phase plane analysis of a binary decision process. Consider the following system (in unit-free
variables)
dhE,1
dt
=−hE,1 +(wEE −α)gE(hE,1)−α gE(hE,2)+hext
1 ,
(16.18)
dhE,2
dt
=−hE,2 +(wEE −α)gE(hE,2)−α gE(hE,1)+hext
2 ,
(16.19)
where α = 1 and wEE = 1.5. The function g(h) is piecewise linear: g(h) = 0 for h < −0.2; g(h) =
0.1+0.5h for −0.2 ≤h ≤0.2; g(h) = h for 0.2 < h < 0.8 g(h) = 0.4+0.5h for 0.8 ≤h ≤1.2;
and g(h) = 1 for h > 1.2.
(a) Draw the two nullclines (dh1/dt = 0 and dh2/dt = 0) in the phase plane with horizontal axis
h1 and vertical axis h2 for the case hext
1
= hext
2
= 0.8.
(b) Add ﬂow arrows on the nullclines.
(c) Set hext
1
= hext
2
= b and study the ﬁxed point on the diagonal h1 = h2 = h∗. Find an expression

16.6 Summary
441
for h∗(b) under the assumption that the ﬁxed point is in the region where g(h) = h. Analyze the
stability of this ﬁxed point.
(d) We now drop the assumption that the ﬁxed point is in the region where g(h) = h. Consider an
arbitrary sufﬁciently smooth function g(h) as well as arbitrary couplings α and wEE, and give a
formula for the ﬁxed point on the diagonal.
(e) Assume now that α = 0.75 and wEE = 1.5. Linearize about the ﬁxed point in (d) and calculate
the two eigenvalues.
Hint: Introduce a parameter β = 0.75g′(h∗).
(f) Show that the ﬁxed point is stable for g′(h∗) = 0 and unstable for g′(h∗) = 1. At which value
of β does it change stability?
(g) Describe in words your ﬁndings. What happens with a weak or a strong unbiased input to the
decision model?
2. Winner-take-all in artiﬁcial neural networks. Consider a network of formal neurons described
by activities Ak = (hk −1) for 1 ≤hk ≤2, Ak = 0 for hk < 1, and Ak = 1 for hk > 2. We write
Ak = gE(hk).
The update happens in discrete time according to
hk(t +Δt) = w0 g(hk(t))−α ∑
j̸=k
gE(hj(t))+hext
k (t).
(16.20)
The external input vanishes for t ≤0. For t > 0 the input to unit k is hext
k
= (0.5)k +1.0.
(a) Set w0 = 2 and α = 1. Follow the evolution of the activities for three time steps.
(b) What happens if you change α? What happens if you keep α = 1 but decrease w0?
(c) Derive sufﬁcient conditions so that the only ﬁxed point is Ak = δk,1, i.e., only the unit with the
strongest input is active. Assume that the maximal external input to the maximally excited neuron
is hext
k
≤2.
3. Energy picture. Consider the energy function
E(x) = [1−(IA +IB)]x2 + 1
4x4 +(IA −IB)x
(16.21)
where IA and IB are inputs in support of options A and B, respectively.
(a) Draw qualitatively the energy landscape in the absence of input, IA = IB = 0.
(b) Draw qualitatively the energy landscape for IB = 0 when IA takes one of the three values
{0.5,1.0,1.5}.
(c) Draw the energy landscape for IA = IB = c when c varies in the range [0.5,1.5].
(d) Determine the ﬂow Δx = −Δt η dE/dx for a small positive parameter η for all the relevant
cases from (a)-(c).
(e) Compare your results with Fig. 16.9.

17
Memory and attractor dynamics
Humans remember important events in their lives. You might be able to recall every detail
of your ﬁrst exam at college, or of your ﬁrst public speech, or of your ﬁrst day in kinder-
garten, or of the ﬁrst time you went to a new school after your family moved to a new
city. Human memory works with associations. If you hear the voice of an old friend on the
phone, you may spontaneously recall stories that you had not thought of for years. If you
are hungry and see a picture of a banana, you might vividly recall the taste and smell of a
banana ... and thereby realize that you are indeed hungry.
In this chapter, we present models of neural networks that describe the recall of pre-
viously stored items from memory. In Section 17.1 we start with a few examples of asso-
ciative recall to prepare the stage for the modeling work later on. In Section 17.2
we introduce an abstract network model of memory recall, known as the Hopﬁeld model.
We take this network as a starting point and add, in subsequent sections, some biological
realism to the model.
17.1 Associations and memory
A well-known demonstration of the strong associations which are deeply embedded in the
human brain is given by the following task. The aim is to respond as quickly as possible to
three questions. Think of the ﬁrst answer that comes to mind! Are you ready? Here are the
questions: (i) Can you give me an example of a color? (ii) Can you give me an example of
a tool? (iii) Can you give me an example of a fruit? For each of these, what was the very
ﬁrst example that came to your mind? Chances are high that your examples are "red" for
color and "hammer" for tool. In fact, most humans have particularly strong associations
from tool to hammer and from color to red. Regarding fruit, the cultural background plays
a more important role (apple, orange, banana), but since the text at the beginning of this
chapter mentioned bananas, you probably had a slightly stronger bias toward banana at
the moment when you answered the above questions than what you would have had under
normal circumstances. This bias through an earlier word or context is a highly signiﬁcant
effect, called "priming" in psychophysics.
Not surprisingly, the word "red" is associated with seeing the color red and vice versa.
If you read a list of words that contains names of colors, you are normally fast in doing

17.1 Associations and memory
443
I find it rea*l* amazin* t*at y*u ar* 
abl* to re*d  t*is tex* despit* th* 
fac* *hat more t*an t* ent* perc*n* 
of t** char* cte*s a*e mis*ing. 
*his mean* t*at you* brai* i* abl* 
** fill in missin* info* matio*.  
(a)
brain
brai*
atom
brace
brake 
brave 
brain
branch
brass
brain
(b)
Fig. 17.1 Memory recall cued by partial information. (a) Read it! (b) Schematic view of the recall
process. Your brain has memorized a list of words. Based on partial information and the context,
your brain is able to complete the missing characters.
so and do not experience any particular difﬁculty. Similarly, you can easily name the color
of objects. However, people ﬁnd it difﬁcult to name the ink color in lists of words that
contain entries such as red, green, blue, but are written in colors that are inconsistent with
the word (e.g., the word red is written in green, whereas the word green is written in blue).
In this case responses in the color-naming task are slower compared to naming the color
of geometric objects. The measurable difference in reaction time in naming the color of
(inconsistent) words compared to the color of objects is called the Stroop effect (Stroop,
1935; MacLeod, 1991). The association of the color "red" with the word red makes it
difﬁcult to name the ink color (e.g., green) in which the word red is written.
In this chapter we mainly focus on association in the sense of completing partial infor-
mation. Take a look at Fig. 17.1a. Nearly all words are incomplete, but your brain is able
to cope with this situation, just as you are able to follow a phone conversation over a noisy
line, recognize a noisy image of a handwritten character or associate the picture of an
orange with its taste to retrieve your concept of an orange as a tasty fruit.
17.1.1 Recall, recognition, and partial information
If half of an orange is hidden behind a coffee mug, you can still recognize it as an orange
based on the partial information you have. Recognition works because you have seen
oranges before and have memorized the concept "orange," including a prototypical image
of this fruit. More generally, when you see a noisy image of a known object (e.g., the letter
"T") your brain is able to retrieve from memory the prototype version of the object (e.g.,
an idealized "T"). Thus recognizing an object in a noisy environment involves the process
of "memory recall."
A highly simpliﬁed schematic view of memory recall based on partial information is
shown in Fig. 17.1b. The input (e.g., an incomplete word) is compared to a list of all
possible words. The most likely entry (i.e., the one which is most similar to the input) in
the list is given as the output of memory recall.
Similarly, noisy images of objects are recognized if the brain ﬁnds, among the mem-
orized items, one which is highly similar (Fig. 17.2). Let us call the "pure" noise-free
memory item a prototype pμ, where the index 1 ≤μ ≤M labels all different memory

444
Memory and attractor dynamics
Noisy
image
Full
Cue
Recall
Memory
network
image
(a)
(b)
Fig. 17.2 Recall and recognition as search for nearest prototype. (a) A letter "T" in a noisy image
(left) serves as a cue in order to recall a noise-free prototype letter "T" from the memory embedded
in a neural network. (b) Recognition of the input x (black star, representing a noisy "T") can be
interpreted as an algorithm that searches for the nearest prototype pα such that |x −pα| ≤|x −pμ|
for all μ, and pμ denotes all possible prototypes (gray circles). The dashed lines are the sets of points
with equal distance to two different prototypes.
items. The prototype can be visualized as a point in some high-dimensional space. A noisy
input cue x corresponds to another point in the same space. Suppose that we have a sim-
ilarity measure which enables us to calculate the distance |x −pμ| between the input cue
and each of the prototypes. A simple method of memory recall is a search algorithm that
goes through the list of all available prototypes to ﬁnd the nearest one. More formally, the
output of the recall process is the prototype pα with
|x−pα| ≤|x−pμ|
for all μ ,
(17.1)
which gives rise to a simple geometric picture (Fig. 17.2b).
The aim of this chapter is to replace the explicit algorithmic search for the nearest proto-
type by the dynamics of interacting neurons. Instead of an explicit algorithm working
through a list of stored prototypes, the mere cross-talk of neurons embedded in a large
network will ﬁnd the prototype that corresponds best to the noisy cue - in a highly dis-
tributed and automatic fashion, reminiscent of what we believe is happening in the brain
(Fig. 17.2a). Brain-style computation implements an implicit algorithm, as we shall see in
Sections 17.2 and 17.3.
17.1.2 Neuronal assemblies
Neural assemblies play a central role in the implicit algorithm for memory retrieval that
we will discuss in Section 17.2. Neuronal assemblies (Hebb, 1949) are subnetworks of
strongly connected neurons that, together, represent an abstract concept. For example, your
mental concept of a "banana" containing the mental image of its form, color, taste, and
texture could be represented by one assembly of strongly connected neurons, while another

17.1 Associations and memory
445
(a)
Sidney 
Sidney
opera 
SYDNEY
OPERA
20 Hz
1s
(b)
Fig. 17.3 Assemblies and responses to abstract concepts. (a) Schematic diagram of a network of 10
neurons containing two assemblies, deﬁned as strongly connected subgroups (thick solid and dashed
lines, respectively). Note that neuron 9 participates in both assemblies. Assemblies could represent
abstract mental concepts. (b) Response of a single unit in the human hippocampus (Quiroga et al.,
2005). The same neuron responds strongly to an image of the Sydney opera house and the words
"Sydney opera," but much more weakly to images of other landmarks such as the Pisa tower. Vertical
lines indicate the one-second period of stimulation with images of Sydney opera house, words, or
Pisa tower, respectively. The photographic images used in the real experiment are replaced here by
sketches. Adapted from Quiroga et al. (2005).
might represent your concept of Paris with mental pictures of the Eiffel Tower and the
Louvre, and yet another your concept of Sydney with its famous opera house.
The assembly as a subgroup of strongly connected neurons has been an inﬂuential theo-
retical notion, introduced by Hebb (1949). Do such assemblies exist? The short answer is:
We don't know. Neurons belonging to an assembly do not have to be neighbors but can be
widely distributed across one, or even several, brain areas. Experimentally, it is therefore
difﬁcult to check for the presence of an assembly as a group of neurons. However, Quiroga
et al. (2005) found individual neurons in human patients that code for abstract mental con-
cepts such as the Sydney opera house. These patients suffer from severe treatment-resistant
epilepsy which makes a surgical intervention necessary. In order to precisely locate the
focus of the epilepsy in relation to important brain areas (such as those for speech or motor
control), electrophysiological recordings are made while the patient performs various tasks.
In contrast to neurons in the visual cortex which respond in the presence of an appropriate
visual stimulus, single neurons in the medial temporal lobe of the human cortex (in par-
ticular, in the hippocampus) do not respond to a speciﬁc stimulus, but to a much broader
set of stimuli that are linked to the same mental concept. For example, the written word
"Sydney" and a picture of the opera house in Sydney both cause a response in the same
neuron (Fig. 17.3), which we can therefore interpret as one of the neurons belonging to the
assembly of neurons encoding the mental concept "Sydney."
Three aspects are worth emphasizing. First, it is unlikely that the neuron responding
to the Sydney opera house is the only one to do so. Therefore, we should not think of a
single neuron as representing a concept or memory item, but rather a group of neurons.

446
Memory and attractor dynamics
The idea that a single neuron represents one concept is sometimes called the "grandmother
cell" code: if the cell coding for grandmother were to die in our brain, our memory of
grandmother would disappear as well. At the current stage of research, neural codes based
on groups of cells are a more likely code than a grandmother cell code.
Second, the same neuron participates in several assemblies. In the recording sessions of
Quiroga et al. where a large collection of pictures of famous individuals and landmarks
were used, each unit showed strong responses to about 3% of the stimuli (Quiroga et al.,
2005).
Third, some, but not all, of the neurons showed prolonged responses that persisted after
the end of stimulus presentation. This could potentially indicate that a memory item is
retrieved and kept in the brain even after the stimulus has disappeared. All three aspects
play a role in the memory model discussed in Section 17.2.
17.1.3 Working memory and delayed matching-to-sample tasks
In contrast to long-term memory, items in working memory do not have to be kept for a
lifetime. For example, humans use their working memory when they write down a phone
number that they just received or search in the supermarket for items on their shopping
list. Neural activity during working memory tasks has been recorded in monkeys, in the
particular in the prefrontal and inferotemporal cortex (Miyashita, 1988a; Fuster and Jervey,
1982; Miller and Cohen, 2001). In a delayed matching-to-sample task, a monkey has to
indicate whether a second stimulus is, or is not, identical to a ﬁrst stimulus received one or
several seconds earlier.
To correctly perform the task, the monkey has to remember the sample stimulus during
the delay period where no stimulation is given. Some neurons in the prefrontal cortex show
sustained activity during the delay period (Fig. 17.4a). This has been interpreted as a neural
signature of working memory. During the delay period, the time course of neural activity
varies widely between different objects for one neuron (Fig. 17.4b). and across a population
of neurons (Rainer and Miller, 2002), which indicates that simple models such as the ones
discussed in this chapter do not explain all aspects of working memory.
17.2 Hopﬁeld model
The Hopﬁeld model (Hopﬁeld, 1982), consists of a network of N neurons, labeled by a
lower index i, with 1 ≤i ≤N. Similar to some earlier models (McCulloch and Pitts, 1943;
Little, 1974; Willshaw et al., 1969), neurons in the Hopﬁeld model have only two states. A
neuron i is "ON" if its state variable takes the value Si = +1 and "OFF" (silent) if Si = −1.
The dynamics evolve in discrete time with time steps Δt. There is no refractoriness and the
duration of a time step is typically not speciﬁed. If we take Δt = 1 ms, we can interpret
Si(t) = +1 as an action potential of neuron i at time t. If we take Δt = 500 ms, Si(t) = +1
should rather be interpreted as an episode of high ﬁring rate.

17.2 Hopﬁeld model
447
1s
Sample
Match
10Hz
(a)
Match
Sample
500 ms
10 Hz
R
(b)
Fig. 17.4 Delayed matching-to-sample task. (a) PSTH of a neuron in the anterior ventral temporal
cortex in a visual working memory task. The monkey has to indicate whether a ﬁrst stimulus (sample,
presented for 0.2 s at time marked by arrow) is identical to a second one which can be either a
matching (arrow) or an unfamiliar stimulus; adapted from Miyashita (1988a). (b) PSTH of a single
neuron in the prefrontal cortex in response to two different images, one object (dashed line) and one
different noise pattern (solid line). Sample stimuli were presented for 650 ms. After a delay period
of 1 s, a matching stimulus was presented. "R" marks a period when responses tend to recover after
a transient dip. Vertical axis: ﬁring rate measured with respect to baseline activity. Adapted from
Rainer and Miller (2002).
Neurons interact with each other with weights wi j. The input potential of neuron i, inﬂu-
enced by the activity of other neurons is
hi(t) = ∑
j
wi j S j(t).
(17.2)
The input potential at time t inﬂuences the probabilistic update of the state variable Si in
the next time step:
Prob{Si(t +Δt) = +1|hi(t)} = g(hi(t)) = g
!
∑
j
wi j S j(t)
"
,
(17.3)
where g is a monotonically increasing gain function with values between zero and 1. A
common choice is g(h) = 0.5[1 + tanh(βh)] with a parameter β. For β →∞, we have
g(h) = 1 for h > 0 and zero otherwise. The dynamics are therefore deterministic and sum-
marized by the update rule
Si(t +Δt) = sgn[h(t)].
(17.4)
For ﬁnite β the dynamics are stochastic. In the following we assume that in each time step
all neurons are updated synchronously (parallel dynamics), but an update scheme where
only one neuron is updated per time step is also possible.
The aim of this section is to show that, with a suitable choice of the coupling matrix wi j,
memory items can be retrieved by the collective dynamics deﬁned in Eq. (17.3), applied
to all N neurons of the network. In order to illustrate how collective dynamics can lead

448
Memory and attractor dynamics
S
N
(a)
Impure
magnet
Pure
magnet
(b)
Fig. 17.5 Physics of ferromagnets. (a) Magnetic materials consist of atoms, each with a small mag-
netic moment, here visualized as an arrow, a symbol for a magnetic needle. At low temperature,
all magnetic needles are aligned. Inset: Field lines around one of the magnetic needles. (b) At high
temperature, some of the needles are misaligned (dashed circles). Cooling the magnet leads to a
spontaneous alignment and reforms a pure magnet. Schematic ﬁgure.
to meaningful results, we start, in Section 17.2.1, with a detour through the physics of
magnetic systems. In Section 17.2.2, the insights from magnetic systems are applied to the
case at hand, i.e., memory recall.
17.2.1 Detour: magnetic analogy
Magnetic material contains atoms which carry a so-called spin. The spin generates a mag-
netic moment at the microscopic level visualized graphically as an arrow (Fig. 17.5a). At
high temperature, the magnetic moments of individual atoms point in all possible direc-
tions. Below a critical temperature, however, the magnetic moment of all atoms sponta-
neously align with each other. As a result, the microscopic effects of all atomic magnetic
moments add up and the material exhibits the macroscopic properties of a ferromagnet.
In order to understand how a spontaneous alignment can arise, let us study Eqs. (17.2)
and (17.3) in the analogy of magnetic materials. We assume that wi j = w0 > 0 between all
pairs of neurons i ̸= j, and that self-interaction vanishes, wii = 0.
Each atom is characterized by a spin variable Si = ±1 where Si = +1 indicates that the
magnetic moment of atom i points "upward." Suppose that, at time t = 0, all spins take a
positive value (SI = +1), except that of atom i which has a value Si(0) = −1 (Fig. 17.5a).
We calculate the probability that, at time step t = Δt, the spin of neuron i will switch to
Si = +1. This probability is according to Eq. (17.3)
Prob{Si(t +Δt) = +1|hi(t)} = g(hi(t)) = g
!
N
∑
j=1
wi j Sj(t)
"
= g(w0 (N −1)),
(17.5)
where we have used our assumptions. With g(h) = 0.5[1 + tanh(βh)] and w0 = β = 1,
we ﬁnd that, for any network of more than three atoms, the probability that the magnetic
moments of all atoms would align is extremely high. In physical systems, β plays the role

17.2 Hopﬁeld model
449
of an inverse temperature. If β becomes small (high temperature), the magnetic moments
no longer align and the material loses its spontaneous magnetization.
According to Eq. (17.5) the probability of alignment increases with the network size.
This is an artifact of our model with all-to-all interaction between all atoms. Physical inter-
actions, however, rapidly decrease with distance, so that the sum over j in Eq. (17.5) should
be restricted to the nearest neighbors of neuron i, e.g., about 4 to 20 atoms depending on
the conﬁguration of the atomic arrangement and the range of the interaction. Interestingly,
neurons, in contrast to atoms, are capable of making long-range interactions because of
their far-reaching axonal cables and dendritic trees. Therefore, the number of topological
neighbors of a given neuron is in the range of thousands.
An arrangement of perfectly aligned magnetic elements looks rather boring, but physics
offers more interesting examples as well. In some materials, typically consisting of two
different types of atoms, say A and B, an anti-ferromagnetic ordering is possible (Fig.
17.6). While one layer of magnetic moments points upward, the next one points downward,
so that the macroscopic magnetization is zero. Nevertheless, a highly ordered structure is
present. Examples of anti-ferromagnets are some metallic oxides and alloys.
To model an anti-ferromagnet, we choose interactions wi j = +1 if i and j belong to the
same class (e.g., both are in a layer of type A or both in a layer of type B), and wi j = −1
if one of the two atoms belongs to type A and the other to type B. A simple repetition
of the calculation in Eq. (17.5) shows that an anti-ferromagnetic organization of the spins
emerges spontaneously at low temperature.
The same idea of positive and negative interactions wi j can be used to embed an arbi-
trary pattern into a network of neurons. Let us draw a pattern of black and white pixels
corresponding to active (pi = +1) and inactive (pi = −1) neurons, respectively. The rule
extracted from the anti-ferromagnet implies that pixels of opposite color are connected by
negative weights, while pixels of the same color have connections with positive weight.
This rule can be formalized as
wi j = pi pj .
(17.6)
This rule forms the basis of the Hopﬁeld model.
17.2.2 Patterns in the Hopﬁeld model
The Hopﬁeld model consists of a network of N binary neurons. A neuron i is characterized
by its state Si = ±1. The state variable is updated according to the dynamics deﬁned in Eq.
(17.3).
The task of the network is to store and recall M different patterns. Patterns are labeled
by the index μ with 1 ≤μ ≤M. Each pattern μ is deﬁned as a desired conﬁguration

pμ
i = ±1;1 ≤i ≤N

. The network of N neurons is said to correctly represent pattern μ,
if the state of all neurons 1 ≤i ≤N is Si(t) = Si(t +Δt) = pμ
i . In other words, patterns must
be ﬁxed points of the dynamics (17.3).
For us as human observers, a meaningful pattern could, for example, be a conﬁguration

450
Memory and attractor dynamics
A 
B A B 
A 
B A B A 
(a)
(b)
Fig. 17.6 Storing patterns. (a) Physical anti-ferromagnets consist of layers of atoms A and B. All
magnetic moments are aligned within a layer of identical neurons, but exhibit different orientations
between layers. A model where interactions within atoms of the same type are positive (solid lines)
and interactions between atoms of different type are negative (dashed lines) can explain the sponta-
neous order in the arrangement of magnetic moments. The interaction scheme for two atoms with
their ten nearest neighbors is indicated. (b) If we replace magnetic moments by black and white
pixels (squares), represented by active and inactive neurons, respectively, the neuronal network can
store a pattern, such as T. Interactions are positive (solid lines) between pixels of the same color
(black-to-black or white-to-white) and negative otherwise. Only a few representative interactions are
shown. Schematic ﬁgure.
in form of a "T," such as depicted in Fig. 17.6b. However, visually attractive patterns have
large correlations between each other. Moreover, areas in the brain related to memory
recall are situated far from the retinal input stage. Since the conﬁguration of neurons in
memory-related brain areas is probably very different from those at the retina, patterns in
the Hopﬁeld model are chosen as ﬁxed random patterns; see Fig. 17.7.
During the set-up phase of the Hopﬁeld network, a random number generator generates,
for each pattern μ, a string of N independent binary numbers {pμ
i = ±1;1 ≤i ≤N} with
expectation value ⟨pμ
i ⟩= 0. Strings of different patterns are independent. The weights are
chosen as
wi j = c
M
∑
μ=1
pμ
i pμ
j ,
(17.7)
with a positive constant c > 0. The network has full connectivity. Note that for a single
pattern and c = 1, Eq. (17.7) is identical to the connections of the anti-ferromagnet, Eq.
(17.6). For reasons that become clear later on, the standard choice of the constant c is
c = 1/N.

17.2 Hopﬁeld model
451
1 
2       ...  
N 
i    ... 
1 
2       ...  
N 
i    ... 
S(t)
(a)
m = 1
m = 2
m = 3
m = 1
1 
2       ...  
N
i    ... 
m =1
m =2
m =3
m
n
(b)
Fig. 17.7 Hopﬁeld model. (a) Top: Three random patterns μ = 1,2,3 in a network of N = 8 neurons.
Black squares (pμ
i = +1) and white squares (pμ
i = −1) are arranged in random order. Bottom: The
overlap m1 = (1/N)∑i p1
i Si(t) measures the similarity between the current state S(t) = {Si(t);1 ≤
i ≤N} and the ﬁrst pattern. Here only a single neuron exhibits a mismatch (dotted line). The desired
value in the pattern is shown as black and white squares, while the current state is indicated as black
and white circles. Schematic ﬁgure. (b) Orthogonal patterns have a mutual overlap of zero so that
correlations are Cμν = (1/N)∑i pμ
i pν
i = δ μν (top) whereas random patterns exhibit a small residual
overlap for μ ̸= ν (bottom).
17.2.3 Pattern retrieval
In many memory retrieval experiments, a cue with partial information is given at the begin-
ning of a recall trial. The retrieval of a memory item is veriﬁed by the completion of the
missing information.
To mimic memory retrieval in the Hopﬁeld model, an input is given by initializing the
network in a state S(t0) = {Si(t0);1 ≤i ≤N}. After initialization, the network evolves
freely under the dynamics (17.3). Ideally the dynamics should converge to a ﬁxed point
corresponding to the pattern μ which is most similar to the initial state.
To measure the similarity between the current state S(t) = {Si(t);1 ≤i ≤N} and a
pattern μ, we introduce the overlap (Fig. 17.7a)
mμ(t) = 1
N ∑
i
pμ
i Si(t).
(17.8)
The overlap takes a maximum value of 1 if Si(t) = pμ
i , i.e., if the pattern is retrieved. It
is close to zero if the current state has no correlation with pattern μ. The minimum value
mμ(t) = −1 is achieved if each neuron takes the opposite value to that desired in pattern
μ.
The overlap plays an important role in the analysis of the network dynamics. In fact,
using Eq. (17.2) the input potential hi of a neuron i is
hi(t) = ∑
j
wi j Sj(t) = c
N
∑
j=1
M
∑
μ=1
pμ
i pμ
j S j(t) = cN
M
∑
μ=1
pμ
i mμ(t),
(17.9)
where we have used Eqs. (17.7) and (17.8). To make the results of the calculation

452
Memory and attractor dynamics
independent of the size of the network, it is standard to choose the factor c = 1/N, as
mentioned above. In what follows we always take c = 1/N unless indicated otherwise. For
an in-depth discussion, see the scaling arguments in Chapter 12.
To close the argument, we now use the input potential in the dynamics equation (17.3)
and ﬁnd
Prob{Si(t +Δt) = +1|hi(t)} = g

M
∑
μ=1
pμ
i mμ(t)

.
(17.10)
Equation (17.10) highlights that the M macroscopic similarity values mμ with 1 ≤μ ≤M
completely determine the dynamics of the network.
Example: Memory retrieval
Let us suppose that the initial state has a signiﬁcant similarity with pattern μ = 3, for
example an overlap of mμ(t0) = 0.4 and no overlap with the other patterns mν = 0 for
ν ̸= 3.
In the noiseless case Eq. (17.10) simpliﬁes to
Si(t0 +Δt) = sgn

M
∑
μ=1
pμ
i mμ

= sgn

p3
i m3(t0)

= p3
i
for all i.
(17.11)
Hence, each neuron takes, after a single time step, the desired state corresponding to the
pattern. In other words, the pattern with the strongest similarity to the input is retrieved,
as it should be.
For stochastic neurons we ﬁnd
Prob{Si(t0 +Δt) = +1|hi(t)} = g[p3
i m3(t0)].
(17.12)
We note that, given the overlap m3(t0), the right-hand side of Eq. (17.12) can take only
two different values, corresponding to p3
i = +1 and p3
i = −1. Thus, all neurons that
should be active in pattern 3 share the same probabilistic update rule:
Prob{Si(t0 +Δt) = +1|hi(t)} = g[m3(t0)]
for all i with p3
i = +1.
(17.13)
Similarly all those that should be inactive share another rule:
Prob{Si(t0 +Δt) = +1|hi(t)} = g[−m3(t0)]
for all i with p3
i = −1.
(17.14)
Thus, despite the fact that there are N neurons and M different patterns, during recall
the network breaks up into two macroscopic populations: those that should be active
and those that should be inactive. This is the reason why we can expect to arrive at
macroscopic population equations, similar to those encountered in Part III of the book.
Let us use this insight for the calculation of the overlap at time t0 +Δt. We denote the
size of the two populations (active, inactive) by N3
+ and N3
−, respectively, and ﬁnd

17.2 Hopﬁeld model
453
mn(t0)
mn(t + Dt)
(a)
1
0
-1
Perror
(b)
s
Fig. 17.8 Memory retrieval in the Hopﬁeld model. (a) The overlap mν(t +Δt) with a speciﬁc pattern
ν is given as a function of the overlap with the same pattern mν(t) in the previous time step (solid
line); see Eq. (17.16). The overlap with the M −1 other patterns is supposed to vanish. The iterative
update can be visualized as a path (arrow) between the overlap curve and the diagonal (dashed line).
The dynamics approach a ﬁxed point (circle) with high overlap corresponding to the retrieval of the
pattern. (b) The probability Perror that during retrieval an erroneous state ﬂip occurs corresponds to
the shaded area under the curve; see Eq. (17.20). The width σ of the curve is proportional to the
pattern load M/N. Schematic ﬁgure.
m3(t0 +Δt) = 1
N ∑
i
p3
i Si(t0 +Δt)
(17.15)
= N3
+
N
⎡
⎣1
N3
+
∑
i with p3
i =+1
Si(t0 +Δt)
⎤
⎦−N3
−
N
⎡
⎣1
N3
−
∑
i with p3
i =+1
Si(t0 +Δt)
⎤
⎦.
We can interpret the two terms enclosed by the square brackets as the average activity
of those neurons that should, or should not, be active, respectively. In the limit of a
large network (N →∞) both groups are very large and of equal size N3
+ = N3
−= N/2.
Therefore, the averages inside the square brackets approach their expectation values.
The technical term, used in the physics literature, is that the network dynamics are "self-
averaging." Hence, we can evaluate the square brackets with probabilities introduced in
Eqs. (17.13) and (17.14). With Prob{Si(t0 + Δt) = −1|hi(t)} = 1 −Prob{Si(t0 + Δt) =
+1|hi(t)}, we ﬁnd
m3(t0 +Δt) = 1
2 {2g[m3(t0)]−1}−1
2 {2g[−m3(t0)]−1}.
(17.16)
In the special case that g(h) = 0.5[1+tanh(βh)] Eq. (17.16) simpliﬁes to an update law
m3(t +Δt) = tanh[β m3(t)],
(17.17)
where we have replaced t0 by t, in order to highlight that updates should be iterated over
several time steps.
We close with three remarks. First, the dynamics of N neurons has been replaced, in a
mathematically precise limit, by the iterative update of one single macroscopic variable,
i.e., the overlap with one of the patterns. The result is reminiscent of the analysis of the

454
Memory and attractor dynamics
macroscopic population dynamics performed in Part III of the book. Indeed, the basic
mathematical principles used for the equations of the population activity A(t) are the same
as the ones used here for the update of the overlap variable mμ(t).
Second, if β > 1, the dynamics converge from an initially small overlap to a ﬁxed point
with a large overlap, close to 1. The graphical solution of the update of pattern ν = 3
(for which a nonzero overlap existed in the initial state) is shown in Fig. 17.8. Because
the network dynamics is "attracted" toward a stable ﬁxed point characterized by a large
overlap with one of the memorized patterns (Fig. 17.9a), the Hopﬁeld model and variants
of it are also called "attractor" networks or "attractor memories" (Amit, 1989; Barbieri and
Brunel, 2008).
Finally, the assumption that, apart from pattern 3, all other patterns have an initial overlap
exactly equal to zero is artiﬁcial. For random patterns, we expect a small overlap between
arbitrary pairs of patterns. Thus, if the network is exactly in pattern 3 so that m3 = 1,
the other patterns have a small but ﬁnite overlap |mμ| ̸= 0, because of spurious correlations
Cμν = (1/N)∑i pμ
i pν
i between any two random patterns μ and ν; Fig. 17.7b. If the number
of patterns is large, the spurious correlations between the patterns can generate problems
during memory retrieval, as we shall see now.
17.2.4 Memory capacity
How many random patterns can be stored in a network of N neurons? Memory retrieval
implies pattern completion, starting from a partial cue. An absolutely minimal condition
for pattern completion is that at least the dynamics should not move away from the pattern,
if the initial cue is identical to the complete pattern (Hertz et al., 1991). In other words,
we require that a network with initial state Si(t0) = pν
i for 1 ≤i ≤N stays in pattern ν.
Therefore pattern ν must be a ﬁxed point under the dynamics.
We study a Hopﬁeld network at zero temperature (β = ∞). We start the calculation as in
Eq. (17.9) and insert Sj(t0) = pν
j . This yields
Si(t0 +Δt) = sgn

1
N
N
∑
j=1
M
∑
μ=1
pμ
i pμ
j pν
j

= sgn

pν
i
!
1
N
N
∑
j=1
pν
j pν
j
"
+ 1
N ∑
μ̸=ν∑
j
pμ
i pμ
j pν
j

,
(17.18)
where we have separated the pattern ν from the other patterns. The factor in parentheses on
the right-hand side adds up to 1 and can therefore be dropped. We now multiply the second
term on the right-hand side by a factor 1 = pν
i pν
i . Finally, because pν
i = ±1, a factor pν
i
can be pulled out of the argument of the sign-function:
Si(t0 +Δt) = pν
i sgn

1+ 1
N ∑
j ∑
μ̸=ν
pμ
i pν
i pμ
j pν
j

= pν
i sgn[1−aiν].
(17.19)

17.2 Hopﬁeld model
455
The desired ﬁxed point exists only if 1 > aiν = 1
N ∑j ∑μ̸=ν pμ
i pν
i pμ
j pν
j for all neurons i. In
other words, even if the network is initialized in perfect agreement with one of the patterns,
it can happen that one or a few neurons ﬂip their sign. The probability of moving away from
the pattern is equal to the probability of ﬁnding a value aiν > 1 for one of the neurons i.
Because patterns are generated from independent random numbers pμ
i = ±1 with zero
mean, the product pμ
i pν
i pμ
j pν
j = ±1 is also a binary random number with zero mean.
Since the values pμ
i are chosen independently for each neuron i and each pattern μ, the
term aiν can be visualized as a random walk of N (M −1) steps and step size 1/N. For a
large number of steps, the positive or negative walking distance can be approximated by a
Gaussian distribution with zero mean and standard deviation σ =

(M −1)/N ≈

M/N
for M ≫1. The probability that the activity state of neuron i erroneously ﬂips is therefore
proportional to (Fig. 17.86)
Perror =
1
√
2πσ
 ∞
1 e
−x2
2σ2 dx ≈1
2

1−erf
!*
N
2M
"
,
(17.20)
where we have introduced the error function
erf(x) =
1
√π
 x
0 e−y2 dy.
(17.21)
The most important insight is that the probability of an erroneous state ﬂip increases with
the ratio M/N. Formally, we can deﬁne the storage capacity Cstore of a network as the
maximal number Mmax of patterns that a network of N neurons can retrieve
Cstore = Mmax
N
= Mmax N
N2
.
(17.22)
For the second equality sign we have multiplied both numerator and denominator by a
common factor N which gives rise to the following interpretation. Since each pattern con-
sists of N neurons (i.e., N binary numbers), the total number of bits that need to be stored at
maximum capacity is Mmax N. In the Hopﬁeld model, patterns are stored by an appropriate
choice of the synaptic connections. The number of available synapses in a fully connected
network is N2. Therefore, the storage capacity measures the number of bits stored per
synapse.
Example: Erroneous bits
We can evaluate Eq. (17.20) for various choices of Perror. For example, if we accept
an error probability of Perror = 0.001, we ﬁnd a storage capacity of Cstore = 0.105.
Hence, a network of 10 000 neurons is capable of storing about 1000 patterns with
Perror = 0.001. Thus in each of the patterns, we expect that about 10 neurons exhibit
erroneous activity. We emphasize that the above calculation focuses on the ﬁrst iteration
step only. If we start in the pattern, then about 10 neurons will ﬂip their state in the ﬁrst
iteration. But these ﬂips could in principle cause further neurons to ﬂip in the second
iteration and eventually initiate an avalanche of many other changes.

456
Memory and attractor dynamics
m  = 1
3
m17=1 
(a)
E
m   = 1
17
m  = 1
3
(b)
Fig. 17.9 Attractor picture and energy landscape. (a) The dynamics are attracted toward ﬁxed points
corresponding to memory states (overlap mν = 1). Four attractor states are indicated. The dashed
lines show the boundaries of the basin of attraction of each memory. (b) The Hopﬁeld model has
multiple equivalent energy minima, each one corresponding to the retrieval (overlap mν = 1) of one
pattern. Between the main minima, additional local minima (corresponding to mixtures of several
patterns) may also exist.
A more precise calculation shows that such an avalanche does not occur if the number
of stored patterns stays below a limit such that Cstore = 0.138 (Amit et al., 1985, 1987b).
17.2.5 The energy picture
The Hopﬁeld model has symmetric interactions wi j = wji = c∑M
μ=1 pμ
i pμ
j . We now show
that, in any network with symmetric interactions and asynchronous deterministic dynamics
Si(t +Δt) = sgn[h(t)] = sgn

∑
j
wi j S j(t)

,
(17.23)
the energy
E = −∑
i ∑
j
wi j Si S j
(17.24)
decreases with each state ﬂip of a single neuron (Hopﬁeld, 1982).
In each time step only one neuron is updated (asynchronous dynamics). Let us assume
that after application of Eq. (17.23) neuron k has changed its value from Sk at time t to
S′
k = −Sk while all other neurons keep their value S′
j = S j for j ̸= k. The prime indicates
values evaluated at time t +Δt. The change in energy caused by the state ﬂip of neuron k is
E′ −E = −∑
i
wik Si (S′
k −Sk)−∑
j
wk j S j (S′
k −Sk).
(17.25)
First, because of the update of neuron k, we have S′
k −Sk = 2S′
k. Second, because of the
symmetry wi j = wji, the two terms on the right-hand side are identical, and ∑i wikSi =
∑i wkiSi = hk. Third, because of Eq. (17.23), the sign of hk determines the new value S′
k of

17.2 Hopﬁeld model
457
neuron k. Therefore the change in energy is E′ −E = −4hk sgnhk < 0. In other words, the
energy E is a Liapunov function of the deterministic Hopﬁeld network.
Since the dynamics leads to a decrease of the energy, we may wonder whether we can
say something about the global or local minimum of the energy. If we insert the deﬁnition
of the connection weights into the energy function (17.24), we ﬁnd
E = −∑
i ∑
j
!
c∑
μ
pμ
i pμ
j
"
Si S j = −cN2∑
μ
(mμ)2 ,
(17.26)
where we have used the deﬁnition of the overlap; see Eq. (17.8).
The maximum value of the overlap with a ﬁxed pattern ν is mν = 1. Moreover, for
random patterns, the correlations between patterns are small. Therefore, if mν = 1 (i.e.,
recall of pattern ν) the overlap with other patterns μ ̸= ν is mμ ≈0. Therefore, the energy
landscape can be visualized with multiple minima of the same depth, each minimum cor-
responding to retrieval of one of the patterns (Fig. 17.9b).
17.2.6 Retrieval of low-activity patterns
There are numerous aspects in which the Hopﬁeld model is rather far from biology. One
of these is that, in each memory pattern, 50% of the neurons are active.
To characterize patterns with a lower level of activity, let us introduce random variables
ξ μ
i ∈{0,1} for 1 ≤i ≤N and 1 ≤μ ≤M with mean ⟨ξ μ
i ⟩= a. For a = 0.5 and pμ
i =
2ξ μ
i −1 we are back to the patterns in the Hopﬁeld model. In the following we are, however,
interested in patterns with an activity a < 0.5. To simplify some of the arguments below,
we suppose that patterns are generated under the constraint ∑i ξ μ
i = N a for each μ, so that
all patterns have exactly the same target activity a.
The weights in the Hopﬁeld model of Eq. (17.7) are replaced by
wi j = c′
M
∑
μ=1
(ξ μ
i −b)(ξ μ
j −a),
(17.27)
where a is the mean activity of the stored patterns, 0 ≤b ≤1 a constant, and c′ =
[2a(1 −a)N]−1. Note that Eq. (17.7) is a special case of Eq. (17.27) with a = b = 0.5
and c′ = 2c.
As before, we work with binary neurons Si = ±1 deﬁned by the stochastic update rule in
Eqs. (17.2) and (17.3). To analyze pattern retrieval we proceed analogously to Eq. (17.10).
Introducing the overlap of low-activity patterns
mμ =
1
2a(1−a)N ∑
j
(ξ μ
j −a)Sj,
(17.28)
we ﬁnd
Prob{Si(t +Δt) = +1|hi(t)} = g

M
∑
μ=1
(ξ μ
i −b)mμ(t)

.
(17.29)

458
Memory and attractor dynamics
Example: Memory retrieval and attractor dynamics
Suppose that at time t the overlap with one of the patterns, say pattern 3, is signiﬁ-
cantly above zero while the overlap with all other patterns vanishes mμ ≈mδ μ3, where
δ nm denotes the Kronecker-δ. The initial overlap is 0.1 < m ≤1. Then the dynamics of
the low-activity networks split up into two groups of neurons, i.e., those that should be
"ON" in pattern 3 (ξ 3
i = 1) and those that should be "OFF" (ξ 3
i = 0).
The size of both groups scales with N: there are a · N "ON" neurons and (1 −a) · N
"OFF" neurons. For N →∞, the population activity AON of the "ON" group (i.e., the
fraction of neurons with state Si = +1 in the "ON" group) is therefore well described by
its expectation value
AON(t +Δt) = g[(1−b)m3(t)].
(17.30)
Similarly, the "OFF" group has activity
AOFF(t +Δt) = g[(−b)m3(t)].
(17.31)
To close the argument we determine the overlap at time t + Δt. Exploiting the split
into two groups of size a·N and (1−a)·N, respectively, we have
m3(t +Δt) =
1
2a(1−a)N
⎡
⎣
∑
j with ξ 3
j =1
(1−a)Sj(t +Δt)+
∑
j with ξ 3
j =0
(−a)Sj(t +Δt)
⎤
⎦
= 1
2

AON(t +Δt)−AOFF(t +Δt)

.
(17.32)
Thus, the overlap with pattern 3 has changed from the initial value m3(t) = m to a new
value m3(t +Δt). Retrieval of memories works if iteration of Eqs. (17.30)-(17.32) makes
m3 converge to a value close to unity while, at the same time, the other overlaps mν (for
ν ̸= 3) stay close to zero.
We emphasize that the analysis of the network dynamics presented here does not
require symmetric weights but is possible for arbitrary values of the parameter b. How-
ever, a standard choice is b = a, which leads to symmetric weights and to a high memory
capacity (Tsodyks and Feigelman, 1986).
17.3 Memory networks with spiking neurons
The Hopﬁeld model is an abstract conceptual model and rather far from biological reality.
In this section we aim at pushing the abstract model in the direction of increased biological
plausibility. We focus on two aspects. In Section 17.3.1 we replace the binary neurons of
the Hopﬁeld model with spiking neuron models of the class of Generalized Linear Models
or Spike Response Models; see Chapter 9. Then, in Section 17.3.2 we ask whether it is
possible to store multiple patterns in a network where excitatory and inhibitory neurons
are functionally separated from each other.

17.3 Memory networks with spiking neurons
459
17.3.1 Activity of spiking networks
Neuron models such as the Spike Response Model with escape noise, formulated in the
framework of Generalized Linear Models, can predict spike times of real neurons to a
high degree of accuracy; see Chapters 9 and 11. We therefore choose the Spike Response
Model (SRM) as our candidate for a biologically plausible neuron model. Here we use
these neuron models to analyze the macroscopic dynamics in attractor memory networks
of spiking neurons.
As discussed in Chapter 9, the membrane potential ui of a neuron i embedded in a large
network can be described as
ui(t) = ∑
f
η(t −t f
i )+hi(t)+urest,
(17.33)
where η(t −t f
i ) summarizes the refractoriness caused by the spike-afterpotential and hi(t)
is the (deterministic part of the) input potential
hi(t) = ∑
j
wi jε(t −t f
j ) = ∑
j
wi j
 ∞
0 ε(s)Sj(t −s)ds.
(17.34)
Here i denotes the postsynaptic neuron, wi j is the coupling strength from a presynaptic
neuron j to i, and S j(t) = ∑f δ(t −t f
j ) is the spike train of neuron j.
Statistical ﬂuctuations in the input as well as intrinsic noise sources are both incorporated
into an escape rate (or stochastic intensity) ρi(t) of neuron i,
ρi(t) = f(ui(t)−ϑ),
(17.35)
which depends on the momentary distance between the (noiseless) membrane potential
and the threshold ϑ.
In order to embed memories in the network of SRM neurons we use Eq. (17.27) and
proceed as in Section 17.2.6. There are three differences compared to the previous section:
First, while previously Sj denoted a binary variable ±1 in discrete time, we now work with
spikes δ(t −t f
j ) in continuous time. Second, in the Hopﬁeld model a neuron can be active in
every time step while here spikes must have a minimal distance because of refractoriness.
Third, the input potential h is only one of the contributions to the total membrane potential.
Despite these differences the formalism of Section 17.2.6 can be directly applied to the
case at hand. Let us deﬁne the instantaneous overlap of the spike pattern in the network
with pattern μ as
mμ(t) =
1
2a(1−a)N ∑
j
(ξ μ
j −a)Sj(t),
(17.36)
where Sj(t) = ∑f δ(t −t f
j ) is the spike train of neuron j. Note that, because of the Dirac
δ-function, we need to integrate over mμ in order to arrive at an observable quantity. Such

460
Memory and attractor dynamics
A
I
A
I
Linear
inhibitory
population
Excitatory
population
Threshold
inhibitory
population
Fig. 17.10 A population of excitatory neurons interacts with two populations of inhibitory neurons.
Memory patterns are embedded as Hebbian assemblies in the excitatory population. All neurons are
integrate-and-ﬁre neurons. Theory predicts that the ﬁrst inhibitory population should be activated to
levels where the gain function (left inset) is approximately linear. The second inhibitory population
is activated if the total input is above some threshold value (right inset).
an integration is automatically performed by each neuron. Indeed, the input potential Eq.
(17.34) can be written as
hi(t) = ∑
j
!
1
2a(1−a)N
M
∑
μ=1
(ξ μ
i −b)(ξ μ
j −a)
" ∞
0 ε(s)Sj(t −s)ds
=
M
∑
μ=1
(ξ μ
i −b)
 ∞
0 ε(s)mμ(t −s)ds,
(17.37)
where we have used Eqs. (17.27) and (17.36).
Thus, in a network of N neurons (e.g., N = 100 000) which has stored M patterns (e.g.,
M = 2000) the input potential is completely characterized by the M overlap variables,
which reﬂects an enormous reduction in the complexity of the mathematical problem. Nev-
ertheless, each neuron keeps its identity for two reasons:
(i) Each neuron i is characterized by its "private" set of past ﬁring times t f
i . Therefore
each neuron is in a different state of refractoriness and adaptation which manifests itself
by the term ∑f η(t −t f
i ) in the total membrane potential.
(ii) Each neuron has a different functional role during memory retrieval. This role is
deﬁned by the sequence ξ 1
i ,ξ 2
i ,...,ξ M
i . For example, if neuron i is part of the active assem-
bly in patterns μ = 3,μ = 17,μ = 222,μ = 1999 and should be inactive in the other 1996
patterns, then its functional role is deﬁned by the set of numbers ξ 3
i = ξ 17
i
= ξ 222
i
= ξ 1999 =
1 and ξ μ
i = 0 otherwise. In a network that stores M different patterns there are 2M different
functional roles so it is extremely unlikely that two neurons play the same role. Therefore
each of the N neurons in the network is different!

17.3 Memory networks with spiking neurons
461
However, during retrieval we can reduce the complexity of the dynamics drastically.
Suppose that during the interval t0 < t < t0 + T all overlaps are negligible, except the
overlap with one of the patterns, say pattern ν. Then the input potential in Eq. (17.37)
reduces for t > t0 +T
hi(t) = (ξ ν
i −b)
 ∞
0 ε(s)mν(t −s)ds,
(17.38)
where we have assumed that ε(s) = 0 for s > T. Therefore, the network with its N different
neurons splits up into two homogeneous populations: the ﬁrst one comprises all neurons
with ξ ν
i = +1, i.e., those that should be "ON" during retrieval of pattern ν; and the second
comprises all neurons with ξ ν
i = 0, i.e., those that should be "OFF" during retrieval of
pattern ν.
In other words, we can apply the mathematical tools of population dynamics that were
presented in Part III of this book to analyze memory retrieval in a network of N different
neurons.
Example: Spiking neurons without adaptation
In the absence of adaptation, the membrane potential depends only on the input poten-
tial and the time since the last spike. Thus, Eq. (17.33) reduces to
ui(t) = η(t −ˆti)+hi(t)+urest,
(17.39)
where ˆti denotes the last ﬁring time of neuron i and η(t −ˆti) summarizes the effect of
refractoriness. Under the assumption of an initial overlap with pattern ν and no overlap
with other patterns, the input potential is given by Eq. (17.38). Thus, the network of N
splits into an "ON" population with input potential
hON(t) = (1−b)
 ∞
0 ε(s)mν(t −s)ds
(17.40)
and an "OFF" population with input potential
hOFF(t) = (−b)
 ∞
0 ε(s)mν(t −s)ds.
(17.41)
For each of the populations, we can write down the integral equation of the popula-
tion dynamics that we saw in Chapter 14. For example, the "ON"-population evolves
according to
AON(t) =
 t
−∞PI(t|ˆt)A(ˆt)dˆt
(17.42)
with
PI(t|ˆt) = ρ(t) exp

−
 t
ˆt ρ(t′)dt′

,
(17.43)

462
Memory and attractor dynamics
Neuron #
0
10
20
30
40
50
60
t [s]
0
10
20
30
40
50
m* [Hz]
1
2
3
4
5
6
Fig. 17.11 Attractor network with spiking neurons. Memory retrieval in a network of 8000 excita-
tory neurons which stores 90 different patterns. Top: The spike raster shows 30 neurons selected and
relabeled so that the ﬁrst ﬁve neurons respond to pattern 1, the second group of ﬁve neurons to pattern
2, etc. Bottom: Overlap deﬁned here as mμ∗= AON(t) with the ﬁrst six patterns 1 ≤μ ≤6. After
a partial cue (t = 8,18.5, 19.5, 40, 51 s), one of the patterns is retrieved and remains stable without
further input during a delay period of 10 seconds. Occasionally a global input to the inhibitory neu-
rons is given leading to a reset of the network (t = 38 s). After the reset, the network remains in the
spontaneously activity state.
where ρ(t) = f(η(t −ˆt) + hON(t) + urest −ϑ). An analogous equation holds for the
"OFF"-population.
Finally, we use Eq. (17.36) to close the system of equations. The sum over all neu-
rons can be split into one sum over the "ON"-population and another over the "OFF"-
population, of size a·N and (1−a)·N, respectively. If the number N of neurons is large,
the overlap is therefore
mν(t) = 1
2[AON(t)−AOFF(t)].
(17.44)
Thus, the retrieval of pattern ν is controlled by a small number of macroscopic equations.
In an analogous sequence of calculations one needs to check that the overlap with the
other patterns μ (with μ ̸= ν) does not increase during retrieval of pattern ν.
17.3.2 Excitatory and inhibitory neurons
Synaptic weights in the Hopﬁeld model can take both positive and negative values. How-
ever, in the cortex, all connections originating from the same presynaptic neuron have the
same sign, either excitatory or inhibitory. This experimental observation, called Dale's law,
gives rise to a primary classiﬁcation of neurons as excitatory or inhibitory.
In Chapter 16 we started with models containing separate populations of excitatory and
inhibitory neurons, but could show that the model dynamics are, under certain conditions,

17.3 Memory networks with spiking neurons
463
equivalent to an effective network where the excitatory populations excite themselves but
inhibit each other. Thus explicit inhibition was replaced by an effective inhibition. Here we
take the inverse approach and transform the effective mutual inhibition of neurons in the
Hopﬁeld network into an explicit inhibition via populations of inhibitory neurons.
To keep the arguments transparent, let us stick to discrete time and work with random
patterns ξ μ
i ∈{0,1} with mean activity (∑i ξ μ
i )/N = a. We take weights wi j = c′ ∑μ(ξ μ
i −
b)(ξ μ
j −a) and introduce a discrete-time spike variable σi = 0.5(Si +1) so that σi = 1 can
be interpreted as a spike and σi = 0 as the quiescent state. Under the assumption that each
pattern μ has exactly a·N entries with ξ μ
i = 1, we ﬁnd that the input potential hi = ∑j wi jS j
can be rewritten with the spike variable σ
hi(t) = 2c′∑
j ∑
μ
(ξ μ
i −b)ξ μ
j σ j −2c′∑
j ∑
μ
(ξ μ
i −b)aσj .
(17.45)
In what follows we choose b = 0 and c′ = 1/4N. Then the ﬁrst sum on the right-hand side
of Eq. (17.45) describes excitatory and the second one inhibitory interactions.
To interpret the second term as arising from inhibitory neurons, we make the following
assumptions. First, inhibitory neurons have a linear gain function and ﬁre stochastically
with probability
Prob{σk = +1|hinh
k } = g(hinh
k (t))Δt = γ hinh
k (t),
(17.46)
where the constant γ takes care of the units and k is the index of the inhibitory neuron with
1 ≤k ≤Ninh. Second, each inhibitory neuron k receives input from C excitatory neurons.
Connections are random and of equal weight wE→I = 1/C. Thus, the input potential of
neuron k is hinh
k
= (1/C)∑j∈Γk σj where Γk is the set of presynaptic neurons. Third, the
connection from an inhibitory neuron k back to an excitatory neuron i has weight
wI→E
ik
=
a
γ Ninh ∑
μ
ξ μ
i .
(17.47)
Thus, inhibitory weights onto a neuron i which participates in many patterns are stronger
than onto one which participates in only a few patterns. Fourth, the number Ninh of inhibitory
neurons is large. Taken together, the four assumptions give rise to an average inhibitory
feedback to each excitatory neuron proportional to ∑j ∑μ ξ μ
i aσj. In other words, the inhi-
bition caused by the inhibitory population is equivalent to the second term in Eq. (17.45).
Because of our choice b = 0, patterns are only in weak competition with each other
and several patterns can become active at the same time. In order to also limit the total
activity of the network, it is useful to add a second pool of inhibitory neurons which turn
on whenever the total number of spikes in the network exceeds a·N. Note that biological
cortical tissue contains many different types of inhibitory interneurons, which are thought
to play different functional roles; Fig. 17.10.
Figure 17.11 shows that the above argument carries over to the case of integrate-and-
ﬁre neurons in continuous time. We emphasize that the network of 8000 excitatory and

464
Memory and attractor dynamics
two groups of inhibitory neurons (2000 neurons each) has stored 90 patterns of activity
a ≈0.1. Therefore each neuron participates in many patterns (Curti et al., 2004).
In practice, working memory models with spiking neurons require some parameter tun-
ing. Adding to working models a mechanism of synaptic short-term facilitation (see Chap-
ter 3) improves stability of memory retrieval during the delay period (Mongillo et al.,
2008).
17.4 Summary
The Hopﬁeld model is an abstract model of memory retrieval. After a cue with a partial
overlap with one of the stored memory patterns is presented, the memory item is retrieved.
Because the Hopﬁeld model has symmetric synaptic connections, memory retrieval can be
visualized as downhill movement in an energy landscape. An alternative view is that of
memories forming attractors of the collective network dynamics. While the energy picture
does not carry over to networks with asymmetric interactions, the attractor picture remains
applicable even for biologically more plausible network models with spiking neurons.
Attractor networks where each neuron participates in several memory patterns can be
seen as a realization of Hebb's idea of neuronal assemblies. At the current state of research,
it remains unclear whether increased spiking activity observed in the cortex during delayed
matching-to-sample tasks has a relation to attractor dynamics. However, the ideas of Hebb
and Hopﬁeld have deﬁnitely inﬂuenced the thinking of many researchers.
Literature
Precursors of the Hopﬁeld model are the networks models of Willshaw et al. (1969),
Kohonen (1972), Anderson (1972), and Little (1974). The model of associative memory of
Willshaw et al. (1969) was designed for associations between a binary input pattern ξ μ,A
and a binary output vector ξ μ,B, where ξ μ,A/B
i
∈{0,1} and interactions weights wi j are
taken to vary as ξ μ,B
i
ξ μ,A
j
where j is a component of the input and i a component of the
desired output pattern. A recurrent network can be constructed if the dimensionality of
inputs and outputs match and the output from step n is used as input to step n+1.
Intrinsically recurrent models of memory were studied with linear neurons by Kohonen
(1972) and Anderson (1972) and with stochastic binary units by Little (1974). The latter
showed that, under some assumptions, persistent states that can be identiﬁed with potential
memory states can exist in such a network.
Hopﬁeld's (1982) paper has inﬂuenced a whole generation of physicists and is probably
the most widely cited paper in computational neuroscience. It initiated a wave of studies of
storage capacity and retrieval properties in variants of the Hopﬁeld model using the tools of
statistical physics (Amit et al., 1985, 1987b) including extensions to low-activity patterns
(Amit et al., 1987a; Tsodyks and Feigelman, 1986), sparsely connected networks (Derrida
et al., 1987) and temporal sequences (Sompolinsky and Kanter, 1986; Herz et al., 1989).
The energy function in Hopﬁeld (1982) requires symmetric interactions, but the dynamics

17.4 Summary
465
can also be analyzed directly on the level of overlaps. The book by Hertz et al. (1991)
presents an authoritative overview of these and related topics in the ﬁeld of associative
memory networks.
The transition from abstract memory networks to spiking network models began after
1990 (Amit and Tsodyks, 1991; Gerstner, 1991; Gerstner and van Hemmen, 1992; Treves,
1993; Amit and Brunel, 1997a,b) and continued after 2000 (Curti et al., 2004; Mongillo
et al., 2008), but a convincing memory model of spiking excitatory and inhibitory neurons
where each neuron participates in several memory patterns is still missing. The relation of
attractor network models to persistent activity in electrophysiological recordings in mon-
key prefrontal cortex during memory tasks is discussed in the accessible papers of Barbieri
and Brunel (2008) and Balaguer-Ballester et al. (2011).
Exercises
1. Storing one or several patterns.
Fig. 17.12 Patterns for "E" and "F" in a Hopﬁeld network of 25 neurons.
(a) In a Hopﬁeld network of 25 binary neurons (Fig. 17.12), how would you encode the letter E?
Write down couplings wij from arbitrary neurons onto neuron i if i is either the black pixel in the
lower left corner of the image or the white pixel in the lower right corner.
(b) Suppose the initial state is close to the stored image, except for m pixels which are ﬂipped.
How many time steps does the Hopﬁeld dynamics take to correct the wrong pixels? What is the
maximum number of pixels that can be corrected? What happens if 20 pixels are ﬂipped?
(c) Store as a second pattern the character F using the Hopﬁeld weights wij = ∑μ pμ
i pμ
j . Write
down the dynamics in terms of overlaps. Suppose that the initial state is exactly F. What is the
overlap with the ﬁrst pattern?
2. Mixture states. Use the rule of the Hopﬁeld network to store the six orthogonal patterns such as
those shown in Fig. 17.7b but of size 8×8.
(a) Suppose the initial state is identical to pattern ν = 4. What is the overlap with the other
patterns μ ̸= ν?
Hint: Why are these patterns orthogonal?
(b) How many pixels can be wrong in the initial state, so that pattern ν = 4 is retrieved with
deterministic dynamics?
(c) Start with an initial state which has overlap with two patterns: m1 = (1 −α)m and m2 =
α m and mμ = 0 for μ ≥3. Analyze the evolution of the overlap over several time steps, using
deterministic dynamics.
(d) Repeat the calculation in (c) but for a mixed cue m1(t) = m2(t) = m3(t) = m < 1 and mν(t) = 0
for ν > 3. Is the mixture of three patterns a stable attractor of the dynamics?

466
Memory and attractor dynamics
(e) Repeat the calculation in (d), for stochastic dynamics.
3. Binary codes and spikes. In the Hopﬁeld model, neurons are characterized by a binary variable
Si = ±1. For an interpretation in terms of spikes it is, however, more appealing to work with a
binary variable σi ∈{0,1}.
(a) Write Si = 2σi −1 and rewrite the Hopﬁeld model in terms of the variable σi. What are the
conditions so that the the input potential in the rewritten model is simply hi = ∑j wijσj?
(b) Repeat the same calculation for low-activity patterns and weights wij = c′ ∑μ(ξ μ
i −b)(ξ μ
j −
a) with some constants a,b,c′ and ξ μ
i ∈{0,1}. What are conditions such that hi = ∑j wijσ j?

18
Cortical ﬁeld models for perception
The world is continuous. Humans walk along corridors and streets, move their arms, turn
their head, and orient the direction of gaze. All of these movements and gestures can be
described by continuous variables such as position, head direction, gaze orientation, etc.
These continuous variables need to be represented in the brain. Field models are designed
to encode such continuous variables.
Objects such as houses, trees, cars, pencils have a ﬁnite extension in three-dimensional
space. Visual input arising from these and other objects is projected onto the retinal photo-
receptors and gives rise to a two-dimensional image in the retina. This image is already
preprocessed by nerve cells in the retina and undergoes some further processing stages
before it arrives in the cortex. A large fraction of the primary visual cortex is devoted to
processing of information from the retinal area around the fovea. As a consequence, the
activation pattern on the cortical surface resembles a coarse, deformed and distorted image
of the object (Fig. 18.1). Topology is largely preserved so that neighboring neurons in the
cortex process neighboring points of retinal space. In other words, neighboring neurons
have similar receptive ﬁelds, which give rise to cortical maps; see Chapter 12.
In this chapter we describe the activity of local groups of cortical neurons. We exploit
the fact that neighboring neurons have similar receptive ﬁelds so as to arrive at a continuum
model of cortical activity. Neural continuum models are often called ﬁeld models. Neurons
in a ﬁeld model typically receive input on a forward path, from sensory modalities such as
vision, audition, or touch, but they also interact with each other. Field models of sensory
areas in the cortex are suitable to explain some, but not all, aspects of perception. For
example, the lateral interaction of neurons in the visual cortex (and also in the retina!)
gives rise to visual phenomena such as Mach bands or grid illusions (Fig. 18.2).
Field models are also used for some forms of working memory. As an example, let us
focus on the sense of orientation. Normally, when reading this book for example, you are
able to point spontaneously in the direction of the door of your room. Let us imagine that
you spin around with closed eyes until you get dizzy and lose your sense of orientation.
When you open your eyes your sense of orientation will re-establish itself based on the
visual cues in your surroundings. Thus, visual input strongly inﬂuences self-orientation.
Nevertheless, the sense of orientation also works in complete darkness. If somebody turns
the lights off, you still remember where the door is. Thus, humans (and animals) have a

468
Cortical ﬁeld models for perception
Retina
LGN
Visual
Cortex
(a)
Retina
Fovea
Fovea
Surface of right
visual cortex
Left
visual
field
(b)
Fig. 18.1 Transformation from visual space to the cortex. (a) The image of an object is projected
onto the retina and from there transmitted, via the optic tract and lateral geniculate nucleus (LGN),
to the visual cortex. The pattern of activation on the medial surface of visual cortex represents a
"distorted" image. (b) Concentric rings on the retina give rise to vertical stripes of activation along
the surface of the cortical tissue. A large fraction of neurons in V1 process information from a small
region around the fovea in the retina. From Kandel et al. (2000).
rather stable "internal compass" which can be used, even in complete darkness, to walk a
few steps in the right direction.
While the memory effect of the "internal compass" can be related to the regime of bump
attractors in a continuum model, perceptual phenomena can be described by the same class
of continuum models, but in the input-driven regime. Both regimes will be discussed in
this chapter. We start with a general introduction to continuum models in Section 18.1. We
then turn to the input-driven regime in Section 18.2 in order to account for some perceptual
and cortical phenomena. Finally we discuss the regime of bump attractors in the context of
the sense of orientation (Section 18.3).
18.1 Spatial continuum model
We focus on networks that have a spatial structure. In doing so we emphasize two charac-
teristic features of the cerebral cortex, namely the high density of neurons and its virtually
two-dimensional architecture.
Each cubic millimeter of cortical tissue contains more than 104 neurons. This impressive
number suggests that a description of neuronal dynamics in terms of an averaged popula-
tion activity is more appropriate than a description on the single-neuron level. Furthermore,
the cerebral cortex is huge. More precisely, the unfolded cerebral cortex of humans covers
a surface of 2200-2400 cm2, but its thickness amounts on average to only 2.5-3.0 mm. If
we do not look too closely, the cerebral cortex can hence be treated as a continuous two-
dimensional sheet of neurons. Neurons will no longer be labeled by discrete indices but
by continuous variables that give their spatial position on the sheet. The coupling of two
neurons i and j is replaced by the average coupling strength between neurons at position x
and those at position y, or, even more radically simpliﬁed, by the average coupling strength
of two neurons being separated by the distance |x−y|. Similarly to the notion of an average
coupling strength we will also introduce the average activity of neurons located at position
x and describe the dynamics of the network in terms of these averaged quantities only.
The details of how these average quantities are deﬁned have been discussed in Chapter 12.

18.1 Spatial continuum model
469
Whiteness
(a)
(b)
Fig. 18.2 Visual illusions. (a) Mach bands. Gray stripes touching each other are perceived as non-
uniform, despite the fact that inside each stripe the gray value is constant. Top: Actual (solid line)
and perceived (dashed line) whiteness (vertical axis) as a function of position along the horizontal
axis of the image. (b) Helmholtz grid illusion. A grid of black squares on a white background gives
rise to scintillating bright or gray dots at the intersections of the white bands.
We now introduce - without a formal justiﬁcation - ﬁeld equations for the spatial activity
A(x,t) in a spatially extended, but otherwise homogeneous, population of neurons.
We work with the population rate equations that we introduced in Chapter 15. As we
have seen, these equations neglect rapid transients and oscillations that can show up in
simulations of spiking neurons. On the other hand, in the limit of high noise and short
refractoriness, the approximation of population dynamics by differential equations is good;
see Chapter 15.
Consider a single sheet of densely packed neurons. We assume that all neurons have
similar properties and that the connectivity is homogeneous and isotropic, i.e., that the
coupling strength of two neurons is a function of their distance only. We loosely deﬁne
a quantity h(x,t) as the average input potential at time t of the group of neurons located
at position x. We have seen in Chapter 12 that in the stationary state the "activity" of a
population of neurons is strictly given by the single-neuron gain function A0(x) = F[h(x)];
see Fig. 18.3. If we assume that changes of the input potential are slow enough so that the
population always remains in a state of incoherent ﬁring, then we can set
A(x,t) = F[h(x,t)],
(18.1)
even for time-dependent situations. According to Eq. (18.1), the activity A(x,t) of the pop-
ulation around location x is a function of the input potential at that location.
The synaptic input current to a given neuron depends on the level of activity of its pre-
synaptic neurons and on the strength of the synaptic couplings. We assume that the ampli-
tude of the input current is simply the presynaptic activity scaled by the average coupling
strength of these neurons. The total input current Isyn(x,t) to a neuron at position x is

470
Cortical ﬁeld models for perception
-2
0
2
4
6
h
0
0.2
0.4
0.6
0.8
1
(a)
F
-4
-2
0
2
4
x - y
-0.2
0
0.2
0.4
0.6
0.8
(b)
1
w
Fig. 18.3
(a) Generic form of the sigmoidal gain function F of graded response neurons that
describes the relation between the potential h and the "activity" of the neural population. (b) Typical
"Mexican-hat"-shaped function for the coupling w of two neurons as a function of their distance x.
therefore
Isyn(x,t) =

dy w(|x−y|) A(y,t).
(18.2)
Here, w is the average coupling strength of two neurons as a function of their distance.
To complete the deﬁnition of the model, we need to specify a relation between the input
current and the resulting membrane potential. To keep things simple we treat each neuron
as a leaky integrator. The input potential is thus given by a differential equation of the form
τ ∂h
∂t = −h+RIsyn +RIext ,
(18.3)
with τ being the time constant of the integrator and Iext an additional external input. In
what follows we work with unit-free variables and set R = 1. If we put things together we
obtain the ﬁeld equation
τ ∂h(x,t)
∂t
= −h(x,t)+

dy w(|x−y|) F[h(y,t)]+Iext(x,t);
(18.4)
see Wilson and Cowan (1973); Feldman and Cowan (1975); Amari (1977). This is a non-
linear integro-differential equation for the average membrane potential h(x,t).
18.1.1 Mexican-hat coupling
In order to be more speciﬁc, we now specify the connection strength w as a function of
interneuron distance. In what follows we consider a connectivity pattern that is excitatory
for proximal neurons and predominantly inhibitory for distal neurons. Figure 18.3b shows
the typical "Mexican-hat" shape of the corresponding coupling function.
There are a few simplifying assumptions in the choice of the Mexican-hat function which
are worth mentioning. First, Eq. (18.2) assumes that synaptic interaction is instantaneous.
In a more detailed model we could include the axonal transmission delay and synaptic time
constants. In that case, A(y,t) on the right-hand side of Eq. (18.2) should be replaced by
 α(s)A(y,t −s)ds where α(s) is the temporal interaction kernel.

18.1 Spatial continuum model
471
0
L/4
-L/4
Exc
-L/2=L/2
x
x
Inh
(a)
(b)
Fig. 18.4 Ring model with spiking neurons. (a) Neurons are organized on a ring, i.e., neurons at posi-
tion x = L/2 are neighbors of neurons at position x = −L/2 (top). The dashed vertical line indicates
the position where the ring was cut for the unfolded ﬁgure at the bottom. At each position x excita-
tory and inhibitory neurons interact with each other. Inhibitory interactions have a longer range than
the excitatory ones. Both neuron types are integrate-and-ﬁre models with identical model parameters
and interaction patterns. (b) Spike patterns of sample neurons. In the input-driven regime, activity is
spatially homogeneous (top) while for stronger lateral interactions an activation bump forms spon-
taneously (bump attractor, bottom). Vertical axis shows different neurons, plotted according to their
position on the ring. In both cases input is spatially uniform. From Shriki et al. (2003) by permission
of MIT Press Journals.
Second, in Eq. (18.2) presynaptic neurons at location x can give rise to both excitatory
and inhibitory input whereas cortical neurons are either excitatory or inhibitory. The reason
is that our population model is meant to be an effective model. There are two alternative
ways to arrive at such an effective model. Either we work out the effective coupling model
using the mathematical steps of Chapter 16 starting from a common pool of inhibitory neu-
rons shared by all excitatory cells. Or we assume that excitatory and inhibitory neurons at
each location receive the same mean input and have roughly the same neuronal parameters
(Shriki et al., 2003), but have slightly different output pathways (Fig. 18.4a). In both cases,
inhibition needs to be of longer range than excitation to arrive at the effective Mexican-
hat coupling. A third, and biologically more plausible alternative is discussed in Section
18.2.4.
With Mexican-hat coupling, two different regimes emerge (Fig. 18.4):
(i) In the input-driven regime the activity pattern is, in the absence of input, spatially
uniform. In other words, any spatial structure in the neuronal activity pattern is causally
linked to the input.
(ii) In the regime of bump attractors, spatially localized activity patterns develop even in
the absence of input (or with spatially uniform input).
The two regimes are discussed in Sections 18.2 and 18.3, respectively.
Example: Ring model with spiking neurons
Excitatory and inhibitory integrate-and-ﬁre models are coupled with a ring-like topol-
ogy (Fig. 18.4a). Excitatory neurons make connections to their excitatory and inhibitory

472
Cortical ﬁeld models for perception
neighbors. Inhibitory neurons make long-range connections. Let us suppose that the
ring model is driven by a spatially uniform input. Depending on the interaction strength
(Shriki et al., 2003), either a spatially homogeneous spike pattern or a spatially local-
ized spike pattern can emerge (Fig. 18.4b). The ﬁrst case corresponds to the input-driven
regime, the second case to the regime of bump attractors.
18.2 Input-driven regime and sensory cortex models
In this section we study the ﬁeld equation (18.4) in the input-driven regime. Thus, if the
input is spatially uniform, the activity pattern is also spatially uniform. From a mathemat-
ical perspective, the spatially uniform activity pattern is the homogeneous solution of the
ﬁeld equation (Section 18.2.1). The stability of the homogeneous solution is discussed in
Section 18.2.2.
A non-trivial spatial structure in the input gives rise to deviations from the homoge-
neous solution. Thus the input drives the formation of spatial activity patterns. This regime
can account for perceptual phenomena such as contrast enhancement as shown in Sec-
tion 18.2.3. Finally, we discuss how the effective Mexican-hat interaction, necessary for
contrast enhancement, could be implemented in the cortex with local inhibition (Section
18.2.4).
18.2.1 Homogeneous solutions
Although we have kept the above model as simple as possible, the ﬁeld equation (18.4) is
complicated enough to prevent comprehensive analytical treatment. We therefore start our
investigation by looking for a special type of solution, i.e., a solution that is uniform over
space, but not necessarily constant over time. We call this the homogeneous solution and
write h(x,t) ≡h(t). We expect that a homogeneous solution exists if the external input is
homogeneous as well, i.e., if Iext(x,t) ≡Iext(t).
Substitution of the ansatz h(x,t) ≡h(t) in Eq. (18.4) yields
τ dh(t)
dt
= −h(t)+ ¯wF[h(t)] +Iext(t),
(18.5)
with ¯w =
 dy w(|y|). This is a nonlinear ordinary differential equation for the average
input potential h(t). We note that the equation for the homogeneous solution is identical to
that of a single population without spatial structure; see Chapter 15.
The ﬁxed points of the above equation with Iext = 0 are of particular interest because
they correspond to a resting state of the network. More generally, we search for stationary
solutions for a given constant external input Iext(x,t) ≡Iext. The ﬁxed points of Eq. (18.5)
are solutions of
F(h) = h−Iext
¯w
,
(18.6)

18.2 Input-driven regime and sensory cortex models
473
-2
0
2
4
6
h
0
0.2
0.4
0.6
0.8
1
F , (h -Iext )/w
i
ii
iii
iv
v
Fig. 18.5
Graphical representation of the ﬁxed-
point equation (18.6). The solid line corresponds
to the neuronal gain function F(h) and the dashed
lines to (h−Iext)/ ¯w for different amounts of exter-
nal stimulation Iext. Depending on the amount of
Iext there is either a stable ﬁxed point at low activ-
ity (i), a stable ﬁxed point at high activity (v), or
a bistable situation with stable ﬁxed points (ii-iv)
separated by an unstable ﬁxed point at intermedi-
ate level of activity (iii).
which is represented graphically in Fig. 18.5.
Depending on the strength of the external input three qualitatively different situations
can be observed. For low external stimulation there is a single ﬁxed point at a very low
level of neuronal activity. This corresponds to a quiescent state where the activity of the
whole network has ceased. Large stimulation results in a ﬁxed point at an almost saturated
level of activity which corresponds to a state where all neurons are ﬁring at their maximum
rate. Intermediate values of external stimulation, however, may result in a situation with
more than one ﬁxed point. Depending on the shape of the output function and the mean
synaptic coupling strength ¯w, three ﬁxed points may appear. Two of them correspond to
the quiescent and the highly activated state, which are separated by the third ﬁxed point at
an intermediate level of activity.
Any potential physical relevance of ﬁxed points clearly depends on their stability. Sta-
bility under the dynamics deﬁned by the ordinary differential equation (18.5) is readily
checked using standard analysis. Stability requires that at the intersection
F′(h) < ¯w−1 .
(18.7)
Thus all ﬁxed points corresponding to quiescent or highly activated states are stable whereas
the middle ﬁxed point in the case of multiple solutions is unstable; see Fig. 18.5. This,
however, is only half the truth because Eq. (18.5) describes only homogeneous solutions.
Therefore, it may well be that the solutions are stable with respect to Eq. (18.5), but unsta-
ble with respect to inhomogeneous perturbations, i.e., to perturbations that do not have the
same amplitude everywhere in the net.
18.2.2 Stability of homogeneous states (*)
In what follows we will perform a linear stability analysis of the homogeneous solutions
found in the previous section. Readers not interested in the mathematical details can jump
directly to Section 18.2.3.
We study the ﬁeld equation (18.4) and consider small perturbations about the homoge-
neous solution. A linearization of the ﬁeld equation will lead to a linear differential equa-

474
Cortical ﬁeld models for perception
-10
-5
0
5
10
x - y
0
0.2
0.4
0.6
0.8
1
(a)
w
-1
-0.5
0
0.5
1
k
0
0.5
1
1.5
2
2.5
w
(b)
Fig. 18.6 (a) Synaptic coupling function with zero mean as in Eq. (18.14) with σ1 = 1 and
σ2 = 10. (b) Fourier transform of the coupling function shown in (a); see Eq. (18.16).
tion for the amplitude of the perturbation. The homogeneous solution is said to be stable if
the amplitude of every small perturbation is decreasing whatever its shape.
Suppose h(x,t) ≡h0 is a homogeneous solution of Eq. (18.4), i.e.,
0 = −h0 +

dy w(|x−y|) F[h0]+Iext .
(18.8)
Consider a small perturbation δh(x,t) with initial amplitude |δh(x,0)| ≪1. We substitute
h(x,t) = h0 +δh(x,t) in Eq. (18.4) and linearize with respect to δh,
τ ∂
∂t δh(x,t) = −h0 −δh(x,t)
+

dy w(|x−y|)[F(h0)+F′(h0)δh(y,t)]+Iext(x,t)+O(δh2).
(18.9)
Here, a prime denotes the derivative with respect to the argument. Zero-order terms cancel
each other because of Eq. (18.8). If we collect all terms linear in δh we obtain
τ ∂
∂t δh(x,t) = −δh(x,t)+F′(h0)

dy w(|x−y|)δh(y,t).
(18.10)
We make two important observations. First, Eq. (18.10) is linear in the perturbations δh -
simply because we have neglected terms of order (δh)n with n ≥2. Second, the coupling
between neurons at locations x and y is mediated by the coupling kernel w(|x−y|) that
depends only on the distance |x−y|. If we apply a Fourier transform over the spatial coordi-
nates, the convolution integral turns into a simple multiplication. It sufﬁces therefore to dis-
cuss a single (spatial) Fourier component of δh(x,t). Any speciﬁc initial form of δh(x,0)
can be created from its Fourier components by virtue of the superposition principle. We
can therefore proceed without loss of generality by considering a single Fourier compo-

18.2 Input-driven regime and sensory cortex models
475
-1
0
(a)
1
2
3
4
h
0
0.2
0.4
0.6
0.8
1
F
-1
0
1
2
3
4
h
0
0.2
0.4
0.6
0.8
1
1.2
(b)
F
Fig. 18.7 (a) Gain function F(h) = {1 + exp[β(x −θ)]}−1 with β = 5 and θ = 1. The dashed line
indicates that part of the graph where the slope exceeds the critical slope s∗. (b) Derivative of the
gain function shown in (a) (solid line) and critical slope s∗(dashed line).
nent, namely, δh(x,t) = c(t)eikx. If we substitute this ansatz in Eq. (18.10) we obtain
τ c′(t) = −c(t)

1−F′(h0)

dy w(|x−y|)eik(y−x)

= −c(t)

1−F′(h0)

dz w(|z|)eikz

,
(18.11)
which is a linear differential equation for the amplitude c of a perturbation with wave
number k. This equation is solved by
c(t) = c(0)e−κ(k)t ,
(18.12)
with
κ(k) = 1−F′(h0)

dz w(|z|)eikz .
(18.13)
Stability of the solution h0 with respect to a perturbation with wave number k depends on
the sign of the real part of κ(k). Note that - quite intuitively - only two quantities enter
this expression, namely the slope of the activation function evaluated at h0 and the Fourier
transform of the coupling function w evaluated at k. If the real part of the Fourier transform
of w stays below 1/F′(h0), then h0 is stable. Note that Eqs. (18.12) and (18.13) are valid
for an arbitrary coupling function w(|x −y|). In the following, we illustrate the typical
behavior for a speciﬁc choice of the lateral coupling.
Example: "Mexican-hat" coupling with zero mean
We describe Mexican-hat coupling by a combination of two bell-shaped functions
with different width. For the sake of simplicity we will again consider a one-dimensional
sheet of neurons. For the lateral coupling we take
w(x) = σ2 e−x2/(2σ2
1 ) −σ1 e−x2/(2σ2
2 )
σ2 −σ1
,
(18.14)

476
Cortical ﬁeld models for perception
with σ1 < σ2. The normalization of the coupling function has been chosen so that w(0) =
1 and
 dx w(x) = ¯w = 0; cf Fig. 18.6a.
As a ﬁrst step we search for a homogeneous solution. If we substitute h(x,t) = h(t) in
Eq. (18.4) we obtain
τ dh(t)
dt
= −h(t)+Iext .
(18.15)
The term containing the integral drops out because ¯w = 0. This differential equation
has a single stable ﬁxed point at h0 = Iext. This situation corresponds to the graphical
solution of Fig. 18.5 with the dashed lines replaced by vertical lines ("inﬁnite slope").
We still have to check the stability of the homogeneous solution h(x,t) = h0 with
respect to inhomogeneous perturbations. In the present case, the Fourier transform of w,

dxw(x)eikx =
√
2π σ1 σ2
σ2 −σ1

e−k2 σ2
1 /2 −e−k2 σ2
2 /2	
,
(18.16)
vanishes at k = 0 and has its maximum at
km = ±
2 ln(σ2
2 /σ2
1 )
σ2
2 −σ2
1
1/2
.
(18.17)
At the maximum, the amplitude of the Fourier transform has a value of
ˆwm = max
k

dxw(x)eikx =
√
2π σ1 σ2
σ2 −σ1
⎡
⎢⎣
σ2
1
σ2
2

σ2
1
σ2
2 −σ2
1 −
σ2
1
σ2
2

σ2
2
σ2
2 −σ2
1
⎤
⎥⎦,
(18.18)
see Fig. 18.6b. We use this result in Eqs. (18.12) and (18.13) and conclude that stable
homogeneous solutions can only be found for those parts of the graph of the output
function F(h) where the slope s = F′(h) does not exceed the critical value s∗= 1/ ˆwm,
s∗=
σ2 −σ1
√
2π σ1 σ2
⎡
⎢⎣
σ2
1
σ2
2

σ2
1
σ2
2 −σ2
1 −
σ2
1
σ2
2

σ2
2
σ2
2 −σ2
1
⎤
⎥⎦
−1
.
(18.19)
Figures 18.6 and 18.7 show that, depending on the choice of coupling w and gain func-
tions F, a certain interval for the external input exists without a corresponding stable
homogeneous solution. In this parameter domain a phenomenon called pattern forma-
tion can be observed: small ﬂuctuations around the homogeneous state grow exponen-
tially until a characteristic pattern of regions with low and high activity has developed;
see Fig. 18.8.
18.2.3 Contrast enhancement
More than a hundred years ago Mach described the psychophysical phenomenon of edge
enhancement or contrast enhancement (Mach, 1906): the sharp transition between two

18.2 Input-driven regime and sensory cortex models
477
0
20
40
60
80
100
x
0
10
20
30
40
50
t
- 1
0
1
2
h
0
20
40
60
80
x
(a)
(Iext =0.4)
0
20
40
60
80
100
x
0
10
20
30
40
50
t
-1
0
1
2
h
0
20
40
60
80
x
(b)
(Iext = 0.6)
100
x
0
10
20
30
40
50
t
-1
0
1
2
(c)
h
0
20
40
60
80
x
(Iext =1.4)
100
x
0
10
20
30
40
50
t
-1
0
1
2
(d)
h
0
20
40
60
80
x
(Iext = 1.6)
Fig. 18.8 Spontaneous pattern formation in a one-dimensional sheet of neurons with "Mexican-hat"
type of interaction and homogeneous external stimulation. The parameters for the coupling function
and the output function are the same as in Figs. 18.6-18.7. The graphs show the evolution in time of
the spatial distribution of the average membrane potential h(x,t). (a) For Iext = 0.4 the homogeneous
low-activity state is stable, but it loses stability at Iext = 0.6. (b) Here, small initial ﬂuctuations in
the membrane potential grow exponentially and result in a global pattern of regions with high and
low activity. (c) Similar situation to that in (b), but with Iext = 1.4. (d) Finally, at Iext = 1.6 the
homogeneous high-activity mode is stable.
regions of different intensities generates perceptual bands along the borders that enhance
the perceived intensity difference (Fig. 18.2a). Edge enhancement is already initiated in
the retina (Mach, 1865), but likely to have cortical components as well.
Field models with a Mexican-hat interaction kernel generically generate contrast
enhancement in the input-driven regime (Fig. 18.9a). Because of the nonlinear lateral
interactions, an incoming spatial input pattern is transformed (Wilson and Cowan, 1973;
Grossberg, 1973). For example, a spatial input with rectangular proﬁle boosts activity at
the borders, while a smooth input with sinusoidal modulation across space boosts activity
at the maximum (Fig. 18.9b). A spatial input with a staircase intensity proﬁle generates
activity patterns that resemble the perceptual phenomenon of Mach bands.

478
Cortical ﬁeld models for perception
1
2
3
4
x [a.u.]
0
1
2
3
4
5
6
F(h(t)) [a.u.]
(a)
-L/2
0
L/2
0
50
(b)
x
A [Hz]
Fig. 18.9 (a) Mach bands in a ﬁeld model with Mexican-hat coupling. Reﬂecting Fig. 18.2a, the
external current Iext(x,t) = Iext(x) forms a staircase as a function of distance. The resulting activ-
ity F(h(t)) is shown for four different times. The equilibrium solution is indicated by a thick line.
(b) An implementation of a ﬁeld model of excitatory and inhibitory spiking neurons, stimulated with
a sinusoidal spatial proﬁle (dashed line) generates a peak at the maximum. From Shriki et al. (2003)
by permission of MIT Press Journals.
Example: An application to orientation selectivity in V1
Continuum models can represent not only spatial position proﬁles, but also more
abstract variables. For example, ring models have been used to describe orientation
selectivity of neurons in the visual cortex (Ben-Yishai et al., 1995; Hansel and Som-
polinsky, 1998; Shriki et al., 2003).
As discussed in Chapter 12, cells in the primary visual cortex (V1) respond prefer-
entially to lines or bars that have a certain orientation within the visual ﬁeld. There are
neurons that "prefer" vertical bars; others respond maximally to bars with a different
orientation (Hubel, 1988). Up to now it is still a matter of debate where this orienta-
tion selectivity comes from. It may be the result of the wiring of the input to the visual
cortex, i.e., the wiring of the projections from the LGN to V1, or it may result from intra-
cortical connections, i.e., from the wiring of the neurons within V1, or both. Here we
will investigate the extent to which intracortical projections can contribute to orientation
selectivity.
We consider a network of neurons forming a so-called hyper column. These are neu-
rons with receptive ﬁelds which correspond to roughly the same zone in the visual ﬁeld
but with different preferred orientations. The orientation of a bar at a given position
within the visual ﬁeld can thus be coded faithfully by the population activity of the
neurons from the corresponding hyper column.
Instead of using spatial coordinates to identify a neuron in the cortex, we label the
neurons in this section by their preferred orientation θ which may vary from −π/2 to
+π/2. In doing so we assume that the preferred orientation is indeed a good "name
tag" for each neuron so that the synaptic coupling strength can be given in terms of the
preferred orientations of presynaptic and postsynaptic neuron. Following the formalism
developed in the previous sections, we assume that the synaptic coupling strength w of
neurons with preferred orientation θ and θ ′ is a symmetric function of the difference

18.2 Input-driven regime and sensory cortex models
479
θ −θ ′, i.e., w = w(|θ −θ ′|). Since we are dealing with angles from [−π/2,+π/2] it is
natural to assume that all functions are π-periodic so that we can use Fourier series to
characterize them. Non-trivial results are obtained even if we retain only the ﬁrst two
Fourier components of the coupling function,
w(θ −θ ′) = w0 +w2 cos[2(θ −θ ′)].
(18.20)
Similarly to the intracortical projections we take the (stationary) external input from
the LGN as a function of the difference of the preferred orientation θ and the orientation
of the stimulus θ0,
Iext(θ) = c0 +c2 cos[2(θ −θ0)].
(18.21)
Here, c0 is the mean of the input and c2 describes the modulation of the input that arises
from anisotropies in the projections from the LGN to V1.
Analogously to Eq. (18.4) the ﬁeld equation for the present setup thus has the form
τ ∂h(θ,t)
∂t
= −h(θ,t)+
 +π/2
−π/2
dθ ′
π
w(|θ −θ ′|)F[h(θ ′,t)]+Iext(θ).
(18.22)
We are interested in the distribution of the neuronal activity within the hyper column
as it arises from a stationary external stimulus with orientation θ0. This will allow us to
study the role of intracortical projections in sharpening orientation selectivity.
In order to obtain conclusive results we have to specify the form of the gain function
F. A particularly simple case is the piecewise linear function,
F(h) = [h]+ ≡

h,
h ≥0,
0,
h < 0,
(18.23)
so that neuronal ﬁring increases linearly monotonously once the input potential exceeds
a certain threshold.
If we assume that the average input potential h(θ,t) is always above threshold, then
we can replace the gain function F in Eq. (18.22) by the identity function. We are thus
left with the following linear equation for the stationary distribution of the average mem-
brane potential,
h(θ) =
 +π/2
−π/2
dθ ′
π
w(|θ −θ ′|)h(θ ′)+Iext(θ).
(18.24)
This equation is solved by
h(θ) = h0 +h2 cos[2(θ −θ0)],
(18.25)
with
h0 =
c0
1−w0
and
h2 =
2c2
2−w2
.
(18.26)
As a result of the intracortical projections, the modulation h2 of the response of the

480
Cortical ﬁeld models for perception
-p/2
0
0.5
1
1.5
(a)
F, I ext
-p/4
p/4
p/2
0
q
0
0.5
1
1.5
F,I ext
−π/2
−π/4
π/4
π/2
0
θ
(b)
Fig. 18.10 Activity proﬁles (solid line) that result from stationary external stimulation (dashed line)
in a model of orientation selectivity. (a) Weak modulation (c0 = 0.8, c2 = 0.2) of the external input
results in a broad activity proﬁle; see Eq (18.24). (b) Strong modulation (c0 = 0.6, c2 = 0.4) produces
a narrow proﬁle; see Eq. (18.27). Other parameters are ω0 = 0, ω2 = 1, θ0 = 0.
neurons from the hyper column is thus ampliﬁed by a factor 2/(2−w2) compared to the
modulation of the input c2.
In deriving Eq. (18.24) we have assumed that h always stays above threshold so that
we have an additional condition, namely, h0−|h2| > 0, in order to obtain a self-consistent
solution. This condition may be violated depending on the stimulus. In that case the
above solution is no longer valid and we have to take the nonlinearity of the gain function
into account (Ben-Yishai et al., 1995), i.e., we have to replace Eq. (18.24) by
h(θ) =
 θ0+θc
θ0−θc
dθ ′
π w(|θ −θ ′|)h(θ ′)+Iext(θ).
(18.27)
Here, θ0 ± θc are the cut-off angles that deﬁne the interval where h(θ) is positive. If
we use (18.25) in the above equation, we obtain together with h(θ0 ± θc) = 0 a set of
equations that can be solved for h0, h2, and θc. Figure 18.10 shows two examples of the
resulting activity proﬁles F[h(θ)] for different modulation depths of the input.
Throughout this example we have described neuronal populations in terms of an aver-
aged input potential and the corresponding ﬁring rate. At least for stationary input and
a high level of noise this is indeed a good approximation of the dynamics of spiking
neurons. Figure 18.11 shows two examples of a simulation based on SRM0 neurons
with escape noise and a network architecture that is equivalent to what we have used
above. The stationary activity proﬁles shown in Fig. 18.11 for a network of spiking neu-
rons are qualitatively similar to those of Fig. 18.10 derived for a rate-based model. For
low levels of noise, however, the description of spiking networks in terms of a ﬁring
rate is no longer valid, because the state of asynchronous ﬁring becomes unstable (see
Section 14.2.3) and neurons tend to synchronize (Laing and Chow, 2001).
18.2.4 Inhibition, surround suppression, and cortex models
There are several concerns when writing down a standard ﬁeld model such as Eq. (18.4)
with Mexican-hat interaction. In this section, we aim to move ﬁeld models closer to biology
and consider three of these concerns.

18.2 Input-driven regime and sensory cortex models
481
0
0.3
(a)
A [kHz]
−π/2
π/2
θ
0
0
0.3
(b)
A [kHz]
−π/2
π/2
θ
0
Fig. 18.11 Activity proﬁles in a model of orientation selectivity obtained by simulations based on
SRM0 neurons (dots) compared to the theoretical prediction (solid line) during stimulation with a
low-contrast orientation input at θ = 0. (a) If lateral coupling is not distance-dependent [ω2 = 0;
see Eq. (18.20)] the activity proﬁle reﬂects the weak modulation of the input pattern. (b) Excitatory
coupling between cells of the same orientation and long-range inhibition (ω2 = 10) generates a sharp
activity proﬁle centered at θ = 0. From Spiridon and Gerstner (2001) with permission of Informa
Healthcare.
A. Does Mexican-hat connectivity exist in the cortex? The Mexican-hat interaction pat-
tern has a long tradition in theoretical neuroscience (Wilson and Cowan, 1973; Grossberg,
1973; Kohonen, 1984), but, from a biological perspective, it has two major shortcomings.
First, in ﬁeld models with Mexican-hat interaction, the same presynaptic population gives
rise to both excitation and inhibition whereas in the cortex excitation and inhibition require
separate groups of neurons (Dale's law). Second, inhibition in Mexican-hat connectivity
is of longer range than excitation whereas biological data suggests the opposite. In fact,
inhibitory neurons are sometimes called local interneurons because they make only local
interactions. Pyramidal cells, however, make long-range connections within and beyond
cortical areas.
B. Are there electrophysiological correlates of contrast enhancement? Simple and com-
plex cells in the visual cortex respond best if they are stimulated by a slowly moving grat-
ing with optimal orientation and of a size that is matched to the cells' receptive ﬁeld; see
Chapter 12. If the grating is optimally oriented but larger than the receptive ﬁeld, the
response is reduced compared to that of a smaller grating (Fig. 18.12). At ﬁrst sight, this
ﬁnding is consistent with contrast enhancement through Mexican-hat interaction: a uni-
form large stimulus evokes a smaller response because it generates inhibition from neu-
rons which are further apart. Paradoxically, however, neurons receive less inhibition (Fig.
18.13) with the larger stimulus than with the smaller one (Ozeki et al., 2009).
C. How can we interpret the "position" variable in ﬁeld models? In the previous sections
we varied the interpretation of the "space" variable from physical position in the cortex to
an abstract variable representing the preferred orientation of cells in the primary visual
cortex. Indeed, in the visual cortex several variables need to be encoded in parallel: the
location of a neuron's receptive ﬁeld and its preferred orientation and potentially its pre-
ferred color and potentially the relative importance of input from left and right eye - while

482
Cortical ﬁeld models for perception
Rate [Hz] 
Size
A1
(a)
A2
(b)
Fig. 18.12 Surrounding suppression. (a) Schematic. A1. Firing rate of a V1 cell as a function of the
size of a moving grid stimulus. The grid has optimal orientation and optimal line spacing. Larger
grids cause weaker responses than smaller ones. A2. Heuristic interpretation of surrounding sup-
pression. The feedforward pathway from LGN to a cell (arrow, bottom row) gives rise to a small
receptive ﬁeld (RF size and location indicated above cell). Neighboring neurons with overlapping
receptive ﬁelds excite each other and can be grouped into a local population (dashed circle). If the
size of the stimulus is slightly larger, the response of the recorded neuron (middle) is enhanced
because of excitatory input from neighboring cells. Right: Distal neurons inhibit the central neuron.
Therefore an even larger stimulus suppresses the ﬁring rate of the recorded neuron. (b) Experimental
data. A moving grating causes a modulation of the membrane potential and spike ﬁring. The number
of spikes and the membrane potential are larger for a small grating than for a bigger one. Dashed
horizontal line: mean membrane potential in the absence of stimulation. From Ozeki et al. (2009)
with permission from Elsevier.
each neuron also has a physical location in the cortex. Therefore a distance-dependent con-
nectivity pattern needs to be distance dependent for several dimensions in parallel while
respecting the physical properties of a nearly two-dimensional cortical sheet.
In what follows, we present a model by Ozeki et al. (2009) that addresses concerns A
and B and enables us to comment on point C.
We group neurons with overlapping receptive ﬁelds of similar orientation preference
(Fig. 18.12a) into a single population. Inside the population neurons excite each other.
We imagine that we record from a neuron in the center of the population. Neurons with
receptive ﬁelds far away from the recorded neuron inhibit its activity.
Inhibition is implemented indirectly as indicated in Fig. 18.13c. The excitatory neurons
in the central population project onto a group of local inhibitory interneurons, but also onto
populations of other inhibitory neurons further apart. Each population of inhibitory neurons
makes only local connections to the excitatory population in their neighborhood. Input to
the central group of excitatory neurons therefore induces indirect inhibition of excitatory
neurons further apart. Such a network architecture therefore addresses concern A.
To address concern B, the network parameters are set such that the network is in the
inhibition-stabilized regime. A network is said to be inhibition-stabilized if the positive
feedback through recurrent connections within an excitatory population is strong enough

18.2 Input-driven regime and sensory cortex models
483
Rate[Hz]
500 ms
(a)
gexc
ginh
500 ms
(b)
Exc
(c)
x
Inh
Fig. 18.13 Network stabilized by local inhibition. The schematic model could potentially explain
why larger gratings lead not only to less excitatory input gexc, but also to less inhibitory input ginh.
(a) The ﬁring rate as a function of the phase of the moving grating for the three stimulus conditions
(blank screen, small grating, and large grating). (b) Top: Excitatory input into the cell. Bottom:
Inhibitory input into the same cell. As in (a), left, middle, and right correspond to a blank screen, a
small grating, and a large grating. Note that the larger grating leads to a reduction of both excitation
and inhibition. Adapted from Ozeki et al. (2009). (c) Network model with long-range excitation and
local inhibition. Excitatory neurons within a local population excite themselves (feedback arrow),
and also send excitatory input to inhibitory cells (downward arrows). Inhibitory neurons project to
local excitatory neurons.
to cause run-away activity in the absence of inhibition. To counterbalance the positive
excitatory feedback, inhibition needs to be even stronger (Tsodyks et al., 1997). As a result,
an inhibition-stabilized network responds to a positive external stimulation of inhibitory
neurons with a decrease of both excitatory and inhibitory activity (see Exercises).
If the coupling from excitatory populations to neighboring inhibitory populations is
stronger than that to neighboring excitatory populations, an inhibition-stabilized network
can explain the phenomenon of surrounding suppression and at the same time account
for the fact that during surrounding suppression both inhibitory and excitatory drive are
reduced (Fig. 18.13b). Such a network architecture therefore addresses concern B (Ozeki
et al., 2009).
In the above simpliﬁed model we focused on populations of neurons with the same pre-
ferred orientation, say vertical. However, in the same region of the cortex, there are also
neurons with other preferred orientations, such as diagonal or horizontal. The surround-
ing suppression effect is much weaker if the stimulus in the surroundings has a different
orientation than in the central region. We therefore conclude that the cortical connectivity
pattern does not simply depend on the physical distance between two neurons, but also on

484
Cortical ﬁeld models for perception
the difference in preferred orientation as well on the neuron type, layer, etc. Therefore, for
generalized ﬁeld models of the primary visual cortex the coupling from a neuron j with
receptive ﬁeld center xj to a neuron i with receptive ﬁeld center xi could be written as
wi j = w(xi,x j,θi,θ j,typei,typej,layeri,layer j),
(18.28)
where type refers to the type of neuron (e.g., pyramidal, fast-spiking interneuron, non-fast
spiking interneuron) and layer to the vertical position of the neurons in the cortical sheet.
Other variables should be added to account for color preference, binocular preference, etc.
18.3 Bump attractors and spontaneous pattern formation
In this section we study a continuum model with strong recurrent connections such that a
spatial activity proﬁle emerges even in cases when the input is homogeneous.
18.3.1 "Blobs" of activity: inhomogeneous states
From a computational point of view bistable systems are of particular interest because they
can be used as "memory units." For example, a homogeneous population of neurons with
all-to-all connections can exhibit a bistable behavior where either all neurons are quiescent
or all neurons are ﬁring at their maximum rate. By switching between the inactive and
the active state, the neuronal population is able to represent, store, or retrieve one bit of
information. The exciting question that arises now is whether a neuronal net with distance-
dependent coupling w(|x −y|) can store more than just a single bit of information, but
spatial patterns of activity. Sensory input, such as visual stimulation, could switch part of
the network to its excited state whereas the unstimulated part would remain in its resting
state. Owing to bistability this pattern of activity could be preserved even if the stimulation
is turned off again and thus provide a neuronal correlate of working memory.
Let us suppose we prepare the network in a state where neurons in one spatial domain are
active and all remaining neurons are quiescent. Will the network stay in that conﬁguration?
In other words, we are looking for an "interesting" stationary solution h(x) of the ﬁeld
equation (18.4). The borderline where quiescent and active domains of the network meet
is obviously most critical to the function of the network as a memory device. To start with
the simplest case with a single borderline, we consider a one-dimensional spatial pattern
where the activity changes at x = 0 from the low-activity to the high-activity state. This
pattern could be the result of inhomogeneous stimulation in the past, but since we are
interested in a memory state we now assume that the external input is simply constant, i.e.,
Iext(x,t) = Iext. Substitution of h(x) for h(x,t) in the ﬁeld equation yields
h(x)−Iext =

dy w(|x−y|)F[h(y)].
(18.29)
This is a nonlinear integral equation for the unknown function h(x).

18.3 Bump attractors and spontaneous pattern formation
485
We can ﬁnd a particular solution of Eq. (18.29) if we replace the output function by a
simple step function, for example
F(h) =

0,
h < ϑ,
1,
h ≥ϑ .
(18.30)
In this case F[h(x)] is either zero or 1 and we can exploit translation invariance to deﬁne
F[h(x)] = 1 for x > 0 and F[h(x)] = 0 for x < 0 without loss of generality. The right-hand
side of Eq. (18.29) now no longer depends on h and we ﬁnd
h(x) = Iext +
 x
−∞dz w(|z|),
(18.31)
and in particular
h(0) = Iext + 1
2 ¯w,
(18.32)
with ¯w =
 dy w(|y|). We have calculated this solution under the assumption that F[h(x)] =
1 for x > 0 and F[h(x)] = 0 for x < 0. This assumption imposes a self-consistency condition
on the solution, namely that the membrane potential reaches the threshold ϑ at x = 0.
A solution in the form of a stationary border between quiescent and active neurons can
therefore only be found if
Iext = ϑ −1
2 ¯w.
(18.33)
If the external stimulation is either smaller or greater than this critical value, then the border
will propagate to the right or to the left.
Following the same line of reasoning, we can also look for a localized "blob" of activity.
Assuming that F[h(x)] = 1 for x ∈[x1,x2] and F[h(x)] = 0 outside this interval leads to a
self-consistency condition of the form
Iext = ϑ −
 Δ
0 dx w(x),
(18.34)
with Δ = x2 −x1. The mathematical arguments are qualitatively the same if we replace the
step function by a more realistic smooth gain function.
Figure 18.14 shows that solutions in the form of sharply localized excitations exist for a
broad range of external stimulations. A simple argument also shows that the width Δ of the
blob is stable if w(Δ) < 0 (Amari, 1977). In this case blobs of activity can be induced with-
out the need for ﬁne tuning the parameters in order to fulﬁll the self-consistency condition,
because the width of the blob will adjust itself until stationarity is reached and Eq. (18.34)
holds; see Fig. 18.14a.
18.3.2 Sense of orientation and head direction cells
Head direction cells in the rodent entorhinal cortex are thought to be a neural correlate of
the internal compass of rodents. A head direction cell responds maximally if the head of

486
Cortical ﬁeld models for perception
(a)
20
100
0
20
40
60
80
100
t
-1
0
1
2
h
0
40
60
80
x
-20
-10
0
10
20
x
-0.5
0
0.5
1
1.5
2
(b)
h
Fig. 18.14 Localized "blobs" of activity. (a) A small initial perturbation develops into a stable blob
of activity. (b) Stationary proﬁle of a localized excitation for various amounts of external stimulation
(Iext = 0,0.5,...,0.3 in order of increasing width). Note that, for strong stimuli, neurons in the center
of the activity blob are less active than those close to the edge of the blob.
the animal points in the direction preferred by this cell (Taube and Muller, 1998). Different
head direction cells have different receptive ﬁelds. The preferred direction of head direction
cells depends not on absolute north and south, but rather on visual cues. In a laboratory
setting, one speciﬁc head direction cell will, for example, always ﬁre when a salient cue
card is 60◦to the left of the body axis, another one when it is 40◦to the right (Fig. 18.15a).
In an experiment during recordings from the entorhinal cortex (Zugaro et al., 2003), a
rat was trained to sit still while eating food with its head pointing in the preferred direction
of one of the cells in the entorhinal cortex. Recordings from this cell show high activity
(Fig. 18.15b). The cell remains active after the light has been switched off, indicating that
the rat has memorized its momentary orientation. We emphasize that the orientation of the
head can be described by a continuous variable. It is therefore this continuous value which
needs to be kept in memory!
During the second phase of the experiment, while lights are switched off, the cues are
rotated. Finally, in the last phase of the experiment, lights are switched on again. After
a few milliseconds, the internal compass aligns with the new position of the cues. The
activity of the recorded cell drops (Fig. 18.15b), because, in the new frame of reference,
the head direction is now outside its receptive ﬁeld (Zugaro et al., 2003). Two aspects are
important from a modeling perspective. First, memory content depends on the external
input. Second, the memory must be capable of storing a continuous variable - in contrast
to the memory models of Chapter 17 where discrete memory items are stored.
In order to represent the continuous head direction variable, ring models have been used
(Redish et al., 1996; Zhang, 1996). The location of a neuron on the ring represents its
preferred head direction (Fig. 18.16). Cells with similar preferred head direction excite
each other whereas cells with opposite preferred head direction inhibit each other. Thus,

18.3 Bump attractors and spontaneous pattern formation
487
Time [s] 
0 
0.4
-0.4
Head direction q
Cue
(a)
(b)
(c)
(d)
q
Fig. 18.15 Head direction cells. (a) The head direction θ is deﬁned with respect to salient cues in the
environment. (b) Firing rate as a function of θ. The cell responds maximally when the head points
in the cell's preferred direction. (c) The cell remains active, even if the lights are switched off. Spike
raster shows action potentials of a single head direction cell. For t < 0 the room is dark. During the
lights-off phase, the cue is manually rotated. At t = 0 the light is switched on again, with the cue in
the new position. (d) Compared to the new cue position, the head of the rat no longer points in the
cell's preferred direction and, after a few milliseconds, the cell becomes silent. Adapted from Zugaro
et al. (2003).
the ring model has a Mexican-hat connectivity. Parameters are chosen such that the model
is in the regime of bump attractors, so that the present value of presumed head direction is
kept in memory, even if stimulation stops.
Example: Activation of head direction cells
Head direction cells rely on visual cues, but also on information arising from the
acceleration sensors in the inner ears. One of the intriguing open questions is how the
sensory information from the inner ear is transformed into updates of the head direction
system (Redish et al., 1996; Zhang, 1996). A second question is how head direction
information can be maintained in the absence of further visual or acceleration input.
Here we focus on this second question.
Since the activity of head direction cells does not stop when the light is turned off,
interactions in a ring model of head direction must be chosen such that activity bumps are
stable in the absence of input. Initially, a strong visual cue ﬁxates the bump of activity at
one speciﬁc location on the ring. If the visual input is switched off, the bump remains at

488
Cortical ﬁeld models for perception
θ
(a)
(b)
(c)
Head 
direction 
Fig. 18.16 Ring model of head direction cells. (a) Different neurons code for different head direc-
tions, visualized by their position on a ring. Neighboring neurons excited each other while neurons
at larger distances along the ring inhibit each other. (b) If the input is switched to a new location
the activity bump could slowly rotate to the new location particularly if old and new inputs are close
to each other. (c) Alternatively, a switch in the input could cause the bump to reappear at the new
location; see the experimental data from Fig. 18.15. From Zugaro et al. (2003).
its location so that the past head direction is memorized. When a new input with rotated
cues is switched on, the activity bump could either rotate towards the new location or
disappear at the old and reappear at the new location (Fig. 18.16). For large jumps in
the input, the latter seems to be more likely in view of the existing experimental data
(Zugaro et al., 2003).
18.4 Summary
The cortex is a large, but thin sheet of neurons. Field models, in their spatial interpretation,
describe the population activity of neurons as a function of the location on the cortical
sheet.
Field models are, however, also used in a more general setting. In sensory cortices,
neuronal activity encodes continuous variables, such as position of an object, orientation
of edges, direction of movement etc. Field models, in their more abstract interpretation,
represent the distribution of activity along the axes representing one or several of these
variables.
In ﬁeld models, interactions between populations of neurons depend on the distance of
neurons in the physical, or abstract, space. Classical ﬁeld models assume a Mexican-hat
interaction pattern where local excitation is combined with long-range inhibition. Field
models with Mexican-hat interaction have two important regimes of parameter settings. In
the input-driven regime, spatial activity patterns can only arise if the input has a non-trivial
spatial structure. In the bump-attractor regime, however, localized blobs of activity emerge
even in the absence of input.
Mexican-hat interaction combines excitation and inhibition from the same presynaptic

18.4 Summary
489
population and must therefore be considered as an effective, mathematical coupling scheme
between neurons. It is, however, possible to construct similar ﬁeld models with separate
populations of excitatory neurons with long-range interactions, and inhibitory neurons with
short-range interactions. These models bring the main results of ﬁeld models a step closer
to biological reality.
Exercises
1. Bump formation. Consider a one-dimensional discrete recurrent network with population units
1 ≤i ≤N and update rule
Ai(t +1) = F
!
∑
k
wikxk(t)+∑
j
BijAj(t)
"
,
(18.35)
where wik is the coupling strength to the input xk and Bij are the recurrent weights. Each neuron
receives local excitation from its d neighbors on both sides, Bij = 1 for |i−j| ≤d, and inhibition
from all others, Bij = −β ≤−1 for |i −j| > d. The gain function F(h) is the Heaviside step
function, i.e., F(h) = 1 for h > 0 and F(h) = 0 for h ≤0.
(a) Imagine that one single unit is stimulated and therefore becomes active. This neuron will
excite its neighbors. Show that in the steady state of the network the number N of active neurons
is larger than 2d.
Hint: Consider the balance of excitation and inhibition at the border of the blob.
(b) How does the value of β inﬂuence the number of active neurons? What happens in the limit
of β →1?
(c) Assume that d = 5, N = 1000 and the input to neuron i = 17 is 1. Compute the ﬁrst three time
steps of the network dynamics.
2. Stability of homogeneous solution with excitatory coupling.
(a) Consider the purely excitatory coupling
w(x) =
¯w
√
2π σ2 e−x2/(2σ2) ,
(18.36)
with the mean strength
 dx w(x) = ¯w and Fourier transform

dxw(x)eikx = ¯we−k2 σ2/2 .
(18.37)
Under what conditions is the homogeneous solution stable (assume F′(h0) > 0)?
(b) Consider a general coupling function w(x) such that this function can be written as an auto-
correlation
w(x) = ¯w
 ∞
−∞f(x′ −x)f(x′)dx′ ,
(18.38)
for some real function f(x). Under what conditions is the homogeneous solution stable? Hint:
The convolution theorem.
3. Phase plane analysis of inhibition-stabilized network. An excitatory population is coupled to
an inhibitory population, controlled by the activity equations
τE
dAE
dt
= −AE +F(wEEAE −wEIAI +IE),
τI
dAI
dt = −AI +F(wIEAE −wIIAI +II −ϑ).
(18.39)
Assume that F(h) = 0 for h < 0; F(h) = h for 0 ≤h ≤1 and F(h) = 1 for h > 1.

490
Cortical ﬁeld models for perception
(a) Draw the nullclines in the phase plane spanned by the variables AE (x-axis) and AI (y-axis) in
the absence of input IE = II = 0 and ϑ = 0.5. Assume that wEE = wEI = 2, wIE = 1 and wII = 0.
(b) Assume that the inhibitory population receives positive input II = 0.2. Redraw the nullclines.
Does the population activity of excitatory or inhibitory populations increase or decrease? Does
this correspond to your intuition? Can you interpret the result?
4. Surrounding inhibition. We study the model of the previous exercise in the linear region (F(h) =
h). Two instantiations i = 1,2 of the model are coupled via an additional connection from AE,1
to Ai,2 and from AE,2 to Ai,1 with lateral connections wlat > 0.
(a) Assume that the ﬁrst excitatory population receives an input IE,1 = 0.3. Calculate the station-
ary population activity of all four populations.
(b) Assume that both excitatory populations receive an input IE,1 = 0.3 = IE,2. Calculate the
stationary population activity of AE,1 and AI,1. Do the population activities increase or decrease
compared to the case considered in (a)?
(c) Can you interpret your result in the context of the surrounding suppression?

19
Synaptic plasticity and learning
In the network models discussed in Parts III and IV, each synapse has so far been charac-
terized by a single constant parameter wi j, called the synaptic weight, synaptic strength, or
synaptic efﬁcacy. If wi j is constant, the amplitude of the response of a postsynaptic neuron
i to the arrival of action potentials from a presynaptic neuron j should always be the same.
Electrophysiological experiments, however, show that the response amplitude is not ﬁxed
but can change over time. In experimental neuroscience, changes of the synaptic strength
are called synaptic plasticity.
Appropriate stimulation paradigms can induce changes of the postsynaptic response that
last for hours or days. If the stimulation paradigm leads to a persistent increase of the
synaptic efﬁcacy, the effect is called long-term potentiation of synapses, or LTP for short.
If the result is a decrease of the synaptic efﬁcacy, it is called long-term depression (LTD).
These persistent changes are thought to be the neuronal correlate of learning and memory.
LTP and LTD are different from short-term synaptic plasticity such as synaptic facilitation
or depression that we have encountered in Section 3.1. Facilitated or depressed synapses
decay back to their normal strength within less than a few seconds, whereas, after an LTP
or LTD protocol, synapses keep their new values for hours. The long-term storage of the
new values is thought to be the basis of long-lasting memories.
In the formal theory of neural networks, the weight wi j of a connection from neuron j
to i is considered a parameter that can be adjusted so as to optimize the performance of a
network for a given task. The process of parameter adaptation is called learning and the
procedure for adjusting the weights is referred to as a learning rule. Here learning is meant
in its widest sense. It may refer to synaptic changes during development just as much as to
the speciﬁc changes necessary to memorize a visual pattern or to learn a motor task. There
are many different learning rules, all of which we cannot cover in this chapter. In particular,
we leave aside the large class of "supervised" learning rules which are an important topic
in the ﬁelds of artiﬁcial neural networks and machine learning. Here we focus on two other
classes of learning rules that are of biological relevance.
In Section 19.1 we introduce the Hebb rule and discuss its relation to experimental pro-
tocols for long-term potentiation (LTP) and spike-timing-dependent plasticity (STDP). In
Section 19.2 we formulate mathematical models of Hebbian plasticity. We shall see in Sec-
tion 19.3 that Hebbian plasticity causes synaptic connections to tune to the statistics of the

492
Synaptic plasticity and learning
post
(a)
pre
wij
j
i
k
= Active
= Inactive
Banana
assembly
Apple
assembly
(b)
Fig. 19.1 Hebbian learning. (a) The change of a synaptic weight wij depends on the state of the
presynaptic neuron j and the postsynaptic neuron i and the present efﬁcacy wij, but not on the state
of other neurons k. (b) Hebbian learning strengthens the connectivity within assemblies of neurons
that ﬁre together, for example during the perception of a banana. Schematic ﬁgure.
input. Such a self-tuning of network properties is an example of unsupervised learning.
While unsupervised learning is thought to be a major drive for developmental plasticity in
the brain, it is not sufﬁcient to learn speciﬁc behaviors such as pressing a button in order
to receive a reward. In Section 19.4 we discuss reward-based learning rules in the form
of STDP modulated by reward. Reward-modulated synaptic plasticity is thought to be the
basis of behavioral learning observed in animal conditioning experiments.
19.1 Hebb rule and experiments
Since the 1970s, a large body of experimental results on synaptic plasticity has been accu-
mulated. Many of these experiments are inspired by Hebb's postulate (Hebb, 1949), which
describes how the connection from a presynaptic neuron A to a postsynaptic neuron B
should be modiﬁed:
When an axon of cell A is near enough to excite cell B and repeatedly or persistently takes part in
ﬁring it, some growth process or metabolic change takes place in one or both cells such that A's
efﬁciency, as one of the cells ﬁring B, is increased.
Today this famous postulate is often rephrased in the sense that modiﬁcations of the
synaptic transmission efﬁcacy are driven by correlations in the ﬁring activity of pre- and
postsynaptic neurons; see Fig. 19.1a. The shortest summary is: neurons that "ﬁre together,
wire together" (Shatz, 1992). Note that the term "ﬁre together" is less precise than Hebb's
original formulation which contains an asymmetry since a neuron that "contributes to ﬁr-
ing" another one has to be active slightly before the latter. Even though the idea of learning
through correlations dates further back in the past (James, 1890), correlation-based learn-
ing is now generally called Hebbian learning.
Hebb formulated his principle on purely theoretical grounds. He realized that such a
mechanism would help to stabilize speciﬁc neuronal activity patterns in the brain; see

19.1 Hebb rule and experiments
493
Fig. 19.1b. If neuronal activity patterns correspond to behavior, then stabilization of spe-
ciﬁc patterns implies learning of speciﬁc types of behaviors (Hebb, 1949). We empha-
size that Hebbian learning is unsupervised, because there is no notion of "good" or "bad"
changes of a synapse. Synaptic changes happen whenever there is joint activity of pre- and
postsynaptic neurons, i.e., they are driven by the neuronal ﬁring patterns. These patterns
may reﬂect sensory stimulation as well as ongoing brain activity, but there is no feedback
signal from a "supervisor" or from the environment.
In this section we review experimental protocols that induce lasting synaptic changes
and discuss their relation to Hebbian learning.
19.1.1 Long-term potentiation
The classic paradigm of LTP induction is, very schematically, the following (Brown et al.,
1989; Bliss and Collingridge, 1993). Neuronal activity is monitored by an extracellular or
intracellular electrode, while presynaptic ﬁbers are stimulated by means of a second (extra-
cellular) electrode. Small pulses are applied to the presynaptic ﬁbers in order to measure
the strength of the postsynaptic response (Fig. 19.2a). The amplitude of the test pulse is
chosen such that the stimulation evokes a postsynaptic potential, but no action potentials.
In a second step, the input ﬁbers are strongly stimulated by a sequence of high-frequency
pulses so as to evoke postsynaptic ﬁring (Fig. 19.2b). After that, the strength of the post-
synaptic response to small pulses is tested again and a signiﬁcantly increased amplitude of
postsynaptic potentials is found (Fig. 19.2c). This change in the synaptic strength persists
over many hours and is thus called long-term potentiation or LTP (Fig. 19.2d).
The increase of the synaptic weights can be interpreted as "Hebbian," because it occurred
after an episode of joint activity of pre- and postsynaptic neurons. Early LTP experiments
were done with two extracellular electrodes (one for the stimulation of presynaptic ﬁbers,
the other for the measurement of the neuronal response), but in later experiments LTP was
also studied with intracellular recordings.
Example: Voltage dependence of LTP
With an intracellular electrode, an experimenter can not only record the response to an
incoming spike, but also manipulate the membrane potential of the postsynaptic neuron;
see Fig. 19.3. If presynaptic spikes arrive during a period where the neuron is strongly
depolarized, LTP is induced at the activated synapses. On the other hand, spike arrival
combined with weak depolarization causes LTD (Artola et al., 1990; Artola and Singer,
1993; Ngezahayo et al., 2000). These and similar experiments reveal the importance of
the postsynaptic voltage during the induction of synaptic plasticity. If we interpret strong
depolarization of the postsynaptic neuron as a substitute of neuronal activity, the above
protocol for LTP induction can be called "Hebbian."

494
Synaptic plasticity and learning
(a)
(b)
(c)
I
t
t
V
I
t
I
t
t
V
t
V
100
150
200
(d)
50
1
2
3
4
Time [h]
Relative amp. [%]
a
c
b
Fig. 19.2 Schematic drawing of a paradigm of LTP induction. (a) A weak test pulse (left) evokes
the postsynaptic response sketched on the right-hand side of the ﬁgure. (b) A strong stimulation
sequence (left) triggers postsynaptic ﬁring (right, the peak of the action potential is out of bounds).
(c) A test pulse applied some time later evokes a larger postsynaptic response (right; solid line) than
the initial response. The dashed line is a copy of the initial response in (a). (d) The relative amplitude
as measured with the test pulses illustrated in (a) and (c) is increased after the strong stimulation at
t = 1 h. Schematic ﬁgure.
19.1.2 Spike-timing-dependent plasticity
Pairing experiments with multiple intracellular electrodes in synaptically coupled neurons
have opened the possibility of studying synaptic plasticity at an excellent spatial and tem-
poral resolution (Markram et al., 1997; Zhang et al., 1998; Debanne et al., 1998; Bi and
Poo, 1998, 1999; Sj¨ostr¨om et al., 2001); see Bi and Poo (2001) and Sj¨ostr¨om and Gerstner
(2010) for reviews.
Figure 19.4 illustrates a pairing experiment with cultured hippocampal neurons where
the presynaptic neuron (j) and the postsynaptic neuron (i) are forced to ﬁre spikes at time
t f
j and t f
i , respectively (Bi and Poo, 1998). The resulting change in the synaptic efﬁcacy
Δwi j after several repetitions of the experiment turns out to be a function of the difference
t f
j −t f
i between the ﬁring times of the pre- and postsynaptic neuron. This observation

19.2 Models of Hebbian learning
495
300
200
100
-50
-30
-10
10
LTP
LTD
V [mV]
Relative amp. [%]
Fig. 19.3
Voltage dependence of LTP. Repeating the
experiment shown in Fig. 19.2 while holding the mem-
brane potential of the postsynaptic neuron shows a
decrease in EPSP amplitude when holding at −30 mV
and an increase when holding a higher voltage. Vertical
axis: Ratio of EPSP amplitude wij(T)/wij(0) before
(t = 0) and after (t = T) the plasticity inducing pro-
tocol. Adapted from Ngezahayo et al. (2000).
has given rise to the term "spike-timing-dependent plasticity" (STDP). Most notably, the
direction of the change depends critically on the relative timing of pre- and postsynaptic
spikes on a millisecond time scale (Markram et al., 1997). The synapse is strengthened if
the presynaptic spike occurs shortly before the postsynaptic neuron ﬁres, but the synapse is
weakened if the sequence of spikes is reversed; see Fig. 19.4b. This observation is indeed
in agreement with Hebb's postulate because presynaptic neurons that are active slightly
before the postsynaptic neuron are those which "take part in ﬁring it" whereas those that
ﬁre later obviously did not contribute to the postsynaptic action potential. An asymmetric
learning window such as the one in Fig. 19.4f is thus an implementation of the causality
requirement that is implicit in Hebb's principle.
Similar results on spike-time-dependent synaptic plasticity have been found in various
neuronal systems (Abbott and Nelson, 2000; Bi, 2002; Caporale and Dan, 2008), but there
are also characteristic differences. Synapses between parallel ﬁbers and "Purkinje-cells"
in the cerebellar-like structure of electric ﬁsh, for example, show the opposite dependence
on the relative timing of presynaptic input and the (so-called "broad") postsynaptic spike
(Bell et al., 1997). In this case the synapse is weakened if the presynaptic input arrives
shortly before the postsynaptic spike (anti-Hebbian plasticity).
19.2 Models of Hebbian learning
Before we turn to spike-based learning rules, we ﬁrst review the basic concepts of
correlation-based learning in a ﬁring rate formalism. Firing rate models (see Chapter 15)
have been used extensively in the ﬁeld of artiﬁcial neural networks; see Hertz et al. (1991);
Haykin (1994) for reviews.
19.2.1 A mathematical formulation of Hebb's rule
In order to ﬁnd a mathematically formulated learning rule based on Hebb's postulate we
focus on a single synapse with efﬁcacy wi j that transmits signals from a presynaptic neuron
j to a postsynaptic neuron i. For the time being we content ourselves with a description in

496
Synaptic plasticity and learning
I
t
V
I
t
I
(a)
(b)
(c)
I
t
V
Δt
75
100
125
0
25
50
a
c
b
Relative amp. [%]
Time [min]
t j
f
f
−ti =-10ms
t j
f
f
−ti =10ms
(d)
Δwij
wij
0
1
−0.5
0
40
−40
t j
f
f
−ti
(f)
j
i
t j
f
f
ti
(e)
Fig. 19.4 Spike-Timing Dependent Plasticity. (a) Intracellular electrodes are used to manipulate two
synaptically coupled neurons (axons are shown as dashed lines). A test pulse (I) injected into the
presynaptic neuron causes an EPSP in the postsynaptic neuron (V). (b) During the plasticity induc-
tion protocol of a few seconds ("pairing"), both neurons are stimulated with current pulses forcing
spikes at precise moments in time. (c) After the pairing protocol, the presynaptic neuron is stimu-
lated by another current pulse, testing the level of potentiation of the synapse (before pairing protocol,
dashed line; after, full line). (d) Amplitude of EPSP relative to initial amplitude as a function of time
after the pairing protocol. If the presynaptic spike is 10 ms before the postsynaptic one, potentiation
occurs (full line). If the order of the spikes is inverted, depression occurs (data points redrawn after
Markram et al. (1997)). (e) Synaptic changes Δwij occur only if presynaptic ﬁring at t f
j and post-
synaptic activity at t f
i occur sufﬁciently close to each other. (f) The STDP window summarizes the
timing requirements between pre- and postsynaptic spikes. Experimentally measured weight changes
(circles) as a function of t f
j −t f
i in milliseconds overlaid on a schematic two-phase learning window
(solid line). A positive change (LTP) occurs if the presynaptic spike precedes the postsynaptic one;
for a reversed timing, synaptic weights are decreased (data points redrawn after the experiments of
Bi and Poo (1998)).
terms of mean ﬁring rates. In what follows, the activity of the presynaptic neuron is denoted
by νj and that of the postsynaptic neuron by νi.
There are two aspects of Hebb's postulate that are particularly important: locality and
joint activity. Locality means that the change of the synaptic efﬁcacy can depend only on
local variables, i.e., on information that is available at the site of the synapse, such as pre-
and postsynaptic ﬁring rate, and the actual value of the synaptic efﬁcacy, but not on the
activity of other neurons. Based on the locality of Hebbian plasticity we can write down a
rather general formula for the change of the synaptic efﬁcacy,

19.2 Models of Hebbian learning
497
d
dt wi j = F(wi j;νi,ν j).
(19.1)
Here, dwi j/dt is the rate of change of the synaptic coupling strength and F is a so-far-
undetermined function (Sejnowski and Tesauro, 1989). We may wonder whether there are
other local variables (e.g., the input potential hi; see Chapter 15) that should be included
as additional arguments of the function F. It turns out that in standard rate models this is
not necessary, since the input potential hi is uniquely determined by the postsynaptic ﬁring
rate, νi = g(hi), with a monotone gain function g.
The second important aspect of Hebb's postulate is the notion of "joint activity" which
implies that pre- and postsynaptic neurons have to be active simultaneously for a synaptic
weight change to occur. We can use this property to learn something about the function F.
If F is sufﬁciently well behaved, we can expand F in a Taylor series about νi = ν j = 0,
d
dt wi j = c0(wi j)+cpre
1 (wi j)ν j +cpost
1
(wi j)νi +cpre
2 (wi j)ν2
j
+cpost
2
(wi j)ν2
i +ccorr
11 (wi j)νi ν j +O(ν3).
(19.2)
The term containing ccorr
11 on the right-hand side of (19.2) is bilinear in pre- and postsynaptic
activity. This term implements the AND condition for joint activity. If the Taylor expansion
had been stopped before the bilinear term, the learning rule would be called "non-Hebbian,"
because pre- or postsynaptic activity alone induces a change of the synaptic efﬁcacy, and
joint activity is irrelevant. Thus a Hebbian learning rule needs either the bilinear term
ccorr
11 (wi j)νi ν j with ccorr
11 > 0 or a higher-order term (such as c21(wi j)ν2
i ν j) that involves
the activity of both pre- and postsynaptic neurons.
Example: Hebb rules, saturation, and LTD
The simplest choice for a Hebbian learning rule within the Taylor expansion of Eq.
(19.2) is to ﬁx ccorr
11 at a positive constant and to set all other terms in the Taylor expansion
to zero. The result is the prototype of Hebbian learning,
d
dt wi j = ccorr
11 νi ν j .
(19.3)
We note in passing that a learning rule with ccorr
11 < 0 is usually called anti-Hebbian
because it weakens the synapse if pre- and postsynaptic neuron are active simultane-
ously, a behavior that is just contrary to that postulated by Hebb.
Note that, in general, the coefﬁcient ccorr
11
may depend on the current value of the
weight wi j. This dependence can be used to limit the growth of weights at a maximum
value wmax. The two standard choices of weight-dependence are called "hard bound"
and "soft bound," respectively. Hard bound means that ccorr
11 = γ2 is constant in the range
0 < wi j < wmax and zero otherwise. Thus, weight growth stops abruptly if wi j reaches
the upper bound wmax.

498
Synaptic plasticity and learning
Post
Pre
dwij/dt ∝
dwij/dt ∝
dwij/dt ∝
dwij/dt ∝
dwij/dt ∝
νi
νj
νi νj
νi νj −c0
(νi−νθ)νj
νi (νj−νθ)
(νi−⟨νi⟩)(νj−⟨νj⟩)
ON
ON
+
+
+
+
+
ON
OFF
0
−
0
−
−
OFF
ON
0
−
−
0
−
OFF
OFF
0
−
0
0
+
Table 19.1 The change d
dt wi j of a synapse from j to i for various Hebb rules as a function
of pre- and postsynaptic activity. "ON" indicates a neuron ﬁring at high rate (ν > 0),
whereas "OFF" means an inactive neuron (ν = 0). From left to right: Standard Hebb
rule, Hebb with decay, Hebb with postsynaptic or presynaptic LTP/LTD threshold,
covariance rule. The parameters are 0 < νθ < νmax and 0 < c0 < (νmax)2.
A soft bound for the growth of synaptic weights can be achieved if the parameter ccorr
11
in Eq. (19.3) tends to zero as wi j approaches its maximum value wmax,
ccorr
11 (wi j) = γ2 (wmax −wi j)β ,
(19.4)
with positive constants γ2 and β. The typical value of the exponent is β = 1, but other
choices are equally possible (G¨utig et al., 2003). For β →0, the soft-bound rule (19.4)
converges to the hard-bound one.
Note that neither Hebb's original proposal nor the simple rule (19.3) contains a possi-
bility for a decrease of synaptic weights. However, in a system where synapses can only
be strengthened, all efﬁcacies will eventually saturate at their upper maximum value.
Our formulation (19.2) is sufﬁciently general to allow for a combination of synaptic
potentiation and depression. For example, if we set wmax = β = 1 in (19.4) and combine
it with a choice c0(wi j) = −γ0 wi j, we obtain a learning rule
d
dt wi j = γ2 (1−wi j)νi ν j −γ0 wi j ,
(19.5)
where, in the absence of stimulation, synapses spontaneously decay back to zero. Many
other combinations of the parameters c0,...,ccorr
11
in Eq. (19.2) exist. They all give
rise to valid Hebbian learning rules that exhibit both potentiation and depression; see
Table 19.1.
Example: Covariance rule
Sejnowski (1977) has suggested a learning rule of the form
d
dtwi j = γ (νi −⟨νi⟩) (ν j −⟨ν j⟩) ,
(19.6)
called the covariance rule. This rule is based on the idea that the rates νi(t) and ν j(t)
ﬂuctuate around mean values ⟨νi⟩,⟨ν j⟩that are taken as running averages over the recent

19.2 Models of Hebbian learning
499
ﬁring history. To allow a mapping of the covariance rule to the general framework of
Eq. (19.2), the mean ﬁring rates ⟨νi⟩and ⟨ν j⟩have to be constant in time.
Example: Oja's rule
All of the above learning rules had cpre
2
= cpost
2
= 0. Let us now consider a nonzero
quadratic term cpost
2
= −γ wi j. We take ccorr
11 = γ > 0 and set all other parameters to zero.
The learning rule
d
dt wi j = γ [νi ν j −wi j ν2
i ]
(19.7)
is called Oja's rule (Oja, 1982). Under some general conditions Oja's rule converges
asymptotically to synaptic weights that are normalized to ∑j w2
i j = 1 while keeping
the essential Hebbian properties of the standard rule of Eq. (19.3); see Exercises. We
note that normalization of ∑j w2
i j implies competition between the synapses that make
connections to the same postsynaptic neuron, i.e., if some weights grow, others must
decrease.
Example: Bienenstock-Cooper-Munro rule
Higher-order terms in the expansion on the right-hand side of Eq. (19.2) lead to more
intricate plasticity schemes. Let us consider
d
dt wi j = φ (νi −νθ)ν j
(19.8)
with a nonlinear function φ and a reference rate νθ. If we take νθ to be a function f(⟨νi⟩)
of the average output rate ⟨νi⟩, then we obtain the so-called Bienenstock-Cooper-Munro
(BCM) rule (Bienenstock et al., 1982).
The basic structure of the function φ is sketched in Fig. 19.5. If presynaptic activity
is combined with moderate levels of postsynaptic excitation, the efﬁcacy of synapses
activated by presynaptic input is decreased. Weights are increased only if the level of
postsynaptic activity exceeds a threshold, νθ. The change of weights is restricted to those
synapses which are activated by presynaptic input. A common choice for the function
φ is
d
dt wi j = η νi (νi −νθ)ν j = c21ν2
i ν j −ccorr
11 νiν j,
(19.9)
which can be mapped to the Taylor expansion of Eq. (19.2) with c21 = η and ccorr
11 =
−ηνθ.
For stationary input, it can be shown that the postsynaptic rate νi under the BCM-rule
(19.9) has a ﬁxed point at νθ which is unstable (see Exercises). To avoid the postsynaptic
ﬁring rate blowing up or decaying to zero, it is therefore necessary to turn νθ into an
adaptive variable which depends on the average rate ⟨νi⟩. The BCM rule leads to input

500
Synaptic plasticity and learning
ni
nq
n0
dt
d
LTP
wij
LTD
0
Fig. 19.5 BCM rule. Synaptic plasticity is
characterized by two thresholds for the post-
synaptic activity (Bienenstock et al., 1982).
Below ν0 no synaptic modiﬁcation occurs,
between ν0 and νθ synapses are depressed,
and for postsynaptic ﬁring rates beyond νθ
synaptic potentiation can be observed. Often
ν0 is set to zero.
selectivity (see Exercises) and has been successfully used to describe the development
of receptive ﬁelds (Bienenstock et al., 1982).
19.2.2 Pair-based models of STDP
We now switch from rate-based models of synaptic plasticity to a description with spikes.
Suppose a presynaptic spike occurs at time tpre and a postsynaptic one at time tpost. Most
models of STDP interpret the biological evidence in terms of a pair-based update rule, i.e.,
the change in weight of a synapse depends on the temporal difference |Δt| = |tpost −tpre|;
see Fig. 19.4f. In the simplest model, the updates are
Δw+ = A+(w)·exp(−|Δt|/τ+) at tpost
for tpre < tpost,
Δw−= A−(w)·exp(−|Δt|/τ−) at tpre
for tpre < tpost,
(19.10)
where A±(w) describes the dependence of the update on the current weight of the synapse.
The update of synaptic weights happens immediately after each presynaptic spike (at time
tpre) and each postsynaptic spike (at time tpost). A pair-based model is fully speciﬁed by
deﬁning: (i) the weight-dependence of the amplitude parameter A±(w); (ii) which pairs
are taken into consideration to perform an update. A simple choice is to take all pairs
into account. An alternative is to consider for each postsynaptic spike only the nearest
presynaptic spike or vice versa. Note that spikes that are far apart hardly contribute because
of the exponentially fast decay of the update amplitude with the interval |Δt|. Instead of
an exponential decay (Song et al., 2000), some other arbitrary time dependence, described
by a learning window W+(s) for LTP and W−(s) for LTD is also possible (Gerstner et al.,
1996a; Kempter et al., 1999a).
If we introduce Sj = ∑f δ(t −t f
j ) and Si = ∑f δ(t −t f
i ) for the spike trains of pre- and
postsynaptic neurons, respectively, then we can write the update rule in the form (Kistler
and van Hemmen, 2000)
d
dt wi j(t) = S j(t)

apre
1 +
 ∞
0 A−(wi j)W−(s)Si(t −s) ds

+Si(t)

apost
1
+
 ∞
0 A+(wi j)W+(s)S j(t −s) ds

,
(19.11)

19.2 Models of Hebbian learning
501
where W± denotes the time course of the learning window while apre
1
and apost
1
are non-
Hebbian contributions, analogous to the parameters cpre
1
and cpost
1
in the rate-based model
of Eq. (19.2). In the standard pair-based STDP rule, we have W±(s) = exp(−s/τ±) and
apre
1
= apost
1
= 0; see 19.10.
Example: Implementation by local variables
The pair-based STDP rule of 19.10 can be implemented with two local variables,
i.e., one for a low-pass ﬁltered version of the presynaptic spike train and one for the
postsynaptic spikes. Suppose that each presynaptic spike at synapse j leaves a trace x j,
i.e., its update rule is
dx j
dt = −xj
τ+
+∑
f
δ(t −t f
j ),
(19.12)
where t f
j is the ﬁring time of the presynaptic neuron. In other words, the variable is
increased by an amount of one at the moment of a presynaptic spike and decreases
exponentially with time constant τ+ afterward. Similarly, each postsynaptic spike leaves
a trace yi
dyi
dt = −yi
τ−
+∑
f
δ(t −t f
i ).
(19.13)
The traces x j and yi play an important role during the weight update. At the moment
of a presynaptic spike, a decrease of the weight is induced proportional to the value of
the postsynaptic trace yi. Analogously, potentiation of the weight occurs at the moment
of a postsynaptic spike proportional to the trace xj left by a previous presynaptic spike,
dwi j/dt = −A−(wi j)yi(t)∑
f
δ(t −t f
j )+A+(wi j)xj(t)∑
f
δ(t −t f
i ).
(19.14)
The traces xj and yi correspond here to the factors exp(−|Δt|/τ±) in 19.10. For the
weight dependence of the factors A−and A+, one can use either hard bounds or soft
bounds; see Eq. (19.4).
19.2.3 Generalized STDP models
There is considerable evidence that the pair-based STDP rule discussed above cannot give
a full account of experimental results with STDP protocols. Speciﬁcally, they reproduce
neither the dependence of plasticity on the repetition frequency of pairs of spikes in an
experimental protocol, nor the results of triplet and quadruplet experiments.
STDP experiments are usually carried out with about 50−60 pairs of spikes. The tempo-
ral distance of the spikes in the pair is of the order of a few to tens of milliseconds, whereas

502
Synaptic plasticity and learning
xj(t)
yi(t)
wij(t)
i
j
Fig. 19.6 Implementation of pair-based plasticity by local variables: The presynaptic spikes leave
a trace xj(t), postsynaptic spikes a trace yi(t). The weight increases at the moment of a postsynap-
tic spike proportional to the momentary value of the trace xj(t) left by previous presynaptic spike
arrivals. Analogously we get depression for post-before-pre pairings at the moment of a presynaptic
spike (vertical dashed lines highlight moments of spike ﬁring). From Morrison et al. (2008).
the temporal distance between the pairs is of the order of hundreds of milliseconds to
seconds. In the case of a potentiation protocol (i.e., pre-before-post), standard pair-based
STDP models predict that if the repetition frequency ρ is increased, the strength of the
depressing interaction (i.e., post-before-pre) becomes greater, leading to less net poten-
tiation. However, experiments show that increasing the repetition frequency leads to an
increase in potentiation (Sj¨ostr¨om et al., 2001; Senn et al., 2001). Other experimenters have
employed multiple-spike protocols, such as repeated presentations of symmetric triplets of
the form pre-post-pre and post-pre-post (Bi, 2002; Froemke and Dan, 2002; Wang et al.,
2005; Froemke et al., 2006). Standard pair-based models predict that the two sequences
should give the same results, as they each contain one pre-post pair and one post-pre pair.
Experimentally, this is not the case.
Here we review two examples of simple models which account for these experimental
ﬁndings (Pﬁster and Gerstner, 2006; Clopath et al., 2010), but there are other models which
also reproduce frequency dependence, (e.g., Senn, 2002).
Triplet model
One simple approach to modeling STDP which addresses the issues of frequency depen-
dence is the triplet rule developed by Pﬁster and Gerstner (2006). In this model, LTP is
based on sets of three spikes (one presynaptic and two postsynaptic). The triplet rule can
be implemented with local variables as follows. Similarly to pair-based rules, each spike
from the presynaptic neuron j contributes to a trace xj at the synapse:
dxj
dt = −xj
τ+
+∑
t f
j
δ

t −t f
j
	
,
where t f
j denotes the ﬁring times of the presynaptic neuron. Unlike pair-based rules, each
spike from postsynaptic neuron i contributes to a fast trace yi,1 and a slow trace yi,2 at the

19.2 Models of Hebbian learning
503
xj(t)
yi,1(t)
yi,2(t)
i
j
Fig. 19.7 Implementation of the triplet rule by local variables. The spikes of a presynaptic neuron j
contribute to a trace x j(t), the spikes of postsynaptic neuron i contribute to a fast trace yi,1(t) and a
slow trace yi,2(t). The update of the weight wij at the moment of a presynaptic spike is proportional
to the momentary value of the fast trace yi,1(t), as in the pair-based model of Fig. 19.6. The update
of the weight wij at the moment of a postsynaptic spike is proportional to the momentary value of
the trace x j(t) and the value of the slow trace yi,2(t) just before the spike. Moments of weight update
are indicated by vertical dashed lines. From Morrison et al. (2008).
synapse:
dyi,1
dt
= −yi,1
τ1
+∑
f
δ(t −t f
i ),
dyi,2
dt
= −yi,2
τ2
+∑
f
δ(t −t f
i ),
where τ1 < τ2; see Fig. 19.7. The new feature of the rule is that LTP is induced by a triplet
effect: the weight change is proportional to the value of the presynaptic trace x j evaluated
at the moment of a postsynaptic spike and also to the slow postsynaptic trace yi,2 remaining
from previous postsynaptic spikes:
Δw+
i j

t f
i
	
= A+ (wi j) xj

t f
i
	
yi,2

t f−
i
	
(19.15)
where t f−
i
indicates that the function yi,2 is to be evaluated before it is incremented due to
the postsynaptic spike at t f
i . LTD is analogous to the pair-based rule, given in (19.14), i.e.,
the weight change is proportional to the value of the fast postsynaptic trace yi,1 evaluated
at the moment of a presynaptic spike.
The triplet rule reproduces experimental data from visual cortical slices (Sj¨ostr¨om et al.,
2001) that increasing the repetition frequency in the STDP pairing protocol increases net
potentiation (19.8). It also gives a good ﬁt to experiments based on triplet protocols in
hippocampal culture (H.-X.Wang et al., 2005).
The main functional advantage of such a triplet learning rule is that it can be mapped
to the BCM rule of Eqs. (19.8) and (19.9): if we assume that the pre- and postsynaptic
spike trains are governed by Poisson statistics, the triplet rule exhibits depression for low

504
Synaptic plasticity and learning
t j
f
t i
f
j
i
(a)
1/r
0
10
20
30
40
50
100
150
200
50
ρ[Hz]
Relative amp. [%]
(b)
Fig. 19.8
Frequency dependence of STDP. (a) The experimental protocol depicted in Fig. 19.4
was repeated for different frequency, ρ, of pre-post pairs. (b) The triplet rule reproduces the ﬁnding
that increased frequency of pair repetition leads to increased potentiation in visual cortex pyramidal
neurons. Top curve t f
j −t f
i = 10 ms, bottom curve -10 ms. Data from Sj¨ostr¨om et al. (2001), ﬁgure
adapted from Pﬁster et al. (2006).
postsynaptic ﬁring rates and potentiation for high postsynaptic ﬁring rates (Pﬁster and Ger-
stner, 2006); see Exercises. If we further assume that the triplet term in the learning rule
depends on the mean postsynaptic frequency, a sliding threshold between potentiation and
depression can be deﬁned. In this way, the learning rule matches the requirements of the
BCM theory and inherits the properties of the BCM learning rule such as the input selec-
tivity (see Exercises). From the BCM properties, we can immediately conclude that the
triplet model should be useful for receptive ﬁeld development (Bienenstock et al., 1982).
Example: Plasticity model with voltage dependence
Spike timing dependence is only one of several manifestations of synaptic plasticity.
Apart from spike timing, synaptic plasticity also depends on several other variables, in
particular on postsynaptic voltage (Fig. 19.3). In this example, we present the voltage-
dependent model of Clopath et al. (2010).
The Clopath model exhibits separate additive contributions to the plasticity rule, one
LTD and another for LTP. For the LTD part, presynaptic spike arrival at a synapse from
a presynaptic neuron j to a postsynaptic neuron i induces depression of the synap-
tic weight wi j by an amount −ALTD [ui,−(t) −θ−]+ that is proportional to the average
postsynaptic depolarization ui,−. The brackets []+ indicate rectiﬁcation, i.e., any value
ui,−< θ−does not lead to a change; see Artola et al. (1990) and Fig. 19.3. The quantity
ui,−(t) is an low-pass ﬁltered version of the postsynaptic membrane potential u(t) with
a time constant τ−:
τ−
d
dt ui,−(t) = −ui,−(t)+ui(t).
Introducing the presynaptic spike train Sj(t) = ∑f δ(t −t f
j ), the update rule for

19.3 Unsupervised learning
505
depression is (Fig. 19.9)
d
dt wLTD
i j
= −ALTD( ¯ui)Sj(t)[ui,−(t)−θ−]+
if wij > wmin,
(19.16)
where ALTD( ¯ui) is an amplitude parameter that depends on the mean depolarization ¯u of
the postsynaptic neuron, averaged over a time scale of 1 second. A choice ALTD( ¯ui) =
α
¯u2
i
u2
ref where u2
ref is a reference value, is a simple method to avoid a run-away of the rate
of the postsynaptic neuron, analogous to the sliding threshold in the BCM rule of Eq.
(19.9). A comparison with the triplet rule above shows that the role of the trace yi (which
represents a low-pass ﬁlter of the postsynaptic spike train, see Eq. (19.13)) is taken over
by the low-pass ﬁlter ui,−of the postsynaptic voltage.
For the LTP part, we assume that each presynaptic spike at the synapse wi j increases
the trace ¯x j(t) of some biophysical quantity, which decays exponentially with a time
constant τ+ in the absence of presynaptic spikes; see Eq. (19.12). The potentiation of
wi j depends on the trace ¯xj(t) and the postsynaptic voltage via (see also Fig. 19.9)
d
dt wLTP
i
= +ALTP ¯xj(t)[ui(t)−θ+]+ [ui,+(t)−θ−]+
if wij < wmax.
(19.17)
Here, ALTP > 0 is a constant parameter and ui,+(t) is another low-pass ﬁltered version
of ui(t) similar to u−(t) but with a shorter time constant τ+ around 10 ms. Thus positive
weight changes can occur if the momentary voltage ui(t) surpasses a threshold θ+ and,
at the same time the average value ui,+(t), is above θ−. Note again the similarity to the
triplet STDP rule. If the postsynaptic voltage is dominated by spikes, so that ui(t) =
∑f δ(t −t f
i ), the Clopath model and the triple STDP rule are in fact equivalent.
The Clopath rule is summarized by the equation
d
dt wi j = −ALTD( ¯u)Sj(t)[ui,−(t)−θ−]+ +ALTP ¯xi(t)[ui(t)−θ+]+ [ui,+(t)−θ−]+,(19.18)
combined with hard bounds 0 ≤wi j ≤wmax.
The plasticity rule can be ﬁtted to experimental data and can reproduce several exper-
imental paradigms (Sj¨ostr¨om et al., 2001) that cannot be explained by pair-based STDP
or other phenomenological STDP rules without voltage dependence.
19.3 Unsupervised learning
In artiﬁcial neural networks some, or even all, neurons receive input from external sources
as well as from other neurons in the network. Inputs from external sources are typically
described as a statistical ensemble of potential stimuli. Unsupervised learning in the ﬁeld
of artiﬁcial neural networks refers to changes of synaptic connections which are driven
by the statistics of the input stimuli - in contrast to supervised learning or reward-based
learning where the network parameters are optimized to achieve, for each stimulus, an
optimal behavior. Hebbian learning rules, as introduced in the previous section, are the
prime example of unsupervised learning in artiﬁcial neural networks.

506
Synaptic plasticity and learning
50[ms]
40[mV]
xj
ui,-
ui,+
xj
xj
θ+
LTD
LTP
ui
(b)
(a)
θ-
ui
j
i
Fig. 19.9
Clopath model of voltage-dependent plasticity. Synaptic weights react to presynaptic
events (top) and postsynaptic membrane potential (bottom) (a) The synaptic weight is decreased
if a presynaptic spike xj (dashed vertical line) arrives when the low-pass ﬁltered value ui,−(thick
black line) of the membrane potential is above θ−(dashed horizontal line). (b) The synaptic weight
is increased if three criteria are met (shaded ellipses): (i) the membrane potential ui (thin black line)
is above a threshold θ+ (horizontal dashed line); (ii) the low-pass ﬁltered value of the membrane
potential ui,+ (thick black line) is higher than a threshold θ−; and (iii) the presynaptic low-pass ﬁlter
¯x is above zero; adapted from Clopath et al. (2010).
In the following we always assume that there are N input neurons 1 ≤j ≤N. Their ﬁring
rates ν j are chosen from a set of P ﬁring rate patterns with index 1 ≤μ ≤P. While one of
the patterns, say pattern μ with ξ μ = (ξ μ
1 ,...,ξ μ
N ), is presented to the network, the ﬁring
rates of the input neurons are ν j = ξ μ
j . In other words, the input rates form a vector ν = ξ μ
where ν = (ν1,...,νN). After a time Δt a new input pattern is randomly chosen from the
set of available patterns. We call this the static pattern scenario.
19.3.1 Competitive learning
In the framework of Eq. (19.2), we can deﬁne a Hebbian learning rule of the form
d
dt wi j = γ νi [ν j −νθ(wi j)],
(19.19)
where γ is a positive constant and νθ is some reference value that may depend on the
current value of wi j. A weight change occurs only if the postsynaptic neuron is active,
νi > 0. The direction of the weight change depends on the sign of the expression in the
rectangular brackets.
Let us suppose that the postsynaptic neuron i is driven by a subgroup of highly active
presynaptic neurons (νi > 0 and ν j > νθ). Synapses from one of the highly active presy-
naptic neurons onto neuron i are strengthened while the efﬁcacy of other synapses that have
not been activated is decreased. Firing of the postsynaptic neuron thus leads to LTP at the
active pathway ("homosynaptic LTP") and at the same time to LTD at the inactive synapses
("heterosynaptic LTD"); for reviews see Brown et al. (1991) and Bi and Poo (2001).

19.3 Unsupervised learning
507
A particularly interesting case from a theoretical point of view is the choice νθ(wi j) =
wi j, i.e.,
d
dt wi j = νi [ν j −wi j].
(19.20)
The synaptic weights thus move toward the ﬁxed point wi j = ν j whenever the postsynaptic
neuron is active. In the stationary state, the set of weight values wi j reﬂects the presynaptic
ﬁring pattern ν j,1 ≤j ≤N. In other words, the presynaptic ﬁring pattern is stored in the
weights.
The above learning rule is an important ingredient of competitive unsupervised learn-
ing (Kohonen, 1984; Grossberg, 1976). To implement competitive learning, an array of K
(postsynaptic) neurons receive input from the same set of N presynaptic neurons which
serve as the input layer. The postsynaptic neurons inhibit each other via strong lateral
connections, so that, whenever a stimulus is applied at the input layer, the K postsynap-
tic neurons compete with each other and only a single postsynaptic neuron responds. The
dynamics in such competitive networks where only a single neuron "wins" the competition
have already been discussed in Chapter 16.
In a learning paradigm with the static pattern scenario, all postsynaptic neurons use the
same learning rule (19.20), but only the active neuron i′ (i.e., the one which "wins" the
competition) will effectively update its weights (all others have zero update because νi = 0
for i ̸= i′). The net result is that the weight vector wi′ = (wi′1 ...wi′N) of the winning neuron
i′ moves closer to the current vector of inputs ν = ξ μ. For a different input pattern μ′ the
same or another postsynaptic neuron may win the competition. Therefore, different neu-
rons specialize for different subgroups ("clusters") of patterns and each neuron develops a
weight vector which represents the center of mass of "its" cluster.
Example: Developmental learning with STDP
The results of simulations of the Clopath model shown in Fig. 19.10 can be interpreted
as a realization of a soft form of competitive learning. Neurons form subnetworks that
specialize on the same features of the input. Because of inhibition, different subnetworks
specialize on different segments of the input space.
Ten excitatory neurons (with all-to-all connectivity) are linked to three inhibitory neu-
rons. Each inhibitory neuron receives input from eight randomly selected excitatory neu-
rons and randomly projects back to six excitatory neurons (Clopath et al., 2010). In addi-
tion to the recurrent input, each excitatory and inhibitory neuron receives feedforward
spike input from 500 presynaptic neurons j that generate stochastic Poisson input at a
rate ν j. The input neurons can be interpreted as a sensory array. The rates of neighbor-
ing input neurons are correlated, mimicking the presence of a spatially extended object
stimulating the sensory layer. Spiking rates at the sensory layer change every 100 ms.
Feedforward connections and lateral connections between model pyramidal neurons
are plastic whereas connections to and from inhibitory neurons are ﬁxed. In a simulation

508
Synaptic plasticity and learning
(a)
Before
After
(c)
(b)
Time [s]
0
1000
1
10
Neuron #
Neuron post
Input pre
10
1
500
Neuron post
Neuron pre
10
10
Neuron post
Input pre
10
500
Neuron post
Neuron pre
10
1
1
1
10
1
1
1
1
500
1
Input #
Weak
unidir.
Strong
unidir.
No
connect.
Strong
reciproc.
Fig. 19.10
Receptive ﬁeld development and lateral connectivity. (a) A network of ten excitatory
neurons (empty circles, not all neurons are shown) is connected to three inhibitory neurons (solid
circles) and receives feedforward inputs from 500 Poisson spike trains with a Gaussian proﬁle of
ﬁring rates. The center of the Gaussian is shifted randomly every 100 ms. Between the two schematic
ﬁgures representing the network before (left) and after the plasticity experiment (right), we depict the
evolution of input weights and recurrent excitatory weights onto one selected excitatory neuron. (b)
Mean feedforward weights (left) and recurrent excitatory weights (right) averaged over 100 s. The
gray level graph for the feedforward weights (left) indicates that neurons develop receptive ﬁelds
that are localized in the input space. The diagonal in the matrix of recurrent connectivity is black,
since self-connections do not exist in the model. (c) Same as (b) but for the sake of visual clarity the
index of neurons is reordered so that neurons with similar receptive ﬁelds have adjacent numbers,
highlighting that neurons with similar receptive ﬁelds (e.g., neurons 1 to 3) have strong bilateral
connections. Adapted from Clopath et al. (2010).
of the model network, the excitatory neurons developed localized receptive ﬁelds, i.e.,
weights from neighboring inputs to the same postsynaptic neuron become either strong
or weak together (Fig. 19.10a). Similarly, lateral connections onto the same postsynap-
tic neuron develop strong or weak synapses, that remain, apart from ﬂuctuations, sta-
ble thereafter (Fig. 19.10a) leading to a structured pattern of synaptic connections (Fig.
19.10b). While the labeling of the excitatory neurons at the beginning of the experiment
was randomly assigned, we can relabel the neurons after the formation of lateral con-
nectivity patterns so that neurons with similar receptive ﬁelds have similar indices. After
reordering we can clearly distinguish that two groups of neurons have been formed,
characterized by similar receptive ﬁelds and strong bidirectional connectivity within the
group, and different receptive ﬁelds and no lateral connectivity between groups (Fig.
19.10c).

19.3 Unsupervised learning
509
n1
pre
(a)
nN
pre
.
.
.
.
.
x m
wN
w1
n post
n post
h
h
0
g(h)
(b)
Fig. 19.11 Elementary model. (a) Patterns ξ μ are applied as a set of presynaptic ﬁring rates νj, i.e.,
ξ μ
j = νpre
j
for 1 ≤j ≤N. (b) The gain function of the postsynaptic neuron is taken as linear, i.e.,
νpost = h. It can be seen as a linearization of the sigmoidal gain function g(h).
19.3.2 Learning equations for rate models
We focus on a single analog neuron that receives input from N presynaptic neurons with
ﬁring rates νpre
j
via synapses with weights wj; see Fig. 19.11a. Note that we have dropped
the index i of the postsynaptic neuron since we focus in this section on a single output neu-
ron. We think of the presynaptic neurons as "input neurons," which, do not, however, have
to be sensory neurons. The input layer could, for example, consist of neurons in the lateral
geniculate nucleus (LGN) that project to neurons in the visual cortex. As before, the ﬁring
rate of the input neurons is modeled by the static pattern scenario. We will show that the
statistical properties of the input control the evolution of synaptic weights. In particular, we
identify the conditions under which unsupervised Hebbian learning is related to principal
component analysis (PCA).
In the following we analyze the evolution of synaptic weights using the simple Hebbian
learning rule of Eq. (19.3). The presynaptic activity drives the postsynaptic neuron and the
joint activity of pre- and postsynaptic neurons triggers changes of the synaptic weights:
Δwi = γ νpost νpre
i
.
(19.21)
Here, 0 < γ ≪1 is a small constant called the "learning rate." The learning rate in the static
pattern scenario is closely linked to the correlation coefﬁcient ccorr
11 in the continuous-time
Hebb rule introduced in Eq. (19.3). In order to highlight the relation, let us assume that each
pattern ξ μ is applied during an interval Δt. For Δt sufﬁciently small, we have γ = ccorr
11 Δt.
In a general rate model, the ﬁring rate νpost of the postsynaptic neuron is given by a
nonlinear function of the total input
νpost = g
!
∑
j
wj νpre
j
"
;
(19.22)
see Fig. 19.11b and Chapter 15. For the sake of simplicity, we restrict our discussion in the

510
Synaptic plasticity and learning
−2
−1
0
1
2
3
−2
−1
0
1
2
3
(a)
Dw2
Dw1
−2
−1
0
1
2
3
−2
−1
0
1
2
3
(b)
Dw2
Dw1
Fig. 19.12 Weight changes induced by the standard Hebb rule. Input patterns ξ μ ∈R2 are marked as
circles. The sequence of weight vectors w(1), w(2), ...is indicated by crosses connected by a solid
line. (a) The weight vector evolves in the direction of the center of mass of the cloud of data points,
because this is the dominant eigenvector of the (non-normalized) correlation matrix of the data. (b) If
the input patterns are normalized so that their center of mass is at the origin, then the weight vector
becomes parallel to the ﬁrst principal component e1 of the dataset.
following to a linear rate model with
νpost = ∑
j
wj νpre
j
= w·νpre ,
(19.23)
where we have introduced vector notation for the weights w = (w1,...,wN), the presynap-
tic rates νpre = (ν1,...,νN) and the dot denotes a scalar product. Hence we can interpret
the output rate νpost as a projection of the input vector onto the weight vector.
If we combine the learning rule (19.21) with the linear rate model of Eq. (19.23) we ﬁnd
after the presentation of pattern ξ μ
Δwi = γ ∑
j
w j νpre
j
νpre
i
= γ ∑
j
w j ξ μ
j ξ μ
i .
(19.24)
The evolution of the weight vector w = (w1,...,wN) is thus determined by the iteration
wi(n+1) = wi(n)+γ ∑
j
w j ξ μn
j ξ μn
i
,
(19.25)
where μn denotes the pattern that is presented during the nth time step. Eq. (19.25) is called
an "online" rule, because the weight update happens immediately after the presentation of
each pattern. The evolution of the weight vector w = (w1,...,wN) during the presentation
of several patterns is shown in Fig. 19.12.
If the learning rate γ is small, a large number of patterns has to be presented in order to
induce a substantial weight change. In this case, there are two equivalent routes to proceed
with the analysis. The ﬁrst one is to study a version of learning where all P patterns are

19.3 Unsupervised learning
511
presented before an update occurs. Thus, Eq. (19.25) is replaced by
wi(n+1) = wi(n)+ ˜γ ∑
j
wj
P
∑
μ=1
ξ μ
j ξ μ
i
(19.26)
with a new learning rate ˜γ = γ/P. This is called a "batch update." With the batch update
rule, the right-hand side can be rewritten as
wi(n+1) = wi(n)+γ ∑
j
Ci j wj(n),
(19.27)
where we have introduced the correlation matrix
Ci j = 1
P
P
∑
μ=1
ξ μ
i ξ μ
j = ⟨ξ μ
i ξ μ
j ⟩μ .
(19.28)
Thus, the evolution of the weights is driven by the correlations in the input.
The second, alternative, route is to stick to the online update rule, but study the expecta-
tion value of the weight vector, i.e., the weight vector ⟨w(n)⟩averaged over the sequence
(ξ μ1,ξ μ2,...,ξ μn) of all patterns that so far have been presented to the network. From
Eq. (19.25) we ﬁnd
⟨wi(n+1)⟩= ⟨wi(n)⟩+γ ∑
j
-
wj(n)ξ μn+1
j
ξ μn+1
i
.
= ⟨wi(n)⟩+γ ∑
j
/
wj(n)
0 -
ξ μn+1
j
ξ μn+1
i
.
= ⟨wi(n)⟩+γ ∑
j
Ci j
/
wj(n)
0
.
(19.29)
The angle brackets denote an ensemble average over the whole sequence of input pat-
terns (ξ μ1,ξ μ2,...). The second equality is due to the fact that input patterns are chosen
independently in each time step, so that the average over w j(n) and (ξ μn+1
j
ξ μn+1
i
) can be
factorized. Note that Eq. (19.29) for the expected weights in the online rule is equivalent to
Eq. (19.27) for the weights in the batch rule.
Expression (19.29), or equivalently (19.27), can be written in a more compact form using
matrix notation (we drop the angle brackets in the following)
w(n+1) = (1I+γC)w(n) = (1I+γC)n+1 w(0),
(19.30)
where w(n) = (w1(n),...,wN(n)) is the weight vector and 1I is the identity matrix.
If we express the weight vector in terms of the eigenvectors ek of C,
w(n) = ∑
k
ak(n)ek ,
(19.31)
we obtain an explicit expression for w(n) for any given initial condition ak(0), namely,
w(n) = ∑
k
(1+λk)n ak(0)ek .
(19.32)

512
Synaptic plasticity and learning
Since the correlation matrix is positive semi-deﬁnite, all eigenvalues λk are real and pos-
itive. Therefore, the weight vector is growing exponentially, but the growth will soon be
dominated by the eigenvector with the largest eigenvalue, i.e., the ﬁrst principal compo-
nent,
w(n) n→∞
−−−→(1+λ1)n a1(0)e1 .
(19.33)
Recall that the output of the linear neuron model (19.23) is proportional to the projection
of the current input pattern ξ μ on the direction w. For w ∝e1, the output is therefore
proportional to the projection on the ﬁrst principal component of the input distribution. A
Hebbian learning rule such as (19.21) is thus able to extract the ﬁrst principal component
of the input data.
From a data-processing point of view, the extraction of the ﬁrst principal component
of the input dataset by a biologically inspired learning rule seems to be very compelling.
There are, however, a few drawbacks and pitfalls when using the above simple Hebbian
learning scheme. Interestingly, all three can be overcome by slight modiﬁcations in the
Hebb rule.
First, the above statement about the Hebbian learning rule is limited to the expectation
value of the weight vector. However, it can be shown that if the learning rate is sufﬁciently
low, then the actual weight vector is very close to the expected one so that this is not a
major limitation.
Second, while the direction of the weight vector moves in the direction of the principal
component, the norm of the weight vector grows without bounds. However, variants of
Hebbian learning such as the Oja learning rule (19.7) allow us to normalize the length of
the weight vector without changing its direction; see Exercises.
Third, principal components are only meaningful if the input data is normalized, i.e.,
distributed around the origin. This requirement is not consistent with a rate interpretation
because rates are usually positive. This problem can, however, be overcome by learning
rules such as the covariance rule of Eq. (19.6) that are based on the deviation of the rates
from a certain mean ﬁring rate. Similarly, STDP rules can be designed in such a way that
the output rate remains normalized so that learning is sensitive only to deviations from the
mean ﬁring rate and can thus ﬁnd the ﬁrst principal component even if the input is not
properly normalized (Kempter et al., 1999a; Song et al., 2000; Kempter et al., 2001).
Example: Correlation matrix and principal component analysis
For readers not familiar with principal component analysis (PCA) we review here
the basic ideas and main results. PCA is a standard technique to describe statistical
properties of a set of high-dimensional data points and is performed to ﬁnd the direction
in which the data shows the largest variance. If we think of the input dataset as a cloud of
points in a high-dimensional vector space centered around the origin, then the ﬁrst prin-
cipal component is the direction of the longest axis of the ellipsoid that encompasses the

19.3 Unsupervised learning
513
cloud; see Fig. 19.13a. In what follows, we will explain the basic idea and show that the
ﬁrst principal component gives the direction where the variance of the data is maximal.
Let us consider an ensemble of data points {ξ 1,...,ξ P} drawn from a (high-dimen-
sional) vector space, for example ξ μ ∈RN. For this set of data points we deﬁne the
correlation matrix Ci j as
Ci j = 1
P
P
∑
μ=1
ξ μ
i ξ μ
j =
-
ξ μ
i ξ μ
j
.
μ .
(19.34)
Angle brackets ⟨·⟩μ denote an average over the whole set of data points. In a similar way
to the variance of a single random variable we can also deﬁne the covariance matrix Vi j
of our dataset,
Vi j =
-
(ξ μ
i −⟨ξ μ
i ⟩μ)(ξ μ
j −⟨ξ μ
j ⟩μ)
.
μ .
(19.35)
Here we will assume that the coordinate system is chosen so that the center of mass
of the set of data points is located at the origin, i.e., ⟨ξi⟩μ =
/
ξj
0
μ = 0. In this case,
correlation matrix and covariance matrix are identical.
The principal components of the set {ξ 1,...,ξ P} are deﬁned as the eigenvectors of
the covariance matrix V. Note that V is symmetric, i.e., Vi j = Vji. The eigenvalues of V
are thus real-valued and different eigenvectors are orthogonal (Horn and Johnson, 1985).
Furthermore, V is positive semi-deﬁnite since
yTV y = ∑
i j
yi
-
ξ μ
i ξ μ
j
.
μ yj =
1
∑
i
yi ξ μ
i

2
2
μ
≥0
(19.36)
for any vector y ∈RN. Therefore, all eigenvalues of V are non-negative.
We can sort the eigenvectors ei according to the size of the corresponding eigenvalues
λ1 ≥λ2 ≥··· ≥0. The eigenvector with the largest eigenvalue is called the ﬁrst principal
component.
The ﬁrst principal component points in the direction where the variance of the data is
maximal. To see this we calculate the variance of the projection of ξ μ onto an arbitrary
direction y (Fig. 19.13b) that we write as y = ∑i ai ei with ∑i a2
i = 1 so that ∥y∥= 1. The
variance σ2y along y is
σ2y =
-
ξ μ ·y
2.
μ = yTV y = ∑
i
λi a2
i .
(19.37)
The right-hand side is maximal under the constraint ∑i a2
i = 1 if a1 = 1 and ai = 0 for
i = 2,3,...,N, i.e., if y = e1.
19.3.3 Learning equations for STDP models (*)
The evolution of synaptic weights in the pair-based STDP model of 19.10 can be assessed
by assuming that pre- and postsynaptic spike trains can be described by Poisson processes.

514
Synaptic plasticity and learning
e1
e2
e3
(a)
e1
y
(b)
Fig. 19.13 Principal component analysis. (a) Ellipsoid approximating the shape of a cloud of data
points. The ﬁrst principal component e1 corresponds to the principal axis of the ellipsoid. (b) Sample
distribution of data points in two dimensions. The ﬁrst principal component e1 points in the direction
where the variance of the data is maximal. Projection (dashed line) of data points onto an arbitrary
other axis y gives a distribution of smaller variance.
For the postsynaptic neuron, we take the linear Poisson model in which the output spike
train is generated by an inhomogeneous Poisson process with rate
νi(ui) = [α ui −ν0]+
(19.38)
with scaling factor α, threshold ν0 and membrane potential ui(t) = ∑j wi jε

t −t f
j
	
, where
ε(t) denotes the time course of an excitatory postsynaptic potential generated by a presy-
naptic spike arrival. The notation [x]+ denotes a piecewise linear function: [x]+ = x for
x > 0 and zero otherwise. In the following we assume that the argument of our piecewise
linear function is positive so that we can suppress the square brackets.
For the sake of simplicity, we assume that all input spike trains are Poisson processes
with a constant ﬁring rate ν j. In this case the expected ﬁring rate of the postsynaptic neuron
is simply:
⟨νi⟩= −ν0 +α ¯ε∑
j
wi j ν j ,
(19.39)
where ¯ε =
 ε(s)ds is the total area under an excitatory postsynaptic potential. The con-
ditional rate of ﬁring of the postsynaptic neuron, given an input spike at time t f
j , is given
by
νi(t) = −ν0 +α ¯ε∑
j
wi jν j +αwi jε

t −t f
j
	
.
(19.40)
Since the conditional rate is different from the expected rate, the postsynaptic spike train
Si(t) is correlated with the presynaptic spike trains Sj(t′). The correlations can be calcu-
lated to be
Γji(s) = ⟨Si(t +s)Sj(t)⟩= ⟨νi⟩ν j +α wi jν j ε(s).
(19.41)
In a similar way to the expected weight evolution for rate models in Section 19.3.2, we now

19.3 Unsupervised learning
515
study the expected weight evolution in the spiking model with the pair-based plasticity rule
of Eq. (19.10). The result is (Kempter et al., 1999a)
⟨˙wi j⟩= ν j ⟨νi⟩[−A−(wi j)τ−+A+ (wi j)τ+]+αwi jν j A+(wi j)

W+(s)ε(s)ds.
(19.42)
The ﬁrst term is reminiscent of rate-based Hebbian learning, Eq. (19.3), with a coefﬁcient
ccorr
11
proportional to the integral under the learning window. The last term is due to pre-
before-post spike timings that are absent in a pure rate model. Hence, despite the fact that
we started off with a pair-based STDP rule, the synaptic dynamics contains a term of the
form αν jwA+(w)
 W+(s)ε(s)ds that is linear in the presynaptic ﬁring rate (Kempter et al.,
1999a, 2001).
Example: Stabilization of postsynaptic ﬁring rate
If spike arrival rates ν j = ν at all synapses are identical, we expect a solution of the
learning equation to exist where all weights are identical, wi j = w. For simplicity we
drop the averaging signs. Eq. (19.42) then becomes
˙w
ν = νi [−A−(w)τ−+A+ (w)τ+]+αwA+(w)

W+(s)ε(s)ds.
(19.43)
Moreover, we can use Eq. (19.39) to express the postsynaptic ﬁring rate in terms of the
input rate ν:
νi = −ν0 +αν ¯εN w.
(19.44)
If the weight w increases, the postsynaptic ﬁring rate also increases. We now ask whether
the postsynaptic ﬁring has a ﬁxed point νFP.
The ﬁxed point analysis can be performed for a broad class of STDP models. How-
ever, for the sake of simplicity we focus on the model with hard bounds in the range
where 0 < w < wmax. We introduce a constant C = A−(w)τ−−A+ (w)τ+. If the integral
of the learning window is negative, then C > 0 and LTD dominates over LTP. In this
case, a ﬁxed point exists at
νFP =
Cssν0
NCν ¯ε −Css
(19.45)
where Css = A+(w)
 W+(s)ε(s)ds denotes the contribution of the spike-spike correla-
tions. The mean ﬁring rate of the neuron is, under rather general conditions, stabilized
at the ﬁxed point (Kempter et al., 2001). Hence STDP can lead to a control of the post-
synaptic ﬁring rate (Kempter et al., 1999a; Song et al., 2000; Kempter et al., 2001). We
emphasize that the existence of a ﬁxed point and its stability does not crucially depend
on the presence of soft or hard bounds on the weights. Since, for constant input rates
ν, we have νi = ν0 + αν ¯ε ∑j wi j, stabilization of the output rate automatically implies
normalization of the summed weights.

516
Synaptic plasticity and learning
A2
A1
(a)
A3
Time
Neural activity
Pre
Post
Motor
cortex
Striatum
Sensory
cortex
= Active
= Inactive
B2
B1
B3
Time
Neural activity
Success
Pre
Post
Motor
cortex
Striatum
Sensory
cortex
Success 
signal
= Active
= Inactive
(b)
Fig. 19.14 Hebbian learning versus reward-modulated Hebbian learning in a T-maze decision task
(schematic). The momentary sensory state of the animal is encoded by the layer of sensory cortex
neurons, the action plan by a set of striatal neurons, and the motor output by neurons in motor
cortex. (a) Hebbian learning. Joint activity of neurons in sensory, striatal, and motor areas strengthens
the links between the active neurons, despite the fact that turning left does not lead to success. (b)
Reward-modulated Hebbian learning. Joint activity of pre- and postsynaptic neurons strengthens
connections only if, within a delay of a few seconds, a success signal is broadcast in the brain.
19.4 Reward-based learning
In conditioning experiments, animals learn complex action sequences if the desired behav-
ior is rewarded. For example, in a simple T-maze an animal has to decide at the bifurcation
point whether to turn left or right (Fig. 19.14a). In each of several trials, the same arm of
the maze is baited with a piece of cheese that is hidden in a hole in the ﬂoor and therefore
neither visible nor smellable. After a few trials the animal has learned to reliably turn into
the baited arm of the maze.
Unsupervised Hebbian learning is of limited use for behavioral learning, because it
makes no distinction between actions that do and those that do not lead to a successful
outcome. The momentary sensory state at the bifurcation point is represented by activity in
the sensory cortices and, possibly, in hippocampal place cells. The action plan "turn left" is
represented by groups of cells in several brain areas likely to include the striatum, whereas
the ﬁnal control of muscle activity involves areas in the motor cortex. Therefore, during the
realization of the action plan "turn left," several groups of neurons are jointly active (Fig.
19.14a). Unsupervised Hebbian learning strengthens the connections between the jointly
active cells so that, at the next trial, it becomes more likely that the animal takes the same
decision again. However, turning left does not lead to success if the cheese is hidden in the
other branch of the maze.
In order to solve the above task, two important aspects have to be taken into account
that are neglected in unsupervised Hebbian learning rules. First, rules of synaptic plasticity
have to take into account the success of an action. Neuromodulators such a dopamine are
ideal candidates to broadcast a success signal in the brain (Fig. 19.15), where success can
loosely be deﬁned as "reward minus expected reward" (Schultz et al., 1997; Schultz, 2007,

19.4 Reward-based learning
517
0
1
2
Time  [s]
Reward
Conditioning
stimulus
PSTH
(a)
(b)
(c)
0
1
2
PSTH
0
1
2
PSTH
Fig. 19.15 Dopamine encodes reward minus
expected reward. (a) The activity of dopamin-
ergic
neurons
(PSTH)
increases
at
the
moment when a reward R occurs. (b) If a con-
ditioning stimulus (CS) such as a tone beep or
a light reliably occurs one second before the
reward, the same neurons no longer respond
to the reward but instead respond after the CS
that predicts the reward. (c) If the reward is
predicted by the CS but not given, the PSTH
exhibits a dip below the baseline (dashed
lines) at the moment when the reward is
expected. Schematic ﬁgure summarizing data
from Schultz et al. (1997).
2010). Second, the success often comes with a delay of a few seconds after an action has
been taken; see Fig. 19.14b. Thus, the brain needs somehow to store a short-term memory
of past actions. A suitable location for such a memory is the synapses themselves.
The above two points can be used to formulate a ﬁrst qualitative model of reward-
modulated Hebbian learning. In Hebbian learning, weight changes Δwi j depend on the
spikes pre j of the presynaptic neuron j and the state posti of the postsynaptic neuron
i. Correlations between the pre- and postsynaptic activity are picked up by the Hebbian
function H(prej, posti). We assume that synapses keep track of correlations by updating a
synaptic eligibility trace
τe
d
dt ei j = −ei j +H(pre j, posti).
(19.46)
If the joint activity of pre- and postsynaptic neurons stops, the Hebbian term H vanishes
and the eligibility trace decays back to zero with a time constant τe. The Hebbian term H
could be modeled by one of the rate models in the framework of Eq. (19.2) or an STDP
model such as the one deﬁned in 19.10.
The update of synaptic weights requires a nonzero-eligibility trace as well as the pres-
ence of a neuromodulatory success signal M
d
dt wi j = M ·ei j .
(19.47)
While in standard Hebbian learning synaptic plasticity depends on two factors (i.e., pre-
and postsynaptic activity), weight changes in Eq. (19.47) now depend on three factors, i.e.,
the two Hebbian factors and the neuromodulator M. The class of plasticity rules encom-
passed by Eq. (19.47) is therefore called three-factor learning rules. In models of reward-
based learning, the modulator signal M is most often taken as "reward minus expected
reward,"
M(t) = R(t)−⟨R⟩,
(19.48)
where R denotes the reward and the expectation ⟨R⟩is empirically estimated as a running

518
Synaptic plasticity and learning
75
100
125
0
25
50
Relative amp. [%]
Time [min]
t j
f− t i
f=-10ms
DA-R blocked
Ctrl
(a)
DA
Ctrl
100
120
80
0
-50
-100
50
100
Relative amp. [%]
tj
f−t f
i [ms]
(b)
Fig. 19.16 Dopamine-modulated Hebbian learning. (a) An STDP protocol normally gives rise to
long-term potentiation (pre-before-post, solid black line as in Fig. 19.4d). However, if dopamine
receptors are blocked, no change occurs (schematic representation of experiments in Pawlak and Kerr
(2008)). (b) The STDP window in a control situation (dashed line and solid data points) changes if
additional extracellular dopamine is present (solid lines, open squares). Adapted from Zhang et al.
(2009).
average. The time constant τe is typically chosen in the range of one second, so as to bridge
the delay between action choice and ﬁnal reward signal.
Three-factor rules have been suggested for rate-based (Reynolds and Wickens, 2002;
Loewenstein, 2008) as well as spike-based Hebbian models. In spike-based Hebbian mod-
els, the Hebbian term is often taken as a standard pair-based STDP function (Izhikevich,
2007a; Legenstein et al., 2008; Florian, 2007) or an STDP model that also depends on
postsynaptic voltage (Pﬁster et al., 2006; Florian, 2007; Baras and Meir, 2007). Experi-
ments have shown that the shape of the STDP window is indeed modulated by dopamine
as well as other neuromodulators (Fig. 19.16); for a review see Pawlak et al. (2010).
Example: R-STDP and learning of spike sequences
Suppose a table tennis player plays a serve or a piano player a rapid scale. In both
cases the executed movements are extremely rapid, have been practiced many times,
and are often performed in "open loop" mode, for example, without visual feedback
during the movement. There is, however, feedback after some delay which signals the
success (or failure) of the performed action, for example the ball went off the table or
the scale contained a wrong note.
A rapid scale on a piano means touching about 10 different keys per second. Similarly,
the complex gliding movement to give the ball its spin takes less than a second. It is likely
that for such fast movements spike timing plays an important role. The motor cortex is
involved in the control of limb movements. Experimental data from the arm area of the
primary motor cortex indicates that populations of neurons encode the direction of hand

19.5 Summary
519
motion during reaching movements in three-dimensional space (Georgopoulos et al.,
1988). Each neuron i has a preferred direction of motion represented as a vector di.
The vectors of different neurons are added up with a weighting function proportional
to the cell's ﬁring rate (Georgopoulos et al., 1988). For the rapid movements of less
than one second that we consider here, a single neuron is expected to emit at most a
few spikes. Therefore a desired trajectory can be represented as a target spatio-temporal
spike pattern; see Fig. 19.17.
Model neurons in the motor cortex receive spike input from neurons in sensory areas
that represent, for example, the vertical movement of the ball that is launched at the
beginning of the serve, as well as the intention of the player. During practice sessions,
the aim is to associate the spatio-temporal spike pattern in the input layer with the target
spike pattern in the layer of motor cortex neurons while the only feedback is the success
signal available at the end of the movement.
Figure 19.17 shows that a two-layer network of spiking neurons can learn this task if
synaptic connections use a reward-modulated STDP rule (R-STDP) where the Hebbian
term H in Eq. (19.47) is the pair-based STDP rule deﬁned in (19.10). It is important that
the global neuromodulatory signal provided at the end of each trial is not the raw reward,
but success deﬁned as "reward - expected reward" as in Eq. (19.48). If a single task has
to be learned, the expected reward can be estimated from the running average over past
trials. However, if several trajectories (e.g., two different serves or two different scales)
have to be learned in parallel, then the expected reward needs to be estimated separately
for each trajectory (Fremaux et al., 2010).
R-STDP rules have also been used for several other tasks, see, (e.g., Izhikevich,
2007a; Florian, 2007).
19.5 Summary
The Hebb rule (19.2) is an example of a local unsupervised learning rule. It is a local
rule, because it depends only on pre- and postsynaptic ﬁring rates and the present state wi j
of the synapse, i.e., information that is easily "available" at the location of the synapse.
Experiments have shown that not only the ﬁring rates, but also the membrane voltage of
the postsynaptic neuron, as well as the relative timing of pre- and postsynaptic spikes,
determine the amplitude and direction of change of the synaptic efﬁcacy. To account for
spike timing effects, classical pair-based models of STDP are formulated with a learning
window that consists of two parts: If the presynaptic spike arrives before a postsynaptic
output spike, the synaptic change is positive. If the timing is reversed, the synaptic change
is negative. However, classical pair-based STDP models neglect the frequency and voltage
dependence of synaptic plasticity, which are included in modern variants of STDP models.
The synaptic weight dynamics of Hebbian learning can be studied analytically if weights
are changing slowly compared to the time scale of the neuronal activity. Weight changes
are driven by correlations between pre- and postsynaptic activity. More speciﬁcally, simple

520
Synaptic plasticity and learning
N =50
N= 200
r1(t) v
v
v
r2(t)
r3(t)
(a)
(b)
N=150
N=150
3
3
Fig. 19.17 Learning with R-STDP. (a) The input consists of 350 spike trains with a temporal preci-
sion of 20 ms. Fifty unspeciﬁc neurons ﬁred for both tasks, whereas half of the other neurons ﬁred
only for task A or task B. The output consists of 200 spiking model neurons. (b) Output spike trains
were convolved with a ﬁlter (top). The resulting continuous signal for neuron i is interpreted as the
speed of movement in direction di, where different neurons code for different directions. The two tar-
get trajectories (bottom, dashed lines) correspond to two different target spatio-temporal spike-train
patterns. After a learning period of 10 000 trials, the network output generates a trajectory (full black
lines) close to the target trajectories.
Hebbian learning rules in combination with a linear neuron model ﬁnd the ﬁrst principal
component of a normalized input dataset. Generalized Hebb rules, such as Oja's rule, keep
the norm of the weight vector approximately constant during plasticity.
The interesting aspect of STDP is that it naturally accounts for temporal correlations
by means of a learning window. Explicit expressions for temporal spike-spike correlations
can be obtained for certain simple types of neuron model such as the linear Poisson model.
Spike-based and rate-based rules of plasticity are equivalent as long as temporal spike-
spike correlations are disregarded. If ﬁring rates vary slowly, then the integral over the
learning window plays the role of the Hebbian correlation term.
Hebbian learning and STDP are examples of unsupervised learning rules. Hebbian learn-
ing is considered to be a major principle of neuronal organization during development and
a driving force for receptive ﬁeld formation. However, Hebbian synaptic plasticity is not
useful for behavioral learning, since it does not take into account the success (or failure)
of an action. Three-factor learning rules combine the two Hebbian factors (i.e., pre- and
postsynaptic activity) with a third factor (i.e., a neuromodulator such as dopamine) which
conveys information about an action's success. Three-factor rules with an eligibility trace
can be used to describe behavioral learning, in particular during conditioning experiments.

19.5 Summary
521
Literature
Correlation-based learning can be traced back to Aristoteles1 and has been discussed exten-
sively by James (1890), who formulated a learning principle on the level of "brain pro-
cesses" rather than neurons:
When two elementary brain-processes have been active together or in immediate succession, one
of them, on re-occurring, tends to propagate its excitement into the other.
A chapter of James' book is reprinted in volume 1 of Anderson and Rosenfeld's collection
on neurocomputing (Anderson and Rosenfeld, 1988). The formulation of synaptic plas-
ticity in Hebb's book (Hebb, 1949), of which two interesting sections are reprinted in the
collection of Anderson and Rosenfeld (1988), has had a long-lasting impact on the neuro-
science community. The historical context of Hebb's postulate is discussed in the reviews
of Sejnowski (1999) and Makram et al. (2011).
There are several classical experimental studies on STDP (Markram et al., 1997; Zhang
et al., 1998; Debanne et al., 1998; Bi and Poo, 1998, 1999; Sj¨ostr¨om et al., 2001), but
precursors of timing-dependent plasticity can be found even earlier (Levy and Stewart,
1983). Note that for some synapses, the learning window is reversed (Bell et al., 1997).
For reviews on STDP, see Abbott and Nelson (2000), Bi and Poo (2001), Caporale and
Dan (2008), and Sj¨ostr¨om and Gerstner (2010).
The theory of unsupervised learning and principal component analysis is reviewed in the
textbook by Hertz et al. (1991). Models of the development of receptive ﬁelds and cortical
maps have a long tradition in the ﬁeld of computational neuroscience (see, e.g., von der
Malsburg, 1973; Willshaw and von der Malsburg, 1976; Sejnowski, 1977; Bienenstock
et al., 1982; Kohonen, 1984; Linsker, 1986; Miller et al., 1989; MacKay and Miller, 1990;
Miller, 1994; for reviews see, e.g., Erwin et al., 1995; Wiskott and Sejnowski, 1998). The
essential aspects of the weight dynamics in linear networks are discussed in Oja (1982) and
Miller and MacKay (1994). Articles by Grossberg (1976) and Bienenstock et al. (1982) or
the book by Kohonen (1984) illustrate the early use of the rate-based learning rules in
computational neuroscience.
The early theory of STDP was developed by Gerstner et al. (1993, 1996a); Kempter et al.
(1999a); Roberts and Bell (2000); van Rossum et al. (2000); Song et al. (2000); Rubin
et al. (2001) but precursors of timing-dependent plasticity can be found in earlier rate-
based formulations (Herz et al., 1988; Sompolinsky and Kanter, 1986). Modern theories
of STDP go beyond the pair-based rules (Senn et al., 2001; Pﬁster and Gerstner, 2006),
consider voltage effects (Clopath et al., 2010), variations of boundary conditions (G¨utig
et al., 2003) or calcium-based models (Lisman et al., 2002; Lisman, 2003) and for reviews
see Morrison et al. (2008) and Sj¨ostr¨om and Gerstner (2010).
Experimental support for three-factor learning rules is reviewed in Reynolds and Wick-
ens (2002) and Pawlak et al. (2010). Model studies to reward modulated STDP are
1Aristoteles, "De memoria et reminiscentia": There is no need to consider how we remember what is distant, but only what is
neighboring, for clearly the method is the same. For the changes follow each other by habit, one after another. And thus, whenever
someone wishes to recollect he will do the following: He will seek to get a starting point for a change after which will be the
change in question.

522
Synaptic plasticity and learning
Izhikevich (2007a); Legenstein et al. (2008); Florian (2007); Fremaux et al. (2010). The
consequences for behavior are discussed in Loewenstein and Seung (2006) and Loewen-
stein (2008). The classic reference for dopamine in relation to reward-based learning is
Schultz et al. (1997). Modern reviews on the topic are Schultz (2007, 2010).
Exercises
1. Normalization of ﬁring rate. Consider a learning rule d
dt wij = γ (νi −νθ )νj , i.e., a change of
synaptic weights can only occur if the presynaptic neuron is active (ν j > 0). The direction of the
change is determined by the activity of the postsynaptic neuron. The postsynaptic ﬁring rate is
given by νi = g(∑N
j=1 wijνj). We assume that presynaptic ﬁring rates νj are constant.
(a) Show that νi has a ﬁxed point at νi = νθ.
(b) Discuss the stability of the ﬁxed point. Consider the cases γ > 0 and γ < 0.
(c) Discuss whether the learning rule is Hebbian, anti-Hebbian, or non-Hebbian.
2. Fixed point of BCM rule. Assume a single postsynaptic neuron νi which receives constant input
νj > 0 at all synapses 1 ≤j ≤N.
(a) Show that the weights wij have a ﬁxed point under the BCM rule (19.9).
(b) Show that this ﬁxed point is unstable.
3. Receptive ﬁeld development with BCM rule. Twenty presynaptic neurons with ﬁring rates νj
connect onto the same postsynaptic neuron which ﬁres at a rate νpost
i
= ∑20
j=1 wij νj. Synaptic
weights change according to the BCM rule (19.9) with a hard lower bound 0 ≤wij and νθ =
10 Hz.
The 20 inputs are organized in two groups of 10 inputs each. There are two possible input patterns
ξ μ, with μ = 1,2.
(a) The two possible input patterns are: μ = 1, a group 1 ﬁres at 3 Hz and group 2 is quiescent;
and μ = 2, group 2 ﬁres at 1 Hz and group 1 is quiescent. Inputs alternate between both patterns
several times back and forth. Each pattern presentation lasts for Δt. How do weights wij evolve?
Show that the postsynaptic neuron becomes specialized to one group of inputs.
(b) Similar to (a), except that that the second pattern is now μ = 2: group 2 ﬁres at 2.5 Hz and
group 1 is quiescent. How do weights wij evolve?
(c) As in (b), but you are allowed to make νθ a function of the time-averaged ﬁring rate ¯νpost
i
of the postsynaptic neuron. Is νθ = ¯νpost
i
a good choice? Why is νθ = (¯νpost
i
)2/10Hz a better
choice?
Hint: Consider the time it takes to update your time-averaged ﬁring rate in comparison to the
presentation time Δt of the patterns.
4. Weight matrix of Hopﬁeld model. Consider synaptic weights that change according to the fol-
lowing Hebbian learning rule: d
dt wij = c(νi −ν0)(νj −ν0).
(a) Identify the parameters c and ν0 with the parameters of Eq. (19.2).
(b) Assume a fully connected network of N neurons. Suppose that the initial weights wij vanish.
During presentation of a pattern μ, activities of all neurons 1 ≤k ≤N are ﬁxed to values νk = pμ
k ,
where pμ
k ∈{0,1} and synapses change according to the Hebbian learning rule. Patterns are
applied one after the other, each for a time Δt. Choose an appropriate value for ν0 so that, after
application of P patterns, the ﬁnal weights are wij = γ ∑P
j=1 pμ
i pμ
j . Express the parameter γ by
c,ν0,Δt.
(c) Compare your results with the weight matrix of the Hopﬁeld model in Chapter 17. Is the above
learning procedure realistic? Can it be classiﬁed as unsupervised learning?
Hint: Consider not only the learning phase, but also the recall phase. Consider the situation
where input patterns are chosen stochastically.
5. PCA with Oja's learning rule. In order to show that Oja's learning rule (19.7) selects the ﬁrst
principal component proceed in three steps.
(a) Show that the eigenvectors {e1,...,eN} of C are ﬁxed points of the dynamics.

19.5 Summary
523
Hint: Apply the methods of Section 19.3 to the batch version of Oja's rule and show that
Δw = γCw−γ w[w·Cw].
(19.49)
The claim then follows.
(b) Show that only the eigenvector e1 with the largest eigenvalue is stable.
Hint: Assume that the weight vector w = e1 + εek has a small perturbation ε ≪1 in one of the
principal direction. Derive an equation for dε/dt and show that the perturbation grows if k ̸= 1.
(c) Show that the output rate represents the projection of the input onto the ﬁrst principal compo-
nent.
6. Triplet STDP rule and BCM. Show that for Poisson spike arrival and output spike generated
by an independent Poisson process of rate νi, the triplet STDP model gives rise to a rate-based
plasticity model identical to BCM. Identify the function φ in Eqs. (19.8) and (19.9) with the
parameters of the triplet model in (19.15).
Hint: Use the methods of Section 19.3.3. Independent Poisson output means that you can neglect
the pre-before-post spike correlations.

20
Outlook: dynamics in plastic networks
In this ﬁnal chapter, we combine the dynamics of single neurons (Parts I and II) and
networks (Part III) with synaptic plasticity (Chapter 19) and illustrate their interaction in a
few applications.
In Section 20.1 on "reservoir computing" we show that the network dynamics in random
networks of excitatory and inhibitory neurons is sufﬁciently rich to serve as a computing
device that buffers past inputs and computes on present ones. In Section 20.2 we study
oscillations that arise in networks of spiking neurons and outline how synaptic plasticity
interacts with oscillations. Finally, in Section 20.3, we illustrate why the study of neu-
ronal dynamics is not just an intellectual exercise, but might, one day, become useful for
applications or, eventually, beneﬁt human patients.
20.1 Reservoir computing
One of the reasons the dynamics of neuronal networks are rich is that networks have a non-
trivial connectivity structure linking different neuron types in an intricate interaction pat-
tern. Moreover, network dynamics are rich because they span many time scales. The fastest
time scale is set by the duration of an action potential, i.e., a few milliseconds. Synaptic
facilitation and depression (Chapter 3) or adaptation (Chapter 6) occur on time scales from
a few hundred milliseconds to seconds. Finally, long-lasting changes of synapses can be
induced in a few seconds, but last from hours to days (Chapter 19).
These rich dynamics of neuronal networks can be used as a "reservoir" for inter-
mediate storage and representation of incoming input signals. Desired outputs can then be
constructed by reading out appropriate combinations of neuronal spike trains from the net-
work. This kind of "reservoir computing" encompasses the notions of "liquid computing"
(Maass et al., 2002) and "echo state networks" (Jaeger and Haas, 2004). Before we discuss
some mathematical aspects of randomly connected networks, we illustrate rich dynamics
by a simulated model network.

20.1 Reservoir computing
525
20.1.1 Rich dynamics
A nice example of rich network dynamics is the work by Maass et al. (2007). Six hundred
leaky integrate-and-ﬁre neurons (80 % excitatory and 20 % inhibitory) were placed on a
three-dimensional grid with distance-dependent random connectivity of small probability
so that the total number of synapses is about 10 000. Synaptic dynamics included short-
term plasticity (Chapter 3) with time constants ranging from a few tens of milliseconds to
a few seconds. Neuronal parameters varied from one neuron to the next and each neuron
received independent noise.
To check the computational capabilities of such a network, Maass et al. stimulated it
with four input streams targeting different subgroups of the network (Fig. 20.1). Each input
stream consisted of Poisson spike trains with time-dependent ﬁring rate ν(t).
Streams 1 and 2 ﬁred at a low background rate but switched occasionally to a short
period of high ﬁring rate ("burst"). In order to build a memory of past bursts, synaptic
weights from the network onto a group of eight integrate-and-ﬁre neurons ("memory" in
Fig. 20.1) were adjusted by an optimization algorithm, so that the spiking activity of these
eight neurons reﬂects whether the last ﬁring rate burst happened in stream 1 (memory
neurons are active = memory "on") or 2 (the same neurons are inactive = memory "off").
Thus, these neurons provided a 1-bit memory ("on"/"off") of past events.
Streams 3 and 4 were used to perform a non-trivial online computation. A network
output with value νonline was optimized to calculate the sum of activity in streams 3 and
4, but only if the memory neurons were active (memory "on"). Optimization of weight
parameters was achieved in a series of preliminary training trials by minimizing the squared
error (Chapter 10) between the target and the actual output.
Figure 20.1 shows that, after optimization of the weights, the network could store a
memory and, at the same time, perform the desired online computation. Therefore, the
dynamics in a randomly connected network with feedback from the output are rich enough
to generate an output stream which is a non-trivial nonlinear transformation of the input
streams (Maass et al., 2007; Jaeger and Haas, 2004; Sussillo and Abbott, 2009).
In the above simulation, the tunable connections (Fig. 20.1a) have been adjusted "by
hand" (or rather by a suitable algorithm), in a biologically non-plausible fashion, so as to
yield the desired output. However, it is possible to learn the desired output with the three-
factor learning rules discussed in Section 19.4. This has been demonstrated on a task and
set-up very similar to Fig. 20.1, except that the neurons in the network were modeled by
rate units (Hoerzer et al., 2012). The neuromodulatory signal M (see Section 19.4) took a
value of 1 if the momentary performance was better than the average performance in the
recent past, and zero otherwise.
20.1.2 Network analysis (*)
Networks of randomly connected excitatory and inhibitory neurons can be analyzed for the
case of rate units (Rajan and Abbott, 2006). Let xi denote the deviation from a spontaneous

526
Outlook: dynamics in plastic networks
Input
Memory
nmem
Output
nonline
n3
n2
n1
n4
(a)
Neuron #
Burst in
100
100
200
100
50
0
0
0
Time [ms]500
0
Rate [Hz]
(b)
n3+ n4
nmem [Hz]
nonline[Hz]
|n3−n4|
n1
n1
n2
Fig. 20.1 Reservoir computing. (a) A randomly connected network of integrate-and-ﬁre neurons
receives four input streams, each characterized by spike trains with a time-dependent Poisson ﬁring
rate νk. The main network is connected to two further pools of neurons, called "memory" and "out-
put." Memory neurons are trained to ﬁre at high rates if the last burst in ν1 is more recent than the last
burst in ν2. Spike trains of the memory neurons are fed back into the network. The output νonline is
trained to calculate either the sum ν3 +ν4 or the difference |ν3 −ν4| of the two other input streams,
depending on the current setting of the memory unit. The tunable connections onto the memory and
output neurons are indicated by curly arrows. (b) Spiking activity of the main network (top) and of
two memory neurons (second from top) as well as mean ﬁring rate of memory neurons (second from
top), and online output (third, thick solid line; the dashed lines give the momentary targets). The two
input streams ν1,ν2 are shown at the bottom. The periods when the memory unit should be active
are shaded. Adapted from Maass et al. (2007).
background rate ν0, i.e., the rate of neuron i is νi = ν0 + xi. Let us consider the update
dynamics
xi(t +1) = g
!
∑
j
wi jxj
"
(20.1)
for a monotone transfer function g with g(0) = 0 and derivative g′(0) = 1.
The background state (xi = 0 for all neurons i) is stable if the weight matrix has no
eigenvalues with real part larger than 1. If there are eigenvalues with real part larger than
1, spontaneous chaotic network activity may occur (Sompolinksy et al., 1988).
For weight matrices of random networks, a surprising number of mathematical results
exist. We focus on mixed networks of excitatory and inhibitory neurons. In a network
of N neurons, there are fN excitatory and (1 −f)N inhibitory neurons where f is the
fraction of excitatory neurons. Outgoing weights from an excitatory neuron j take values
wi j ≥0 for all i (and wi j ≤0 for weights from inhibitory neurons), so that all columns

20.1 Reservoir computing
527
 
 
Im (l)
(a)
Re (l)
r
Im (l)
Re (l)
1
r
(b)
100Hz
5Hz
Re(l)>1
Re(l)<1
}
}
(c)
Fig. 20.2 Random networks. (a) Distribution of eigenvalues in the complex plane for a network of
excitatory and inhibitory neurons with detailed balance. The distribution is circular and stays within
a spectral radius r. Adapted from Rajan and Abbott (2006). (b) Inhibitory plasticity quenches the real
part of eigenvalues into a smaller band (dashed ellipse). Thus an unstable random network (where
some eigenvalues have Re(λ) > 1, open circles) can be turned into stable one (Re(λ) < 1, solid
circles); schematic ﬁgure. (c) Time course of the activity of three sample neurons while the network is
driven with a small amount of noise. Neuronal activity in unstable random networks exhibits chaotic
switching between maximally low and high rates (top three traces) whereas the same neurons show
only a small amount of ﬂuctuations after stabilization through inhibitory plasticity (bottom three
traces). Adapted from Hennequin (2014).
of the weight matrix have the same sign. We assume non-plastic random weights with
the following three constraints: (i) Input to each neuron is balanced so that ∑j wi j = 0 for
all i ("detailed balance"). In other words, if all neurons are equally active, excitation and
inhibition cancel each other on a neuron-by-neuron level. (ii) Excitatory weights are drawn
from a distribution with mean μE/
√
N > 0 and variance r/N. (iii) Inhibitory weights are
drawn from a distribution with mean μI/
√
N < 0 and variance r/N. Under the conditions
(i)-(iii), the eigenvalues of the weight matrix all lie within a circle (Fig. 20.2a) of radius r,
called the spectral radius (Rajan and Abbott, 2006).
The condition of detailed balance stated above as item (i) may look artiﬁcial at ﬁrst
sight. However, experimental data supports the idea of detailed balance (Froemke et al.,
2007; Okun and Lampl, 2008). Moreover, plasticity of inhibitory synapses can be used to
achieve such a balance of excitation and inhibition on a neuron-by-neuron basis (Vogels
et al., 2011).
To understand how inhibitory plasticity comes into play, consider a rate model in con-
tinuous time
τ dxi
dt = −xi +g
!
∑
j
wi jxj
"
+ξ(t),
(20.2)
where τ is a time constant and xi is, as before, the deviation of the ﬁring rate from a
background level ν0. The gain function g(h) with g(0) and g′(0) = 1 is bounded between
xmin = −ν0 and xmax. Gaussian white noise ξ(t) of small amplitude is added on the right-
hand side of Eq. (20.2) to kick network activity out of the ﬁxed point at x = 0.
We subject inhibitory weights wi j < 0 (where j is one of the inhibitory neurons) to

528
Outlook: dynamics in plastic networks
Hebbian plasticity
d
dt wi j = −γ xi(t)x j(t),
(20.3)
where x j(t) =
 ∞
0 exp(−s/τ)xj(t −s)ds is the synaptic trace left by earlier presynaptic
activity. For γ > 0, this is a Hebbian learning rule because the absolute size of the inhibitory
weight increases if postsynaptic and presynaptic activity are correlated (Chapter 19).
In a random network of N = 200 excitatory and inhibitory rate neurons with an initial
weight matrix that had a large distribution of eigenvalues, inhibitory plasticity according to
Eq. (20.3) led to a compression of the real parts of the eigenvalues (Hennequin, 2013). Heb-
bian inhibitory plasticity can therefore push a network from the regime of unstable dynam-
ics into a stable regime (Fig. 20.2b,c) while keeping the excitatory weights strong. Such
networks, which have strong excitatory connections, counterbalanced by equally strong
precisely tuned inhibition, can potentially explain patterns of neural activity in the motor
cortex during arm movements (Churchland et al., 2012). In-depth understanding of pat-
terns in the motor cortex could eventually contribute to the development of neural prosthe-
sis (Shenoy et al., 2011) that detect and decode neural activity in motor-related brain areas
and translate it into intended movements of a prosthetic limb; see Chapter 11.
Example: Generating movement trajectories with inhibition stabilized networks
During the preparation and performance of arm movements (Fig. 20.3a) neurons in
the motor cortex exhibit collective dynamics (Churchland et al., 2012). In particular,
during the preparation phase just before the start of the movement, the network activity
approaches a stable pattern of ﬁring rates, which is similar across different trials. This
stable pattern can be interpreted as an initial condition for the subsequent evolution of
the network dynamics during arm movement, which is rather stereotypical across trials
(Shenoy et al., 2011).
Because of its sensitivity to small perturbations, a random network with chaotic net-
work dynamics may not be a plausible candidate for stereotypical dynamics, necessary
for reliable arm movements. On the other hand, in a stable random network with a circu-
lar distribution of eigenvalues with spectral radius r < 1, transient dynamics after release
from an initial condition are short and dominated by the time constant τ of the single-
neuron dynamics (unless one of the eigenvalues is hand-tuned to lie very close to unity).
Moreover, as discussed in Chapter 18, the cortex is likely to work in the regime of an
inhibition-stabilized network (Tsodyks et al., 1997; Ozeki et al., 2009) where excitatory
connections are strong, but counterbalanced by even stronger inhibition.
Inhibitory plasticity is helpful to generate inhibition-stabilized random networks.
Because excitatory connections are strong but random, transient activity after release
from an appropriate initial condition is several times longer than the single-neuron time
constant τ. Different initial conditions put the network onto different, but reliable trajec-
tories. These trajectories of the collective network dynamics can be used as a reservoir
to generate simulated muscle output for different arm trajectories (Fig. 20.3).

20.2 Oscillations: good or bad?
529
Wait
Single neurons 
Muscle 1
Muscle 2
Other
muscles
Go!
Muscles
t=420ms
t=180ms
t=0
Fig. 20.3 Movement preparation and execution. Top: A typical delayed movement generation task
in behavioral neuroscience starts with the instruction of what movement must be prepared. The arm
must be held still until the go cue is given. Middle: During the preparatory period, model neurons
receive a ramp input (dashed) which is withdrawn when the go cue is given. Thereafter the network
dynamics move freely from the initial condition set during the preparatory period. Model neurons
(four sample black lines) then exhibit transient oscillations which drive muscle activation (gray lines).
Bottom: To prepare the movement B (e.g., butterﬂy movement), the network (gray box, middle) is
initialized in the desired state by the slow activation of the corresponding pool of neurons (gray
circle). Muscles (right) in the model are activated by a suitable combination of neuronal activity read
out from the main network. Note that no feedback is given during the drawing movement. Adapted
from Hennequin et al. (2014).
20.2 Oscillations: good or bad?
Oscillations are a prevalent phenomenon in biological neural systems and manifest them-
selves experimentally in electroencephalograms (EEG), recordings of local ﬁeld potentials
(LFP), and multi-unit recordings. Oscillations are thought to stem from synchronous net-
work activity and are often characterized by the associated frequency peak in the Fourier
spectrum. For example, oscillations in the range 30-70 Hz are called gamma oscillations
and those above 100 Hz "ultrafast" or "ripples" (Traub, 2006; Buzsaki, 2011). Among
the slower oscillations, prominent examples are delta oscillations (1-4 Hz) and spindle
oscillations in the EEG during sleep (7-15 Hz) (Bazhenov and Timofeev, 2006) or theta
oscillations (4-10 Hz) in the hippocampus and other areas (Buzsaki, 2011).
Oscillations are thought to play an important role in the coding of sensory information.
In the olfactory system an ongoing oscillation of the population activity provides a tempo-
ral frame of reference for neurons coding information about the odorant (Laurent, 1996).

530
Outlook: dynamics in plastic networks
Similarly, place cells in the hippocampus exhibit phase-dependent ﬁring activity relative to
a background oscillation (O'Keefe and Recce, 1993; Buzsaki, 2011). Moreover, rhythmic
spike patterns in the inferior olive may be involved in various timing tasks and motor coor-
dination (Welsh et al., 1995; Kistler and van Hemmen, 2000). Finally, synchronization
of ﬁring across groups of neurons has been hypothesized to provide a potential solution
to the so-called binding problem (Singer, 1993, 2007). The common idea across all the
above examples is that an oscillation provides a reference signal for a "phase code": the
signiﬁcance of a spike depends on its phase with respect to the global oscillatory reference;
see Section 7.6 and Fig. 7.17. Thus, oscillations are potentially useful for intricate neural
coding schemes.
On the other hand, synchronous oscillatory brain activity is correlated with numerous
brain diseases. For example, an epileptic seizure is deﬁned as "a transient occurrence of
signs and/or symptoms due to abnormal excessive or synchronous neuronal activity in the
brain" (Fisher et al., 2005). Similarly, Parkinson's disease is characterized by a high level
of neuronal synchrony in the thalamus and basal ganglia (Pare et al., 1990) while neurons in
the same areas ﬁre asynchronously in the healthy brain (Nini et al., 1995). Moreover, local
ﬁeld potential oscillations at theta frequency in thalamic or subthalamic nuclei are linked
to tremor in human Parkinsonian patients, i.e., rhythmic ﬁnger, hand or arm movement at
3-6 Hz (Pare et al., 1990; Tass et al., 2010). Therefore, in these and in similar situations, it
seems to be desirable to suppress abnormal, highly synchronous oscillations so as to shift
the brain back into its healthy state.
Simulations of the population activity in homogeneous networks typically exhibit oscil-
lations when driven by a constant external input. For example, oscillations in networks of
purely excitatory neurons arise because, as soon as some neurons in the network ﬁre, they
contribute to exciting others. Once the avalanche of ﬁring has run across the network, all
neurons pass through a period of refractoriness, until they are ready to ﬁre again. In this
case the time scale of the oscillation is set by neuronal refractoriness (Fig. 20.4a). A similar
argument can be made for a homogeneous network of inhibitory neurons driven by a con-
stant external stimulus. After a ﬁrst burst by a few neurons, mutual inhibition will silence
the population until inhibition wears off. Thereafter, the whole network ﬁres again.
Oscillations also arise in networks of coupled excitatory and inhibitory neurons. The
excitatory connections cause a synchronous bursts of the network activity leading to a
build-up of inhibition which, in turn, suppresses the activity of excitatory neurons. The
oscillation period in the two latter cases is therefore set by the build-up and decay time of
inhibitory feedback (Fig. 20.4b).
Even slower oscillations can be generated in "winner-take-all" networks (see Chapter
16) with dynamic synapses (see Chapter 3) or adaptation (see Chapter 6). Suppose the
networks consists of K populations of excitatory neurons which share a common pool of
inhibitory neurons. Parameters can be set such that excitatory neurons within the momen-
tarily "winning" population stimulate each other so as to overcome inhibition. In the pres-
ence of synaptic depression, however, the mutual excitation fades away after a short time,
so that now a different excitatory population becomes the new "winner" and switches on.

20.2 Oscillations: good or bad?
531
Time
Refractory
Spiking
T
(a)
(b)
Time
Exc
Inh
T
Fig. 20.4 Types of network oscillation. (a) In a homogeneous network of excitatory neurons, near-
synchronous ﬁring of all neurons is followed by a period of refractoriness, leading to fast oscillations
with period T. Active neurons: vertical dash in spike raster and solid circle in network schema. Silent
neurons: open circle in schema. (b) In a network of excitatory and inhibitory neurons, activity of the
excitatory population alternates with activity of the inhibitory one. The period T is longer than in (a).
As a result, inhibition arising from inhibitory neurons turns the activity of the previously
winning group off, until inhibition has decayed and excitatory synapses have recovered
from depression. The time scale is then set by a combination of the time scales of inhibi-
tion and synaptic depression. Networks of this type have been used to explain the shift of
attention from one point in a visual scene to the next (Itti et al., 1998).
In this section, we brieﬂy review mathematical theories of oscillatory activity (Sections
20.2.1-20.2.3) before we study the interaction of oscillations with STDP (Section 20.2.4)
The results of this section will form the basis for the discussion of Section 20.3.
20.2.1 Synchronous oscillations and locking
Homogeneous networks of spiking neurons show a natural tendency toward oscillatory
activity. In Sections 13.4.2 and 14.2.3, we analyzed the stability of asynchronous ﬁring. In
the stationary state the population activity is characterized by a constant value A0 of the
population activity. An instability of the dynamics with respect to oscillations at period
T, appears as a sinusoidal perturbation of increasing amplitude; see Fig. 20.5a as well as
Fig. 14.8. The analysis of the stationary state shows that a high level of noise, network
heterogeneity, or a sufﬁcient amount of inhibitory plasticity, all contribute to stabilizing
the stationary state. The linear stability analysis, however, is only valid in the vicinity
of the stationary state. As soon as the amplitude ΔA of the oscillations is of the same
order of magnitude as A0, the solution found by linear analysis is no longer valid since the
population activity cannot become negative.
Oscillations can, however, also be analyzed from a completely different perspective. In
a homogeneous network with ﬁxed connectivity in the limit of low noise we expect strong

532
Outlook: dynamics in plastic networks
A(t)
0 
T 
2T
t
A0
(a)
0
T
2T
t
A(T)
A(0)
2 d0
(b)
Fig. 20.5 Population activity A(t) during oscillations and synchrony. (a) An instability of asyn-
chronous ﬁring at rate A0 leads to a sinusoidal oscillation of increasing amplitude. (b) If the fully
synchronized state is stable, the width δ0 of the rectangular population pulses decreases while their
amplitude A(kT) increases with each period.
oscillations. In the following, we focus on the synchronous oscillatory mode where nearly
all neurons ﬁre in "lockstep" (Fig. 20.5b). We study whether such periodic synchronous
bursts of the population activity can be a stable solution of network equations.
To keep the arguments simple, we consider a homogeneous population of identical
SRM0 neurons (Chapter 6 and Section 9.3) which is nearly perfectly synchronized and ﬁres
almost regularly with period T. To analyze the existence and stability of a fully locked syn-
chronous oscillation we approximate the population activity by a sequence of square pulses
k, k ∈{0,±1,±2,...}, centered around t = kT. Each pulse k has a certain half-width δk
and amplitude (2δk)−1 - since all neurons are supposed to ﬁre once in each pulse; see
Fig. 20.5b. If we ﬁnd that the amplitude of subsequent pulses increases while their width
decreases (i.e., limk→∞δk = 0), we conclude that the fully locked state in which all neurons
ﬁre simultaneously is stable.
In the examples below, we will prove that the condition for stable locking of all neurons
in the population can be stated as a condition on the slope h′ of the input potential h at the
moment of ﬁring. More precisely, if the last population pulse occurred at about t = 0 with
amplitude A(0) the amplitude of the population pulse at t = T increases if h′(T) > 0:
h′(T) > 0
⇐⇒
A(T) > A(0).
(20.4)
If the amplitude of subsequent pulses increases, their width must decrease accordingly. In
other words, we have the following locking theorem. In a homogeneous network of SRM0
neurons, a necessary and, in the limit of a large number of presynaptic neurons (N →∞),
also sufﬁcient condition for a coherent oscillation to be asymptotically stable is that ﬁring
occurs when the postsynaptic potential arising from all previous spikes in the population is
increasing in time (Gerstner et al., 1996b).
Example: Perfect synchrony in network of inhibitory neurons
Locking in a population of spiking neurons can be understood by simple geometrical
arguments. To illustrate this argument, we study a homogeneous network of N identical
SRM0 neurons which are mutually coupled with strength wi j = J0/N. In other words, the
interaction is scaled with 1/N so that the total input to a neuron i is of order 1 even if the

20.2 Oscillations: good or bad?
533
number of neurons is large (N →∞). Since we are interested in synchrony we suppose
that all neurons have ﬁred simultaneously at ˆt = 0. When will the neurons ﬁre again?
Since all neurons are identical we expect that the next ﬁring time will also be syn-
chronous. Let us calculate the period T between one synchronous pulse and the next.
We start from the ﬁring condition of SRM0 neurons
ϑ = ui(t) = η(t −ˆti)+∑
j
wi j∑
f
ε

t −t f
j
	
+h0 ,
(20.5)
where ε(t) is the postsynaptic potential. The axonal transmission delay Δax is included in
the deﬁnition of ε, i.e., ε(t) = 0 for t < Δax. Since all neurons have ﬁred synchronously
at t = 0, we set ˆti = t f
j = 0. The result is a condition of the form
ϑ −η(t) = J0 ε(t)+h0,
(20.6)
since wi j = J0/N for j = 1,...,N. Note that we have neglected the postsynaptic poten-
tials that may have been caused by earlier spikes t f
j < 0 back in the past.
The graphical solution of Eq. (20.6) for the case of inhibitory neurons (i.e., J0 < 0)
is presented in Fig. 20.6. The ﬁrst crossing point of the effective dynamic threshold
ϑ −η(t) and J0 ε(t)+h0 deﬁnes the time T of the next synchronous pulse.
What happens if synchrony at t = 0 was not perfect? Let us assume that one of the
neurons is slightly late compared to the others (Fig. 20.6b). It will receive the input
J0 ε(t) from the others, thus the right-hand side of Eq. (20.6) remains the same. The
left-hand side, however, is different since the last ﬁring was at δ0 instead of zero. The
next ﬁring time is at t = T +δ1 where δ1 is found from
ϑ −η(T +δ1 −δ0) = h0 +J0 ε(T +δ1).
(20.7)
Linearization with respect to δ0 and δ1 then yields:
δ1 < δ0
⇐⇒
J0ε′(T) > 0,
(20.8)
where we have exploited that neurons with "normal" refractoriness and adaptation prop-
erties have η′ > 0. From Eq. (20.8) we conclude that the neuron which has been late is
"pulled back" into the synchronized pulse of the others if the postsynaptic potential J0ε
is rising at the moment of ﬁring at T. Equation (20.8) is a special case of the locking
theorem.
Example: Proof of the locking theorem (*)
To check whether the fully synchronized state is a stable solution of the network
dynamics, we exploit the population integral equation (14.5) and assume that the popu-
lation has already ﬁred a couple of narrow pulses for t < 0 with widths δk ≪T, k ≤0,
and calculate the amplitude and width of subsequent pulses.

534
Outlook: dynamics in plastic networks
t
T
0
u
J - h(t)
J0 e(t)
(a)
d0
t
J - h(t −d0)     
T
d1
0
u
J0 e(t)
(b)
Fig. 20.6 Synchronous ﬁring in a network with inhibitory coupling. (a) Bottom: Spike raster - all
neurons have ﬁred synchronously at ˆt = 0. Top: The next spike occurs when the total input potential
h0 +J0 ε(t) (solid line; the offset corresponds to a constant background input h0 > 0) has increased
sufﬁciently to cross the dynamic threshold ϑ −η(t). (b) Stability of perfect synchrony. The last
neuron is out of tune. The ﬁring time difference at t = 0 is δ0. One period later the ﬁring time
difference is reduced (δ1 < δ0), since the threshold is reached at a point where J0 ε(t) is rising.
Therefore this neuron is eventually pulled back into the synchronous group.
To translate the above idea into a step-by-step demonstration, we use
A(t) =
∞
∑
k=−∞
1
2δk
Θ[t −(kT −δk)]Θ[(kT +δk)−t]
(20.9)
as a parameterization of the population activity; see Fig. 20.5b. Here, Θ(.) denotes the
Heaviside step function with Θ(s) = 1 for s > 0 and Θ(s) = 0 for s ≤0. For stabil-
ity, we need to show that the amplitude A(0),A(T),A(2T),... of the rectangular pulses
increases while the width δk of subsequent pulses decreases.
To prove the theorem, we assume that (i) all neurons in the network have identical
refractoriness η(s) with dη/ds > 0 for all s > 0; (ii) all neurons have identical shape
ε(s) of the postsynaptic potential; (iii) all couplings are identical, wi j = w0 = J0/N; and
(iv) all neurons receive the same constant external drive h0. The sequence of rectangular
activity pulses in the past therefore gives rise to an input potential
h(t) = h0 +J0
 ∞
0 ε(s)A(t −s)ds = h0 +
∞
∑
k=0
J0 ε(t +kT) + O

(δk)2
,
(20.10)
which is identical for all neurons.
To determine the period T, we consider a neuron in the center of the square pulse
which has ﬁred its last spike at ˆt = 0. The next spike of this neuron must occur at t = T,
i.e., in the center of the next square pulse. We use ˆt = 0 in the threshold condition for

20.2 Oscillations: good or bad?
535
spike ﬁring, which yields
T = min

t |η(t)+h0 +J0
∞
∑
k=0
ε(t +kT) = ϑ
 
.
(20.11)
If a synchronized solution exists, (20.11) deﬁnes its period.
We now use the population equation of renewal theory, Eq. (14.5). In the limit of low
noise, the interval distribution PI(t|ˆt) becomes a δ-function: neurons that have ﬁred at
time ˆt ﬁre again at time t = ˆt +T(ˆt). Using the rules for calculation with δ-functions and
the threshold condition (Eq. (20.11)) for ﬁring, we ﬁnd
A(t) =

1+ h′
η′

A(t −Tb),
(20.12)
where the prime denotes the temporal derivative. Tb is the "backward interval:" neurons
that ﬁre at time t have ﬁred their previous spike at time t −Tb. According to our assump-
tion η′ > 0. A necessary condition for an increase of the activity from one cycle to the
next is therefore that the derivative h′ is positive - which is the essence of the locking
theorem.
The locking theorem is applicable in a large population of SRM neurons (Gerstner
et al., 1996b). As discussed in Chapter 6, the framework of SRM encompasses many
neuron models, in particular the leaky integrate-and-ﬁre model. Note that the above lock-
ing argument is a "local" stability argument and requires that network ﬁring is already
close to the fully synchronized state. A related but global locking argument has been
presented by Mirollo and Strogatz (1990).
20.2.2 Oscillations with irregular ﬁring
In the previous subsection, we have studied fully connected homogeneous network models
which exhibit oscillations of the neuronal activity. In the locked state, all neurons ﬁre reg-
ularly and in near-perfect synchrony. However, experiments show that, though oscillations
are a common phenomenon, spike trains of individual neurons are often highly irregular.
Periodic large-amplitude oscillations of the population activity are compatible with irreg-
ular spike trains if individual neurons ﬁre at an average frequency that is signiﬁcantly lower
than the frequency of the population activity (Fig. 20.7). If the subgroup of neurons that is
active during each activity burst changes from cycle to cycle, then the distribution of inter-
spike intervals can be broad, despite a prominent oscillation. For example, in the inferior
olivary nucleus, individual neurons have a low ﬁring rate of one spike per second while
the population activity oscillates at about 10 Hz. Strong oscillations with irregular spike
trains have interesting implications for short-term memory and timing tasks (Kistler and
De Zeeuw, 2002).

536
Outlook: dynamics in plastic networks
2T
3T
4T
5T
T
A(t)
Fig. 20.7 Synchronous oscillation with irregular spike trains. Neurons tend to ﬁre synchronously
but with an average rate that is signiﬁcantly lower than the oscillation frequency of the population
activity (bottom). Each neuron is thus ﬁring only in one out of approximately four cycles, giving
rise to highly irregular spike trains. Short vertical lines indicate the spikes of a set of six neurons
(schematic ﬁgure).
20.2.3 Phase models
For weak coupling, synchronization and locking of periodically ﬁring neurons can be sys-
tematically analyzed in the framework of phase models (Kuramoto, 1984; Ermentrout and
Kopell, 1984; Kopell, 1986; Pikovsky and Rosenblum, 2007).
Suppose a neuron driven by a constant input ﬁres regularly with period T, i.e., it evolves
on a periodic limit cycle. We have already seen in Chapter 4 that the position on the limit
cycle can be represented by a phase φ. In contrast to Chapter 4, we adopt here the con-
ventions that (i) spikes occur at phase φ = 0 (Fig. 20.8) and (ii) between spikes the phase
increases from zero to 1 at a constant speed f0 = 1, where f0 = 1/T is the frequency of the
periodic ﬁring. In more formal terms, the phase of an uncoupled neural "oscillator" evolves
according to the differential equation
d
dt φ = f0
(20.13)
and we identify the value 1 with zero. Integration yields φ(t) = (t/T)mod1 where "mod1"
means "modulo 1." The phase φ represents the position on the limit cycle (Fig. 20.8a).
Phase models for networks of N interacting neurons are characterized by the intrinsic
frequencies f j of the neurons (1 ≤j ≤N) as well as the mutual coupling. For weak cou-
pling, the interaction can be directly formulated for the phase variables φ j,
d
dt φi = fi +ε∑
j
wi jP(φi,φ j),
(20.14)
where ε ≪1 is the overall coupling strength, wi j are the relative pairwise coupling, and P
the phase coupling function. For pulse-coupled oscillators, an interaction from neuron j to

20.2 Oscillations: good or bad?
537
t
T 
0
t/T
1
(a)
2
0.5
f= (t/T)mod1
1
f
(b)
t
T 
0
0
0.5
T
tstim
fstim
f
0.5
Δ
1
fstim
Fig. 20.8 Phase models. (a) For a neuron ﬁring with period T (top), we can introduce a phase variable
φ = (t/T)mod1 (bottom). (b) If a weak input pulse of amplitude ε is given at a phase φstim, the
interspike interval T ′ is shorter. The phase response curve ˜F(φstim) measures the phase advance
Δφ = (T −T ′)/T as a function of the stimulation phase φstim.
neuron i happens only at the moment when the presynaptic neuron j emits a spike. Hence
the phase coupling function P(φi,φ j) is replaced by
P(φi,φ j) −→F(φi)∑
f
δ(t −t f
j ),
(20.15)
where {t1
j ,t2
j ,t3
j ,...} are the spike times of the presynaptic neuron, deﬁned by the zero-
crossings of φ j, i.e., {t |φ j(t) = 0}. The function F is the "phase response curve": the
effect of an input pulse depends on the momentary state (i.e., the phase φi) of the receiving
neuron (see the below example below).
For neurons with synaptic currents of ﬁnite duration, phase coupling is not restricted to
the moment of spike ﬁring (φ j = 0) of the presynaptic neuron, but extends also to phase
values φ j > 0. The phase coupling can be positive or negative. Positive values of P lead
to a phase advance of the postsynaptic neuron. Phase models are widely used to study
synchronization phenomena (Pikovsky and Rosenblum, 2007).
Example: Phase response curve
The idea of a phase response curve is illustrated in Fig. 20.8b. A short positive stim-
ulating input pulse of amplitude ε perturbs the period of an oscillator from its refer-
ence value T to a new value T ′, which might be shorter or longer than T (Canavier,
2006; Winfree, 1980). The phase response curve ˜F(φstim) measures the phase advance
Δφ = (T −T ′)/T as a function of the phase φstim at which the stimulus was given.
Knowledge of the stimulation phase is, however, not sufﬁcient to characterize the
effect on the period, because a stimulus of amplitude 2ε is expected to cause a larger
phase shift than a stimulus of amplitude 1ε. The mathematically relevant notion is there-

538
Outlook: dynamics in plastic networks
fore the phase advance, divided by the (small) amplitude ε of the stimulus. More pre-
cisely, the inﬁnitesimal phase response curve is deﬁned as
F(φstim) = lim
ε→0
T −T ′(φstim)
ε T
.
(20.16)
The inﬁnitesimal phase response curve can be extracted from experimental data (Gutkin
et al., 2005) and plays an important role in the theory of weakly coupled oscillators.
Example: Kuramoto model
The Kuramoto model (Kuramoto, 1984; Acebron et al., 2005) describes a network of
N phase oscillators with homogeneous all-to-all connections wi j = J0/N and a sinusoidal
phase coupling function
d
dt φi = fi + J0
N
N
∑
j=1
sin(2π(φ j −φi)),
(20.17)
where fi is the intrinsic frequency of oscillator i. For the analysis of the system, it is
usually assumed that both the coupling strength J0 and the frequency spread ( fi −f)/ f
are small. Here f denotes the mean frequency.
If the spread of intrinsic frequencies is zero, then an arbitrary small coupling J0 > 0
synchronizes all units at the same phase φi(t) = φ(t) = f t. This is easy to see. First,
synchronous dynamics φi(t) = φ j(t) = φ(t) for all i, j are a solution of Eq. (20.17).
Second, if one of the oscillators is late by a small amount, say oscillator n has a phase
φn(t) < φ(t), then the interaction with the others makes it speed up (if the phase differ-
ence is smaller than 0.5) or slow down (if the phase difference is larger than 0.5), until
it is synchronized with the group of other neurons. More generally, for a ﬁxed (small)
spread of intrinsic frequencies, there is a minimal coupling strength Jc above which
global synchronization sets in.
We note that, in contrast to pulse-coupled models, units in the Kuramoto model can
interact at arbitrary phases.
20.2.4 Synaptic plasticity and oscillations
During an oscillation a large fraction of excitatory neurons ﬁres near-synchronously (Fig.
20.4). What happens to the oscillation if the synaptic efﬁcacies between excitatory neurons
are not ﬁxed but subject to spike-timing dependent plasticity (STDP)? In this subsection
we sketch some of the theoretical arguments (Lubenov and Siapas, 2008; Pﬁster and Tass,
2010)
In Fig. 20.9 near synchronous spikes in a pair of pre- and postsynaptic neurons are
shown together with a schematic STDP window; see Section 19.1.2. Note that the hori-
zontal axis of the STDP window is the difference between the spike arrival time tpre at the

20.2 Oscillations: good or bad?
539
}
t post
tpre - tpost
tpre - tpost
t f
(a)
s
s
t post
tf
tpre > tpost
tpre - tpost
(b)
s
s
tf
tpost
tpre < tpost
tpre - tpost
(c)
s
s
Fig. 20.9 Network oscillations and STDP. (a) Top: During a near-synchronous oscillation presynap-
tic spike timings t f have a jitter σ with respect to the spike of a given postsynaptic neuron. Bottom:
Because of axonal transmission delay, the spike arrival time tpre = t f + Δax of presynaptic spikes
at the synapse, is slightly shifted (light shaded area) to the regime "post-before-pre." Therefore, for
an antisymmetric STDP window, synaptic depression dominates; compare the dark shaded areas for
potentiation and depression. (b) Same as in (a), except that the amplitude of potentiation for near-
synchronous ﬁring is larger. As before, the total area under the STDP curve is balanced between
potentiation and depression (the integral over the STDP curve vanishes). (c) Same as in (b), except
that the integral over the STDP curve is now positive, as is likely to be the case at high ﬁring rates.
For large jitter σ potentiation dominates over depression (compare the dark-shaded areas).
presynaptic terminal and the spike ﬁring time t f
i = tpost of the postsynaptic neuron. This
choice (where the presynaptic spike arrival time is identiﬁed with the onset of the EPSP)
corresponds to one option, but other choices (Markram et al., 1997; Sj¨ostr¨om et al., 2001)
are equally common. With our convention, the jump from potentiation to depression occurs
if postsynaptic ﬁring coincides with presynaptic spike arrival. However, because of axonal
transmission delays, synchronous ﬁring leads to spike arrival that is delayed with respect
to the postsynaptic spike. Therefore, consistent with experiments (Sj¨ostr¨om et al., 2001),
synchronous spike ﬁring with small jitter leads, at low repetition frequency, to a depression
of synapses (Fig. 20.9a). Lateral connections within the population of excitatory neurons
are therefore weakened (Lubenov and Siapas, 2008).
However, the shape of the STDP window is frequency dependent with a marked dom-
inance of potentiation at high repetition frequencies (Sj¨ostr¨om et al., 2001). Therefore,
near-synchronous ﬁring with a large jitter σ leads to a strengthening of excitatory connec-
tions (Fig. 20.9c) in the synchronously ﬁring group (Pﬁster and Tass, 2010). In summary,
synchronous ﬁring and STDP tightly interact.
Example: Bistability of plastic networks
Since we are interested in the interaction of STDP with oscillations, we focus on
a recurrent network driven by periodically modulated spike input (Fig. 20.10a). The

540
Outlook: dynamics in plastic networks
lateral connection weights wi j from a presynaptic neuron j to a postsynaptic neuron i
are changed according to Eq. (19.11), which we repeat here for convenience
d
dt wi j(t) = Sj(t)

apre
1 +
 ∞
0 A−(wi j)W−(s)Si(t −s) ds

+Si(t)

apost
1
+
 ∞
0 A+(wi j)W+(s)Sj(t −s) ds

,
(20.18)
where Sj = ∑f δ(t −t f
j ) and Si = ∑f δ(t −t f
i ) denote the spike trains of pre- and
postsynaptic neurons, respectively. The time course of the STDP window is given by
W± = exp(−s/τ±) and apre
1
and apost
1
are non-Hebbian contributions, i.e., an isolated
presynaptic or postsynaptic spike causes a small weight change, even if it is not paired
with activity of the partner neuron. Non-Hebbian terms apre
1
+ apost
1
< 0 are linked to
"homeostatic" or "heterosynaptic" plasticity and are useful to balance weight growth
caused by Hebbian terms (Chapter 19). The amplitude factors A± are given by soft-
bounds analogous to Eq. 19.4:
A+(wi j) = A0
+ (wmax −wi j)β
for 0 < w < wmax,
(20.19)
A−(wi j) = A0
−(wi j)β
for 0 < w < wmax,
(20.20)
with β = 0.05. An exponent β close to zero implies that there is hardly any weight
dependence except close to the bounds at zero and wmax.
The analysis of the network dynamics in the presence of STDP (Pﬁster and Tass, 2010;
Gilson et al., 2009; Kempter et al., 1999a) shows that the most relevant quantities are
(i) the integral over the STDP window A+(w)τ+ + A−(w)τ−evaluated at a value w far
away from the bounds; (ii) the Fourier transform of the STDP window at the frequency
1/T, where T is the period of the oscillatory drive; (iii) the sum of the non-Hebbian
terms apre
1 +apost
1
.
Oscillations of brain activity in the δ or θ frequency band are relatively slow com-
pared to the time scale of STDP. If we restrict the analysis to oscillations with a period
T that is long compared to the time scale τ+/−of the learning window, the Fourier
transform of the STDP window mentioned in (ii) can be approximated by the integral
mentioned in (i). Note that slow sinusoidal oscillations correspond to a large jitter σ of
spike times (Fig. 20.9c).
Pﬁster and Tass (2010) found that the network dynamics are bistable if the integral
over the learning window is positive (which causes an increase of weights for uncorre-
lated Poisson ﬁring), but weight increase is counterbalanced by weight decrease caused
by homeostatic terms in the range C < apre
1 + apost
1
< c < 0 with suitable negative con-
stants C and c. Therefore, for the same periodic stimulation paradigm, the network can
be in either a stable state where the average weight is close to zero, or a different stable
state where the average weight is signiﬁcantly positive (Fig. 20.10b). In the latter case,
the oscillation amplitude in the network is enhanced (Fig. 20.10c).

20.3 Helping patients
541
. 
. 
. 
wij
i
j
nin
nout
(a)
wav
dwav/dt
wmax
i
ii
(b)
Time [s]
νav[Hz]
i
ii
(c)
Fig. 20.10 Bistability of plastic networks. (a) A model network of spiking neurons receives spike
input at a periodically modulated rate νin, causing a modulation of the ﬁring rate νout
i
of network
neurons 1 ≤i ≤N. Lateral weights wij are subject to STDP. (b) Change dwav/dt of the aver-
age weight as a function of wav. For an STDP window with positive integral the average network
weight wav exhibits bistability (arrows indicate direction of change) in the presence of the peri-
odic input drive. The maximum weight is wmax. (c) Bistability of the average network output rate
νav = (1/N)∑N
i=1 νout
i
in the presence of a periodic drive. The weights wij in the two simulations
have an average value wav given by the two ﬁxed points in (b). Adapted from Pﬁster and Tass (2010).
20.3 Helping patients
We would like to close this chapter - and indeed the whole book - with an inspiring appli-
cation of insights derived from the theory of neuronal dynamics to animals and, potentially,
humans. Initial results at the current state of research are encouraging, so that mathematical
considerations could ultimately increase the quality of life of, among others, Parkinsonian
patients.
Parkinson's is a severe brain disease. A prominent symptom in human patients suffering
from Parkinson's disease is involuntary shaking of arms and ﬁngers in a periodic movement
of about 3-6 Hz, called resting tremor. Some patients also exhibit muscle rigidity or akinesia
where they are unable to move. Tremor as well as rigidity are correlated with overly strong
oscillatory synchronization in brain areas such as thalamus and basal ganglia, whose activity
in the healthy state is asynchronous (Pare et al., 1990; Nini et al., 1995; Tass et al., 2010).
Moreover, the oscillation frequency of neural activity is related to the tremor frequency.
One of the presently available treatments of Parkinsonian symptoms is "deep brain stim-
ulation" (DBS) (Benabid et al., 1991, 2009). DBS reduces both tremor and rigidity of
Parkinsonian patients. To perform DBS, a high-frequency stimulus is applied to an elec-
trode implanted in the subthalamic nucleus or globus pallidus (which project indirectly or
directly onto the thalamus) of the patient (Fig. 20.11a). The treatment is reversible so that,
when stimulation is stopped, patients rapidly fall back into tremor or rigidity.
If we view the brain as a dynamical system, we can say that classical DBS shifts the
state of the brain so as to reduce the symptoms of Parkinson's during stimulation, but does
not return the brain's autonomous dynamics back to a healthy state. In other words, the

542
Outlook: dynamics in plastic networks
Subthalamic nuclei (STN) 
Thalamus
Globus pallidus (GPi/GPe) 
STN 
GPe 
GPi
Thalamus
Stimulator
(a)
Network state
h
p
dx
dt
x
f (x)
fstim (x)
(b)
Fig. 20.11 Deep brain stimulation. (a) Schema showing a vertical cut through the brain with
implanted electrode. The tip of the electrode reaches one of the subthalamic nuclei. The electrode
is connected with a wire to the stimulator. The box diagram shows some of the major excitatory
(solid arrows) and inhibitory (dashed arrows) connections from the subthalamic nucleus (STN) to
thalamus. (b) Bistability of a healthy (h) and pathological network state (p, circle), described by the
ﬂow (solid arrows) of an abstract differential equation dx/dt = f(x) (solid line). To kick the network
out of the pathological state, an appropriate stimulus has to be applied that destabilizes p and drives
the network state toward h by changing the right-hand side of the differential equation to fstim(x)
(dashed line and arrows); adapted from Pﬁster and Tass (2010).
patient relies on continuous treatment through DBS. We may visualize the pathological and
healthy conditions as two different conﬁguration in some abstract space of network states.
It is reasonable to assume that brain dynamics in the healthy state is at a stable equilibrium
point - despite ongoing spike ﬁring and plasticity on different time scales; otherwise our
brains would rapidly stop functioning. The fact that, after the end of DBS, the brain returns
to the pathological state indicates that this state is also stable (Fig. 20.11b).
The question arises whether, by suitable stimulation protocols, it would be possible to
shift the pathological brain back into its healthy state. Work of the group of Peter Tass
(Tass, 2003; Tass et al., 2012b), but also other groups (Rubin and Terman, 2004; Rosin
et al., 2011; Wilson et al., 2011) suggests that this may be possible. The treatment relies on
the idea that the pathological state of strong oscillations is probably linked to pathologically
strong intranetwork connections (Fig. 20.10c). An ideal stimulation protocol should thus
not only interfere with the oscillations but also lead to a rewiring of the network with
weaker connections so that, even when the stimulus is removed, the network does not
immediately fall back into the strong oscillatory mode.
How can we interfere with an ongoing synchronized oscillation? As discussed in Section
20.2, neurons in an oscillatory state can be described by a phase φ. An electric pulse deliv-
ered by an electrode tends to synchronize neurons in the neighborhood of the electrode
by shifting their phases by an amount that depends on the current phase of the neuron. If
several electrode ﬁbers are used in the same network, local groups surrounding the tips of
the ﬁbers can be stimulated at different moments in time. Therefore, the phase within each

20.3 Helping patients
543
t
T
(a)
T
(b)
Fig. 20.12 Coordinated reset stimulation. (a) A population of neurons exhibits synchronous ﬁring
activity with period T (schematic). (b) If subgroups of neurons are stimulated at intervals T/4, the
synchronous oscillation is interrupted ("coordinated reset" of oscillators). The stimulation can be
delivered directly in the population or in one of the nuclei projecting onto it. Schematic, after Tass
(2003).
group is reset by roughly the same amount, but the phase shift varies between groups. Con-
sider a stimulation of four ﬁbers given at a relative interval of T/4 (Fig. 20.12). With such a
stimulation paradigm, the global network synchronization is perturbed by the "coordinated
reset" of the four subpopulations (Tass, 2003). With eight or twenty independent elec-
trode ﬁbers one could spread out the stimulation (and therefore the phases of neuronal
oscillators) even more equally over one period. However, the number four is a reasonable
compromise and bundles of four ﬁbers attached together so as to form one single electrode
device are readily available.
If a single sequence of four "coordinated reset" pulses is given to four electrode ﬁbers,
the network returns, after some transients, to the synchronized oscillation. In order to make
the asynchronous state stable, the network wiring needs to be changed. Hebbian synaptic
plasticity requires neurons to be active. It is therefore important to choose a stimulation
protocol which suppresses synchronous oscillations, but not neuronal activity per se. The
"coordinated reset" fulﬁlls this condition since it does not silence the neural oscillators
but just shifts their phases. Therefore, if the "coordinated reset" stimulation is repeated
again and again, so as to keep network activity in a state of asynchronous ﬁring for a sufﬁ-
ciently long time, we may expect that synaptic plasticity causes a rewiring of the network
connectivity. Once the network is rewired, the stimulus can be removed.
Indeed, when monkeys suffering from Parkinsonian symptoms have received a few
hours of DBS with the "coordinated reset" protocol, symptoms are reduced and remain
at a reduced level for more than 24 hours (Fig. 20.13b), before they slowly drift back into
the oscillatory state (Tass et al., 2012b). The beneﬁcial effects of "coordinated reset" stim-
ulation therefore last at least 10 times longer than those of traditional DBS where tremor
reappears rapidly.
From the perspective of dynamical systems, these results suggest that the healthy state
of Parkinsonian patients is not globally stable. However, since the "ruins" (see Chapter 4)

544
Outlook: dynamics in plastic networks
300
(a)
200
Long-lasting after-effect
*
*
*
*
*
#
#
#
100
0
MPTP
Acute after-effect
day 1-5
day 6-10
day 11-15
day 16-20
day 21-25
day 26-30
day 31-35
day 35-40
h
p
f (x)
x
dx
dt
Network state
(b)
Fig. 20.13 Long-lasting plasticity effects. (a) Behavioral performance (vertical) of monkeys suf-
fering from Parkinsonian symptoms before ("MPTP") and after treatment with coordinated reset
stimulation. Stimulation led to an improvement of behavior that persisted for many days after the
end of stimulation. From Tass et al. (2012b) with permission from IOS Press. (b) Dynamical systems
interpretation: In contrast to Fig. 20.11b, the healthy state h of MPTP monkeys is either not a ﬁxed
point at all (solid line) or a marginally stable one (dashed line), but in both cases the ﬂow in the
vicinity of the healthy state (gray area) is slowed down, so that the return to the pathological state
takes some time.
of the ﬁxed point corresponding to healthy asynchronous activity persist, a shift of the
network into the neighborhood of the healthy state leads to a slow down of the dynamics
so that the network remains for a long time in the neighborhood of the healthy condition
(Fig. 20.13c).
Traditional protocols of DBS have been found by trial and error. The standard protocol
consists of continuous high-frequency stimulation (>100 Hz) at rather large amplitude
(Benabid et al., 1991). Remarkably, the mathematical perspective provided by the theory
of dynamical systems together with intensive computational modeling (Tass, 2003; Rubin
and Terman, 2004; Wilson et al., 2011; Pﬁster and Tass, 2010) has now led to protocols
that work with reduced amplitude and do not require continuous stimulation. Instead, only
a few hours of stimulation per day promise to sufﬁce (Tass et al., 2012b). Eventually,
we may hope that these or related (Rosin et al., 2011) protocols will be translated from
monkeys to humans and increase the quality of life of patients suffering from severe forms
of Parkinson's disease. Interestingly, the "coordinated reset" protocol has already found a
ﬁrst successful application in humans suffering from tinnitus (Tass et al., 2012a).
20.4 Summary
Reservoir computing uses the rich dynamics of randomly connected networks as a rep-
resentation on which online computation can be performed. Inhibitory synaptic plasticity
may tune networks into a state of detailed balance where strong excitation is counterbal-

20.4 Summary
545
anced by strong inhibition. The resulting network patterns exhibit similarities with cortical
data.
Oscillations are present in multiple brain areas, and at various frequencies. Oscillations
in networks of coupled model neurons can be mathematically characterized as an instability
of the stationary state of irregular ﬁring (see Chapters 13 and 14) or as a stable limit cycle
where all neurons ﬁre in synchrony. The stability of perfectly synchronized oscillation
is clariﬁed by the locking theorem: a synchronous oscillation is stable if the spikes are
triggered during the rising phase of the input potential, which is the summed contribution
of all presynaptic neurons. Stable synchronous oscillations can occur for a wide range of
parameters and for both excitatory and inhibitory couplings.
Phase models describe neurons in the oscillatory state. If a stimulus is given while the
neuron is at a certain phase, its phase shifts by an amount predicted by the phase response
curves and the size of the stimulus.
Oscillatory activity has been linked to numerous brain diseases, in particular Parkin-
son's. Modern protocols of DBS aim at exploiting the interaction between phase response
curves, oscillations, and synaptic plasticity so as to reduce the motor symptoms of Parkin-
son's disease.
Literature
The potential computational use of the rich network dynamics of randomly connected net-
works has been emphasized in the framework of "liquid computing" (Maass et al., 2002)
and "echo state networks" (Jaeger and Haas, 2004). The network dynamics can be inﬂu-
enced by a variety of optimization algorithms (Jaeger and Haas, 2004; Maass et al., 2007;
Sussillo and Abbott, 2009; Hoerzer et al., 2012) and the resulting networks can be analyzed
with principles from dynamical systems (Ganguli et al., 2008; Sussillo and Barak, 2013).
The theory of random neural networks has been developed around the eigenvalue spectrum
of connectivity matrices (Rajan and Abbott, 2006) and the notion of chaos (Sompolinksy
et al., 1988).
Synchronization is a traditional topic of applied mathematics (Winfree, 1980; Kuramoto,
1984). For pulse-coupled units, synchronization phenomena in pulse-coupled units have
been widely studied in a non-neuronal context, such as the synchronous ﬂashing of tropi-
cal ﬁreﬂies (Buck and Buck, 1976), which triggered a whole series of theoretical papers on
synchronization of pulse-coupled oscillators (see, e.g., Mirollo and Strogatz, 1990). The
locking theorem (Gerstner et al., 1996b) is formulated for SRM neurons which cover a
large class of neuronal ﬁring patterns and includes the leaky integrate-and-ﬁre model as a
special case (see Chapter 6). The more traditional mathematical theories are typically for-
mulated in the phase picture (Winfree, 1980; Kuramoto, 1984; Pikovsky and Rosenblum,
2007) and have found ample applications in the mathematical neurosciences (Gutkin et al.,
2005; Canavier, 2006).
Oscillations in the visual system and the role of synchrony for feature binding have
been reviewed by Singer (1993, 2007). Oscillations in sensory systems have been reviewed

546
Outlook: dynamics in plastic networks
by Ritz and Sejnowski (1997) and, speciﬁcally in the context of the olfactory system, by
Laurent (1996), and the hippocampus by O'Keefe and Recce (1993) and Buzsaki (2011).
For oscillations in EEG, see Bazhenov and Timofeev (2006).
The classic work on DBS is Benabid et al. (1991). The interplay between mathematical
theories of neuronal dynamics and DBS is highlighted in the papers of Rubin and Terman
(2004), Wilson et al. (2011), Pﬁster and Tass (2010), and Tass (2003).

References
Abbott, L. (1994) Decoding neuronal ﬁring and modeling neural networks. Quart. Rev.
Biophys., 27:291-331.
Abbott, L. F. (1991) Realistic synaptic inputs for model neural networks. Network, 2:
245-258.
Abbott, L. F. and Kepler, T. B. (1990) Model neurons: from Hodgkin-Huxley to Hopﬁeld.
In Garrido, L., ed., Statistical Mechanics of Neural Networks, pp. 5-18. Springer,
Berlin.
Abbott, L. F. and Nelson, S. B. (2000) Synaptic plastictiy - taming the beast. Nature Neu-
rosci., 3:1178-1183.
Abbott, L. F. and van Vreeswijk, C. (1993) Asynchronous states in a network of pulse-
coupled oscillators. Phys. Rev. E, 48:1483-1490.
Abbott, L. F., Fahri, E., and Gutmann, S. (1991) The path integral for dendritic trees. Biol.
Cybern., 66:49-60.
Abeles, M. (1991) Corticonics. Cambridge University Press, Cambridge.
Acebron, J., Bonilla, L., Perez Vicente, C., Ritort, F., and Spigler, R. (2005) The Kuramoto
model: A simple paradigm for synchronization phenomena. Rev. Mod. Phys., 77:
137-185.
Adrian, E. D. (1926) The impulses produced by sensory nerve endings. J. Physiol. (Lond.),
61:49-72.
Ahmadian, Y., Packer, A. M., Yuste, R., and Paninski, L. (2011a) Designing optimal stimuli
to control neuronal spike timing. J. Neurophys., 106(2):1038-1053.
Ahmadian, Y., Pillow, J., and Paninski, L. (2011b) Efﬁcient Markov Chain Monte Carlo
methods for decoding population spike trains. Neural Comput., 1(23):46-96.
Ahrens, M., Paninski, L., and Sahani, M. (2008) Inferring input nonlinearities in neural
encoding models. Network, 19:35-67.
Aizenman, C. and Linden, D. (1999) Regulation of the rebound depolarization and spon-
taneous ﬁring patterns of deep nuclear neurons in slices of rat cerebellum. J. Neuro-
physiol., 82:1697-1709.
Albright, T., Desimone, R., and Gross, C. (1984) Columnar organization of directionally
selective cells in visual area MT of the macaque. J. Neurophysiol., 51:16-31.
Amari, S. (1972) Characteristics of random nets of analog neuron-like elements. IEEE
Trans. Syst. Man. Cyber., 2:643-657.
Amari, S. (1974) A method of statistical neurodynamics. Kybernetik, 14:201-215.
Amari, S. (1977) A mathematical foundation of statistical neurodynamics. SIAM J. Appl.
Math., 33:95-126.
Amit, D. J. (1989) Modeling Brain Function: The World of Attractor Neural Networks.
Cambridge University Press, Cambridge.

548
References
Amit, D. J. and Brunel, N. (1997a) Dynamics of a recurrent network of spiking neurons
before and following learning. Network, 8:373-404.
Amit, D. J. and Brunel, N. (1997b) A model of spontaneous activity and local delay activity
during delay periods in the cerebral cortex. Cerebral Cortex, 7:237-252.
Amit, D. J., Gutfreund, H., and Sompolinsky, H. (1985) Storing inﬁnite numbers of patterns
in a spin-glass model of neural networks. Phys. Rev. Lett., 55:1530-1533.
Amit, D. J., Gutfreund, H., and Sompolinsky, H. (1987a) Information storage in neural
networks with low levels of activity. Phys. Rev. A, 35:2293-2303.
Amit, D. J., Gutfreund, H., and Sompolinsky, H. (1987b) Statistical mechanics of neural
networks near saturation. Ann. Phys. (NY), 173:30-67.
Amit, D. J. and Tsodyks, M. V. (1991) Quantitative study of attractor neural networks
retrieving at low spike rates. 1: Substrate — spikes, rates, and neuronal gain. Network,
2:259-273.
Anderson, J. A. (1972) A simple neural network generating an interactive memory. Math.
Biosci., 14:197-220.
Anderson, J. A. and Rosenfeld, E., eds (1988) Neurocomputing: Foundations of Research.
MIT Press, Cambridge, MA.
Angelucci, A. and Bressloff, P. (2006) Contribution of feedforward, lateral and feedback
connections to the classical receptive ﬁeld center and extra-classical receptive ﬁeld
surround of primate v1 neurons. Prog. Brain Res., 154:93-120.
Aracri, P., Colombo, E., Mantegazza, M., et al. (2006) Layer-speciﬁc properties of the
persistent sodium current in sensorimotor cortex. J. Neurophysiol., 95(6):3460-3468.
Artola, A. and Singer, W. (1993) Long-term depression of excitatory synaptic transmission
and its relationship to long-term potentiation. Trends Neurosci., 16(11):480-487.
Artola, A., Br¨ocher, S., and Singer, W. (1990) Different voltage dependent thresholds for
inducing long-term depression and long-term potentiation in slices of rat visual cortex.
Nature, 347:69-72.
Atkinson, K. (1997) The Numerical Solution of Integral Equations of the Second Kind,
Vol. 4. Cambridge University Press, Cambridge.
Avery, R. B. and Johnston, D. (1996) Multiple channel types contribute to the low-voltage-
activated calcium current in hippocampal CA3 pyramidal neurons. J. Neurosci,
16(18):5567-82.
Aviel, Y. and Gerstner, W. (2006) From spiking neurons to rate models: a cascade model
as an approximation to spiking neuron models with refractoriness. Phys. Rev. E,
73:51908.
Badel, L., Lefort, S., Berger, T., Petersen, C., Gerstner, W., and Richardson, M.
(2008a) Extracting non-linear integrate-and-ﬁre models from experimental data using
dynamic I-V curves. Biol. Cybernetics, 99(4-5):361-370.
Badel, L., Lefort, S., Brette, R., Petersen, C., Gerstner, W., and Richardson, M. (2008b)
Dynamic I-V curves are reliable predictors of naturalistic pyramidal-neuron voltage
traces. J. Neurophysiol, 99:656-666.
Bair, W. and Koch, C. (1996) Temporal precision of spike trains in extrastriate cortex of
the behaving macaque monekey. Neural Comput., 8:1185-1202.
Bair, W., Koch, C., Newsome, W., and Britten, K. (1994) Power spectrum analysis of MT
neurons in the behaving monkey. J. Neurosci., 14:2870-2892.
Balaguer-Ballester, E., Lapish, C., Seamans, J., and Durstewitz, D. (2011) Dynamics of
frontal cortex ensembles during memory-guided decision-making. PLOS Comput.
Biol., 7:e1002057.

References
549
Baras, D. and Meir, R. (2007) Reinforcement learning, spike-time-dependent plasticity,
and the BCM rule. Neural Comput., 19(8):2245-2279.
Barbieri, F. and Brunel, N. (2008) Can attractor network models account for the statistics
of ﬁring during persistent activity in prefrontal cortex? Front. Neurosci., 2:114-122.
Bauer, H. U. and Pawelzik, K. (1993) Alternating oscillatory and stochastic dynamics in a
model for a neuronal assembly. Physica D, 69:380-393.
Bazhenov, M. and Timofeev, I. (2006) Thalamocortical oscillations. Scholarpedia, 1:1319.
Bell, C., Han, V., Sugawara, Y., and Grant, K. (1997) Synaptic plasticity in a cerebellum-
like structure depends on temporal order. Nature, 387:278-281.
Ben Arous, G. and Guionnet, A. (1995) Large deviations for Langevin spin glass dynamics.
Prob. Theory Rel. Fields, 102:455-509.
Ben-Yishai, R., Bar-Or, R., and Sompolinsky, H. (1995) Theory of orientation tuning in
visual cortex. Proc. Natl. Acad. Sci. USA, 92:3844-3848.
Benabid, A., Chabardes, S., Mitrofanis, J., and Pollak, P. (2009) Deep brain stimulation
of the subthalamic nucleus for the treatment of Parkinson's disease. Lancet Neurol.,
8:67-81.
Benabid, A., Pollak, P., et al. (1991) Long-term suppression of tremor by chronic stimula-
tion of the ventral intermediate thalamic nucleus. Lancet, 337:403-406.
Benda, J. and Herz, A. V. M. (2003) A universal model for spike-frequency adaptation.
Neural Comput., 15(11):2523-2564.
Berger, T. K., Perin, R., Silberberg, G., and Markram, H. (2009) Frequency-dependent
disynaptic inhibition in the pyramidal network: a ubiquitous pathway in the develop-
ing rat neocortex. J. Physiol., 587(22):5411-5425.
Bernander, ¨O., Douglas, R. J., Martin, K. A. C., and Koch, C. (1991) Synaptic background
activity inﬂuences spatiotemporal integration in single pyramidal cells. Proc. Natl.
Acad. Sci. USA, 88:11569-11573.
Berry, M. and Meister, M. (1998) Refractoriness and neural precision. J. Neurosci.,
18:2200-2211.
Berry, M. J., Warland, D. K., and Meister, M. (1997) The structure and precision of retinal
spike trains. Proc. Natl. Acad. Sci. USA, 94:5411-5416.
Bi, G. and Poo, M. (1998) Synaptic modiﬁcations in cultured hippocampal neurons: depen-
dence on spike timing, synaptic strength, and postsynaptic cell type. J. Neurosci.,
18:10464-10472.
Bi, G. and Poo, M. (1999) Distributed synaptic modiﬁcation in neural networks induced
by patterned stimulation. Nature, 401:792-796.
Bi, G. and Poo, M. (2001) Synaptic modiﬁcation of correlated activity: Hebb's postulate
revisited. Ann. Rev. Neurosci., 24:139-166.
Bi, G.-Q. (2002) Spatiotemporal speciﬁcity of synaptic plasticity: cellular rules and mech-
anisms. Biol. Cybernetics, 87(5-6):319-332.
Bialek, W., Rieke, F., de Ruyter van Stevenick, R. R., and Warland, D. (1991) Reading a
neural code. Science, 252:1854-1857.
Bienenstock, E., Cooper, L., and Munroe, P. (1982) Theory of the development of neuron
selectivity: orientation speciﬁcity and binocular interaction in visual cortex. J. Neu-
rosci., 2:32-48.
Binczak, S., Eilbeck, J., and Scott, A. C. (2001) Ephaptic coupling of myelinated nerve
ﬁbers. Physica D, 148(1):159-174.
Bliss, T. V. P. and Collingridge, G. L. (1993) A synaptic model of memory: long-term
potentiation in the hippocampus. Nature, 361:31-39.

550
References
Bogacz, R., Brown, E., Moehlis, J., Holmes, P., and Cohen, J. (2006) The physics of opti-
mal decision making: a formal analysis of models of performance in two-alternative
forced-choice tasks. Psychol. Rev., 113:700-765.
Bonhoeffer, T. and Grinvald, A. (1991) Iso-orientation domains in cat visual cortex are
arranged in pinwheel-like patterns. Nature, 353:429-431.
Bower, J. M. and Beeman, D. (1995) The Book of Genesis. Springer, New York.
Brass, M. and Haggard, P. (2007) To do or not to do: the neural signature of self-control.
J. Neurosci., 27:9141-9145.
Bressloff, P. C. and Cowan, J. D. (2002) The visual cortex as a crystal. Physica D:
Nonlinear Phenomena, 173(3-4):226-258.
Bressloff, P. C. and Taylor, J. G. (1994) Dynamics of compartmental model neurons.
Neural Networks, 7:1153-1165.
Brette, R. and Gerstner, W. (2005) Adaptive exponential integrate-and-ﬁre model as an
effective description of neuronal activity. J. Neurophysiol., 94:3637-3642.
Brette, R., Rudolph, M., et al. (2007) Simulation of networks of spiking neurons: a review
of tools and strategies. J. Comput. Neurosci., 23(3):349-398.
Brillinger, D. R. (1988) Maximum likelihood analysis of spike trains of interacting nerve
cells. Biol. Cybern., 59:189-200.
Brillinger, D. R. (1992) Nerve cell spike train data analysis: a progression of techniques. J.
Am. Stat. Assoc., 87:260-271.
Brockwell, A., Rojas, A., and Kass, R. (2004) Recursive Bayesian decoding of motor cor-
tical signals by particle ﬁltering. J. Neurophysiol., 91(4):1899-1907.
Brockwell, A., Kass, R. E., and Schwartz, A. (2007) Statistical signal processing and the
motor cortex. Proc. IEEE, 95(5):881-898.
Brown, E., Barbieri, R., Ventura, V., Kass, R., and Frank, L. (2002) The time-rescaling
theorem and its application to neural spike train data analysis. Neural Comput., 14:
325-346.
Brown, E., Frank, L., Tang, D., Quirk, M., and Wilson, M. (1998) A statistical paradigm
for neural spike train decoding applied to position prediction from ensemble ﬁring
patterns of rat hippocampal place cells. J. Neurosci., 18:7411-7425.
Brown, T. H., Ganong, A. H., Kairiss, E. W., Keenan, C. L., and Kelso, S. R. (1989) Long-
term potentation in two synaptic systems of the hippocampal brain slice. In Byrne, J.
and Berry, W., eds, Neural Models of Plasticity, pp. 266-306. Academic Press, San
Diego, CA.
Brown, T. H., Zador, A. M., Mainen, Z. F., and Claiborne, B. J. (1991) Hebbian modiﬁca-
tions in hippocampal neurons. In Baudry, M. and Davis, J., eds, Long-term Potentia-
tion, pp. 357-389. MIT Press, Cambridge, MA.
Brunel, N. (2000) Dynamics of sparsely connected networks of excitatory and inhibitory
neurons. Comput. Neurosci., 8:183-208.
Brunel, N., Chance, F., Fourcaud, N., and Abbott, L. (2001) Effects of synaptic noise
and ﬁltering on the frequency response of spiking neurons. Phys. Rev. Lett., 86:
2186-2189.
Brunel, N. and Hakim, V. (1999) Fast global oscillations in networks of integrate-and-ﬁre
neurons with low ﬁring rates. Neural Comput., 11:1621-1671.
Bryant, H. L. and Segundo, J. P. (1976) Spike initiation by transmembrane current: a white
noise analysis. J. Physiol., 260:279-314.
Buck, J. and Buck, E. (1976) Synchronous ﬁreﬂies. Scientiﬁc American, 234:74-85.

References
551
Bugmann, G., Christodoulou, C., and Taylor, J. G. (1997) Role of temporal integration and
ﬂuctuation detection in the highly irregular ﬁring of a leaky integrator neuron model
with partial reset. Neural Comput., 9:985-1000.
Burkitt, A. N. and Clark, G. M. (1999) Analysis of integrate-and-ﬁre neurons: synchro-
nization of synaptic input and spike output. Neural Comput., 11:871-901.
Bussgang, J. J. (1952) Cross-correlation function of amplitude-distorted Gaussian signals.
In Tech. Rep. 216, Research Lab. Electronics, Institute of Technology, Cambridge,
MA.
Buzsaki, G. (2011) Hippocampus. Scholarpedia, 6:1468.
Calvin, W. and Stevens, C. (1968) Synaptic noise and other sources of randomness in
motoneuron interspike intervals. J. Neurophysiol., 31:574-587.
Canavier, C. (2006) Phase response curve. Scholarpedia, 1:1332.
Capocelli, R. M. and Ricciardi, L. M. (1971) Diffusion approximation and ﬁrst passage
time problem for a neuron model. Kybernetik, 8:214-223.
Caporale, N. and Dan, Y. (2008) Spike timing-dependent plasticity: a Hebbian learning
rule. Ann. Rev. Neurosci., 31:25-46.
Carnevale, N. and Hines, M. (2006) The Neuron Book. Cambridge University Press,
Cambridge.
Cessac, B. (2008) A discrete time neural network model with spiking neurons: rigorous
results on the spontaneous dynamics. J. Math. Biol., 56:311-345.
Cessac, B., Doyon, B., Quoy, M., and Samuleides, M. (1994) Mean-ﬁeld equations, bifur-
cation map and route to chaos in discrete time neural networks. Physica D, 74:24-44.
Chacron, M., Longtin, A., St-Hilaire, M., and Maler, L. (2000) Suprathreshold stochas-
tic ﬁring dynamics with memory in P-type electroreceptors. Phys. Rev. Lett., 85:
1576-1579.
Chichilnisky, E. J. (2001) A simple white noise analysis of neuronal light responses.
Network, 12:199-213.
Chornoboy, E., Schramm, L., and Karr, A. (1988) Maximum likelihood identiﬁcation of
neural point process systems. Biol. Cybernetics, 59:265-275.
Chow, C. C. (1998) Phase-locking in weakly heterogeneous neuronal networks. Physica
D, 118:343-370.
Chow, C. C. and White, J. (1996) Spontaneous action potential ﬂuctuations due to channel
ﬂuctuations. Biophys. J., 71:3013-3021.
Churchland, M., Cunningham, J., Kaufman, et al. (2012) Neural population dynamics dur-
ing reaching. Nature, 487:51-56.
Clopath, C., Busing, L., Vasilaki, E., and Gerstner, W. (2010) Connectivity reﬂects cod-
ing: A model of voltage-based spike-timing-dependent-plasticity with homeostasis.
Nature Neurosci., 13:344-352.
Cohen, M. A. and Grossberg, S. (1983) Absolute stability of global pattern formation
and parallel memory storage by competitive neural networks. IEEE Trans. Sys. Man
Cybernetics, 13:815-823.
Collins, J., Chow, C., Capela, A., and Imhoff, T. (1996) Aperiodic stochastic resonance.
Phy. Rev. E, 54:5575-5584.
Connors, B. W. and Gutnick, M. J. (1990) Intrinsic ﬁring patterns of diverse cortical
neurons. Trends Neurosci., 13:99-104.
Contreras, D., Destexhe, A., and Steriade, M. (1997) Intracellular and computational char-
acterization of the intracortical inhibitory control of synchronized thalamic inputs in
vivo. J. Neurophysiol., 78(1):335-350.
Cover, T. and Thomas, J. (1991) Elements of Information Theory. Wiley, New York.

552
References
Cox, D. R. (1962) Renewal Theory. Methuen, London.
Cox, D. R. and Lewis, P. A. W. (1966) The Statistical Analysis of Series of Events.
Methuen, London.
Crisanti, A. and Sompolinsky, H. (1988) Dynamics of spin systems with randomly asym-
metric bonds - Ising spins and Glauber dynamics. Phys. Rev. A, 37:4865-4874.
Crochet, S. and Petersen, C. (2006) Correlating whisker behavior with membrane potential
in barrel cortex of awake mice. Nature Neurosci., 9:608-610.
Crochet, S., Poulet, J. F. A., Kremer, Y., and Petersen, C. C. H. (2011) Synaptic mecha-
nisms underlying sparse coding of active touch. Neuron, 69(6):1160-75.
Cullheim, S., Fleshman, J. W., Glenn, L. L., and Burke, R. E. (1987) Membrane area
and dendritic structure in type-identiﬁed triceps surae alpha motoneurons. J. Comp.
Neurol., 255(1):68-81.
Curti, E., Mongillo, G., La Camera, G., and Amit, D. (2004) Mean ﬁeld and capacity
in realistic networks of spiking neurons storing sparsely coded random memories.
Neural Comput., 16:2597-2637.
Dayan, P. and Abbott, L. F. (2001) Theoretical Neuroscience. MIT Press, Cambridge, MA.
de Boer, E. and Kuyper, P. (1968) Triggered correlation. IEEE Trans. Biomed. Enging,
15:169-179.
de Ruyter van Steveninck, R. R. and Bialek, W. (1988) Real-time performance of a
movement-sensitive neuron in the blowﬂy visual system: coding and information
transfer in short spike sequences. Proc. R. Soc. Lond. B, 234:379-414.
de Ruyter van Steveninck, R. R., Lowen, G. D., Strong, S. P., Koberle, R., and Bialek, W.
(1997) Reproducibility and variability in neural spike trains. Science, 275:1805.
Debanne, D., G¨ahwiler, B., and Thompson, S. (1998) Long-term synaptic plasticity
between pairs of individual CA3 pyramidal cells in rat hippocampal slice cultures.
J. Physiol., 507:237-247.
Debanne, D., Campanac, E., Bialowas, A., Carlier, E., and Alcaraz, G. (2011) Axon phys-
iology. Phys. Rev., 91(2):555-602.
deCharms, R. and Merzenich, M. (1996) Primary cortical representation of sounds by the
coordination of action-potential timing. Nature, 381:610-613.
Deco, G., Rolls, E., and Romo, R. (2009) Stochastic dynamics as a principle of brain
function. Progr. Neurobiol., 88:1-16.
Deco, G., Rolls, E., and Romo, R. (2010) Synaptic dynamics and decision-making. Proc.
Natl. Acad. Sci. USA, 107:7545-7549.
Deger, M., Schwalger, T., Naud, R., and Gerstner, W. (2013) Dynamics of interacting ﬁnite-
sized networks of spiking neurons with adaptation. arXiv: 1311.4206.
DeAngelis, G. C., Ohzwaw, I., and Freeman, R. D. (1995) Receptive-ﬁeld dynamics in the
central visual pathways. Trends Neurosci., 18:451-458.
Derrida, B., Gardner, E., and Zippelius, A. (1987) An exactly solvable asymmetric neural
network model. Europhys. Lett., 4:167-173.
Destexhe, A., Contreras, D., Sejnowski, T. J., and Steriade, M. (1994a) A model of spin-
dle rhythmicity in the isolated thalamic reticular nucleus. J. Neurophysiol., 72(2):
803-818.
Destexhe, A., Mainen, Z., and Sejnowski, T. (1994b) Synthesis of models for excitable
membranes, synaptic transmission and neuromodulation using a common kinetic for-
malism. J. Comput. Neurosci., 1:195-230.
Destexhe, A. and Pare, D. (1999) Impact of network activity on the integrative properties
of neocortical pyramidal neurons in vivo. J. Neurophysiol., 81:1531-1547.

References
553
Destexhe, A., Rudolph, M., and Pare, D. (2003) The high-conductance state of neocortical
neurons in vivo. Nature Rev. Neurosci., 4:739-751.
DiMattina, C. and Zhang, K. (2011) Active data collection for efﬁcient estimation and
comparison of nonlinear neural models. Neural Comput., 23(9):2242-88.
Dobson, A. and Barnett, A. (2008) Introduction to Generalized Linear Models, 3rd edn.
Chapman and Hall, London.
Donoghue, J. (2002) Connecting cortex to machines: recent advances in brain interfaces.
Nature Neurosci., 5:1085-1088.
Donoghue, J. P., Sanes, J. N., Hatsopoulos, N. G., and Ga´al, G. (1998) Neural discharge and
local ﬁeld potential oscillations in primate motor cortex during voluntary movements.
J. Neurophys., 79(1):159-173.
Douglass, J., Wilkens, L., Pantazelou, E., and Moss, F. (1993) Noise enhancement of
information transfer in crayﬁsh mechanoreceptors by stochastic resonance. Nature,
365:337-340.
Druckmann, S., Bannitt, Y., Gidon, A. A., Schuermann, F., and Segev, I. (2007) A novel
multiple objective optimization framework for constraining conductance-based neu-
ron models by experimental data. Front Neurosci, 1:1.
Eckhorn, R., Bauer, R., Jordan, W., Brosch, M., Kruse, W., Munk, M., and Reitboeck, H. J.
(1988) Coherent oscillations: a mechanism of feature linking in the visual cortex?
Biol. Cybern., 60:121-130.
Eckhorn, R., Krause, F., and Nelson, J. L. (1993) The RF-cinematogram: a cross-
correlation technique for mapping several visual ﬁelds at once. Biol. Cybern., 69:37-
55.
Eden, U., Truccolo, W., Fellows, M., Donoghue, J., and Brown, E. (2004) Reconstruction
of hand movement trajectories from a dynamic ensemble of spiking motor cortical
neurons. In Engineering in Medicine and Biology Society, 2004. IEMBS '04. 26th
Annual International Conference of the IEEE, Vol. 2, pp. 4017-4020. IEEE.
Edwards, B. and Wakeﬁeld, G. H. (1993) The spectral shaping of neural discharges by
refractory effects. J. Acoust. Soc. Am., 93:3553-3564.
Eggermont, J. J., Aertsen, A. M., and Johannesma, P. I. (1983) Quantitative characterisation
procedure for auditory neurons based on the spectro-temporal receptive ﬁeld. Hearing
Res., 10(2):167-90.
Ermentrout, G. B. (1996) Type I membranes, phase resetting curves, and synchrony.
Neural Comput., 8(5):979-1001.
Ermentrout, G. B. and Kopell, N. (1984) Frequency plateaus in a chain of weakly coupled
oscillators. SIAM J. Math. Anal., 15:215-237.
Ermentrout, G. B. and Kopell, N. (1986) Parabolic bursting in an excitable system coupled
with a slow oscillation. SIAM J. Appl. Math., 46:233-253.
Erneux, T. and Nicolis, G. (1993) Propagating waves in discrete bistable reaction-diffusion
systems. Physica D, 67(1):237-244.
Ernst, U., Pawelzik, K., and Geisel, T. (1995) Synchronization induced by temporal delays
in pulse-coupled oscillators. Phys. Rev. Lett., 74:1570-1573.
Erwin, E., Obermayer, K., and Schulten, K. (1995) Models of orientation and ocular domi-
nance columns in the visual cortex: a critcal comparison. Neural Comput., 7:425-468.
Faisal, A., Selen, L., and Wolpert, D. (2008) Noise in the nervous system. Nat. Rev. Neu-
rosci., 9:202.
Faugeras, O., Touboul, J., and Cessac, B. (2009) A constructive mean-ﬁeld analysis of
multi-population neural networks with random synaptic weights and stochastic inputs.
Front. Comput. Neurosci., 3:1.

554
References
Feldman, J. L. and Cowan, J. D. (1975) Large-scale activity in neural nets I: Theory with
application to motoneuron pool responses. Biol. Cybern., 17:29-38.
Feng, J. (2001) Is the integrate-and-ﬁre model good enough? - a review. Neural Networks,
14:955-975.
Feynman, R. P., Hibbs, A. R., and Styer, D. F. (2010) Quantum Mechanics and Path
Integrals, 2nd edn. Dover, New York.
Fisher, R., van Emde Boas, W., Blume, W., et al. (2005) Epileptic seizures and epilepsy:
deﬁnitions proposed by the International League Against Epilepsy (ILAE) and the
International Bureau for Epilepsy (IBE). Epilepsia, 46:470-472.
Fishman, H. M., Poussart, D. J. M., Moore, L. E., and Siebenga, E. (1977) Conduction
description from the low frequency impedance and admittance of squid axon. J. Mem-
brane Biol., 32:255-290.
FitzHugh, R. (1961) Impulses and physiological states in models of nerve membrane. Bio-
phys. J., 1:445-466.
Fleidervish, I. A., Friedman, A. and Gutnick, M. J. (1996) Slow inactivation of Na+ current
and slow cumulative spike adaptation in mouse and guinea-pig neocortical neurones
in slices. J. Physiol., 493:83-97.
Florian, R. V. (2007) Reinforcement learning through modulation of spike-timing-
dependent synaptic plasticity. Neural Comput., 19:1468-1502.
Fourcaud, N. and Brunel, N. (2002) Dynamics of the ﬁring probability of noisy integrate-
and-ﬁre neurons. Neural Comput., 14:2057-2110.
Fourcaud, N. and Brunel, N. (2005) Dynamics of the instantaneous ﬁring rate in response
to changes in input statistics. J. Comput. Neurosci., 18:311-321.
Fourcaud-Trocme, N., Hansel, D., van Vreeswijk, C., and Brunel, N. (2003) How spike
generation mechanisms determine the neuronal response to ﬂuctuating input. J. Neu-
rosci., 23:11628-11640.
Fremaux, N., Sprekeler, H., and Gerstner, W. (2010) Functional requirements for reward-
modulated spike-timing-dependent plasticity. J. Neurosci., 40:13326-13337.
French, A. and Stein, R. (1970) A ﬂexible neural analog using integrated circuits. IEEE
Trans. Bio-med. Enging., 17(3):248-253.
Froemke, R. and Dan, Y. (2002) Spike-timing dependent plasticity induced by natural spike
trains. Nature, 416:433-438.
Froemke, R. C., Merzenich, M. M., and Schreiner, C. E. (2007) A synaptic memory trace
for cortical receptive ﬁeld plasticity. Nature, 450:425-429.
Froemke, R. C., Tsay, I., Raad, M., Long, J., and Dan, Y. (2006) Contribution of indi-
vidual spikes in burst-induced long-term synaptic modiﬁcation. J. Neurophysiol., 95:
1620-1629.
Fuortes, M. and Mantegazzini, F. (1962) Interpretation of the repetitive ﬁring of nerve cells.
J. Gen. Physiol., 45:1163-1179.
Fusi, S. and Mattia, M. (1999) Collective behavior of networks with linear (VLSI) integrate
and ﬁre neurons. Neural Comput., 11:633-652.
Fuster, J. and Jervey, J. (1982) Neuronal ﬁring in the inferotemporal cortex of the monkey
in a visual memory task. J. Neurosci., 2:361-375.
Gabbiani, F. and Koch, C. (1998) Principles of spike train analysis. In Koch, C. and
Segev, I., eds, Methods in Neuronal Modeling, 2nd edn, pp. 312-360. MIT Press,
Cambridge, MA.
Gabbiani, F., Midtgaard, J., and Knopfel, T. (1994) Synaptic integration in a model of
cerebellar granule cells. J. Neurophys., 72(2):999-1009.

References
555
Gammaitoni, L., H¨anggi, P., Jung, P., and Marchesoni, F. (1998) Stochastic resonance. Rev.
Mod. Phys., 70:223-287.
Ganguli, S., Huch, D., and Sompolinsky, H. (2008) Memory traces in dynamics systems.
Proc. Natl. Acad. Sci. USA, 105:18970-18975.
Gawne, T. J., Richmond, B. J., and Optican, L. M. (1991) Interactive effects among several
stimulus parameters on the response of striate cortical complex cells. J. Neurophys.,
66(2):379-389.
Geisler, C. and Goldberg, J. (1966) A stochastic model of repetitive activity of neurons.
Biophys. J., 6:53-69.
Georgopoulos, A. P., Schwartz, A., and Kettner, R. E. (1986) Neuronal population coding
of movement direction. Science, 233:1416-1419.
Georgopoulos, A., Kettner, R., and Schwartz, A. (1988) Primate motor cortex and free arm
movements to visual targets in three-dimensional space. II. Coding of the direction of
movement by a neuronal population. J. Neurosci., 8:2928-2937.
Gerhard, F., Haslinger, R., and Pipa, G. (2011) Applying the multivariate time-rescaling
theorem to neural population models. Neural Comput., 23:1452-1483.
Gerstein, G. L. and Perkel, D. H. (1972) Mutual temporal relations among neuronal spike
trains. Biophys. J., 12:453-473.
Gerstner, W. (1991) Associative memory in a network of 'biological' neurons. In
Lippmann, R. P., Moody, J. E., and Touretzky, D. S., eds, Advances in Neural
Information Processing Systems 3, pp. 84-90. Morgan Kaufmann, San Mates, CA.
Conference in Denver 1990.
Gerstner, W. (1995) Time structure of the activity in neural network models. Phys. Rev. E,
51(1):738-758.
Gerstner, W. (2000) Population dynamics of spiking neurons: fast transients, asynchronous
states and locking. Neural Comput., 12:43-89.
Gerstner, W. (2008) Spike-response model. Scholarpedia, 3(12):1343.
Gerstner, W. and Brette, R. (2009) Adaptive exponential integrate-and-ﬁre model. Schol-
arpedia, 4:8427.
Gerstner, W. and Kistler, W. K. (2002) Spiking Neuron Models: Single Neurons, Popula-
tions, Plasticity. Cambridge University Press, Cambridge.
Gerstner, W. and van Hemmen, J. L. (1992) Associative memory in a network of 'spiking'
neurons. Network, 3:139-164.
Gerstner, W. and van Hemmen, J. L. (1993) Coherence and incoherence in a globally cou-
pled ensemble of pulse emitting units. Phys. Rev. Lett., 71(3):312-315.
Gerstner, W., Ritz, R., and van Hemmen, J. L. (1993) Why spikes? Hebbian learning and
retrieval of time-resolved excitation patterns. Biol. Cybern., 69:503-515.
Gerstner, W., Kempter, R., van Hemmen, J., and Wagner, H. (1996a) A neuronal learning
rule for sub-millisecond temporal coding. Nature, 383(6595):76-78.
Gerstner, W., van Hemmen, J. L., and Cowan, J. D. (1996b) What matters in neuronal
locking. Neural Comput., 8:1653-1676.
Gigante, G., Mattia, M., and Del Giudice, P. (2007) Diverse population-bursting modes of
adapting spiking neurons. Phys. Rev. Lett., 98:148101.
Gilson, M., Burkitt, A., Grayden, D., Thomas, D., and van Hemmen, J. L. (2009) Emer-
gence of network structure due to spike-timing-dependent plasticity in recurrent neu-
ronal networks IV: Structuring synaptic pathways among recurrent connections. Biol.
Cybern., 27:427-444.

556
References
Giorno, V., Nobile, A. G., and Ricciardi, L. M. (1992) Instantaneous return processes and
neuronal ﬁrings. In Trappl, R., ed., Cybernetics and Systems Research, Vol. 1, pp.
829-236. World Scientiﬁc Press, Hackensack, NJ.
Glimcher, P., Fehr, E., Camerer, C., and Poldrack, R. (2008) Neuroeconomics. Academic
Press, Salt Lake City, UT.
Gluss, B. (1967) A model of neuron ﬁring with exponential decay of potential resulting in
diffusion equations for the probability density. Bull. Math. Biophys., 29:233-243.
Gold, J. and Shadlen, M. (2007) The neural basis of decision making. Ann. Rev. Neurosci.,
30:535-547.
Goldberg, J., Adrian, H., and Smith, F. (1964) Response of neurons of the superior olivary
complex of the cat to acoustic stimuli of long duration. J. Neurophys., 27:706-749.
Golding, N., Mickus, T. J., Katz, Y., Kath, W. L., and Spruston, N. (2005) Factors mediat-
ing powerful voltage attenuation along CA1 pyramidal neuron dendrites. J. Physiol.,
568:69-82.
Gollisch, T. and Meister, M. (2008) Rapid neural coding in the retina with relative spike
latencies. Science, 319:1108-1111.
Golomb, D., Hansel, D., Shraiman, B., and Sompolinsky, H. (1992) Clustering in globally
coupled phase oscillators. Phys. Rev. A, 45:3516-3530.
Golomb, D. and Rinzel, J. (1994) Clustering in globally coupled inhibitory neurons. Phys-
ica D, 72:259-282.
Gray, C. M. and Singer, W. (1989) Stimulus-speciﬁc neuronal oscillations in orientation
columns of cat visual cortex. Proc. Natl. Acad. Sci. USA, 86:1698-1702.
Grossberg, S. (1969) On learning, information, lateral inhibition, and transmitters. Math.
Biosci., 4:255-310.
Grossberg, S. (1973) Contour enhancement, short term memory and constancies in rever-
berating neural networks. Stud. Appl. Math., 52:217-257.
Grossberg, S. (1976) Adaptive pattern classiﬁcation and universal recoding I: Parallel
development and coding of neuronal feature detectors. Biol. Cybern., 23:121-134.
G¨utig, R., Aharonov, S., Rotter, S., and Sompolinsky, H. (2003) Learning input corre-
lations through nonlinear temporally asymmetric Hebbian plasticity. J. Neurosci.,
23(9):3697-3714.
Gutkin, B. S., Ermentrout, G. B., and Reyes, A. D. (2005) Phase-response curves give the
responses of neurons to transient inputs. J. Neurophysiol., 94:1623-1635.
Haggard, P. (2008) Human volition: towards a neuroscience of will. Nat. Rev. Neurosci.,
9:934-946.
Hale, J. K. and Koc¸ac, H. (1991) Dynamics and Bifurcations. Text in Applied Mathemat-
ics 3. Springer, Berlin.
Hamill, O. P., Huguenard, J. R., and Prince, D. A. (1991) Patch-clamp studies of voltage-
gated currents in identiﬁed neurons of the rat cerebral cortex. Cerebral Cortex,
1(1):48-61.
Hansel, D. and Mato, G. (2001) Existence and stability of persistent states in large neuronal
networks. Phys. Rev. Lett., 86:4175-4178.
Hansel, D. and Sompolinsky, H. (1998) Modeling feature selectivity in local cortical cir-
cuits. In Koch, C. and Segev, I., eds, Methods in Neuronal Modeling. MIT Press,
Cambridge, MA.
Hay, E., Hill, S., Sch¨urmann, F., Markram, H., and Segev, I. (2011) Models of neocortical
layer 5b pyramidal cells capturing awide range of dendritic and perisomatic active
properties. PLoS Comput. Biol., 7(7):e1002107.
Haykin, S. (1994) Neural Networks. Prentice Hall, Upper Saddle River, NJ.

References
557
Hebb, D. O. (1949) The Organization of Behavior. Wiley, New York.
Helmchen, F., Konnerth, A., and Yuste, R. (2011) Imaging in Neuroscience: A Laboratory
Manual. Cold Spring Harbor Laboratory Press.
Hennequin, G. (2013) Ampliﬁcation and stability in cortical circuits. Thesis, Ecole
Polytechnique F´ed´erale de Lausanne.
Hennequin, G., Vogels, T., and Gerstner, W. (2014) Optimal control of transient dynamics
in balanced networks supports generation of complex movements. Neuron, to appear.
Herrmann, A. and Gerstner, W. (2001) Noise and the PSTH response to current transients:
I. General theory and application to the integrate-and-ﬁre neuron. J. Comput.
Neurosci., 11:135-151.
Hertz, J., Krogh, A., and Palmer, R. G. (1991) Introduction to the Theory of Neural
Computation. Addison-Wesley, Redwood City, CA.
Herz, A. V. M., Sulzer, B., K¨uhn, R., and van Hemmen, J. L. (1988) The Hebb rule:
Representation of static and dynamic objects in neural nets. Europhys. Lett., 7:
663-669.
Herz, A. V. M., Sulzer, B., K¨uhn, R., and van Hemmen, J. L. (1989) Hebbian learning
reconsidered: Representation of static and dynamic objects in associative neural nets.
Biol. Cybern., 60:457-467.
Hessler, N. A., Shirke, A. M., and Malinow, R. (1993) The probability of transmitter release
at a mammalian central synapse. Nature, 366:569-572.
Hill, A. (1936) Excitation and accommodation in nerve. Proc. R. Soc. Lond. B, 119:305-
355.
Hille, B. (1992) Ionic Channels of Excitable Membranes. Sinauer, Sunderland.
Hille, B. (2001) Ion Channels of Excitable Membranes, 3rd edn. Sinauer, Sunderland.
Hodgkin, A. L. (1948) The local electric changes associated with repetitive action in a
non-medullated axon. J. Physiol. (Lond.), 107:165-181.
Hodgkin, A. L. and Huxley, A. F. (1952) A quantitative description of membrane current
and its application to conduction and excitation in nerve. J. Physiol, 117(4):500-544.
Hoehn, K., Watson, T. W., and MacVicar, B. A. (1993) A novel tetrodotoxin-insensitive,
slow sodium current in striatal and hippocampal beurons. Neuron, 10(3):543 - 552.
Hoerzer, G., Legenstein, R., and Maass, W. (2012) Emergence of complex computational
structures from chaotic neural networks through reward-modulated Hebbian learning.
Cerebral Cortex, xx:doi:10.1093/cercor/bhs348.
Hopﬁeld, J. J. (1982) Neural networks and physical systems with emergent collective com-
putational abilities. Proc. Natl. Acad. Sci. USA, 79:2554-2558.
Hopﬁeld, J. J. (1984) Neurons with graded response have computational properties like
those of two-state neurons. Proc. Natl. Acad. Sci. USA, 81:3088-3092.
Hoppensteadt, F. C. and Izhikevich, E. M. (1997) Weakly Connected Neural Networks.
Springer, Berlin.
Horn, R. A. and Johnson, C. R. (1985) Matrix Analysis. Cambridge University Press, Cam-
bridge.
Hubel, D. H. (1988) Eye, Brain, and Vision. W. H. Freeman, New York.
Hubel, D. and Wiesel, T. (1968) Receptive ﬁelds and functional architecture of monkey
striate cortex. J. Physiol., 195:215-243.
Hubel, D. H. and Wiesel, T. N. (1962) Receptive ﬁelds, binocular interaction and functional
architecture in the cat's visual cortex. J. Physiol. (Lond.), 160:106-154.
Huguenard, J. R., Hamill, O. P., and Prince, D. A. (1988) Developmental changes in Na+
conductances in rat neocortical neurons: appearance of a slowly inactivating compo-
nent. J. Neurophysiol., 59(3):778-795.

558
References
Hunter, J. D. and Milton, J. G. (2003) Amplitude and frequency dependence of spike tim-
ing: implications for dynamic regulation. J. Neurophysiol., 90(1):387-94.
Huys, Q. J. M., Ahrens, M. B., and Paninski, L. (2006) Efﬁcient estimation of detailed
single-neuron models. J. Neurophysiol., 96(2):872-890.
Itti, L., Koch, C., and Niebur, E. (1998) A model of saliency-based visual attention for
rapid scene analysis. IEEE Trans. Patt. Anal. Mach. Intell., 20:1254-1259.
Izhikevich, E. M. (2003) Simple model of spiking neurons. IEEE Trans. Neural Networks,
14(6):1569-1572.
Izhikevich, E. (2007a) Solving the distal reward problem through linkage of STDP and
dopamine signaling. Cerebral Cortex, 17:2443-2452.
Izhikevich, E. M. (2007b) Dynamical Systems in Neuroscience: The Geometry of Excitabil-
ity and Bursting. MIT Press, Cambridge, MA.
Jackson, J. (1962) Classical Electrodynamics. Wiley, New York.
Jaeger, H. and Haas, H. (2004) Harnessing nonlinearity: Predicting chaotic systems and
saving energy in wireless communication. Science, 304:78-80.
James, W. (1890) Psychology (Briefer Course), Ch. 16. Holt, New York.
Johannesma, P. I. M. (1968) Diffusion models for the stochastic acticity of neurons. In
Caianiello, E. R., ed., Neural Networks, pp. 116-144. Springer, Berlin.
Johansson, R. and Birznieks, I. (2004) First spikes in ensembles of human tactile afferents
code complex spatial ﬁngertip events. Nature Neurosci., 7:170-177.
Jolivet, R., Lewis, T., and Gerstner, W. (2004) Generalized integrate-and-ﬁre models of
neuronal activity approximate spike trains of a detailed model to a high degree of
accuracy. J. Neurophysiol., 92:959-976.
Jolivet, R., Rauch, A., L¨uscher, H.-R., and Gerstner, W. (2006) Predicting spike timing
of neocortical pyramidal neurons by simple threshold models. J. Comput. Neurosci.,
21:35-49.
Jolivet, R., Kobayashi, R., Rauch, A., Shinomoto, S., and Gerstner, W. (2008a) A bench-
mark test for a quantitative assessment of simple neuron models. J. Neurosci.
Methods, 169:417-424.
Jolivet, R., Schurmann, F., Berger, T., Naud, R., Gerstner, W., and Roth, A. (2008b) The
quantitative single-neuron modeling competition. Biol. Cybern., 99:417-426.
Kandel, E. C., Schwartz, J. H., and Jessell, T. (2000) Principles of Neural Science, 4th edn.
Elsevier, New York.
Kaschube, M., Schnabel, M., Lowel, S., Coppola, D., White, L., and Wolf, F. (2010)
Universality in the evolution of orientation columns in the visual cortex. Science,
330:1113-1116.
Kass, R. and Raftery, A. (1995) Bayes factors. J. Am. Stat. Assoc., 90:773-795.
Kass, R. E. and Ventura, V. (2001) A spike-train probability model. Neural Comput.,
13:1713-1720.
Keat, J., Reinagel, P., Reid, R., and Meister, M. (2001) Predicting every spike: A model for
the responses of visual neurons. Neuron, 30:803-817.
Kempter, R., Gerstner, W., van Hemmen, J. L., and Wagner, H. (1998) Extracting oscilla-
tions: Neuronal coincidence detection with noisy periodic spike input. Neural Com-
put., 10:1987-2017.
Kempter, R., Gerstner, W., and van Hemmen, J. L. (1999a) Hebbian learning and spiking
neurons. Phys. Rev. E, 59:4498-4514.
Kempter, R., Gerstner, W., van Hemmen, J. L., and Wagner, H. (1999b) The quality of
coincidence detection and ITD-tuning: a theoretical framework. In Dau, T., Hohmann,

References
559
V., and Kollmeier, B., eds, Psychophysics, Physiology and Models of Hearing, pp.
185-192. World Scientiﬁc, Singapore.
Kempter, R., Gerstner, W., and van Hemmen, J. L. (2001) Intrinsic stabilization of output
rates by spike-based Hebbian learning. Neural Comput., 13:2709-2741.
Kepler, T. B., Abbott, L. F., and Marder, E. (1992) Reduction of conductance-based neuron
models. Biol. Cybern., 66:381-387.
Kistler, W. M. and De Zeeuw, C. I. (2002) Dynamical working memory and timed
responses: The role of reverberating loops in the olivo-cerebellar system. Neural Com-
put., 14(11):2597-2626.
Kistler, W. M. and van Hemmen, J. L. (2000) Modeling synaptic plasticity in conjunction
with the timing of pre- and postsynaptic potentials. Neural Comput., 12:385-405.
Kistler, W. M., Gerstner, W., and van Hemmen, J. L. (1997) Reduction of Hodgkin-Huxley
equations to a single-variable threshold model. Neural Comput., 9:1015-1045.
Klausberger, T. and Somogyi, P. (2008) Neuronal diversity and temporal dynamics: The
unity of hippocampal circuit operations. Science, 321:53-57.
Knight, B. W. (1972) Dynamics of encoding in a population of neurons. J. Gen. Physiol.,
59:734-766.
Knight, B. W. (2000) Dynamics of encoding in neuron populations: some general mathe-
matical features. Neural Comput., 12:473-518.
Kobayashi, R. and Shinomoto, S. (2007) State space method for predicting the spike times
of a neuron. Phys. Rev. E, 75(1):011925.
Kobayashi, R., Tsubo, Y., and Shinomoto, S. (2009) Made-to-order spiking neuron model
equipped with a multi-timescale adaptive threshold. Front. Comput. Neurosci., 3:9.
Koch, C. (1999) Biophysics of Computation. Oxford University Press, Oxford.
Koch, C., Bernander, ¨O., and Douglas, R. (1995) Do neurons have a voltage or a current
threshold for action potential initiation? J. Comput. Neurosci., 2:63-82.
Kohonen, T. (1972) Correlation matrix memories. IEEE Trans. Comp., C-21:353-359.
Kohonen, T. (1984) Self-Organization and Associative Memory. Springer-Verlag, Berlin.
Kole, M. H. P., Hallermann, S., and Stuart, G. J. (2006) Single Ih channels in pyramidal
neuron dendrites: properties, distribution, and impact on action potential output. J.
Neurosci., 26(6):1677-1687.
K¨onig, P., Engel, A. K., and Singer, W. (1996) Integrator or coincidence detector? The role
of the cortical neuron revisited. Trends Neurosci., 19(4):130-137.
Konishi, M. (1993) Listening with two ears. Scientiﬁc American, 268:34-41.
Kopell, N. (1986) Symmetry and phase locking in chains of weakly coupled oscillators.
Comm. Pure Appl. Math., 39:623-660.
Korngreen, A. and Sakmann, B. (2000) Voltage-gated K+ channels in layer 5 neocorti-
cal pyramidal neurones from young rats: subtypes and gradients. J. Physiol., 525(3):
621-639.
Koyama, S., Castellanos P´erez-Bolde, L., Shalizi, C. R., and Kass, R. E. (2010) Approxi-
mate methods for state-space models. J. Am. Stat. Assoc., 105(489):170-180.
Kree, R. and Zippelius, A. (1991) Asymmetrically diluted neural networks. In Domany,
E., van Hemmen, J., and Schulten, K., eds, Models of Neural Networks, pp. 193-212.
Springer, Berlin.
Kreuz, T., Haas, J., Morelli, A., Abarbanel, H., and Politi, A. (2007) Measuring spike train
synchrony. J. Neurosci. Methods, 165(1):151-161.
Kreuz, T., Chicharro, D., Andrzejak, R. G., Haas, J. S., and Abarbanel, H. D. I. (2009)
Measuring multiple spike train synchrony. J. Neurosci. Methods, 183(2):287-99.

560
References
Kulkarni, J. E. and Paninski, L. (2007) Common-input models for multiple neural spike-
train data. Network: Comp. in Neural Sys., 18(4):375-407.
Kuramoto, Y. (1984) Chemical Oscillations, Waves, and Turbulence. Springer, Berlin.
Laing, C. R. and Chow, C. C. (2001) Stationary bumps in a network of spiking neurons.
Neural Comput., 13:1473-1494.
Lansky, P. (1984) On approximations of Stein's neuronal model. J. Theor. Biol., 107:
631-647.
Lansky, P. (1997) Sources of periodical force in noisy integrate-and-ﬁre models of
neuronal dynamics. Phys. Rev. E, 55:2040-2043.
Lansky, P. and Lanska, V. (1987) Diffusion approximation of the neuronal model with
synaptic reversal potentials. Biol. Cybern., 56:19-26.
Lapicque, L. (1907) Recherches quantitatives sur l'excitation electrique des nerfs trait´ee
comme une polarization. J. Physiol. Pathol. Gen., 9:620-635. Cited in H. C. Tuckwell,
Introduction to Theoretic Neurobiology (Cambridge University Press, Cambridge,
1988).
Larkum, M. and Nevian, T. (2008) Synaptic clustering by dendritic signalling mechanisms.
Curr. Opinion Neurobiol., 18:321-331.
Larkum, M., Zhu, J., and Sakmann, B. (2001) Dendritic mechanisms underlying the cou-
pling of the dendritic with the axonal action potential initiation zone of adult rat layer
5 pyramidal neurons. J. Physiol. (Lond.), 533:447-466.
Latham, P. E., Richmond, B., Nelson, P., and Nirenberg, S. (2000) Intrinsic dynamics in
neuronal networks. I. Theory. J. Neurophysiol., 83:808-827.
Laurent, G. (1996) Dynamical representation of odors by oscillating and evolving neural
assemblies. Trends Neurosci., 19:489-496.
Lefort, S., Tomm, C., Sarria, J., and Petersen, C. (2009) The excitatory neuronal network of
the C2 barrel column in mouse primary somatosensory cortex. Neuron, 61:301-316.
Legenstein, R., Pecevski, D., and Maass, W. (2008) A learning theory for reward-
modulated spike-timing-dependent plasticity with application to biofeedback. PLOS
Comput. Biol., 4:e1000180.
Levy, W. B. and Stewart, D. (1983) Temporal contiguity requirements for long-term asso-
ciative potentiation/depression in hippocampus. Neurosci., 8:791-797.
Lewi, J., Butera, R., and Paninski, L. (2009) Sequential optimal design of neurophysiology
experiments. Neural Comput., 21:619-687.
Libet, B. (1985) Unconscious cerebral initiative and the role of conscious will in voluntary
action. Behav. Brain Sci., 8:529-566.
Lindner, B. and Schimansky-Geier, L. (2001) Transmission of noise coded versus additive
signals through a neuronal ensemble. Phys. Rev. Lett., 86:2934-2937.
Lindner, B., Doiron, B., and Longtin, A. (2005) Theory of oscillatory ﬁring induced by spa-
tially correlated noise and delayed inhibitory feedback. Phys. Rev. E, 72(6):061919.
Linsker, R. (1986) From basic network principles to neural architecture: emergence of
spatial-opponent cells. Proc. Natl. Acad. Sci. USA, 83:7508-7512.
Linz, P. (1985) Analytical and Numerical Methods for Volterra Equations, Vol. 7. SIAM,
Philadelphia, PA.
Lisman, J. (2003) Long-term potentiation: outstanding questions and attempted synthesis.
Phil. Trans. R. Soc. Lond. B, 358:829-842.
Lisman, J., Schulman, H., and Cline, H. (2002) The molecular basis of CaMKII function
in synaptic and behavioural memory. Nat. Rev. Neurosci., 3:175-190.
Little, W. A. (1974) The existence of persistent states in the brain. Math. Biosc., 19:
101-120.

References
561
Liu, Y.-H. and Wang, X.-J. (2001) Spike-frequency adaptation of a generalized leaky
integrate-and-ﬁre model neuron. J. Comput. Neurosci., 10:25-45.
Loewenstein, Y. (2008) Robustness of learning that is based on covariance-driven synaptic
plasticity. PLOS Comput. Biol., 4:e1000007.
Loewenstein, Y. and Seung, H. (2006) Operant matching is a generic outcome of synaptic
plasticity based on the covariance between reward and neural activity. Proc. Natl.
Acad. Sci. USA, 103:15224-15229.
Longtin, A. (1993) Stochastic resonance in neuron models. J. Stat. Phys., 70:309-327.
Lubenov, E. and Siapas, A. G. (2008) Decoupling through synchrony in neuronal circuits
with propagation delays. Neuron, 58:118-131.
Lund, J., Angelucci, A., and Bressloff, P. (2003) Anatomical substrates for functional
columns in macaque monkey primary visual cortex. Cerebral Cortex, 12:15-24.
Lundstrom, B., Higgs, M., Spain, W., and Fairhall, A. (2008) Fractional differentiation by
neocortical pyramidal neurons. Nature Neurosci., 11:1335-1342.
Maass, W., Joshi, P., and Sontag, E. (2007) Computational aspects of feedback in neural
circuits. PLOS Comput. Biol., 3:e165.
Maass, W., Natschl¨ager, T., and Markram, H. (2002) Real-time computing without sta-
ble states: a new framework for neural computation based on perturbations. Neural
Comput., 14:2531-2560.
Mach, E. (1865) ¨Uber die Wirkung der r¨aumlichen Verteilung des Lichtreizes auf die
Netzhaut. Sitz. -Ber. Akad. Wiss. Wien, 52:303-322.
Mach, E. (1906) Die Analyse der Empﬁndungen, 5th edn, Chapter X. Gustav Fischer, Jena,
www.uni-leipzig.de/ psycho/wundt/opera/mach/empfndng/AlysEmIn.htm.
Machens, C. (2002) Adaptive sampling by information maximization. Phys. Rev. Lett.,
88:228104-228107.
Machens, C., Romo, R., and Brody, C. (2005) Flexible control of mutual inhibition: a
neuron model of two-interval discrimination. Science, 307:1121-1124.
Mackay, D. (1992) Information-based objective functions for active data selection. Neural
Comput., 4:589-603.
MacKay, D. J. C. and Miller, K. D. (1990) Analysis of Linsker's application of Hebbian
rules to linear networks. Network, 1:257-297.
MacPherson, J. M. and Aldridge, J. W. (1979) A quantitative method of computer analysis
of spike train data collected from behaving animals. Brain Res., 175(1):183-7.
MacLeod, C. M. (1991) Half a century of research on the Stroop effect: An integrative
review. Psych. Bull., 109:163-203.
Magee, J. C. (1998) Dendritic hyperpolarization-activated currents modify the integrative
properties of hippocampal CA1 pyramidal neurons. J. Neurosci., 18(19):7613-7624.
Mainen, Z. F., Joerges, J., Huguenard, J. R., and Sejnowski, T. J. (1995) A model of spike
initiation in neocortical pyramidal neurons. Neuron, 15(6):1427-1439.
Mainen, Z. F. and Sejnowski, T. J. (1995) Reliability of spike timing in neocortical neurons.
Science, 268:1503-1506.
Mainen, Z. F. and Sejnowski, T. J. (1996) Inﬂuence of dendritic structure on ﬁring pattern
in model neocortical neurons. Nature, 382:363-366.
Makram, H., Sjostrom, J., and Gerstner, W. (2011) A history of spike-timing dependent
plasticity. Front. Syn. Neurosci., 3:4.
Manwani, A. and Koch, C. (1999) Detecting and estimating signals in noisy cable struc-
tures, I: Neuronal noise sources. Neural Comput., 11:1797-1829.
Markram, H. and Tsodyks, M. (1996) Redistribution of synaptic efﬁcacy between neocor-
tical pyramidal neurons. Nature, 382:807-810.

562
References
Markram, H., L¨ubke, J., Frotscher, M., and Sakmann, B. (1997) Regulation of synaptic
efﬁcacy by coincidence of postysnaptic AP and EPSP. Science, 275:213-215.
Markram, H., Toledo-Rodriguez, M., Wang, Y., Gupta, A., Silberberg, G., and Wu, C.
(2004) Interneurons of the neocortical inhibitory system. Nature Rev. Neurosci.,
5:793-807.
Marsalek, P., Koch, C., and Maunsell, J. (1997) On the relationship between synaptic input
and spike output jitter in individual neurons. Proc. Natl. Acad. Sci. USA, 94:735-740.
Mascaro, M. and Amit, D. J. (1999) Effective neural response function for collective
population states. Network, 10:351-373.
Mauro, A., Conti, F., Dodge, F., and Schor, R. (1970) Subthreshold behavior and phe-
nomenological impedance of the squid giant axon. J. Gen. Physiol., 55(4):497-523.
McCormick, D. A., Wang, Z., and Huguenard, J. (1993) Neurotransmitter control of neo-
cortical neuronal activity and excitability. Cereb. Cortex, 3(5):387-398.
McCulloch, W. S. and Pitts, W. (1943) A logical calculus of ideas immanent in nervous
activity. Bull. Math. Biophys., 5:115-133.
McNamara, B. and Wiesenfeld, K. (1989) Theory of stochastic resonance. Phys. Rev. A,
39:4854-4869.
Mel, B. W. (1994) Information processing in dendritic trees. Neural Comput., 6:
1031-1085.
Mensi, S., Naud, R., and Gerstner, W. (2011) From stochastic nonlinear integrate-and-
ﬁre to generalized linear models. In Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira,
F., and Weinberger, K., eds, Advances in Neural Information Processing System 24,
p. 0794.
Mensi, S., Naud, R., Avermann, M., Petersen, C. C. H., and Gerstner, W. (2012) Parameter
extraction and classiﬁcation of three neuron types reveals two different adaptation
mechanisms. J. Neurophys., 107:1756-1775.
Mensi, S., Pozzorini, C., Hagens, O., and Gerstner, W. (2013) Evidence for a nonlin-
ear coupling between ﬁring threshold and subthreshold membrane potential. Cosyne
Abstracts, Salt Lake City, UT.
Meyer, C. and van Vreeswijk, C. (2002) Temporal correlations in stochastic networks of
spiking neurons. Neural Comput., 14:369-404.
Miller, E. and Cohen, J. (2001) An integrative theory of prefrontal cortex function. Ann.
Rev. Neurosci., 24:167-202.
Miller, K. and Fumarola, F. (2012) Mathematical equivalence of two common forms of
ﬁring rate models of neural networks. Neural Comput., 24:25-31.
Miller, K., Keller, J. B., and Stryker, M. P. (1989) Ocular dominance column development:
analysis and simulation. Science, 245:605-615.
Miller, K. D. (1994) A model for the development of simple cell receptive ﬁelds and the
ordered arrangement of orientation columns through activity dependent competition
between ON- and OFF-center inputs. J. Neurosci., 14:409-441.
Miller, K. D. and MacKay, D. J. C. (1994) The role of constraints in Hebbian learning.
Neural Comput., 6:100-126.
Miller, M. I. and Mark, K. (1992) A statistical study of cochlear nerve discharge patterns
in reponse to complex speech stimuli. J. Acoust. Soc. Am., 92:202-209.
Mirollo, R. E. and Strogatz, S. H. (1990) Synchronization of pulse coupled biological
oscillators. SIAM J. Appl. Math., 50:1645-1662.
Miyashita, Y. (1988a) Neuronal correlate of visual associative long-term memory in the
primate temporal cortex. Nature, 335:817-820.

References
563
Miyashita, Y. (1988b) Neuronal correlate of visual associative long-term memory in the
primate temporal cortex. Nature, 335(6193):817-820.
Mongillo, G., Barak, O., and Tsodyks, M. (2008) Synaptic theory of working memory.
Science, 319:1543-1546.
Moreno-Bote, R. and Parga, N. (2004) Role of synaptic ﬁltering on the ﬁring response of
simple model neurons. Phys. Rev. Lett., 92:28102.
Morris, C. and Lecar, H. (1981) Voltage oscillations in the barnacle giant muscle ﬁber.
Biophys. J., 35:193-213.
Morrison, A., Diesmann, M., and Gerstner, W. (2008) Phenomenological models of synap-
tic plasticity based on spike timing. Biol. Cybern., 98:459-478.
Mountcastle, V. B. (1957) Modality and topographic properties of single neurons of cat's
somatosensory cortex. J. Neurophysiol., 20:408-434.
Murray, J. D. (1993) Mathematical Biology, 2nd edn. Biomathematics Texts 19. Springer-
Verlag, Berlin.
Nagumo, J., Arimoto, S., and Yoshizawa, S. (1962) An active pulse transmission line sim-
ulating nerve axon. Proc. IRE, 50:2061-2070.
Naud, R. and Gerstner, W. (2012a) Coding and decoding in adapting neurons: A population
approach to the peri-stimulus time histogram. PLoS Comput. Biol., 8:e1002711.
Naud, R. and Gerstner, W. (2012b) The performance (and limits) of simple neuron mod-
els: Generalizations of the leaky integrate-and-ﬁre model. In Le Nov`ere, N. L., ed.,
Computational Systems Neurobiology. Springer, Berlin.
Naud, R., Marcille, N., Clopath, C., and Gerstner, W. (2008) Firing patterns in the adaptive
exponential integrate-and-ﬁre model. Biol. Cybernetics, 99:335-347.
Naud, R., Gerhard, F., Mensi, S., and Gerstner, W. (2011) Improved similarity measures
for small sets of spike trains. Neural Comput., 23:3016-3069.
Nelder, J. and Wederburn, R. (1972) Generalized linear models. J. R. Stat. Soc. A, 135:370-
384.
Nelken, I., Prut, Y., Vaadia, E., and Abeles, M. (1994) In search of the best stimulus: an
optimization procedure for ﬁnding efﬁcient stimuli in the cat auditory cortex. Hearing
Res., 72:237-253.
Nelson, M. and Rinzel, J. (1995) The Hodgkin-Huxley model. In Bower, J. M. and Beeman,
D., ed, The Book of Genesis, Chapter 4, pp. 27-51. Springer, New York.
Newsome, W., Britten, K., and Movshon, J. (1989) Neuronal correlates of a perceptual
decision. Nature, 341:52-54.
Ngezahayo, A., Schachner, M., and Artola, A. (2000) Synaptic activation modulates the
induction of bidirectional synaptic changes in adult mouse hippocampus. J. Neurosci.,
20:2451-2458.
Nini, A., Feingold, A., Slovin, H., and Bergman, H. (1995) Neurons in the globus pallidus
do not show correlated activity in the normal monkey, but phase-locked oscillations
appear in the MPTP model of parkinsonism. J. Neurophysiol., 74:1800-1805.
N¨utzel, K. (1991) The length of attractors in asymmetric random neural networks with
deterministic dynamics. J. Phys. A., 24:L151-L157.
Nykamp, D. and Tranchina, D. (2000) A population density approach that facilitates large-
scale modeling of neural networks: Analysis and application to orientation tuning. J.
Comput. Neurosci., 8:19-50.
Oja, E. (1982) A simpliﬁed neuron model as a principal component analyzer. J. Math.
Biol., 15:267-273.
O'Keefe, J. and Recce, M. (1993) Phase relationship between hippocampal place units and
the hippocampal theta rhythm. Hippocampus, 3:317-330.

564
References
Okun, M. and Lampl, I. (2008) Instantaneous correlation of excitation and inhibition during
ongoing and sensory-evoked activities. Nat. Neurosci., 11:535-537.
Omurtag, A., Knight, B., and Sirovich, L. (2000) On the simulation of a large population
of neurons. J. Comput. Neurosci., 8:51-63.
Optican, L. M. and Richmond, B. J. (1987) Temporal encoding of two-dimensional patterns
by single units in primate inferior temporal cortex. 3. Information theoretic analysis.
J. Neurophysiol., 57:162-178.
Ostojic, S. and Brunel, N. (2011) From spiking neuron models to linear-nonlinear models.
PLOS Comput. Biol., 7:e1001056.
Ozeki, H., Finn, I., Schaffer, E., Miller, K., and Ferstner, D. (2009) Inhibitory stabilization
of the cortical network underlies visual surround suppression. Neuron, 62:587-592.
Paiva, A. R. C., Park, I., and Pr´ıncipe, J. (2009a) A comparison of binless spike train
measures. Neural Comp. Appl., 19(3):1-15.
Paiva, A. R. C., Park, I., and Pr´ıncipe, J. (2009b) A reproducing kernel hilbert space frame-
work for spike train signal processing. Neural Comput., 21(2):424-449.
Paiva, A. R. C., Park, I., and Pr´ıncipe, J. (2010) Inner products for representation and
learning in the spike train domain. In Oweiss, K. G., ed., Statistical Signal Processing
for Neuroscience and Neurotechnology. Academic Press, New York.
Paninski, L. (2003) Convergence properties of three spike-triggered analysis techniques.
Network, 14:437-464.
Paninski, L. (2004) Maximum likelihood estimation of cascade point-process neural
encoding models. Network, 15:243-262.
Paninski, L. (2005) Asymptotic theory of information-theoretic experimental design. Neu-
ral Comput., 17:1480-1507.
Paninski, L., Fellows, M., Shoham, S., Hatsopoulos, N., and Donoghue, J. (2004) Super-
linear population encoding of dynamic hand trajectory in primary motor cortex. J.
Neurosci., 24:8551-8561.
Paninski, L., Pillow, J., and Lewi, J. (2007) Statistical models for neural encoding, decod-
ing, and optimal stimulus design. In Cisek, P., Drew, T., and Kalaska, J., eds, Com-
putational Neuroscience: Theoretical Insights into Brain Function, Progress in Brain
Research, 165, pp. 493-508. Elsevier Science, Amsterdam.
Paninski, L., Ahmadian, Y., Ferreira, D. G., Koyama, S., Rad, K. R., Vidne, M., Vogelstein,
J., and Wu, W. (2010) A new look at state-space models for neural data. J. Comput.
Neurosci., 29(1-2):107-126.
Paninski, L., Pillow, J., and Simoncelli, E. (2005) Comparing integrate-and-ﬁre-like mod-
els estimated using intracellular and extracellular data. Neurocomputing, 65:379-385.
Papoulis, A. (1991) Probability, Random Variables, and Stochastic Processes. McGraw-
Hill, New York.
Pare, D., Curro'Dossi, R., and Steriade, M. (1990) Neuronal basis of the parkinso-
nian resting tremor: A hypothesis and its implications for treatment. Neurosci., 35:
217-226.
Park, I., Seth, S., Rao, M., and Principe, J. (2012) Strictly positive-deﬁnite spike train
kernels for point-process divergences. Neural Comput., 24(8):2223-2250.
Patlak, J. and Ortiz, M. (1985) Slow currents through single sodium channels of the adult
rat heart. J. Gen. Phys., 86(1):89-104.
Pawlak, V. and Kerr, J. (2008) Dopamine receptor activation is required for corticostriatal
spike-timing-dependent plasticity. J. Neurosci., 28:2435-2446.
Pawlak, V., Wickens, J., Kirkwood, A., and Kerr, J. (2010) Timing is not everything:
neuromodulation opens the STDP gate. Front. Synaptic Neurosci., 2:146.

References
565
Perkel, D. H., Gerstein, G. L., and Moore, G. P. (1967a) Neuronal spike trains and stochas-
tic point processes I. The single spike train. Biophys. J., 7:391-418.
Perkel, D. H., Gerstein, G. L., and Moore, G. P. (1967b) Neuronal spike trains and stochas-
tic point processes II. Simultaneous spike trains. Biophys. J., 7:419-440.
Pﬁster, J.-P. and Gerstner, W. (2006) Triplets of spikes in a model of spike timing-
dependent plasticity. J. Neurosci., 26:9673-9682.
Pﬁster, J.-P. and Tass, P. (2010) STDP in oscillatory recurrent networks: Theoretical condi-
tions for desynchronization and applications to deep brain stimulation. Front. Comput.
Neurosci., 4:22.
Pﬁster, J.-P., Toyoizumi, T., Barber, D., and Gerstner, W. (2006) Optimal spike-timing
dependent plasticity for precise action potential ﬁring in supervised learning. Neural
Comput., 18:1318-1348.
Pikovsky, A. and Rosenblum, M. (2007) Synchronization. Scholarpedia, 2:1459.
Pillow, J., Paninski, L., Uzzell, V., Simoncelli, E., and E. J. Chichilnisky (2005) Prediction
and decoding of retinal ganglion cell responses with a probabilistic spiking model. J.
Neurosci., 25:11003-11023.
Pillow, J., Shlens, J., Paninski, L., Sher, A., Litke, A. M., Chichilnisky, E. J., and
Simoncelli, E. (2008) Spatio-temporal correlations and visual signalling in a com-
plete neuronal population. Nature, 454:995-999.
Pillow, J. W., Ahmadian, Y., and Paninski, L. (2011) Model-based decoding, informa-
tion estimation, and change-point detection techniques for multineuron spike trains.
Neural Comput., 23(1):1-45.
Platt, M. and Huettel, S. (2008) Risky business: the neuroeconomics of decision making
under uncertainty. Nat. Neurosci., 11:398-403.
Plesser, H. (1999) Aspects of Signal Processing in Noisy Neurons. PhD thesis, Georg-
August-Universit¨at, G¨ottingen.
Plesser, H. E. (2000) The ModUhl software collection. Technical report, MPI f¨ur
Str¨omungsforschung, G¨ottingen. www.chaos.gwgd.de/plesser/ModUhl.htm.
Plesser, H. E. and Gerstner, W. (2000) Noise in integrate-and-ﬁre models: from stochastic
input to escape rates. Neural Comput., 12:367-384.
Plesser, H. E. and Tanaka, S. (1997) Stochastic resonance in a model neuron with reset.
Phys. Lett. A, 225:228-234.
Pozzorini, C., Naud, R., Mensi, S., and Gerstner, W. (2013) Temporal whitening by power-
law adaptation in neocortical neurons. Nature Neurosci., 16:942-948.
Prinz, W. (2004) Der Mensch ist nicht frei. Ein Gespr¨ach. In Geyer, C., ed., Hirnforschung
und Willensfreiheit. Suhrkamp, Frankfurt.
Purves, D., Augustine, G. J., Fitzpatrick, D., Hall, W. C., LaMantia, A.-S., and White, L. E.
(2008) Neuroscience, 4th edn. Sinauer, Sunderland, MA.
Quiroga, R. Q., Kreuz, T., and Grassberger, P. (2002) Event synchronization: A simple
and fast method to measure synchronicity and time delay patterns. Phys. Rev. E,
66(4):041904.
Quiroga, R. Q., Reddy, L., Kreiman, G., Koch, C., and Fried, I. (2005) Invariant visual
representation by single neurons in the human brain. Nature, 435:1102-1107.
Rainer, G. and Miller, E. (2002) Timecourse of object-related neural activity in the
primate prefrontal cortex during a short-term memory task. Europ. J. Neurosci., 15:
1244-1254.
Rajan, K. and Abbott, L. (2006) Eigenvalue spectra of random matrices for neural net-
works. Phys. Rev. Lett., 97:188104.

566
References
Rall, W. (1989) Cable theory for dendritic neurons. In Koch, C. and Segev, I., eds.,
Methods in Neuronal Modeling, pp. 9-62. MIT Press, Cambridge, MA.
Ramirez, A. D., Ahmadian, Y., Schumacher, J., Schneider, D., Woolley, S. M. N., and
Paninski, L. (2011) Incorporating naturalistic correlation structure improves spec-
trogram reconstruction from neuronal activity in the songbird auditory midbrain. J.
Neurosci., 31(10):3828-3842.
Ram`on y Cajal, S. (1909) Histologie du syst`eme nerveux de l'homme et des vert´ebr´e. A.
Maloine, Paris.
Randall, A. D. and Tsien, R. W. (1997) Contrasting biophysical and pharmacological prop-
erties of T-type and R-type calcium channels. Neuropharmacology, 36(7):879-93.
Rangel, A., Camerer, C., and Montague, P. (2008) A framework for studying the neurobi-
ology of value-based decision making. Nat. Rev. Neurosci., 9:545-556.
Ranjan, R., Khazen, G., Gambazzi, L., Ramaswamy, S., Hill, S. L., Sch¨urmann, F., and
Markram, H. (2011) Channelpedia: an integrative and interactive database for ion
channels. Front. Neuroinform., 5:36.
Rapp, M., Yarom, Y., and Segev, I. (1994) Physiology, morphology and detailed passive
models of guinea-pig cerebellar Purkinje cells. J. Physiol., 474:101-118.
Ratcliff, R. and McKoon, G. (2008) The diffusion decision model: theory and data for
two-choice decision tasks. Neural Comput., 20:873-922.
Ratcliff, R. and Rouder, J. (1998) Modeling response times for two-choice decisions.
Psychol. Sci., 9:347-356.
Ratnam, R. and Nelson, M. (2000) Nonrenewal statistics of electrosensory afferent spike
trains: Implications for the detection of weak sensory signals. J. Neurosci, 10:
6672-6683.
Redish, A., Elga, A., and Touretzky, D. (1996) A coupled attractor model of the rodent
head direction system. Network, 7:671-685.
Reich, D., Victor, J., and Knight, B. (1998) The power ratio and the interval map: spiking
models and extracellular recordings. J. Neurosci., 18(23):10090-10104.
Renart, A., de la Rocha, J., Hollender, L., Parta, N., Reyes, A., and Harris, K. (2010) The
asynchronous state in cortical circuits. Science, 327:587-590.
Rettig, J., Wunder, F., Stocker, M., et al. (1992) Characterization of a shaw-related potas-
sium channel family in rat brain. EMBO J, 11(7):2473-86.
Reuveni, I., Friedman, A., Amitai, Y., and Gutnick, M. (1993) Stepwise repolarization
from Ca2+ plateaus in neocortical pyramidal cells: evidence for nonhomogeneous
distribution of HVA Ca2+ channels in dendrites. J. Neurosci., 13(11):4609-4621.
Reynolds, J. and Wickens, J. (2002) Dopamine-dependent plasticity of corticostriatal
synapses. Neural Networks, 15:507-521.
Ricciardi, L. (1976) Diffusion approximation for a multi-input neuron model. Biol.
Cybern., 24:237-240.
Richardson, M. (2004) The effects of synaptic conductance on the voltage distribution and
ﬁring rate of spiking neurons. Phys. Rev. E, 69:51918.
Richardson, M. (2007) Firing-rate response of linear and nonlinear integrate-and-ﬁre neu-
rons to modulated current-based and conductance-based synaptic drive. Phys. Rev. E,
76:021919.
Richardson, M. (2009) Dynamics of populations and networks of neurons with voltage-
activated and calcium-activated currents. Phys. Rev. E, 80:021928.
Richardson, M. and Gerstner, W. (2005) Synaptic shot noise and conductance ﬂuctuations
affect the membrane voltage with equal signiﬁcance. Neural Comput., 17:923-947.

References
567
Richardson, M., Brunel, N., and Hakim, V. (2003) From subthreshold to ﬁring-rate reso-
nance. J. Neurophysiol., 89(5):2538-2554.
Rieke, F., Warland, D., de Ruyter van Steveninck, R., and Bialek, W. (1997) Spikes: Explor-
ing the Neural Code. MIT Press, Cambridge, MA.
Rinzel, J. (1985) Excitation dynamics: insights from simpliﬁed membrane models. Theor.
Trends Neurosci., 44(15):2944-2946.
Rinzel, J. and Ermentrout, G. B. (1998) Analysis of neural excitability and oscillations. In
Koch, C. and Segev, I., eds, Methods in Neuronal Modeling, 2nd edn, pp. 251-291.
MIT Press, Cambridge, MA.
Risken, H. (1984) The Fokker Planck Equation: Methods of Solution and Applications.
Springer-Verlag, Berlin.
Ritz, R. and Sejnowski, T. (1997) Synchronous oscillatory activity in sensory systems: new
vistas on mechanisms. Current Opinion Neurobiol., 7:536-546.
Roberts, P. and Bell, C. (2000) Computational consequences of temporally asymmetric
learning rules: II. Sensory image cancellation. Comput. Neurosci., 9:67-83.
Roitman, J. and Shadlen, M. (2002) Response of neurons in the lateral intraparietal
area during a combined visual discrimination reaction time task. J. Neurosci., 22:
9475-9489.
Romo, R. and Salinas, E. (2003) Flutter discrimination: neural codes, perception, memory
and decision making. Nat. Rev. Neurosci., 4:203-218.
Rosin, B., Slovik, M., Mitelman, R., et al. (2011) Closed-loop deep brain stimulation is
superior in ameliorating parkinsonism. Neuron, 72:370-384.
Rospars, J. P. and Lansky, P. (1993) Stochastic model neuron without resetting of dendritic
potential: application to the olfactory system. Biol. Cybern., 69:283-294.
Roxin, A. and Ledberg, A. (2008) Neurobiological models of two-choice decision making
can be reduced to a one-dimensional nonlinear diffusion equation. PLOS Comput.
Biol., 4:e1000046.
Rubin, J., Lee, D. D., and Sompolinsky, H. (2001) Equilibrium properties of temporally
asymmetric Hebbian plasticity. Phys. Rev. Lett., 86:364-367.
Rubin, J. and Terman, D. (2004) High frequency stimulation of the subthalamic nucleus
eliminates pathological thalamic rhythmicity in a computational model. J. Comput.
Neurosci., 16:211-235.
Rust, N., Mante, V., Simoncelli, E., and Movshon, J. (2006) How MT cells analyze the
motion of visual patterns. Nature Neurosci., 11:1421-1431.
Sabah, N. H. and Leibovic, K. N. (1969) Subthreshold oscillatory responses of the
Hodgkin-Huxley cable model for the squid giant axon. Biophys. J., 9(10):1206-1222.
Sahani, M. and Linden, J. (2003) Evidence optimization techniques for estimating
stimulus-response functions. In Advances in Neural Information Processing Systems
15, pp. 301-308. MIT Press, Cambridge, MA.
Sakata, S. and Harris, K. (2009) Laminar structure of spontaneous and sensory-evoked
population activity in auditory cortex. Neuron, 64:298-300.
Salzman, C., Britten, K., and Newsome, W. (1990) Cortical microstimulation inﬂuences
perceptual judgements of motion directions. Nature, 346:174-177.
Sanfey, A. and Chang, L. (2008) Multiple systems in decision making. Ann. NY. Acad. Sci,
1128:53-62.
Schneidman, E., Freedman, B., and Segev, I. (1998) Ion channel stochasticity may be
critical in determining the reliability and precision of spike timing. Neural Comput.,
10:1679-1703.

568
References
Schrauwen, B. and Campenhout, J. (2007) Linking non-binned spike train kernels to
several existing spike train metrics. Neurocomputing, 70(7-9):1247-1253.
Schreiber, S., Fellous, J., Whitmer, D., Tiesinga, P., and Sejnowski, T. J. (2003) A
new correlation-based measure of spike timing reliability. Neurocomputing, 52(54):
925-931.
Schr¨odinger, E. (1915) Zur Theorie der Fall- und Steigversuche and Teilchen mit Brown-
scher Bewegung. Phys. Zeitschrift, 16:289-295.
Schultz, W. (2007) Behavioral dopamine signals. Trends Neurosci., 30(5):203-210.
Schultz, W. (2010) Dopamine signals for reward value and risk: basic and recent data.
Behav. Brain Funct., 6:24.
Schultz, W., Dayan, P., and Montague, R. (1997) A neural substrate for prediction and
reward. Science, 275:1593-1599.
Schwalger, T., Fisch, K., Benda, J., and Lindner, B. (2010) How noisy adaptation in neu-
rons shapes interspike interval histograms and correlations. PLOS Comput. Biol.,
6:e1001026.
Segev, I., Rinzel, J., and Shepherd, G. M. (1994) The Theoretical Foundation of Dendritic
Function. MIT Press, Cambridge, MA.
Sejnowski, T. (1977) Storing covariance with nonlinearly interacting neurons. J. Math.
Biol., 4:303-321.
Sejnowski, T. J. (1999) The book of Hebb. Neuron, 24:773-776.
Sejnowski, T. J. and Tesauro, G. (1989) The Hebb rule for synaptic plasticity: algorithms
and implementations. In Byrne, J. H. and Berry, W. O., eds., Neural Models of Plas-
ticity, Ch. 6, pp. 94-103. Academic Press, Salt Lake City, UT.
Senn, W. (2002) Beyond spike timing: the role of non-linear plasticity and unreliable
synapses. Biol. Cyber., 87:344-355.
Senn, W., Tsodyks, M., and Markram, H. (2001) An algorithm for modifying neurotrans-
mitter release probability based on pre- and postsynaptic spike timing. Neural Com-
put., 13:35-67.
Shadlen, M. N. and Newsome, W. T. (1994) Noise, neural codes and cortical organization.
Current Opinion Neurobiol., 4:569-579.
Shatz, C. (1992) The developing brain. Sci. Am., 267:60-67.
Shenoy, K., Kaufman, M., Sahani, M., and Churchland, M. (2011) A dynamical systems
view of motor preparation: implications for neural prosthetic system design. Progr.
Brain Res., 192:33-58.
Shoham, S. (2001) Advances towards an implantable motor cortical interface. PhD thesis,
University of Utah.
Shriki, O., Hansel, D., and Sompolinsky, H. (2003) Rate models for conductance-based
cortical neuronal networks. Neural Comput., 15:1809-1841.
Siebert, W. M. and Gray, P. R. (1963) Random process model for the ﬁring pattern of
single auditory nerve ﬁbers. Quarterly Progress Report No. 71, Research Laboratory
of Electronics, MIT, pp. 241-245.
Siegert, A. (1951) On the ﬁrst passage time probability problem. Phys. Rev., 81:617-623.
Silberberg, G., Bethge, M., Markram, H., Pawelzik, K., and Tsodyks, M. (2004) Dynam-
ics of population rate codes in ensembles of neocortical neurons. J. Neurophysiol.,
91:704-709.
Simoncelli, E., Paninski, L., Pillow, J., and Schwarz, O. (2004) Characterization of neu-
ral responses with stochastic stimuli. In Gazzaninga, M., ed., The Cognitive Neuro-
sciences, 3rd edn. MIT Press, Cambridge, MA.

References
569
Singer, W. (1993) Synchronization of cortical activity and its putative role in information
processing and learning. Ann. Rev. Physiol., 55:349-374.
Singer, W. (2007) Binding by synchrony. Scholarpedia, 2:1657.
Sirovich, L. and Knight, B. W. (1977) On subthreshold solutions of the Hodgkin-Huxley
equations. Proc. Nat. Acad. Sci., 74(12):5199-5202.
Sj¨ostr¨om, J. and Gerstner, W. (2010) Spike-timing dependent plasticity. Scholarpedia,
5:1362.
Sj¨ostr¨om, P., Turrigiano, G., and Nelson, S. (2001) Rate, timing, and cooperativity jointly
determine cortical synaptic plasticity. Neuron, 32:1149-1164.
Smith, A. and Brown, E. (2003) Estimating a state-space model from point process obser-
vations. Neural Comput., 15:965-991.
Smyth, D., Willmore, B., Baker, G. E., Thompson, I. D., and Tolhurst, D. J. (2003) The
receptive-ﬁeld organization of simple cells in primary visual cortex of ferrets under
natural scene stimulation. J. Neurosci., 23(11):4746-4759.
Softky, W. R. (1995) Simple codes versus efﬁcient codes. Current Opinion Neurobiol.,
5:239-247.
Softky, W. R. and Koch C. (1993) The highly irregular ﬁring pattern of cortical cells is
inconsistent with temporal integration of random EPSPs. J. Neurosci., 13:334-350.
Sompolinsky, H. and Kanter, I. (1986) Temporal association in asymmetric neural net-
works. Phys. Rev. Lett., 57:2861-2864.
Sompolinksy, H., Crisanti, A., and Sommers, H. (1988) Chaos in random neural networks.
Phys. Rev. Lett., 61:259-262.
Song, S., Miller, K., and Abbott, L. (2000) Competitive Hebbian learning through spike-
time-dependent synaptic plasticity. Nature Neurosci., 3:919-926.
Soon, C., Brass, M., Heinze, H., and Haynes, J. (2008) Unconscious determinants of free
decisions in the human brain. Nat. Neurosci., 11:543-545.
Spiridon, M. and Gerstner, W. (2001) Effect of lateral connections on the accuracy of the
population code for a network of spiking neurons. Network, 12(4):409-421.
Spiridon, M., Chow, C., and Gerstner, W. (1998) Frequency spectrum of coupled stochastic
neurons with refractoriness. In Niklasson, L., Bod´en, M., and Ziemke, T., eds, ICANN
98, pp. 337-342. Springer, Berlin.
Srinivasan, L. and Brown, E. N. (2007) A state-space framework for movement control to
dynamic goals through brain-driven interfaces. IEEE Trans. Biomed. Engng., 54(3):
526-535.
Stein, R. B. (1965) A theoretical analysis of neuronal variability. Biophys. J., 5:173-194.
Stein, R. B. (1967a) The information capacity of nerve cells using a frequency code.
Biophys. J., 7:797-826.
Stein, R. B. (1967b) Some models of neuronal variability. Biophys. J., 7:37-68.
Steinmetz, P. N., Roy, A., Fitzgerald, P. J., Hsiao, S. S., Johnson, K., and Niebur, E. (2000)
Attention modulates synchronized neuronal ﬁring in primate somatosensory cortex.
Nature, 404:187-190.
Stevens, C. F. and Zador, A. M. (1998) Novel integrate-and-ﬁre like model of repetitive
ﬁring in cortical neurons. In Proceedings of the 5th Joint Symposium on Neural Com-
putation. Available at: http://cnl.salk.edu/zador/PDF/increpﬁre.pdf.
Strogatz, S. H. (1994) Nonlinear Dynamical Systems and Chaos. Addison Wesley,
Reading, MA.
Stroop, J. (1935) Studies of interference in serial verbal reactions. J. Exp. Psychol., 18:643-
662.

570
References
Stuart, G., Spruston, N., and H¨ausser, M. (2007) Dendrites, 2nd edn. Oxford University
Press, Oxford.
Sussillo, D. and Abbott, L. (2009) Generating coherent patterns of activity from chaotic
neural networks. Neuron, 63: 544-447.
Sussillo, D. and Barak, O. (2013) Opening the black box: Low-dimensional dynamics in
high-dimensional recurrent neural networks. Neural Comput., 25:626-649.
Tass, P. (2003) A model of desynchronizing deep brain stimulation with a demand-
controlled coordinated reset of neural subpopulations. Biol. Cybern., 89:81-88.
Tass, P., Adamchic, I., Freund, H.-J., von Stackelberg, T., and Hauptmann, C. (2012a)
Counteracting tinnitus by acoustic coordinated reset neuromodulation. Restor. Neurol.
Neurosci,, 30:137-159.
Tass, P., Qin, L., et al. (2012b) Coordinated reset has sustained aftereffects in parkinsonian
monkeys. Ann. Neurol., 72:816-820.
Tass, P., Smirnov, D., et al. (2010) The causal relationship between subcortical local ﬁeld
potential oscillations and parkinsonian resting tremor. J. Neur. Eng., 7:016009.
Taube, J. S. and Muller, R. U. (1998) Comparisons of head direction cell activity in the
postsubiculum and anterior thalamus of freely moving rats. Hippocampus, 8:87-108.
Tchumatchenko, T., Malyshev, A., Wolf, F., and Volgushev, M. (2011) Ultrafast population
encoding by cortical neurons. J. Neurosci., 31:12171-12179.
Theunissen, F. and Miller, J. (1995) Temporal encoding in nervous systems: a rigorous
deﬁnition. J. Comput. Neurosci,, 2:149-162.
Thompson, R. F. (1993) The Brain, 2nd edn. W. H. Freeman, New York.
Thorpe, S., Fize, D., and Marlot, C. (1996) Speed of processing in the human visual system.
Nature, 381:520-522.
Tiesinga, P. H. E. (2004) Chaos-induced modulation of reliability boosts output ﬁring rate
in downstream cortical areas. Phys. Rev. E, 69(3 Pt 1):031912.
Toledo-Rodriguez, M., Blumenfeld, B., Wu, C., Luo, J., Attali, B., Goodman, P., and
Markram, H. (2004) Correlation maps allow neuronal electrical properties to be pre-
dicted from single-cell gene expression proﬁles in rat neocortex. Cerebral Cortex,
14:1310-1327.
Touboul, J. (2009) Importance of the cutoff value in the quadratic adaptive integrate-and-
ﬁre model. Neural Comput., 21:2114-2122.
Touboul, J. and Brette, R. (2008) Dynamics and bifurcations of the adaptive exponential
integrate-and-ﬁre model. Biol. Cybernetics, 99:319-334.
Tovee, M. J. and Rolls, E. T. (1995) Information encoding in short ﬁring rate epochs by
single neurons in the primate temporal visual cortex. Visual Cogn., 2(1):35-58.
Traub, R. (2006) Fast oscillations. Scholarpedia, 1:1764.
Treves, A. (1993) Mean-ﬁeld analysis of neuronal spike dynamics. Network, 4:259-284.
Troyer, T. W. and Miller, K. (1997) Physiological gain leads to high ISI variability in a
simple model of a cortical regular spiking cell. Neural Comput., 9:971-983.
Truccolo, W., Eden, U. T., Fellows, M. R., Donoghue, J. P., and Brown, E. N. (2005) A
point process framework for relating neural spiking activity to spiking history, neural
ensemble, and extrinsic covariate effects. J. Neurophysiol., 93(2):1074-1089.
Tsodyks, M. and Feigelman, M. (1986) The enhanced storage capacity in neural networks
with low activity level. Europhys. Lett., 6:101-105.
Tsodyks, M., Mitkov, I., and Sompolinsky, H. (1993) Patterns of synchrony in inhomoge-
neous networks of oscillators with pulse interaction. Phys. Rev. Lett., 71:1281-1283.
Tsodyks, M., Skaggs, W., Sejnowski, T., and McNaughton, B. (1997) Paradoxical effects
of external modulation of inhibitory interneurons. J. Neurosci., 17:4382-4388.

References
571
Tuckwell, H. C. (1988) Introduction to Theoretic Neurobiology. Cambridge University
Press, Cambridge.
Tuckwell, H. C. (1989) Stochastic Processes in the Neurosciences. SIAM, Philadelphia,
PA.
Uhlenbeck, G. E. and Ornstein, L. S. (1930) On the theory of the Brownian motion. Phys.
Rev, 36:823-841.
Uzzell, V. and Chichilnisky, E. (2004) Precision of spike trains in primate retinal ganglion
cells. J. Neurophysiol., 92:780-789.
van Kampen, N. G. (1992) Stochastic Processes in Physics and Chemistry, 2nd edn.
North-Holland, Amsterdam.
van Rossum, M. C. W. (2001) A novel spike distance. Neural Comput., 13:751-763.
van Rossum, M. C. W., Bi, G. Q., and Turrigiano, G. G. (2000) Stable Hebbian learning
from spike timing-dependent plasticity. J. Neurosci., 20:8812-8821.
van Vreeswijk, C. and Sompolinsky, H. (1996) Chaos in neuronal networks with balanced
excitatory and inhibitory activity. Science, 274:1724-1726.
van Vreeswijk, C. and Sompolinsky, H. (1998) Chaotic balanced state in a model of cortical
circuits. Neural Comput., 10:1321-1371.
Victor, J. D. and Purpura, K. (1996) Nature and precision of temporal coding in visual
cortex: a metric-space analysis. J. Neurophysiol., 76(2):1310-1326.
Victor, J. and Purpura, K. (1997) Metric-space analysis of spike trains: theory, algorithms
and application. Network, 8:127-164.
Vidne, M., Ahmadian, Y., Shlens, J. et al. (2012) Modeling the impact of common
noise inputs on the network activity of retinal ganglion cells. J. Comput. Neurosci.,
33(1):97-121.
Vogels, T. P. and Abbott, L. (2005) Signal propagation and logic gating in networks of
integrate-and-ﬁre neurons. J. Neurosci., 25:10786-10795.
Vogels, T. P. and Abbott, L. (2009) Gating multiple signals through detailed balance of
excitation and inhibition in spiking networks. Nature Neurosci., 12:438-491.
Vogels, T., Sprekeler, H., Zenke, F., Clopath, C., and Gerstner, W. (2011) Inhibitory
plasticity balances excitation and inhibition in sensory pathways and memory net-
works. Science, 334:1569-1573.
von der Malsburg, C. (1973) Self-organization of orientation selective cells in the striate
cortex. Kybernetik, 14:85-100.
von der Malsburg, C. (1981) The correlation theory of brain function. Internal Report 81-
2, MPI f¨ur Biophysikalische Chemie, G¨ottingen. Reprinted in Models of Neural Net-
works II, Domany et al. (eds.), Springer, Berlin, 1994, pp. 95-119.
Wang, H.-X., Gerkin, R., Nauen, D., and Wang, G.-Q. (2005) Coactivation and timing-
dependent integration of synaptic potentiation and depression. Nature Neurosci.,
8:187-193.
Wang, X.-J. (2002) Probabilistic decision making by slow reverberation in cortical
circuits. Neuron, 36:955-968.
Wang, Y., Gupta, A., Toledo-Rodriguez, M., Wu, C., and Markram, H. (2002) Anatomical,
physiological, molecular and circuit properties of nest basket cells in the developing
somatosensory cortex. Cerebral Cortex, 12:395-410.
Waxman, S. G. (1980) Determinants of conduction velocity in myelinated nerve ﬁbers.
Musc. Nerve, 3(2):141-150.
Wehmeier, U., Dong, D., Koch, C., and van Essen, D. (1989) Modeling the mammalian
visual system. In Segev, I., ed., Methods in Neuronal Modeling, pp. 335-359. MIT
Press, Cambridge, MA.

572
References
Weiss, T. (1966) A model of the peripheral auditory system. Kybernetik, 3:153-175.
Welsh, J., Lang, E., and Llinas, I. S. (1995) Dynamic organization of motor control within
the olivocerebellar system. Nature, 374:453-457.
Willshaw, D. J., Bunemann, O. P., and Longuet-Higgins, H. C. (1969) Non-holographic
associative memory. Nature, 222:960-962.
Willshaw, D. J. and von der Malsburg, C. (1976) How patterned neuronal connections can
be set up by self-organization. Proc. R. Soc. Lond. B, 194:431-445.
Wilson, C., Beverlin, B., and Netoff, T. (2011) Chaotic desynchronization as the therapeu-
tic mechanism of deep brain stimulation. Front. Syst. Neurosci., 5:50.
Wilson, H. R. and Cowan, J. D. (1972) Excitatory and inhibitory interactions in localized
populations of model neurons. Biophys. J., 12:1-24.
Wilson, H. R. and Cowan, J. D. (1973) A mathematical theory of the functional dynamics
of cortical and thalamic nervous tissue. Kybernetik, 13:55-80.
Wilson, M. A. and McNaughton, B. L. (1993) Dynamics of the hippocampal ensemble
code for space. Science, 261:1055-1058.
Winfree, A. T. (1980) The Geometry of Biological Time. Springer-Verlag, Berlin.
Wiskott, L. and Sejnowski, T. (1998) Constraint optimization for neural map formation:
a unifying framework for weight growth and normalization. Neural Comput., 10:
671-716.
Wolff, L. and Lindner, B. (2011) Mean, variance, and autocorrelation of subthreshold
potential ﬂuctuations driven by ﬁltered conductance shot noise. Neural Comput.,
22:94-120.
Wong, K. and Wang, X. (2006) A recurrent network mechanism of time integration in
perceptual decisions. J. Neurosci., 26:1314-1328.
Woosley, T. A. and Van der Loos, H. (1970) The structural organization of layer IV in the
somatosensory region (SI) of mouse cerebral cortex: The description of a cortical ﬁeld
composed of discrete cytoarchitectonic units. Brain Res., 17:205-242.
Wu, M., David, S., and Gallant, J. (2006) Complete functional characterization of sensory
neurons by system identiﬁcation. Ann. Rev. Neurosci., 29(1):477-505.
Wu, W. and Srivastava, A. (2012) Estimating summary statistics in the spike-train space.
J. Comput. Neurosci., 34(3):391-410.
Yamada, W. M., Koch, C., and Adams, P. R. (1989) Multiple channels and calcium dynam-
ics. In Koch, C. and Segev, I., eds, Methods in Neuronal Modeling. MIT Press,
Cambridge, MA.
Yu, B. M., Cunningham, J. P., Santhanam, G., Ryu, S. I., Shenoy, K. V., and Sahani, M.
(2009) Gaussian-process factor analysis for low-dimensional single-trial analysis of
neural population activity. J. Neurophysiol., 102:614-635.
Zeldovich, Y. B. and Frank-Kamenetskii, D. (1938) Thermal theory of ﬂame propagation.
Zh. Fiz. Khim, 12(1):100-105.
Zhang, J.-C., Lau, P.-M., and Bi, G.-Q. (2009) Gain in sensitivity and loss in temporal
contrast of STDP by dopaminergic modulation at hippocampal synapses. Proc. Natl.
Acad. Sci. USA, 106:13-28-13033.
Zhang, K. (1996) Representaton of spatial orientation by the intrinsic dynamics of the
head-direction ensemble: a theory. J. Neurosci., 16:2112-2126.
Zhang, L., Tao, H., Holt, C., W. A. Harris, and Poo, M.-M. (1998) A critical window
for cooperation and competition among developing retinotectal synapses. Nature,
395:37-44.
Zugaro, M., Arleo, A., Berthoz, A., and Wiener, S. I. (2003) Rapid spatial reorientation
and head direction cells. J. Neurosci., 23(8):3478-3482.

Index
A-current, 48
action potential, 5, 36
channel dynamics, 37
Hodgkin-Huxley model, 37
activity, see population activity
adaptation, 19, 52, 136, 347
biophysical origin, 149, 151
spike-triggered, 136, 149, 151
subthreshold, 136, 149, 152
adaptive integrate-and-ﬁre, 136
parameter space, 148
piecewise linear, 145
AdEx, see adaptive integrate-and-ﬁre
afterpotential, 8, 157
all-to-all coupling, 302
AMPA receptor, 61
Arrhenius & Current model, 237
Arrhenius formula, 237
assembly, neuronal 444
asynchronous ﬁring, 310
stability, 371
asynchronous irregular, 338
attractor network, 454
autocorrelation function, 179
autocorrelation-renewal, 186
axon, 4, 72
myelinated, 74
unmyelinated, 72
balanced excitation and inhibition, 211, 304, 316, 319
Bayesian decoding, 279
Bayesian parameter estimation, 250
Bayesian regularization, 252
BCM rule, 499
bifurcation, 96
Hopf, 101
saddle-node, 97
biophysical neuron model, 43
blobs of activity, 484
Brunel network, 316, 338
bump attractors, 484
bursting, see ﬁring pattern
cable equation, 61
calcium current
low-threshold, 50
calcium spike, 55
calcium-dependent potassium current, 48
close-loop stimulus design, 263
cluster states, 374
coding, 190
correlation code, 195
ﬁring rate, 190
phase code, 194, 530
rate code, 172, 196, 197
timing-based, 192
coefﬁcient of variation, 179
compartmental model, 75
competition, 427
decision making, 428
of populations, 428
of synapses, 499
through common inhibition, 426
through shared inhibition, 427
winner-take-all, 431
competitive network, 430
conductance input, 349
conductance-based neuron model, 32
connectivity
Mexican hat, 470, 475, 480
sparse random, 314
conservation equation, 363
continuity equation, 327
continuum model, 468
of population activity, 470
contrast enhancement, 476
correlation
code, 195
matrix, 513
reverse, 195
cortex, 7, 284, 293, 295, 472
barrel, 295
coupling
full, 302
random, 303

574
Index
covariance matrix, 513
covariance rule, 498
current
pulse, 82
rheobase, 96, 123
step, 84
cut-off frequency, 207
Dale's law, 462
decision making, 421
drift-diffusion model, 435
energy picture, 433
perceptual, 423
decoding, 278
for neuroprosthetics, 283
in vision, 283
deep brain stimulation (DBS), 541
dendrite, 4, 22, 64, 152, 161
compartmental model, 75, 76
dendritic spike, 22, 76
density equation
for membrane potential, 330
for refractory variable, 382
relation with integral equations, 381
depression of synapses, 63
diffusion model, 215, 332
diffusive noise, 404
drift-diffusion model, 435
echo state network, 524
encoding models, 268
escape model, 224
for population, 381
escape noise, 224, 402
escape rate, 224, 225
event-based moment expansion, 388
excitable system, 103
exponential integrate-and-ﬁre, 124
ﬁt to data, 126
f-I plot, 38
facilitation of synapses, 63
ﬁeld equation, 470
blob/bump solution, 484
for hyper column, 479
homogeneous solution, 472
input driven regime, 472
ﬁeld model, 468
ﬁnite-size effects, 391
ﬁring intensity, 225
ﬁring pattern, 136, 137, 140
adapting, 141
bursting, 143, 151, 153, 160
classiﬁcation, 140
facilitating, 141
tonic, 141
transient spike, 148
ﬁring rate, 172, 178, 196
ﬁring regime
asynchronous irregular, 338
synchronous regular, 338
ﬁrst passage time, 219
ﬁrst principal component, 512, 513
FitzHugh-Nagumo model, 88, 103
nullclines, 95
ﬁxed point, 93
ghost, 98
of activity, 368
ﬂow ﬁeld, 92
ﬂux, 327
probability current, 329
drift, 329
jump, 329
refractory, 382
Fokker-Planck equation, 216, 332, 333
linearized, 343
Fourier transform, 17
frequency-current relation, 38
full coupling, 302
gain frequency-dependent, 377, 406, 408
gain function
and population activity, 312
of Hodgkin-Huxley model, 38
of integrate-and-ﬁre model
with noise, 336
type I, 96
type I/II, 38
type II, 96
Gamma distribution, 201
gating variable, 33
Generalized Linear Model (GLM), 248
generative model, 231
ghost of ﬁxed point, 98
GLM (Generalized Linear Model), 248
Green's function, 68
h-current, 52
hazard, 182
Hebb's postulate, 492
Hodgkin-Huxley model, 31
channel opening, 37
gain function, 38
reduction, 149, 151
reduction to two dimensions, 84
refractoriness, 40
Hopf bifurcation, 101
subcritical, 103
supercritical, 103
Hopﬁeld model, 446
energy picture, 456
hyper column, 478
illusion, 469, 476
impulse response, 157

Index
575
inhibition
dominating, 341
effective, 429
shunting, 21
inhibition-stabilized network, 482
inhibitory plasticity, 527
inhibitory rebound, 19, 84
integral equation, 360
adaptive neurons, 413
ﬁnite size, 391
for adaptive neurons, 386
linearized, 375
numerical methods, 365
quasi-renewal, 364
relation with density equations, 381
several populations, 367, 410
stationary state, 368
Wilson-Cowan, 363, 408
integral-equation approach, 357
integrate-and-ﬁre model, 10
as a reduction of Hodgkin-Huxley, 129
exponential IF, 124, 126
nonlinear IF, 121
quadratic IF, 130, 131
refractory exponential IF, 127
multi-compartment, 161
relation to SRM, 163
noisy, 204
nonlinear, 120
quadratic, 129
relation to SRM, 158
two-compartment, 163
interspike interval, 178
interval distribution, 182, 358
for periodic input, 234
input-dependent, 190
ion channel, 31, 42
IA, 48
IM, 48
Ih, 52
IK[Ca], 48
INaP, 51
INaS, 53
Kramers-Moyal expansion, 216
Langevin equation, 204, 217
leaky integrate-and-ﬁre model, 10
learning window, 495
Liapunov function, 434, 456
Libet experiment, 438
likelihood of spike train, 229
limit cycle, 96
linear regression, 246
linear-nonlinear Poisson, 411
linear-nonlinear Poisson Model (LNP), 273
liquid computing, 524
LNP model, see linear-nonlinear Poisson
locking, 532
locking theorem, 532
log-likelihood of a spike train, 230
long-term depression, 491
long-term potentiation, 491, 493
heterosynaptic, 506
homosynaptic, 506
low-connectivity network, 314
LTD, see long-term depression
LTP, see long-term potentiation
M-current, 48
MAP, see maximum a posteriori
Markov Process, 216
matrix random, 527
maximum a posteriori, 280
membrane potential, 7
density, 215, 218, 327
stationary distribution, 334
memory, 442
associative, 442
Hopﬁeld model, 446
retrieval, 451
working memory, 446
Mexican hat, 470
Mexican hat connectivity, 475, 480
Morris-Lecar model, 87, 99
motor cortex, 518
MT neuron, 423
Nernst potential, 29
network, see population
neural mass models, 297
neuron, 3
bursting, 19
postsynaptic, 4
presynaptic, 4
neurotransmitter, 6
NMDA receptor, 61
noise, 168
channel, 171
colored, 206, 351
escape, 224
Gaussian white, 204
Johnson, 170
slow, 400
synaptic, 171
thermal, 170
white, 203
noise model
diffusive noise, 203
escape noise, 224
noisy integration, 203
noisy threshold, 224
random connectivity, 314
stochastic spike arrival, 207

576
Index
noise spectrum, 180
nullclines, 92
Oja's rule, 499
orientation selectivity, model of, 478
Ornstein-Uhlenbeck process, 204, 217
oscillation, 338, 371, 541
as an instability, 371
cluster states, 374
experimental, 529
subthreshold, 40
synchronous locked, 532
overlap, 451
pairing experiment, 494
parameter estimation
Bayesian, 250
decoding, 280
maximum a posteriori (MAP), 280
Parkinson's disease, 541
pattern recognition, 451
with spiking neurons, 458
peri-stimulus-time histogram (PSTH), 175
persistent sodium current, 51
phase code, 194, 530
phase plane, 143, 148
of decision making, 430
phase plane analysis, 91
phase portrait, 92
phase response curve, 537
plasticity
hard bound, 497
of inhibition, 527
soft bound, 498
synaptic short-term, 63
plasticity synaptic, 491
point process, 181
Poisson neuron, 188
Poisson process
absolute refractoriness, 179, 189
autocorrelation, 188
homogeneous, 175
inhomogeneous, 176, 240
population, 177, 295
coupled, 305
fully connected, 302
homogeneous, 298
inhibition dominated, 318
multiple, 336
population activity, 177, 330, 358
asynchronous ﬁring, 310
blobs/bumps of , 484
deﬁnition, 177, 297
ﬁeld equation, 470
linearized, 343
linearized equation, 375, 378
stationary state, 341
time scale, 397
population dynamics, 297
population vector, 192
postsynaptic potential, 8
excitatory, 21
inhibitory, 21
power spectrum, 180
prediction, 267
of membrane potential, 268
of spikes, 270, 272
priming, 442
principal component analysis, 512
principal components, 513
probability current, 329
PSTH, see peri-stimulus-time histogram
pyramidal cell, 76
quasi-steady-state, 85
quasi-renewal theory, 364, 386
random connectivity, 303, 314
random walk, 211
random weight matrix, 527
rate, 172
code, 172
mean ﬁring rate, 173
models, 408
population activity, 177
spike density, 175
rebound spike, 41
rebound, inhibitory, 19, 55, 84
receptive ﬁeld, 7, 273, 293
of MT neurons, 423
reconstruction kernel, 195
refractoriness, 158
refractory density, 381
refractory period, 5
absolute, 5
Hodgkin-Huxley model, 40
regression, linear, 246
regularization, 252
relaxation oscillation, 108
renewal hypothesis, 184
renewal process, 181
renewal theory
for adaptive neurons, 364
time dependent, 232, 233, 358
reservoir computing, 524
resting potential, 7
reversal potential, 21, 30
reverse correlation, 195, 275
rheobase current, 96
ring model, 471, 479
ruins of ﬁxed point, 98
saddle point, 93
scaling behavior, 300
self-averaging, 453

Index
577
separation of time scales, 85, 108
shunting inhibition, 21
signal-to-noise ratio, 180, 239
similarity measure, 262
singular perturbation, 108
slow sodium current, 53
soft threshold, 224
soma, 4
spectral radius, 527
spike, dendritic, 22
spike afterpotential, see afterpotential
spike response model, 154
adaptation, 160
bursting, 160
deﬁnition, 155
interpretation, 157
relation to integrate-and-ﬁre, 158
spike train, 5
distance, 260
irregular, 168
metrics, 260
reliability, 262
variability, 262
vector, 260
spike train decoding
linear, 281
nonlinear, 280
spike-triggered average (STA), 252, 275
spiking neuron model
SRM0, 10
spontaneous activity, 168, 169, 318
STA, see spike-triggered average
stability, 93
stable manifold, 105
stationary state, 368
STDP, 495
protocol, 496
Stein's model, 208
stimulation sub-/superthreshold, 213
stimulus reconstruction
linear, 281
nonlinear, 280
stochastic
differential equation, 204
intensity, 225
process, 203
resonance, 239
STP, see plasticity, synagtic short-term
Stroop effect, 443
subthreshold oscillation, 148
survivor function, 182
synapse, 4, 6, 58
AMPA, 61
depression, 63
excitatory, 61
facilitation, 63
GABAA, 61
GABAB, 61
inhibitory, 60
NMDA, 61
postsynaptic neuron, 4, 6
postsynaptic potential, 8
presynaptic neuron, 4, 6
short-term plasticity, 63
synaptic depression, 64
synaptic plasticity, 491
anti-Hebbian, 495, 497
locality, 496
non-Hebbian, 497
spike-timing dependent, 495
synaptic transmission failures, 171
synchonous regular, 374
synchronization, 541
synchronous regular, 338
synchrony, 195
threshold, 8, 121
dynamics, 155, 156
of Hodgkin-Huxley model, 40, 81
of type I models, 105
of type II models, 108
soft, 224
time-rescaling theorem, 258
transfer function with escape noise, 377
transient spike, 40
type I/II model bifurcations, 96, 97
canonical type I, 106
Hopf bifurcation, 101
onset of oscillations, 96, 103
stable manifold, 105
threshold, 103
visual illusion, 469, 476
Vogels-Abbott network, 319
volition, 438
weight matrix, 527
Wiener-Khinchin theorem, 180
will, see volition
Wilson-Cowan model, 410
ﬁeld equation, 470
winner-take-all, 431
working memory, 446, 484

