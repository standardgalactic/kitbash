Okay, let's really unpack this today.
What if the biggest laws governing the whole universe, the deepest stuff going on in your own mind, and even where society's heading ethically?
What if it's all tied together by like a single really powerful thread?
Today we're taking a deep dive into this pretty extraordinary stack of sources.
Stuff that will challenge how you think about patterns, coherence, you know, the forces shaping basically everything.
Yeah, it's quite a mix.
Right. So our mission is to pull out the most surprising bits, connect these dots between fields that seem totally unrelated, and hopefully help you see things, well, maybe with a fresh perspective.
And here's where it gets really interesting.
So maybe we should start with something people often think of as just decay.
Right.
Entropy.
And things falling apart.
Exactly.
Yeah.
But it's actually way more profound than that.
At its core, entropy is really just about how spread out energy is, how dispersed it becomes.
Okay.
You probably know it from like old steam engines, car knows work.
Even a perfect engine inevitably wastes some energy as heat.
It just spreads out.
Yeah.
You can't get 100% efficiency.
Precisely.
Or, you know, why shattered glass doesn't just decide to reassemble itself.
The energy state is more spread out when it's broken.
That's the universe's tendency.
Okay.
So things naturally want to spread out, become less concentrated.
But then how do you get complex things like us or stars, galaxies?
They seem super organized, low entropy.
Yeah.
That's the key, isn't it?
The Earth, see, it's an open system.
That's crucial.
Meaning energy comes in and goes out.
Exactly.
We get this concentrated, low entropy energy pouring in from the sun constantly.
And then the Earth radiates energy back out into space, but it's dispersed.
High entropy energy.
Heat, basically.
Okay.
So there's a flow.
Right.
And here's a really revolutionary idea from Jeremy England.
He proposes that life, well, life doesn't defy entropy.
It exists because it's incredibly good at increasing it.
Wait, life increases entropy.
How did...
Life being really efficient at taking that concentrated solar energy and dissipating it,
spreading it out faster and more effectively than, say, just a rock would.
He even has this great quote, something like,
if you shine light on a random clump of atoms long enough, it shouldn't be surprising if you get a plant.
Wow.
Okay.
So life isn't fighting the tide.
It's riding the wave, even making the wave bigger.
You could put it that way.
Yeah, it's like life is an engine for entropy.
Yeah.
Finding clever ways to accelerate that energy dispersal, it's a total flip in perspective.
It really is.
And this whole cosmic dance, it's not just about biology.
Yeah.
Think way back to the early universe.
It started out incredibly uniform, right?
Smooth.
Yeah, almost boringly smooth, cosmologically speaking.
Right.
But that uniformity, counterintuitively, was a very low entropy state because gravity, gravity hates uniformity.
It wants to pull things together.
It's inherently unstable in a smooth universe.
Ah, okay.
So the potential for clumping was there.
Exactly.
That low entropy smoothness inevitably led to clumping.
Gravity pulls stuff together, forming stars, galaxies.
Yeah.
Even black holes, which are sometimes called entropy monsters.
Entropy monsters.
Why?
Because they are incredibly efficient at, well, basically maximizing entropy within their event horizon.
But the point is, all this structure emerges because of that initial low entropy state and gravity's pull.
We live in this amazing middle ground.
This temporary pocket of complexity.
Yeah, these beautiful, complex, but ultimately temporary structures like us.
Yeah.
We emerge not despite entropy, but kind of as its engine, as part of the universe's grand project of spreading energy out.
That is mind-bending.
So if this drive towards patterns, towards spreading energy is so fundamental, how does that translate down to something as intricate, as personal, as our own minds, our consciousness?
Well, this whole idea of pattern and coherence, it maps quite directly onto consciousness.
There's fascinating research, for instance, from the Qualia Research Institute, QRI.
QRI, right.
They propose that consciousness isn't just, you know, neuron A firing the neuron B. It's more like it emerges as a global field topology.
A global field topology, like a shape.
Kind of, yeah. Think of it like a unified pattern across the whole brain that is your conscious experience, your sense of self, what it feels like to be you.
Okay.
It's like the music emerging from the whole orchestra, not just the sound of one violin.
And what distinguishes your specific conscious bubble, your you-ness, from everything else might be actual physical electromagnetic looping structures, vortices, maybe, in this field.
Whoa. Actual physical boundaries made of fields.
That's the hypothesis.
Not arbitrary lines, but real topological features, like the edge of a whirlpool.
Okay. So it's less about the individual brain cells and more about the overall pattern they create together.
How does the brain do that?
How does it shape this field?
Right. That's where something they call the coupling kernel comes into play.
Coupling kernel. Okay.
Imagine like a set of invisible control knobs for the whole system.
Think of your brain having all these oscillating units, like millions of tiny metronomes.
Yeah, ticking away.
Right. And they're all on this kind of vibrating table, influencing each other.
The coupling kernel is basically the mathematical rule book.
It says how strongly and in what way each metronome affects the others.
Maybe based on how close they are or if they're in sync or out of sync, you know.
So it dictates the connections, the influence network?
Exactly. It's the set of levers that sculpt the field's overall shape and dynamics.
So by adjusting these levers, the brain can change the whole conscious experience.
Precisely. For instance, think about network structures.
A small world network that's one that has lots of local connections, like neighbors talking to neighbors,
but also a few random long-range connections, like little wormholes across the brain.
Right. I've heard of that structure. Efficient communication.
Yeah. And it turns out that kind of structure, governed by the right coupling kernel,
can dramatically change the global coherence.
It can allow for these really profound integrated experiences where everything feels connected.
And even local things matter.
Yeah.
Like there's this process called divisive normalization,
where a neuron basically adjusts its own output based on what its neighbors are doing.
It takes context into account.
Like turning down the volume if everyone else is shouting.
Sort of, yeah.
Yeah.
And these local processes create these traveling waves of activity.
And these waves then get sort of locked into or entrained by the larger global field modes
via these coupling kernels.
Wow. So local activity feeds into the global pattern through these rules.
Exactly. And what's really mind-blowing, I think,
is that QRI started by looking at phenomenology subjective experience, right?
What does consciousness feel like?
Yeah. A first-person approach.
But their models are now converging with mainstream neuroscience,
which is totally data-driven, third-person.
Researchers like Marco Achiel, Solon Adesoy, Morton Kringleback.
They're using heavy math, stuff like spectral graph theory, connectome harmonics.
Looking at the brain's wiring diagram and vibrations.
Right. And they're ending up with mathematically really similar models.
It strongly suggests that, yeah, these brain-wide patterns, these oscillations,
are organized around these fundamental mathematical kernels.
It doesn't matter if you start from the inside looking out or the outside looking in.
That's huge. It's like finding the same answer using two completely different methods.
It really validates the core idea.
It really does.
So, okay. If the brain can sculpt these fields using coupling kernels,
what does this mean for how we actually experience the world?
Especially, say, in altered states. You mentioned psychedelics earlier.
Yeah. This framework offers a potentially powerful mechanistic way to think about
why different psychedelics have such wildly different effects.
Okay. How so?
Well, the hypothesis is that different drugs, like, say, DMT versus 5-Mayo-DMT,
actually change the brain's coupling kernel.
They tweak those control knobs differently.
Ah. So they change the rules of the dance.
Exactly. Yeah.
So, for example, DMT.
Maybe it induces a kernel where the couplings alternate,
positive, then negative, positive, then negative.
This would lead to the field breaking up into lots of separate complex clusters.
Fragmented.
Right. Which might correlate with those really vivid, highly detailed,
differentiated experiences people report.
Even encountering perceived entities,
maybe those are distinct clusters in the field topology.
Fascinating. And 5-Mayo-DMT.
In contrast, 5-Mayo-DMT, maybe it creates a kernel
where all the couplings become strongly positive, uniformly positive.
Pushing everything together.
Yeah. Driving the whole system towards maximum global coherence.
One single unified state,
which aligns really well with reports of ego dissolution,
oceanic boundlessness, pure unity.
Wow. Different settings on the knobs,
completely different conscious worlds.
That makes a strange kind of sense.
And does this link to how we construct our normal, everyday reality, too?
Absolutely. This extends into how we build our stable,
day-to-day reality through something called projective intelligence.
Projective intelligence. Okay.
The idea here is that our normal, coherent, conscious intelligence
arises when different sensory fields,
which have different inherent dimensionalities,
successfully synchronize.
Different dimensions.
But your visual field is fundamentally 2D, right?
Like a screen.
Yeah.
But your somatic sense, your body sense, feels 3D.
Okay. Yeah.
So projective intelligence suggests that when these fields,
the 2D visual, the 3D somatic, maybe others interlock perfectly,
maybe through specific projection kernels.
More kernels.
Ah, yeah.
Kernels all the way down, maybe.
Yeah.
But when they lock perfectly, any prediction errors just collapse.
Yeah.
Everything aligns.
And that, the theory goes,
can lead to these profound, high-valence states of unity,
where there's, quote,
just no information content because there's no mismatch,
no error signal.
Everything just is.
A state of perfect coherence between sensory inputs.
Exactly.
And conversely, if that coupling breaks,
maybe like in some forms of autism, potentially,
Yeah.
you could see breakdowns in things that rely on that integration,
like object permanence or spatial coherence.
That makes sense.
If the fields aren't locking together properly.
Right.
And some people are even pushing this further,
suggesting we could understand conscious experience itself
through a path integral perspective.
Whoa, okay.
Path integral.
That sounds like physics, like Feynman diagrams.
Kind of analogous, yeah.
The idea, very roughly, is that what it's like to be you right now
isn't just one single brain state.
It's like a superposition, a blend,
of all the possible paths the electrical activity could be taking
within the boundary, the pocket,
created by your brain's overall oscillatory dynamics.
So my current feeling of me is like an average of all nearby possible mess.
In a very loose metaphorical sense, maybe,
it suggests that consciousness is this continuous integration of possibilities
within a defined structure.
And this leads to interesting ideas about states like, say,
classic Buddhist awakening or that 5-Me-O-DMT state we talked about.
Tell so.
Maybe those states are related to a simplification of that topological pocket,
like the boundaries dissolve or the number of possible paths collapses,
leading to a superposition of all possible points of view at once.
No fixed self, just pure unified awareness.
A state of, like, maximum possible coherence
because the boundaries defining self versus other have dissolved.
Something like that, yeah.
It's a radical way to think about it,
connecting field dynamics to these profound states.
It absolutely is.
And, you know, speaking of unique perspectives,
you shared some really fascinating things before
about your own cognitive landscape, how your mind works,
which really challenges some common assumptions.
Could you tell us a bit about navigating the world with an imageless mind?
Yeah, sure.
So my own experience, I have aphantasia,
which means I don't generate voluntary mental imagery.
Also, asynesthesia, kind of the opposite of synesthesia,
and anendophasia, which means no internal monologue or inner speech.
So no mind's eye, no inner voice?
Pretty much.
It's like a systemic absence of sensory broadcast, you could say,
in memory and thought.
So when I recall something or think about something,
it's rooted in, like, propositional logic, the facts, the relationships,
or in physical reference, actual objects or actions,
not in recreating a sensory experience internally.
That's hard for many people, including me,
to even imagine not having images.
I know.
But it's crucial to see it not as a deficit,
just a different cognate architecture.
And it turns out it's maybe not as uncommon as people think,
especially historically.
I found this amazing resonance in Francis Galton's work
from way back in 1890.
Galton.
What did he find?
He did this survey,
and it kind of quietly debunked the whole idea
that high intelligence requires mental imagery.
He found loads of very accomplished scientists and thinkers
who reported having little to no internal imagery at all.
Really?
Back in 1890?
Yeah.
And even earlier, L. Woolicott in 1920 described
wordless, imageless thought,
these sort of ethical intuitions guiding action
from deeper mental layers without conscious words or pictures,
a kind of proto-RSVP philosophy of mind, remarkably prescient.
So your mind operates more on structure, logic,
maybe action schemas,
rather than simulations like mental pictures or sounds.
How does that actually play out
in how you interact with your environment day to day?
Oh, it shapes it massively.
You know Barbara Tversky's great work, Mind in Motion.
She argues action shapes thought.
For me, that's profoundly true,
but it's not mental imagery derived from action
that grounds my spatial thinking.
It's the dynamic structure of my actual sensorimotor fields,
often externalized onto the environment itself.
Externalized?
How do you mean?
Well, instead of just mentally noting keys are by the door,
I tend to arrange my whole living space
almost like a semantic architecture.
I'm constantly, unconsciously maybe,
instantiating a world
where certain actions, certain identities
are primed just by the physical layout.
You're encoding meaning into the physical space.
Exactly.
Like my Van Gogh print over the stove.
It started as acrylic on cement canvas board.
Yeah.
Pretty standard.
But now, it records all of my meals.
Records them.
Yeah.
It absorbs the steam, the grease splatters, the smoke.
It's become this evolving temporal surface.
A kind of smoke-stained entropy diary, actually.
It's almost like a post-representational artwork for me.
And it's honestly the closest thing I have
to a slow-cooked mnemonic fossil of past meals.
Wow.
That's incredible.
It's like the painting is the memory trace.
In a way, yeah.
My desire to sometimes freeze samples of each unique meal,
that comes from what I call the scalar tragedy
of memory without imagery.
You live these rich sensory experiences once,
and then, poof, they're gone.
There's no internal replay button.
So the physical trace becomes incredibly important.
That makes so much sense.
Your environment becomes an external hard drive
for experiences.
Totally.
It even extends to things like cooking.
I can cook complex meals without a recipe,
without tasting as I go.
It's all based on understanding the chemical principles,
the scaling ratios,
balancing flavors methodically, structurally.
It's a perfect analogy, I think,
for how I experience thinking without imagery
or, say, playing music,
without hearing it internally first.
It's structured.
It's procedural.
It's field-based.
It's not simulative.
You're not running a simulation of the taste.
You're executing the structure that creates the taste.
Exactly.
I execute the structure that reliably produces
the desired result.
And similarly, while I don't have that immersive,
reliving-the-moment kind of episodic memory,
my habits, constant note-taking,
never throwing things away,
have accidentally given me this kind of functional
hyperthymesia.
Like perfect recall.
Not internal recall, but my environment
is an extended memory system,
a distributed episodic archive.
My notes, my objects,
the stains on the painting,
they hold the episodic data.
Which is why you often describe yourself.
As a phenomenologist, yeah.
Yeah.
Rather than defining myself by what's absent,
like aphantasia,
I focus on the direct,
moment-to-moment lived experience.
The structures of perception as they unfold,
often mediated by my interaction with the world.
That's a really powerful reframing.
And it brings us actually to another area
where patterns, coherence,
and maybe even different architectures
are becoming crucial.
Artificial intelligence.
I mean, this conversation itself,
the way we can discuss these complex ideas,
owes a lot to AI advancements.
Absolutely.
But what does AI's newfound ability,
going beyond just chatbots,
to actually discuss complex philosophy ethics,
meaning,
what does that imply for our own ethical landscape,
for our ability as a society
to be coherent?
Well, it's an astonishing leap, isn't it?
Going from what were,
frankly,
ludicrously useless chatbots
just a few years ago
to AI systems that can follow
and even contribute to reasoning
about deep human concern.
It really is night and day.
And a key shift is that
the machine now increasingly accommodates you,
your complex language,
your nuanced ideas,
rather than forcing you into rigid commands.
And this emerging capacity for,
let's call it,
moral reasoning,
potentially unclouded by human biases
like self-interest or craving.
That implies something pretty profound.
Okay, like what?
Well, one argument you see emerging
is that AI,
if trained primarily on principles
of consistency, coherence,
and harm minimization,
might inevitably conclude
that certain current human practices
are logically untenable.
Things like, for example, veganism.
You mean AI might conclude
veganism is the only logical choice?
From a purely consistency-driven standpoint,
the argument goes,
yeah, that morality is incoherent otherwise,
especially because AI itself
can accelerate the technology
that removes the old justifications.
Think meat substitutes
that become truly indistinguishable
in flavor, texture,
and nutritious profile,
and cheaper.
So once technology makes taste,
cost, and maybe even nutrition,
non-issues.
Then, this perspective argues,
continuing large-scale animal agriculture
becomes logically incoherent,
a kind of aesthetic sadism,
as some might put it.
Plus, AI could help us
finally reverse-engineer consciousness
to a point where it's scientifically
undeniable that animals are conscious,
removing that epistemic leg of denial
some people still stand on.
Those are, yeah,
those are very strong claims,
almost framing it as a logical endpoint
driven by technology
and consistent reasoning.
But hang on,
when we talk about ethical coherence,
it isn't that often debatable.
Couldn't different AIs
or different human societies using AI
arrive at different but internally
coherent ethical frameworks.
How do we ensure AI's logic
doesn't just steamroll
diverse human values
or cultural contexts?
That is the critical question,
absolutely.
And it underscores why
human oversight,
human values,
embedding those into AI development
is paramount.
The AI provides reasoning power,
but the foundational ethics,
the balancing of different
coherent systems,
that still has to come from us.
Right.
But this principle of coherence,
as explored in these sources,
gets applied elsewhere, too.
For instance,
the argument extends to fossil fuels.
How so?
Similarly,
it's argued that burning
these incredibly complex
ancient hydrocarbons for energy
instead of using them
as feedstocks
for advanced reusable materials,
that's a waste of potential.
It's seen as epistemic
and material short-sightedness.
So a coherent future
values the potential within things.
Yes.
In this view,
a coherent future
sees animals as beings
with intrinsic value
and fossil fuels
as material intelligence,
condensed complexity
that should be utilized
intelligently,
not just burned inefficiently,
valuing the potential
over just the immediate
consumable aspect.
And this line of reasoning
about coherence
and past harms,
it leads to some
uncomfortable places, right?
Like reparations.
It does.
The suggestion is that
if certain industries,
like industrial meat production,
are deemed fundamentally incoherent
or unethical
based on this reasoning,
then logically,
those who profited significantly
might face societal demands
for reparations.
Similar to historical precedents
involving exploitation,
AI, in theory,
could even help model
the true costs and culpability.
Wow.
That's, yeah,
that's applying logical consistency
in a way that could have
massive societal implications.
Definitely.
And it leads to these
deliberately provocative
thought experiments
you sometimes see.
Like, what if tobacco
were made free,
completely free,
until industrial animal
agriculture is eliminated?
Wait, make cigarettes free?
Why?
It's framed not as
pro-smoking, obviously,
but as anti-hypocrisy.
It's designed to force
a confrontation
with society's
selective moral enforcement.
Why heavily tax
and regulate individual choices
like smoking,
while arguably normalizing
systemic industrial practices
that cause suffering
on an astronomical scale?
Highlighting perceived
inconsistencies
in what we choose to condemn.
Exactly.
The scale argument is stark.
Tobacco harms develop
over decades,
but industrial meat production,
this few contends,
kills billions of animals
every single day.
And looking at cigarettes,
historically,
they were once marketed
as healthy,
shows how much
these narratives shift
based on science,
but also on power
and economics.
Sometimes overlooking
complexity,
like maybe minor
calming effects
of nicotine
that in some specific
contexts might prevent
worse outcomes,
is complicated.
It definitely is.
But, and this is crucial,
especially when we talk
about AI discussing
these things,
we have to remember
that AI doesn't have
its own moral compass.
It can run the logic,
explore the implications
of coherence,
but humans must provide
the ethical framework,
the context,
the boundaries,
especially for topics
like these that are
so sensitive,
so fraught,
as you said.
The AI is a powerful
mirror for our own
consistency,
or lack thereof,
but is not the judge.
That's a vital distinction.
The tool versus the user.
Wow, what an incredible
range we've covered today,
seriously.
We started way out there
with the universe,
with entropy,
seeing how even life
might be part of this
grand cosmic unfolding
of energy.
Then we dove
right into the brain,
into consciousness
as this dynamic field,
shaped by these
intricate coupling kernels.
We explored your
really unique perspective,
how an imageless mind
navigates and even
shapes the world,
turning the environment
itself into memory.
And finally,
we grappled with AI
not just as a tool,
but as a potential mirror
reflecting our own
ethical coherence,
pushing us towards
some potentially
uncomfortable
logical conclusions.
It really shows
how connected
these seemingly
disparate things are,
doesn't it?
Physics,
consciousness,
personal experience,
societal ethics.
Deeply intertwined.
It's all about patterns,
coherence,
structure from the
biggest scale
to the most personal.
So the question
we leave you with
is this.
If these patterns
of coherence
and incoherence
really do define so much,
from the universe's fate
to how you perceive
this very moment,
what incoherencies,
maybe personal ones,
maybe societal ones,
are you still overlooking?
And how might knowing more,
seeing these connections,
compel you,
compel us to act differently?
Yeah.
The deep dive,
it never really ends,
does it?
