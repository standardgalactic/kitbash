\documentclass[11pt]{article}

%--------------------------------------------------
% Geometry and Layout
%--------------------------------------------------
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\setstretch{1.15}

%--------------------------------------------------
% Mathematics and Symbols
%--------------------------------------------------
\usepackage{amsmath, amssymb, amsthm, mathtools}
\usepackage{bm}

%--------------------------------------------------
% Physics and Tensor Notation
%--------------------------------------------------
\usepackage{physics}
\usepackage{tensor}

%--------------------------------------------------
% Fonts and Encoding
%--------------------------------------------------
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

%--------------------------------------------------
% References and Links
%--------------------------------------------------
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue
}

%--------------------------------------------------
% Figures (if needed later)
%--------------------------------------------------
\usepackage{graphicx}

%--------------------------------------------------
% Theorem Environments
%--------------------------------------------------
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\theoremstyle{remark}
\newtheorem{remark}{Remark}

\begin{document}

\title{\textbf{Admissibility and Renormalization}\\
\large Geometry as an Effective Interface}

\author{Flyxion}

\date{\today}

\maketitle

\begin{abstract}
The persistent claim that general relativity and quantum mechanics are fundamentally incompatible rests on an implicit state-first ontology in which time evolution and microscopic reversibility are taken as primitive. In this work, we propose an alternative admissibility-first framework in which physical law is defined by global consistency constraints on histories, with irreversibility treated as fundamental rather than emergent.

Within this ontology, locality, causality, and geometric dynamics arise as interface properties induced by coarse-graining and finite observational resolution. We show that the spacetime metric functions as a lossy compression channel, encoding admissibility constraints in a local, covariant form. Wilsonian renormalization group flow is reinterpreted as an irreversible filtering process in admissibility space, explaining the structural success of effective field theory approaches to gravity.

General Relativity emerges as the leading-order geometric interface, while curvature-squared terms are forced by ultraviolet admissibility rather than introduced ad hoc. The resulting quadratic gravity theory exhibits modified spectral and causal structure, including reversed-causal regulator modes. These features are shown to be interface artifacts rather than physical instabilities, preserving unitarity of observable processes while signaling the breakdown of geometric compression at high resolution.

This framework provides an ontological grounding for effective quantum gravity without introducing new degrees of freedom or abandoning locality at observable scales. Quantum gravity is thereby reframed not as a failure of quantization, but as a limitation on the domain of validity of geometric description itself.
\end{abstract}

\section{Introduction: The Persistence of the Incompatibility Myth}

It is frequently asserted, both in popular accounts and in parts of the technical literature, that general relativity and quantum mechanics are fundamentally incompatible. This claim is often framed as a deep structural contradiction between background-independent geometry and probabilistic state evolution, leading to the belief that gravity resists quantization in a way that other interactions do not. However, this narrative obscures a well-established technical fact: gravity has been successfully quantized as an effective field theory for several decades, yielding consistent and predictive results at accessible energy scales.

The persistence of the incompatibility myth reflects not a failure of quantization, but a failure of interpretation. In particular, it rests on an implicit state-first ontology in which physical law is assumed to be fundamentally expressed as time evolution of microscopic states within a reversible analytic framework. Within such an ontology, the breakdown of perturbative renormalizability in Einstein gravity appears pathological, and the emergence of higher-derivative terms or modified causal structure is treated as a sign of theoretical inconsistency.

In this work, we argue that these conclusions are artifacts of misplaced ontological commitments. We propose an admissibility-first framework in which physical law is defined not by state evolution, but by global consistency constraints on histories. Within this framework, irreversibility is fundamental rather than emergent, and locality, causality, and geometry arise only as approximate interface properties induced by coarse-graining and finite observational resolution. When this perspective is adopted, the technical structure of effective quantum gravity—including the necessity of curvature-squared terms and the appearance of reversed-causal regulator modes—follows naturally and without contradiction.

The aim of this paper is therefore not to propose a new theory of quantum gravity, but to provide an ontological grounding for the remarkable empirical and mathematical success of the effective field theory approach to gravity. By deriving geometry and renormalization as consequences of admissibility filtering, we show that General Relativity and its quadratic extensions are not fundamental laws, but minimal viable summaries of deeper irreversible constraints.

\section{Gravity as an Effective Field Theory}

The quantization of gravity as a field theory proceeds by treating the spacetime metric as a dynamical field and expanding about a chosen background, typically flat spacetime. This program was carried out rigorously by Feynman and DeWitt, establishing the Feynman rules for graviton interactions and demonstrating that gravity can be treated on the same footing as other gauge theories within perturbation theory. While the resulting theory is not renormalizable in the traditional sense, it is perfectly well-defined as an effective field theory.

The modern understanding of effective field theory, shaped by Wilsonian renormalization, rejects the notion that fundamental laws must be valid at arbitrarily high energies. Instead, a theory is understood as a scale-dependent description whose predictive content is restricted to a finite domain. Within this framework, nonrenormalizability is not a failure, but a statement about the presence of higher-dimensional operators suppressed by a cutoff scale. These operators encode ignorance of high-energy physics without compromising low-energy predictivity.

A particularly striking demonstration of this principle in gravity is provided by the calculation of quantum corrections to the Newtonian potential. Donoghue showed that loop corrections involving gravitons generate long-distance modifications to the classical potential that scale as inverse powers of distance beyond the familiar $1/r$ behavior. These corrections are nonlocal and therefore insensitive to unknown ultraviolet physics. As a result, they are rigorously calculable using only the low-energy degrees of freedom of General Relativity. The existence of such corrections establishes conclusively that gravity is not incompatible with quantum mechanics, but rather behaves exactly as an effective field theory should.

Despite this technical success, the effective field theory approach is often regarded as provisional, awaiting replacement by a more fundamental geometric or unified framework. In what follows, we argue that this attitude reflects a misunderstanding of what effective field theories represent. Rather than being approximations to deeper state-based dynamics, they are the natural interface descriptions that arise when global admissibility constraints are compressed into local form.

\section{Admissibility-First Ontology}

We now introduce the admissibility-first framework that underlies the remainder of this work. The central conceptual move is to replace the notion of a fundamental state evolving in time with that of a globally admissible history. A history is defined as a complete specification of field configurations across spacetime, and admissibility is a global property determined by the satisfaction of consistency constraints. These constraints need not be local, nor need they be symmetric under time reversal.

In this ontology, dynamics is not primary. What appears as temporal evolution in effective descriptions is the projection of global admissibility onto a local, sequential representation. Crucially, admissibility is irreversible: once a violation occurs, it cannot be undone by subsequent local rearrangements. This irreversibility is encoded in the RSVP framework through the entropy field $S$ and the associated vector field $V_\mu$, which together define an intrinsic arrow of constraint satisfaction.

Observers are not external entities but localized subsystems embedded within admissible histories. Their predictive capacity is limited by finite resolution and finite causal access. As a result, they cannot represent the full nonlocal structure of admissibility and must rely on compressed descriptions. Physical laws, in this sense, are not fundamental prescriptions for evolution, but effective summaries of what remains invariant under coarse-graining.

This perspective immediately reframes the role of geometry. Rather than serving as the fundamental arena of physics, spacetime geometry becomes a representational tool that encodes admissibility information in a form accessible to local observers. The metric does not describe substance; it encodes penalties for deformation away from admissible configurations.

\section{Coarse-Graining as Constraint Preservation}

To formalize this compression process, we consider the space of admissible RSVP histories, denoted $\mathcal{H}_{\mathrm{RSVP}}$. An observer with finite resolution cannot access this space directly and instead constructs an effective description by integrating out degrees of freedom below a characteristic length scale $\ell \sim \Lambda^{-1}$. This defines a coarse-graining map $\mathcal{P}_\Lambda : \mathcal{H}_{\mathrm{RSVP}} \rightarrow \mathcal{H}_{\mathrm{eff}}$.

Unlike coarse-graining in reversible statistical systems, this projection does not merely discard information. Because admissibility violations are irreversible, any microscopic violation present in a history must manifest as an effective inconsistency at the coarse-grained level. Coarse-graining therefore preserves violation structure even as it suppresses microscopic detail. This asymmetry endows the projection with an intrinsic arrow and prevents inversion.

As a consequence, only certain structures remain meaningful at low resolution. An effective operator is admissibility-stable if the constraint it encodes remains well-defined under repeated coarse-graining. Operators that depend sensitively on microscopic configuration wash out and become irrelevant. The surviving operators define the effective laws of physics at scale $\Lambda$.

This observation provides a natural explanation for the structure of low-energy theories. The laws we observe are not arbitrary, nor are they selected for aesthetic simplicity. They are the minimal set of constraints that survive irreversible compression. Effective field theories succeed precisely because they encode only those structures that remain admissible under loss of resolution.

\section{Renormalization Group Flow as Admissibility Filtering}

Within this framework, Wilsonian renormalization group flow acquires a direct ontological interpretation. The distinction between relevant, marginal, and irrelevant operators is no longer merely dimensional. It reflects the stability of admissibility constraints under coarse-graining. Relevant and marginal operators encode protected structures that continue to enforce consistency at large scales, while irrelevant operators correspond to microscopic details that do not affect global admissibility.

The entropy field $S$ provides a physical grounding for the irreversibility of renormalization group flow. Just as thermodynamic entropy defines a preferred temporal direction, admissibility filtering defines a preferred direction in theory space. One may flow from a high-resolution description to a lower-resolution effective theory, but the inverse reconstruction is impossible because the information specifying which microscopic configurations supported macroscopic admissibility has been destroyed.

This interpretation explains the apparent effectiveness of low-energy theories despite their incompleteness. Effective field theories work not because nature is simple, but because the interface produced by admissibility compression is forced to be simple. The renormalization group does not reveal deeper microscopic truth; it reveals which constraints remain enforceable after information loss.

In the gravitational context, this filtering singles out curvature invariants as admissibility-stable operators. Their persistence under coarse-graining reflects the fact that they encode global geometric consistency rather than local microstructure.

\section{The Metric Interface}

We are now in a position to derive the metric interface itself. Any local description accessible to observers must be covariant, since admissibility does not privilege a coordinate system. The effective variables must therefore transform tensorially, and the resulting action must be diffeomorphism invariant.

The spacetime metric $g_{\mu\nu}$ emerges as the unique object capable of encoding admissibility penalties in a local, covariant manner. It functions as a compression channel, translating global consistency constraints into local geometric response. The Einstein field equations are not fundamental laws, but stationarity conditions expressing the balance of admissibility at leading order in resolution.

At lowest order in derivatives, the only scalar invariant available is the Ricci scalar $R$. The Einstein--Hilbert action therefore represents the minimal geometric interface compatible with covariance and locality. Its success at macroscopic scales reflects the stability of curvature-based admissibility constraints under coarse-graining.

However, the same logic already implies the necessity of higher-order terms once the interface is pushed toward higher resolution. The Einstein--Hilbert action provides no suppression of high-frequency geometric fluctuations, and admissibility fails under unrestricted summation over microscopic curvature. This failure does not indicate a breakdown of the admissibility framework, but rather the limits of first-order geometric compression.

The derivation of the required higher-order corrections, and the resulting structure of quadratic gravity, will be taken up in the following sections.

\section{The Emergence of the Metric Interface}

Having established that coarse-graining acts as an admissibility-preserving projection and that renormalization group flow functions as an ontological filter on admissible histories, we now address the central constructive question: what effective variables can stably encode admissibility at long wavelengths? In particular, we ask why the output of this compression takes the specific form of a spacetime metric governed by curvature-based dynamics, rather than some alternative local structure.

The answer is not historical or aesthetic. It follows from the structural requirements imposed on any effective interface that remains predictive after irreversible coarse-graining.

\subsection{Requirements on an Effective Admissibility Interface}

An effective description emerging from admissibility filtering must satisfy several constraints inherited from the underlying ontology. First, it must be local in the operational sense: observers have access only to finite regions of spacetime, and predictive power requires that admissibility violations be encoded in a form that can be evaluated within such regions. Second, it must be covariant. Because admissibility is defined globally on histories rather than relative to a preferred foliation, no frame or time slicing can be introduced by the compression procedure. Third, the interface must couple universally to all forms of constraint accumulation. In particular, energy and momentum flow are sources of admissibility stress, so the interface variable must be capable of responding to them without reference to internal structure.

Finally, the interface must be minimal. Coarse-graining is lossy by construction, and only those degrees of freedom that preserve admissibility under renormalization can survive. Any redundant structure would be unstable under further compression and therefore eliminated by RG flow.

These requirements are not independent assumptions; they are consequences of projecting a global, irreversible constraint structure into a local predictive formalism.

\subsection{Why Scalar and Vector Interfaces Are Insufficient}

One might imagine encoding admissibility using scalar or vector fields. However, such structures fail to satisfy the requirements above. Scalar summaries can encode local density or potential information but cannot represent directional or relational constraint between neighboring regions. Vector fields can encode directed flow, as indeed appears in the RSVP ontology through the field $V_\mu$, but they remain insufficient to describe how admissibility violations deform relations between distinct directions simultaneously.

Admissibility is not a property of isolated points; it concerns the compatibility of neighboring histories. Violations manifest as relational inconsistencies: mismatches between how adjacent regions attempt to satisfy constraints. Encoding such relational deformation requires an object that compares directions pairwise and assigns a local penalty to their relative distortion. Scalars lack this relational capacity, and vectors encode only one direction at a time. Neither can stably summarize admissibility under coarse-graining.

\subsection{The Metric as a Measure of Admissibility Deformation}

The minimal structure capable of encoding relational deformation in a covariant and local manner is a symmetric rank-two tensor. Such an object assigns a bilinear form to tangent directions and thereby measures how neighboring configurations relate to one another infinitesimally. This structure is precisely what is required to encode the local cost of admissibility deformation.

We therefore identify the spacetime metric $g_{\mu\nu}$ not as a fundamental background but as the unique minimal interface that survives admissibility filtering. It is the compression channel through which global consistency constraints are locally summarized. In this interpretation, distances and causal structure are not primitive; they are derived quantities reflecting how strongly admissibility penalizes deformation between neighboring histories.

This identification does not rely on any quantization procedure or classical limit. It follows directly from the requirement that admissibility be encoded locally, covariantly, and relationally after coarse-graining.

\subsection{The Einstein--Hilbert Action as the Leading Admissibility Penalty}

Once the metric is identified as the effective interface variable, the form of its leading-order dynamics is fixed by the same compression logic. Under renormalization group flow, operators with the fewest derivatives dominate at long wavelengths. The admissibility penalty functional must therefore be constructed from the lowest-derivative scalar invariant of the metric.

In four spacetime dimensions, there exists a unique scalar invariant built from the metric and its first and second derivatives that satisfies covariance and locality: the Ricci scalar $R$. The corresponding action,
\[
S_{\mathrm{EH}} = \frac{1}{16\pi G} \int d^4x \sqrt{-g} \, R,
\]
is thus not postulated as a fundamental law but emerges as the leading-order admissibility penalty in the metric interface.

The Einstein field equations follow as the condition that admissibility stress be locally extremized under variations of the interface. In this sense, General Relativity is the lowest-order stable fixed point of admissibility-preserving compression. It is not an ontological statement about spacetime itself, but a constitutive relation governing how the interface responds to constraint accumulation.

\subsection{Interpretation and Transition}

This derivation clarifies both the power and the limitations of geometric descriptions. Geometry is forced upon us by the need to compress admissibility into a local form, but it is necessarily incomplete. The metric interface is designed to preserve admissibility at long wavelengths; it is not required, nor expected, to remain faithful at arbitrarily high curvature or short distance.

When admissibility stress exceeds the resolution capacity of the metric interface, compensatory structures must appear. As we will show in subsequent sections, these structures take the form of higher-derivative curvature terms and associated regulator modes. Their appearance signals not a failure of the framework, but the boundary of validity of local geometric compression.

\section{Quantum Gravity as the Fluctuation Theory of the Interface}

With the emergence of the metric as an admissibility-preserving interface now established, we turn to the question of what it means to quantize gravity within this framework. The conventional framing treats quantum gravity as the problem of quantizing spacetime itself, often motivating the search for microscopic constituents or fundamentally discrete structures. From the admissibility-first perspective developed here, this framing is misplaced. What is quantized is not spacetime as an ontological substrate, but the fluctuations of the metric interface that encodes admissibility at macroscopic scales.

The distinction is subtle but essential. The metric does not represent the fundamental degrees of freedom of the theory; it is a compressed summary of constraint satisfaction. Quantizing the metric therefore does not probe the microstructure of reality in the same way that quantizing a fundamental field would. Instead, it describes how admissibility fluctuates when the interface is subjected to finite-resolution probing.

\subsection{Interface Fluctuations and Effective Degrees of Freedom}

In any lossy compression, the interface variables exhibit residual variance. Distinct admissible histories that agree at coarse resolution nevertheless differ microscopically, and this difference manifests as fluctuations of the effective interface fields. In the present case, fluctuations of the metric represent uncertainty in how admissibility constraints are locally satisfied when global information has been integrated out.

These fluctuations are not arbitrary. They are governed by the same admissibility-preserving logic that produced the interface itself. Consequently, the appropriate framework for describing them is an effective field theory constructed from the metric and constrained by covariance, locality, and renormalization group stability.

From this viewpoint, gravitons are not particles propagating in a pre-existing spacetime, nor are they elementary constituents of geometry. They are the normal modes of fluctuation of the metric interface, analogous to phonons in an elastic medium. Their existence reflects the fact that admissibility compression is not exact and that local summaries necessarily fluctuate around their mean behavior.

\subsection{Why Effective Field Theory Quantization Works}

This interpretation explains the long-standing empirical success of treating gravity as an effective field theory at low energies. When the metric is quantized perturbatively around a smooth background, the resulting theory makes definite and reliable predictions for long-wavelength observables. These predictions are insensitive to unknown high-energy details precisely because the interface is designed to preserve admissibility under coarse-graining.

The effective field theory of gravity does not fail because it is conceptually inconsistent; it fails only when it is pushed beyond the scale at which the metric remains a faithful summary. At energies well below the cutoff set by admissibility resolution, quantum corrections are dominated by long-distance effects and are therefore universal. This is exemplified by the calculability of quantum corrections to the Newtonian potential, which depend only on the low-energy structure of the theory and not on its ultraviolet completion.

Within the admissibility framework, this universality is not surprising. Long-distance fluctuations correspond to variations among admissible histories that survive coarse-graining. High-energy details that do not affect admissibility are filtered out and appear only as renormalizations of local coefficients. Effective field theory works because it faithfully tracks how admissibility-preserving structures respond to perturbations, not because it approximates some deeper microscopic dynamics.

\subsection{Limits of Quantization and the Breakdown of Microcausality}

The effective quantization of the metric interface inherits both its strengths and its limitations. Because the interface is local and covariant only in an approximate sense, its fluctuation theory cannot be expected to preserve all the axioms of fundamental quantum field theory at arbitrarily short distances. In particular, assumptions such as strict microcausality, spectral positivity, and simple analytic structure rely on the existence of a single, global arrow of time and a state-based ontology.

In the admissibility-first framework, irreversibility is fundamental and global. The metric interface encodes this irreversibility imperfectly, translating it into a time-symmetric formalism suitable for local prediction. When this translation is pushed beyond its domain of validity, compensatory effects must appear in the fluctuation theory. These effects signal the failure of the interface to encode admissibility faithfully at high resolution, not a breakdown of consistency in the underlying ontology.

It is therefore expected that the quantized metric exhibits modified causal behavior and nonstandard spectral features at high energies. These features are not pathologies to be cured, but indicators of the boundary between interface-level description and underlying constraint structure.

\subsection{Transition to Higher-Derivative Corrections}

The discussion above clarifies why quantizing the Einstein--Hilbert interface is both successful and incomplete. The lowest-order admissibility penalty captures the dominant long-wavelength behavior, but it provides no mechanism for suppressing high-frequency interface fluctuations. As a result, the effective theory becomes increasingly sensitive to inadmissible configurations at short distances.

The natural response within the admissibility framework is not to abandon locality or introduce new fundamental fields, but to refine the interface so that it remains stable under renormalization. As we will show in the following section, this refinement takes the unique form of curvature-squared corrections. The associated additional modes, often interpreted as ghosts, arise precisely because the interface is being extended beyond the regime where a second-derivative description suffices.

\section{Curvature-Squared Stability and the Role of the Merlin Mode}

The effective quantization of the Einstein--Hilbert interface exposes a structural instability. While the metric description faithfully encodes admissibility at long wavelengths, it provides no intrinsic suppression of high-frequency interface fluctuations. In Wilsonian terms, the Einstein--Hilbert action is incomplete: it fails to define a renormalization-group stable surface once quantum fluctuations of the interface are taken into account.

This instability is not contingent on the choice of quantization scheme, nor does it signal a failure of the effective field theory framework itself. Rather, it reflects a mismatch between the derivative order of the interface action and the resolution demands imposed by coarse-graining. To maintain admissibility preservation under renormalization, the interface must be extended.

\subsection{Why Curvature-Squared Terms Are Forced}

Locality, covariance, and dimensional analysis sharply restrict the form of admissibility-preserving refinements. In four spacetime dimensions, the only available local scalars capable of penalizing short-wavelength metric fluctuations are quadratic in curvature. The most general such action takes the form
\[
S_{\text{eff}} = \int d^4x \sqrt{-g}
\left(
\frac{2}{\kappa^2} R
+ \alpha R^2
+ \beta C_{\mu\nu\rho\sigma} C^{\mu\nu\rho\sigma}
\right),
\]
up to topological terms that do not affect local dynamics.

From the admissibility-first perspective, these terms are not optional embellishments. They represent the minimal extension required to stabilize the interface against inadmissible fluctuations at scales approaching the resolution limit. Any attempt to suppress ultraviolet variance while retaining locality necessarily introduces higher derivatives. The appearance of curvature-squared terms is therefore a structural consequence of interface refinement, not a speculative modification of gravity.

\subsection{Renormalization Group Stability}

The inclusion of curvature-squared operators renders the metric fluctuation theory power-counting renormalizable. More importantly, it defines a closed surface under renormalization group flow. Once these operators are present, quantum corrections do not generate qualitatively new admissibility penalties at the same derivative order.

In ontological terms, this closure reflects the fact that curvature-squared penalties are sufficient to enforce admissibility filtering at all scales accessible to the metric interface. Higher-order operators correspond to finer-grained summaries than the interface is capable of supporting and are therefore suppressed by the same compression logic that filters irrelevant operators in ordinary effective field theories.

\subsection{The Emergence of the Merlin Mode}

The refinement of the interface has an unavoidable spectral consequence. Linearizing the curvature-squared action around a smooth background introduces an additional pole in the spin-two sector of the graviton propagator. In conventional treatments, this pole is interpreted as a massive ghost, signaling negative norm states or violations of unitarity.

This interpretation implicitly assumes that all poles correspond to propagating physical degrees of freedom evolving forward in time. That assumption is incompatible with the admissibility-first ontology. The metric interface is a time-symmetric representation of an underlying irreversible constraint structure. When that structure is compressed into a local second-order formalism and then further stabilized by higher derivatives, compensatory modes must appear.

The additional spin-two pole corresponds to such a compensatory mode. Its propagator has the analytic structure of a time-reversed unstable resonance: it carries positive energy backward in time and decays rapidly into ordinary interface fluctuations. It does not appear as an asymptotic state and therefore does not represent a physical particle. We refer to this mode as the \emph{Merlin mode}, emphasizing its role as a regulator rather than a constituent.

\subsection{Unitarity and the Absence of Instability}

Despite its unconventional causal behavior, the Merlin mode does not destabilize the theory. Unitarity of the $S$-matrix is preserved because only stable asymptotic states contribute to observable transition amplitudes. The reversed-causal mode exists solely as an intermediate regulator channel, enforcing admissibility at high resolution.

This behavior mirrors that of Lee--Wick theories, but its origin here is ontological rather than ad hoc. The Merlin mode exists because the interface is being asked to encode irreversible global constraints using local, reversible variables. The apparent violation of microcausality is therefore an interface artifact, not a fundamental inconsistency.

Importantly, the presence of this mode is not optional. Any local, renormalization-stable metric interface that suppresses ultraviolet inadmissibility must introduce a compensating reversed-causal channel. Attempts to eliminate the ghost without abandoning locality or higher derivatives simply displace the instability elsewhere.

\subsection{Interpretation: Ghosts as Compression Error Terms}

Within the admissibility framework, the Merlin mode admits a precise interpretation. It is the error term of ontological compression. It arises because the metric interface is a lossy summary of a richer constraint space, and no finite-order local action can perfectly encode irreversible admissibility.

The reversed arrow of causality associated with the Merlin mode compensates for the forward-only arrow encoded in the RSVP entropy field. Together, they ensure that admissibility violations are suppressed symmetrically in the time-symmetric interface formalism, even though the underlying ontology remains irreversible.

\subsection{Summary}

Curvature-squared gravity is not a speculative ultraviolet completion of General Relativity. It is the unique stable extension of the metric interface once admissibility preservation under renormalization is taken seriously. The associated ghost-like mode is neither a pathology nor a particle, but a structural regulator required by compression.

The so-called problems of quadratic gravity are therefore not failures of the theory, but signals that the metric has reached the boundary of its role as an admissibility-preserving interface.

\section{Comparative Ontologies in Quantum Gravity}

The admissibility-first framework developed in this paper does not compete with existing approaches to quantum gravity at the level of calculational technique. Rather, it reclassifies them according to the ontological commitments they make prior to quantization. Many apparent disagreements in the field arise not from conflicting predictions, but from incompatible assumptions about what geometry, causality, and laws are taken to be.

In this section, we compare the admissibility-first approach with several influential frameworks, emphasizing that the distinctions are architectural rather than empirical.

\subsection{Effective Field Theory Gravity}

The Effective Field Theory (EFT) treatment of gravity represents the most conservative and empirically grounded approach to quantum gravity. By quantizing the metric as a field and organizing corrections by operator dimension, EFT provides reliable low-energy predictions without requiring a complete ultraviolet theory.

From the admissibility-first perspective, the success of EFT is not accidental. The Wilsonian separation between relevant and irrelevant operators corresponds precisely to admissibility filtering under coarse-graining. Low-energy observables are insensitive to microscopic details because only admissibility-preserving structures survive projection to macroscopic resolution.

What EFT lacks is not technical consistency, but ontological grounding. The admissibility framework explains why EFT works, why it must break down at high resolution, and why curvature-squared terms inevitably appear. In this sense, EFT gravity is not superseded but justified: it is the natural interface theory for a constraint-first ontology.

\subsection{Asymptotic Safety}

The asymptotic safety program seeks a nontrivial ultraviolet fixed point of the gravitational renormalization group flow. If such a fixed point exists, gravity could be predictive at arbitrarily high energies without introducing new degrees of freedom.

While technically distinct, asymptotic safety is compatible with the admissibility-first view at the level of outcomes. A fixed point corresponds to a stable admissibility surface under arbitrarily fine coarse-graining. However, the program typically remains state-first in interpretation, treating the RG flow as a dynamical evolution of couplings rather than as a filtering of constraint summaries.

From the present perspective, the existence or nonexistence of an ultraviolet fixed point is secondary. What matters is that admissibility preservation demands higher-derivative penalties and the sacrifice of strict microcausality at small scales. Whether this manifests as a fixed point or as regulated flow is a technical question layered atop a deeper ontological necessity.

\subsection{String Theory}

String theory replaces pointlike degrees of freedom with extended objects, rendering gravity ultraviolet finite through nonlocality. In doing so, it preserves unitarity and avoids ghost instabilities at the cost of abandoning locality at the fundamental scale.

This trade-off is intelligible within the admissibility framework. Nonlocality is one possible response to the failure of local geometric compression at high resolution. However, string theory elevates this response to a fundamental ontology, treating extended objects and extra dimensions as physically real rather than as interface artifacts.

By contrast, the admissibility-first approach maintains locality as an interface constraint rather than a fundamental principle. Nonlocal behavior appears only as a breakdown of the metric interface, not as evidence for new fundamental entities. The difference is therefore not predictive but interpretive: string theory postulates new ontic structure where admissibility theory diagnoses interface saturation.

\subsection{Loop Quantum Gravity}

Loop Quantum Gravity (LQG) attempts to quantize geometry directly by imposing discreteness at the Planck scale. Areas and volumes acquire discrete spectra, and spacetime is reconstructed from combinatorial data.

From the admissibility standpoint, discreteness is again a possible interface response to ultraviolet instability. However, LQG treats this discreteness as fundamental, rather than as a symptom of compression failure. The admissibility framework predicts that any sufficiently refined interface will exhibit breakdown—whether via discreteness, nonlocality, or reversed-causal regulators—without requiring that such features be ontologically primitive.

Moreover, LQG offers limited insight into why classical geometry emerges so robustly or why EFT methods work so well. These successes follow naturally once geometry is understood as a coarse-grained admissibility summary rather than as the primary arena of dynamics.

\subsection{Random Dynamics and Anti-Unification}

Random Dynamics proposes that high-energy physics is fundamentally chaotic, with low-energy laws emerging as the protected remnants that survive renormalization. Gauge symmetries and conservation laws persist because they are stable under filtering, not because they are fundamental.

This view aligns closely with the admissibility-first ontology. Both reject unification bias and both treat observed laws as survivorship artifacts. The admissibility framework adds structure by identifying the specific mechanism of filtering: irreversible constraint preservation under coarse-graining.

Where Random Dynamics emphasizes chaos, admissibility emphasizes consistency. The two views are complementary. Randomness describes what is filtered out; admissibility describes what remains.

\subsection{Summary of Ontological Differences}

Across these approaches, the central divide is not between quantization schemes but between underlying ontologies. State-first theories treat geometry as fundamental and consequently encounter ultraviolet instabilities when attempting quantization. Structure-first theories respond to these difficulties by introducing additional entities or degrees of freedom in order to stabilize the quantum description. By contrast, an admissibility-first framework treats geometry as an interface rather than a fundamental constituent and therefore anticipates both the domain of validity of geometric description and the specific modes by which it fails at high resolution. 


In this light, Quadratic Gravity, ghost modes, and microcausality violations are not signs of theoretical failure. They are diagnostic features indicating that the interface is being pushed beyond its natural resolution.

The admissibility-first framework therefore does not replace existing approaches. It explains why each works where it does, why each fails where it must, and why no single geometric description can be expected to remain valid at all scales.

\section{Conclusion}

This paper has argued that many of the enduring difficulties in quantum gravity arise not from technical obstruction, but from an ontological misplacement. The dominant formulation of gravity begins with geometry as a fundamental arena and attempts to quantize it directly. While this approach is operationally successful at low energies, it becomes unstable when extended beyond the regime where local geometric description remains a faithful summary of underlying physical constraints.

We have proposed an alternative starting point: a constraint-first ontology in which physical law is defined by global admissibility conditions on histories. Within this framework, irreversibility is fundamental, locality is emergent, and dynamics is a derived interface rather than a primitive concept. The spacetime metric is not a background structure but a compression channel—a minimal, covariant summary of constraint satisfaction accessible to finite observers.

From this perspective, several well-known results acquire a unified explanation. The effectiveness of the Wilsonian renormalization group reflects admissibility filtering under coarse-graining. The success of effective field theory gravity follows from the stability of certain constraint summaries under projection to low resolution. General Relativity emerges as the leading-order geometric interface, while curvature-squared terms are forced by ultraviolet admissibility rather than introduced ad hoc.

The spectral and causal peculiarities of quadratic gravity—long regarded as pathologies—are reinterpreted as interface artifacts. Reversed-causal regulator modes do not signal physical instability but mark the breakdown of geometric compression at high resolution. Unitarity of observable processes is preserved precisely because these modes do not correspond to admissible asymptotic histories.

Importantly, this framework does not compete with existing approaches by proposing new degrees of freedom or alternative quantization rules. It instead provides an ontological explanation for why current methods work where they do, why they fail where they must, and why no single geometric description should be expected to remain valid at all scales. Disagreements among quantum gravity programs are thus recast as differences in how interface breakdown is interpreted rather than as contradictions in physical content.

The central claim of this work is therefore modest but structural: geometry is not the foundation of physical law, but one of its most effective interfaces. Quantum gravity is not obstructed by inconsistency between General Relativity and quantum mechanics, but by the expectation that a local geometric summary can remain exact beyond its natural domain of validity.

Recognizing geometry as an interface resolves this expectation. What remains is not a crisis, but a boundary—one that clarifies both the power and the limits of our most successful descriptions of spacetime.

\section*{Appendices}

\appendix
\section{Formal Structure of Admissibility and Coarse-Graining}
\label{app:admissibility}

This appendix collects formal definitions and structural results used implicitly in the main text. Its purpose is not to extend the physical argument, but to make explicit the mathematical assumptions underlying the admissibility-first framework and its relation to coarse-graining and renormalization.

\subsection{History Space and Admissibility}

Let $M$ be a four-dimensional Lorentzian manifold equipped with a differentiable structure, but no \emph{a priori} metric. Let $\Phi$ denote the space of microscopic field configurations defined on $M$, including scalar, vector, and entropy fields as required by the RSVP framework.

\paragraph{Definition A.1 (History Space).}
A \emph{history} is a section
\[
H : M \to \Phi .
\]
The space of all histories is denoted by $\mathcal{H}$.

\paragraph{Definition A.2 (Admissibility Constraint).}
An admissibility constraint is a functional
\[
\mathcal{C} : \mathcal{H} \to \{0,1\},
\]
where $\mathcal{C}(H) = 1$ indicates that $H$ is globally consistent and $\mathcal{C}(H) = 0$ indicates violation.

The admissible history space is
\[
\mathcal{H}_{\mathrm{adm}} := \{ H \in \mathcal{H} \mid \mathcal{C}(H) = 1 \}.
\]

\paragraph{Remark.}
No assumption is made that $\mathcal{C}$ is local, additive, or reversible. In particular, $\mathcal{C}$ may depend on extended correlations across $M$.

\subsection{Irreversibility}

\paragraph{Definition A.3 (Irreversible Constraint).}
The constraint $\mathcal{C}$ is said to be \emph{irreversible} if there exists a history $H \in \mathcal{H}$ and a compact region $U \subset M$ such that
\[
\mathcal{C}(H) = 0
\quad \text{and} \quad
\mathcal{C}(H + \delta H) = 0
\]
for all variations $\delta H$ supported in $U$.

That is, once violated, admissibility cannot be restored by any local modification.

\paragraph{Lemma A.1 (Failure of Time-Reversal Invariance).}
If $\mathcal{C}$ is irreversible, then it cannot be invariant under a global time-reversal operation $T$ acting on histories.

\emph{Proof.}
If $\mathcal{C}$ were time-reversal invariant, then for any $H$ with $\mathcal{C}(H)=0$, one would have $\mathcal{C}(T[H])=0$. However, reversibility would require that the violation in $T[H]$ could be repaired by forward-local modification, contradicting Definition A.3. $\square$

\subsection{Coarse-Graining as Projection}

Let $\Lambda$ be a momentum cutoff scale. Define a coarse-graining map
\[
\mathcal{P}_\Lambda : \mathcal{H} \to \mathcal{H}_\Lambda
\]
that integrates out degrees of freedom above $\Lambda$.

\paragraph{Definition A.4 (Admissibility-Preserving Projection).}
A coarse-graining map $\mathcal{P}_\Lambda$ is admissibility-preserving if
\[
\mathcal{C}(H) = 0 \implies \mathcal{C}_\Lambda(\mathcal{P}_\Lambda H) = 0,
\]
where $\mathcal{C}_\Lambda$ is the induced constraint on effective histories.

\paragraph{Remark.}
This condition encodes the requirement that violations of global consistency cannot be erased by loss of resolution.

\subsection{Interface Fields}

Let $\Psi_\Lambda$ denote a finite set of effective fields extracted from $\mathcal{P}_\Lambda H$.

\paragraph{Definition A.5 (Interface Theory).}
An interface theory at resolution scale $\Lambda$ is a local effective description intended to encode the admissible subset of histories at that scale. It consists of a collection of local fields $\Psi_\Lambda$ defined on spacetime together with a local action functional $S_\Lambda[\Psi_\Lambda]$. The associated equations of motion are required to admit solutions that approximate, up to resolution $\Lambda$, the projection of the admissible history space $\mathcal{H}_{\mathrm{adm}}$ onto local observables. In this sense, an interface theory provides a compressed, scale-dependent representation of global admissibility constraints in a form suitable for local, covariant analysis.


The interface is \emph{minimal} if no proper subset of $\Psi_\Lambda$ suffices to preserve admissibility information.

\subsection{Metric Emergence}

\paragraph{Proposition A.1 (Uniqueness of Metric Interface).}
If an interface theory is required to be local, diffeomorphism covariant, and capable of encoding relative deformation penalties between nearby admissible histories, then its effective field content must include a symmetric rank-two tensor field $g_{\mu\nu}$. This tensor provides the minimal structure necessary to represent local notions of distance, causal separation, and comparative deformation in a coordinate-independent manner. No scalar or vector field suffices to encode these relational properties under arbitrary diffeomorphisms, and higher-rank tensors introduce unnecessary structure at the interface level. The metric tensor therefore appears as the unique minimal carrier of admissibility information consistent with locality and covariance.


\emph{Sketch of Proof.}
Local covariance restricts interface variables to tensorial objects on $M$. Scalars are insufficient to encode directional penalties; vectors fail to couple universally to stress-energy. A rank-2 symmetric tensor uniquely satisfies these requirements. $\square$

\subsection{Relation to Wilsonian Renormalization}

Under successive projections $\mathcal{P}_{\Lambda_1} \circ \mathcal{P}_{\Lambda_2}$ with $\Lambda_2 < \Lambda_1$, the effective action satisfies
\[
S_{\Lambda_2} = \mathcal{R}_{\Lambda_2 \leftarrow \Lambda_1}(S_{\Lambda_1}),
\]
where $\mathcal{R}$ denotes the renormalization group map.

\paragraph{Interpretation.}
In the admissibility framework, RG flow corresponds to repeated enforcement of admissibility preservation under increasing loss of microscopic detail. Relevant and marginal operators correspond to constraint summaries stable under projection; irrelevant operators encode microscopic structure that does not affect global consistency.

\subsection{Status of Analyticity and Spectral Positivity}

Because the admissibility constraint functional $\mathcal{C}$ is fundamentally irreversible, there is no requirement that the induced effective interface theory be invariant under time reversal or satisfy the axioms ordinarily associated with reflection positivity. In particular, the existence of a positive-definite Källén--Lehmann spectral representation cannot be assumed at the microscopic level. These properties are instead understood as emergent features that may hold approximately in the infrared regime, where coarse-graining suppresses sensitivity to irreversibility. At higher resolutions, however, analyticity and spectral positivity are not fundamental constraints on the interface theory, and their violation signals the breakdown of the geometric description rather than a failure of consistency.

\paragraph{Conclusion of Appendix.}
All structures employed in the main text follow directly from the existence of a global admissibility constraint, the irreversibility of constraint violation, and the necessity of local predictive compression for finite observers. No independent assumption of fundamental geometry is required, nor is any prior commitment to microscopic unitarity or analyticity. These features arise only at the level of the effective interface description and are therefore contingent, scale-dependent properties rather than foundational principles.

\section{Spectral Representation, Causality, and Regulator Modes}
\label{app:spectral}

This appendix reviews the assumptions underlying standard spectral representations in quantum field theory and explains why their controlled violation is both expected and benign in an admissibility-first framework. Particular attention is given to higher-derivative propagators and the appearance of reversed-causal regulator modes.

\subsection{The Källén--Lehmann Representation and Its Assumptions}

In relativistic quantum field theory, the two-point function of a scalar operator $\mathcal{O}(x)$ admits the Källén--Lehmann (KL) spectral representation
\[
\langle 0 | \mathcal{O}(x)\mathcal{O}(y) | 0 \rangle
=
\int_0^\infty d\mu^2 \, \rho(\mu^2)\, \Delta_+(x-y;\mu^2),
\]
where $\rho(\mu^2) \ge 0$ is the spectral density and $\Delta_+$ is the positive-frequency Wightman function.

The existence of such a representation relies on several structural assumptions that are standard in conventional quantum field theory. These include the presence of a stable vacuum state, the completeness of asymptotic particle states, and invariance under microscopic time reversal. In addition, the construction presupposes a positive-definite Hilbert space inner product together with local commutativity of observables at spacelike separation. Collectively, these assumptions encode the requirements of spectral positivity, microcausality, and reversible dynamics that underlie the usual Källén--Lehmann framework. 

While these assumptions hold for standard renormalizable theories with second-order equations of motion, none of them follows from locality alone. In particular, spectral positivity is a \emph{consequence} of reversibility and unitarity assumptions, not an independent physical principle.

\subsection{Higher-Derivative Propagators}

Consider a quadratic action for a field $\phi$ with higher derivatives,
\[
S = \int d^4x \, \phi \left( \Box + \frac{\Box^2}{M^2} \right) \phi .
\]
The corresponding momentum-space propagator is
\[
G(k^2) = \frac{1}{k^2} - \frac{1}{k^2 - M^2}.
\]

This propagator falls as $1/k^4$ at large momentum, ensuring ultraviolet damping. However, it cannot be written in KL form with a positive spectral density: the second term carries the opposite sign.

\paragraph{Observation.}
Any local propagator with asymptotic behavior faster than $1/k^2$ necessarily violates spectral positivity. This is not a peculiarity of gravity but a general consequence of locality and power-counting renormalizability.

\subsection{Contour Prescription and Reversed-Causal Modes}

The presence of an additional pole does not, by itself, determine the physical interpretation of the corresponding mode. The interpretation depends on the choice of contour in the complex energy plane.

In higher-derivative theories, consistency requires assigning opposite $i\epsilon$ prescriptions to different poles. Concretely, one chooses
\[
\frac{1}{k^2 - M^2} \;\;\to\;\; \frac{1}{k^2 - M^2 - i\epsilon},
\]
which corresponds to a mode that propagates backward in time over microscopic intervals.

\paragraph{Interpretation.}
Such modes do not represent physical asymptotic particles. They are unstable, decay rapidly, and do not appear in in/out states. Their role is regulatory: they enforce ultraviolet admissibility while preserving unitarity of observable processes.

\subsection{Unitarity of the S-Matrix}

Despite the modified analytic structure, unitarity of the S-matrix is preserved. This can be demonstrated using the largest-time equation, which shows that only stable asymptotic states contribute to unitarity cuts.

Because reversed-causal modes never appear as asymptotic states, they do not enter the unitarity sum. Their contributions cancel internally, leaving the standard optical theorem intact for physical processes.

\paragraph{Key Point.}
Unitarity constrains observable transitions between admissible histories. It does not require positivity of intermediate virtual states.

\subsection{Microcausality and Its Domain of Validity}

Standard microcausality demands vanishing commutators at spacelike separation,
\[
[\mathcal{O}(x),\mathcal{O}(y)] = 0 \quad \text{for} \quad (x-y)^2 < 0.
\]

In higher-derivative theories with reversed-causal regulator modes, this condition fails at distances comparable to $1/M$. However, the violation is exponentially suppressed and disappears in the infrared limit.

\paragraph{Interpretation.}
Microcausality is an emergent property of the low-energy interface, not a fundamental constraint on admissibility. Its breakdown signals the scale at which geometric compression ceases to be faithful.

\subsection{Relation to Irreversible Admissibility}

The admissibility-first ontology provides a natural explanation for these features. Global constraints are enforced irreversibly across entire histories. When such constraints are compressed into a local, time-symmetric interface, compensation channels necessarily appear.

Reversed-causal regulator modes are the mathematical expression of this compensation. They restore consistency at the interface level without corresponding to physical degrees of freedom in the underlying ontology.

\paragraph{Conclusion of Appendix.}
Violations of spectral positivity and microscopic causality in quadratic gravity are not inconsistencies. They are unavoidable consequences of enforcing ultraviolet admissibility using local geometric variables. When interpreted correctly, they preserve unitarity, locality at observable scales, and predictive control within the effective field theory regime.

\section{Ostrogradsky Stability and the RSVP--Geometry Correspondence}
\label{app:rsvp_geometry}

This appendix addresses two related concerns. First, it revisits the Ostrogradsky instability in the context of higher-derivative metric actions and explains why it does not arise when time evolution is not fundamental. Second, it makes explicit the correspondence between the fields of the RSVP Lagrangian and geometric curvature invariants appearing in the metric interface.

\subsection{Ostrogradsky’s Theorem and Its Domain of Applicability}

Ostrogradsky’s theorem states that non-degenerate Lagrangians containing higher than first-order time derivatives lead to Hamiltonians that are unbounded from below. This result is often invoked as a no-go theorem against higher-derivative gravity.

However, the theorem in question relies on several assumptions that are not satisfied in an admissibility-first ontology. It presupposes that time evolution is fundamental and generated by a Hamiltonian acting on a phase space of states, that canonical coordinates and momenta exist globally, and that all degrees of freedom correspond to physical states propagating forward in time. None of these assumptions holds in the present framework. Instead, the fundamental object is taken to be a space of admissible histories rather than a phase space equipped with Hamiltonian evolution.

The spacetime metric appears only as an interface variable used to encode admissibility constraints in a local and covariant form, rather than as a fundamental dynamical degree of freedom. Higher-derivative terms in the effective action are therefore interpreted not as introducing independent propagating dynamics, but as encoding penalties associated with constraint violation under coarse-graining. From this perspective, the failure of the theorem reflects the inapplicability of its underlying assumptions rather than an inconsistency of the interface theory itself. 

As a result, Ostrogradsky’s construction does not apply. There is no requirement that the interface action admit a globally bounded Hamiltonian, because the interface does not define fundamental time evolution.

\paragraph{Key Point.}
Ostrogradsky instability constrains theories in which higher derivatives represent additional propagating degrees of freedom. In the RSVP framework, higher derivatives represent curvature sensitivity of admissibility, not new physical modes.

\subsection{RSVP Fields and Admissibility Structure}

The RSVP framework is defined in terms of three interacting fields:
\[
(\Phi, V_\mu, S),
\]
where $\Phi$ is a scalar density field, $V_\mu$ is a vector flow field, and $S$ is an entropy field governing irreversible admissibility.

The RSVP action takes the schematic form
\[
\mathcal{L}_{\text{RSVP}} = \mathcal{L}_\Phi(\partial \Phi)
+ \mathcal{L}_V(\nabla V)
+ \mathcal{L}_S(\partial S)
+ \mathcal{L}_{\text{int}}(\Phi, V, S),
\]
with the defining feature that $S$ enforces monotonic admissibility along histories.

\subsection{Coarse-Graining and Emergent Geometry}

Under coarse-graining to length scales $\ell \gg \ell_{\text{RSVP}}$, the detailed configurations of the RSVP fields are projected onto a reduced effective description. The resulting effective variables are required to transform covariantly under spacetime diffeomorphisms, to admit a local formulation to leading order in derivatives, and to remain sensitive to gradients and flows associated with admissibility. These requirements ensure that the reduced description faithfully encodes the macroscopic structure of admissible histories while remaining suitable for local, predictive analysis.


These requirements uniquely select a metric tensor $g_{\mu\nu}$ as the effective interface variable. The metric encodes the distortion of admissible histories under local deformation.

\paragraph{Interpretation.}
The metric does not represent distances between points in an underlying manifold, but penalties associated with deforming admissible RSVP configurations.

\subsection{Mapping RSVP Invariants to Curvature Scalars}

We now make the correspondence explicit.

\subsubsection*{Scalar Sector: $\Phi \rightarrow R$}

Spatial variation of the scalar density field $\Phi$ contributes to local admissibility gradients. At leading order, the invariant encoding second derivatives of $\Phi$ is the Ricci scalar:
\[
R \;\sim\; \nabla_\mu \nabla^\mu \log \Phi + \mathcal{O}((\nabla \Phi)^2).
\]
Thus, the Einstein--Hilbert term arises as the lowest-order scalar penalty on nonuniform admissibility density.

\subsubsection*{Vector Sector: $V_\mu \rightarrow R_{\mu\nu}$}

The vector field $V_\mu$ encodes directed admissibility flow. Its shear and vorticity under coarse-graining map naturally to the Ricci tensor:
\[
R_{\mu\nu} \;\sim\; \nabla_{(\mu} V_{\nu)} + \cdots .
\]
Quadratic contractions $R_{\mu\nu}R^{\mu\nu}$ therefore encode penalties on incompatible directional admissibility flow.

\subsubsection*{Entropy Sector: $S \rightarrow C_{\mu\nu\rho\sigma}C^{\mu\nu\rho\sigma}$}

The entropy field $S$ governs irreversible constraint enforcement. Its coarse-grained fluctuations correspond to conformal distortion of admissibility structure rather than volume change.

These distortions are captured by the Weyl tensor $C_{\mu\nu\rho\sigma}$. Consequently,
\[
(\nabla S)^2 \;\longrightarrow\; C_{\mu\nu\rho\sigma}C^{\mu\nu\rho\sigma}
\]
at the level of quadratic interface penalties.

\paragraph{Summary Mapping.}
\[
\begin{aligned}
\Phi &\longrightarrow R \\
V_\mu &\longrightarrow R_{\mu\nu} \\
S &\longrightarrow C_{\mu\nu\rho\sigma}C^{\mu\nu\rho\sigma}
\end{aligned}
\]

\subsection{Quadratic Gravity as RSVP Interface Closure}

Combining these correspondences, the most general quadratic metric action is seen to be the closure of admissibility penalties arising from RSVP coarse-graining:
\[
S_{\text{QG}} = \int d^4x \sqrt{-g}
\left(
\alpha R^2
+ \beta R_{\mu\nu}R^{\mu\nu}
+ \gamma C_{\mu\nu\rho\sigma}C^{\mu\nu\rho\sigma}
\right).
\]

These terms do not represent independent dynamical choices. They are the geometric image of RSVP constraint enforcement once locality and covariance are imposed.

\subsection{Why No New Degrees of Freedom Appear}

Because the metric is an interface variable, poles appearing in its propagator do not correspond to new admissible histories. They encode the failure modes of compression at high resolution.

The reversed-causal regulator mode (the ``heavy ghost'') is therefore not an instability but a necessary correction ensuring that inadmissible RSVP configurations do not leak into the low-energy interface.

\paragraph{Conclusion of Appendix.}
Higher-derivative curvature terms arise naturally when RSVP admissibility constraints are compressed into a local geometric interface. Ostrogradsky instabilities do not apply because the interface does not define fundamental time evolution. Quadratic gravity is thus stabilized not by fine-tuning but by ontological role separation between admissibility and geometry.

\section{Wilsonian Renormalization as Entropic Admissibility Flow}
\label{app:rg_entropy}

This appendix formalizes the relationship between Wilsonian renormalization group (RG) flow and the admissibility-first ontology introduced in the main text. We show that RG flow is naturally reinterpreted as an irreversible entropic filtering process acting on the space of admissible histories. This correspondence provides an ontological grounding for effective field theory methods without modifying their technical content.

\subsection{Wilsonian Renormalization Group: A Brief Structural Review}

In the Wilsonian formulation, a quantum field theory is defined at a cutoff scale $\Lambda$ by an action
\[
S_\Lambda[\varphi] = \int d^4x \sum_i g_i(\Lambda)\,\mathcal{O}_i(x),
\]
where $\mathcal{O}_i$ are local operators and $g_i(\Lambda)$ their scale-dependent couplings.

RG flow describes how $S_\Lambda$ changes under an infinitesimal reduction of the cutoff,
\[
\Lambda \rightarrow \Lambda - d\Lambda,
\]
by integrating out field configurations with momenta in the shell
\[
\Lambda - d\Lambda < |k| < \Lambda.
\]

The resulting flow equations,
\[
\Lambda \frac{d g_i}{d\Lambda} = \beta_i(\{g\}),
\]
are traditionally interpreted as encoding how physics changes with resolution.

\paragraph{Standard Interpretation.}
RG flow is often described as a trajectory through theory space, parametrized by energy scale, with no intrinsic arrow beyond convention.

\subsection{Irreversibility of RG Flow}

Despite its formal reversibility as a set of differential equations, RG flow is physically irreversible. Once high-momentum modes are integrated out, the microscopic information they carried cannot be reconstructed from the effective action alone.

This irreversibility is usually treated as epistemic: a consequence of limited observational resolution. In the admissibility-first framework, it is elevated to an ontological principle.

\paragraph{Observation.}
RG flow defines a partial order on effective theories:
\[
S_{\Lambda_1} \prec S_{\Lambda_2} \quad \text{for} \quad \Lambda_1 < \Lambda_2,
\]
where $\prec$ denotes loss of admissibility-resolving power.

\subsection{Admissibility Space and RG Projection}

Let $\mathcal{H}_{\text{RSVP}}$ denote the space of RSVP histories satisfying global admissibility constraints. Define a projection operator
\[
\mathcal{P}_\Lambda : \mathcal{H}_{\text{RSVP}} \rightarrow \mathcal{H}_\Lambda
\]
that maps a fine-grained history to its coarse-grained representative at scale $\Lambda$.

Two properties follow immediately from the definition of the coarse-graining map $\mathcal{P}_\Lambda$. First, the map is intrinsically non-invertible, in the sense that many distinct microscopic histories are projected onto a single effective history at scale $\Lambda$. Second, the projection preserves admissibility in the following sense: if a microscopic history violates the admissibility constraint at length scales less than or equal to $1/\Lambda$, then this violation is necessarily reflected in the reduced history space $\mathcal{H}_\Lambda$ as an inadmissible effective configuration. The coarse-graining procedure therefore erases microscopic detail while retaining information relevant to global consistency.


Thus, RG flow is not merely averaging—it is a filter that preserves violations while discarding redundant detail.

\subsection{Entropy and the Arrow of RG Flow}

The RSVP entropy field $S$ provides a natural measure of coarse-graining irreversibility. Define an effective entropy functional
\[
\mathcal{S}(\Lambda) = \log \left| \mathcal{P}_\Lambda^{-1}(H_{\text{eff}}) \right|,
\]
the logarithm of the number of fine-grained admissible histories compatible with a given effective history.

As $\Lambda$ decreases, the preimage $\mathcal{P}_\Lambda^{-1}$ grows monotonically, implying
\[
\frac{d\mathcal{S}}{d\log \Lambda} \leq 0.
\]

\paragraph{Interpretation.}
RG flow is an entropic descent in admissibility space. The direction of flow is fixed not by convention but by irreversible information loss.

\subsection{Relevant Operators as Protected Constraints}

Within this framework, the classification of operators acquires a precise ontological interpretation. Relevant operators correspond to admissibility constraints that remain resolvable under coarse-graining and therefore continue to influence the effective dynamics at scale $\Lambda$. Marginal operators encode constraints that lie at the threshold of resolvability, contributing logarithmically or weakly to the effective description. Irrelevant operators, by contrast, represent microscopic structure whose detailed configuration does not affect admissibility at the coarse-grained scale and is consequently filtered out by the projection process. In this way, the Wilsonian hierarchy of operators is reinterpreted as a hierarchy of constraint survivability under irreversible compression.

This explains why low-energy physics is dominated by a small number of operators despite the vast space of microscopic possibilities.

\paragraph{Example.}
In gravity, curvature invariants of low derivative order survive RG flow because they encode large-scale admissibility penalties. Higher-derivative terms are suppressed unless required to maintain ultraviolet admissibility.

\subsection{Fixed Points and Interface Stability}

RG fixed points correspond to stable interface descriptions: effective theories whose admissibility summaries are self-consistent under further coarse-graining.

In the admissibility-first interpretation, fixed points are not fundamental laws but stable compression attractors.

\paragraph{Key Point.}
The existence of fixed points does not imply fundamental simplicity. It reflects the robustness of certain constraint summaries under lossy projection.

\subsection{Quadratic Gravity and RG Closure}

Quadratic curvature terms arise precisely at the scale where the Einstein--Hilbert interface ceases to suppress inadmissible fluctuations. Their appearance in RG flow signals the need to extend the interface, not to introduce new degrees of freedom.

The heavy regulator mode associated with quadratic gravity corresponds to the least irrelevant correction capable of restoring admissibility at high resolution.

\subsection{Conclusion of Appendix}

Wilsonian renormalization group flow is the operational manifestation of admissibility filtering under irreversible coarse-graining. The success of effective field theory, the stability of low-energy laws, and the inevitability of quadratic gravity all follow from this single structural fact.

RG flow does not reveal how laws evolve with energy. It reveals which summaries of global constraint survive compression.

\begin{thebibliography}{99}

\bibitem{DonoghueEFTIntro}
J.~F.~Donoghue,
\emph{Introduction to the Effective Field Theory Description of Gravity},
arXiv:gr-qc/9512024 (1995).

\bibitem{DonoghueEFTGR}
J.~F.~Donoghue,
\emph{General Relativity as an Effective Field Theory: The Leading Quantum Corrections},
Phys.\ Rev.\ D \textbf{50}, 3874--3888 (1994).

\bibitem{DeWittQG}
B.~S.~DeWitt,
\emph{Quantum Theory of Gravity I–III},
Phys.\ Rev.\ \textbf{160}, 1113--1148 (1967).

\bibitem{FeynmanGrav}
R.~P.~Feynman,
\emph{Quantum Theory of Gravitation},
Acta Phys.\ Polon.\ \textbf{24}, 697 (1963).

\bibitem{WilsonRG}
K.~G.~Wilson,
\emph{The Renormalization Group and Critical Phenomena},
Rev.\ Mod.\ Phys.\ \textbf{55}, 583 (1983).

\bibitem{BurgessQG}
C.~P.~Burgess,
\emph{Quantum Gravity in Everyday Life},
Living Rev.\ Relativ.\ \textbf{7}, 5 (2004).

\bibitem{StelleQG}
K.~S.~Stelle,
\emph{Renormalization of Higher-Derivative Quantum Gravity},
Phys.\ Rev.\ D \textbf{16}, 953--969 (1977).

\bibitem{DonoghueMenezes}
J.~F.~Donoghue and G.~Menezes,
\emph{Unitarity, Causality, and Stability in Quantum Gravity},
Phys.\ Rev.\ D \textbf{100}, 105006 (2019).

\bibitem{NielsenRandom}
H.~B.~Nielsen,
\emph{Random Dynamics and Relations Between the Number of Fermion Generations and the Fine Structure Constants},
Acta Phys.\ Polon.\ B \textbf{20}, 427 (1989).

\bibitem{tHooftNaturalness}
G.~'t~Hooft,
\emph{Naturalness, Chiral Symmetry, and Spontaneous Chiral Symmetry Breaking},
in \emph{Recent Developments in Gauge Theories},
NATO ASI Series B \textbf{59}, 135 (1980).

\bibitem{Prigogine}
I.~Prigogine,
\emph{From Being to Becoming},
W.~H.~Freeman, San Francisco (1980).

\bibitem{Landauer}
R.~Landauer,
\emph{Irreversibility and Heat Generation in the Computing Process},
IBM J.\ Res.\ Dev.\ \textbf{5}, 183 (1961).

\bibitem{Barandes}
J.~Barandes,
\emph{The Physical Meaning of the Wave Function},
arXiv:1808.07354 (2018).

\bibitem{TessmannRossi}
O.~Tessmann and A.~Rossi,
\emph{Geometry as Interface: Parametric and Combinatorial Topological Interlocking Assemblies},
J.\ Appl.\ Mech.\ \textbf{86}, 111002 (2019).

\end{thebibliography}

\end{document}