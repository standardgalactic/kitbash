CHAPTER SEVEN
From Nature to Technology

YaMoR—an acronym for Yet another Modular Robot—is an experimental robot constructed with hinged components, a bit like the segments of a millipede, that can be arranged in a straight line to undulate like a worm, or in leglike pairs to crawl like an amphibian, or even to walk like an insect. And these segments are smart, equipped with reconfigurable hardware, each segment containing a computer chip that can be rewired a bit like a human brain. Built the right way, such robots could learn on the job by rewiring themselves when they need new skills.
Constructed at one of the world’s leading engineering schools, the École Polytechnique Fédérale de Lausanne in Switzerland, YaMoR is a member of a growing family of modular robots created in engineering labs around the world. The family is large but its members lack much resemblance, because their body plans are very different. Some modular robots are dielike cubes, some chains of tetrahedrons. Others are clusters of balls, and still others strings of rotating wheels. Modular robots like YaMoR seem limited only by the constraints of solid geometry.
More than 540 million years before YaMoR took its first steps, an even more diverse family of body plans arose, in a burst of biological innovation known as the Cambrian explosion. It gave rise to every animal body plan now in use, along with dozens more that are extinct, like the entire phylum of limbless segmented marine animals known as the Vetulicolia. YaMoR’s phylum is much more primitive than the Vetulicolia, but if the warp drives that accelerate nature’s innovation could be put to work in human technology, robotic or otherwise, then the first Cambrian explosion may not have been the last. 
This idea—that analogs of genotype networks could accelerate innovation in technology—is not so far-fetched, as we shall see. A first hint is that innovation in nature and innovation in technology show many parallels.
Trial and error, for one thing. Thomas Edison, an archetype of inventive genius, “tested no fewer than 6,000 vegetable growths, and ransacked the world for the most suitable filament material” until he eventually stumbled upon bamboo as the best solution for the fickle filaments of his incandescent light bulb. One of the dozens of quotations attributed to him sums it up: “I have not failed. I have just found ten thousand ways that do not work.” The quote reminds everyone that trial and error—especially error—is as crucial to technological innovations as to biological ones. And it is no less crucial today than in Edison’s time. John Backus, a co-creator of the highly successful computer programming language Fortran, which helps scientists simulate and understand the universe, from the motions of atoms to those of galaxies, said that “you need the willingness to fail all the time. You have to generate many ideas and then you have to work very hard only to discover that they don’t work. And you keep doing that over and over until you find one that does work.” 
To be sure, failure has different consequences in evolution than it does for an inventor with a failed light bulb or for a scientist with a disproved theory. A bar-headed goose with a mutant hemoglobin produced by nature’s tinkering with DNAis a living experiment. If the mutation improves its ability to scavenge oxygen from thin air, great. But woe unto the bird whose mutant globin can no longer bind oxygen. Its lights go out permanently.
Failure in science and technology does not usually mean bodily death, but this does not mean that ideas die easily. Sir Fred Hoyle, one of the world’s most prominent astronomers and astrophysicists, went to his death in 2001 not only denying the Big Bang theory but defending the belief that flu epidemics arise when a lull in the solar wind allows extraterrestrial flu viruses to enter the atmosphere. The nineteenth century’s Lord Kelvin used the laws of thermodynamics—and his Christian faith—to underestimate the age of the earth more than a hundredfold. The historical battlefields of science and technology are littered with brilliant minds who took wrong beliefs to their graves. Max Planck, a father of quantum theory, observed that “a new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die, and a new generation grows up that is familiar with it.” Science, like nature, advances one funeral at a time. 
One of nature’s antidotes against catastrophic failure has been accidentally co-opted by technological innovators: populations. Great inventions aren’t the work of solitary geniuses any more often than nature’s libraries are explored by single organisms. Despite the cliché of human innovators conjuring unimagined worlds from the depths of their minds—from Archimedes in his bathtub to Einstein in his patent office—the truth is that technological innovation depends on the same kind of crowdsourcing that biological innovation uses when its chemical libraries are explored by armies of browsers. A team of people developed Fortran, and Edison used dozens of assistants to create and test new designs for light bulbs, telephones, and telegraphs. The nineteenth-century Industrial Revolution was made possible by the rise of an entire new class—highly educated artisans far more numerous than aristocratic gentlemen scientists—who needed to make money from their work and created a flurry of inventions from steam engines to automatic looms. And today, any new technology, from new cell phones to new drugs and new energy carriers, requires armies of scientists and engineers, intense competition, and myriad failures before finding success. Given the importance of trial and error, it’s hard to see how it could be otherwise: The more explorers, the more solutions can be explored, with correspondingly greater odds of success.
And when the armies of technological innovators advance, they do so on many fronts simultaneously—again like nature. The American sociologist Robert Merton, who also coined the terms “role model” and “self-fulfilling prophecy,” is well remembered in the history of sciences for documenting the prevalence of inventions with multiple origins—he simply called them “multiples.” The list is nearly endless: The relation between the heat and pressure of a gas is known as Boyle’s law in English-speaking countries, and as Mariotte’s law to Francophones, since the same phenomenon was independently derived by Robert Boyle and Edme Mariotte. Robert Fulton, the Marquis de Jouffroy, and James Rumsey are all “inventors” of the first steamboats. The thermometer has at least six different inventors, and calculus, as is well known, was created almost simultaneously by both Isaac Newton and Gottfried Wilhelm Leibniz. Elisha Gray filed for a patent on a working telephone the same dayas Alexander Graham Bell (though Bell won the subsequent legal wrangle over priority). 
Multiple origins are possible because the problems of technology—like those of biology—have multiple solutions. Among the best-documented biological examples are the innovations that remove carbon dioxide from the atmosphere, a process called carbon fixation by biologists and carbon scrubbing by engineers. The premier biological carbon scrubber is the one used by plants, an enzyme that attaches carbon dioxide to a sugar called ribulose-1,5-bisphosphate. It then modifies this carrier further, such that the carbon dioxide eventually becomes part of the plant’s body. This is not only how plants grow and how carbon gets into the fossil fuels we burn. It is also the way carbon dioxide is fed back into the cycle of life. But plants are not the only organisms that fix carbon: Some microbes attach it to the carrier molecule acetyl-CoA, and others add it to molecules from the ancient citric acid cycle. Environmental engineers—they seek to solve the same problem to forestall catastrophic climate change—have already come up with several further carbon-scrubbing technologies that use molecules like monoethanolamine and sodium hydroxide.
Other examples of Merton’s multiples are legion. An automobile’s engine can use reciprocating pistons or an eccentric rotor, and it can trigger fuel combustion with the spark plug of a gasoline engine or through the heat of compression in a diesel engine. Organisms can detect light waves using a flexible single lens, or the rigid compound eye of a fly. Antifreeze proteins of Arctic and Antarctic fish, transparent crystallins that originate from different enzymes, and highly diverse oxygen-binding globins are all multiple solutions to similar problems.
Another commonality of both technological and biological innovations is that they endow old things with new life. The history of technological innovation is practically saturated in examples. In the words of the writer Stephen Johnson, Johannes Gutenberg borrowed “a machine designed to get people drunk”—a screw-driven wine press—“and turned it into an engine of mass communication.” Microwave ovens heat food with a technology originally developed for radar—a radar engineer discovered its heating powers when it melted a chocolate bar in his pocket. (The first commercial version was called the “Radarange.”) The lightweight synthetic Kevlar, originally developed to replace steel in racing tires, has been co-opted for bulletproof vests and steel helmets. The same principle is at work even in mundane contraptions that barely deserve the label “innovation.” A door placed on two sawhorses can make a great desk. Boots can serve as low-tech doorstops. Milk crates can make wonderful filing cabinets, and so on. Edison said it well: “To invent, you need a good imagination and a pile of junk.” 
In 1982, the paleontologists Stephen Jay Gould and Elizabeth Vrba baptized the biological version of this phenomenon “exaptation.” (Once again, Darwin had gotten there first—he reminded the Origin’sreader that “an organ originally constructed for one purpose  .  .  . may be converted into one for a widely different purpose.”)18A classic example of exaptation is the bird’s feather, a complicated assemblage of fibrous proteins called keratins, the same proteins that make up the scales of reptiles. The first feathers were most likely involved in insulation or waterproofing, and were only later co-opted—“exapted”—for flying. Such exaptations also abound in molecules, including those regulators that help make feathers. One of them is a protein called “Sonic hedgehog”—yes, it is named for the character in the eponymous video game—that helps control the growth of both fingers and spinal cord in your body, but was co-opted in birds to sculpt feathers. Likewise, a regulator protein that helps shape legs in some organisms was co-opted to paint eyespots in others, and metabolic enzymes were co-opted as the crystallins of lenses.
Such co-option is a special case of a final parallel between nature and technology: Innovation is combinatorial. It combines old things to make the new. We encountered combinatorial innovations first in metabolism, where new combinations of old reactions turned toxins like pentachlorophenol into fuels to manufacture biomass, and allowed our ancestors to detox their bodies by synthesizing urea. In proteins they are new combinations of old amino acids, and in regulation circuits they are new combinations of interacting regulators. But a technological innovation like the aviation-transforming jet engine is just as combinatorial. Its three principal parts are a compressor that increases the air’s pressure, a combustion chamber that mixes air with fuel and ignites the mixture, and a rotating turbine that generates thrust from the expanding mixture. None of these three elements were new when half a dozen British, German, Hungarian, and Italian engineers—remember those multiples—were building the first jet engines in the twentieth century. The earliest compressors were bellows used to run forges more than two thousand years ago, and have been used in industrial blowers ever since. Combustion chambers had been central to both steam locomotives and internal combustion engines. Archimedes had invented a screw turbine in the third century BC, and the first gas turbine was patented in England in the late eighteenth century.
The jet engine is scarcely unique as a combinatorial innovation. Decades ago, social scientists like the economist Joseph Schumpeter and the sociologist S. Colum Gilfillan argued that combining the old to make the new is essential for technological innovation. In his book The Nature of Technologythe economist W. Brian Arthur goes further to say that even entire “technologies somehow must come into being as fresh combinations of what already exists.” So too in biology, as we heard in previous chapters: All evolutionary innovations, discovered as they are in searches through nearly infinite libraries, are combinatorial, just as new books combine old letters into new meanings.
Trial and error. Populations. Multiple origination. Combination. With all these parallels between technology and nature, it is little surprise that technologists would try to mimic nature’s innovability. And I do not just mean biotechnologsts, whose innovations are already legion, from the enzymes in our laundry detergents that turn my ten-year-old’s mud-caked pants spotless, to the engineered forms of insulin used by diabetics, to crops that have been genetically modified to produce a powerful bacterial toxin that kills insects preying on them. Because biotechnology uses biological materials, it already takes advantage of nature’s libraries. The bigger question is whether technologies built on man-made materials—glass, plastic, or silicon, like YaMoR—can do the same.
Technologists made a big first step to answer this question when they realized that evolution follows an algorithm,a recipe so simple and stereotypical that it could be executed by a machine. By altering DNA, mutations create organisms with new phenotypes, and selection allows some of them to survive and reproduce. Mutate. Select. Repeat over and over. Those technologists who know their automata—computer scientists—created an entirely new research field from this insight, one that revolves around evolutionary algorithms:recipes that use some form of mutation and selection to solve really difficult real-world problems, entirely inside a computer. 
An especially famous and difficult such problem is known as the traveling salesman problem, a mathematical puzzle first formulated in the mid-nineteenth century by the Irish mathematician William Rowan Hamilton. The basics are simple: A salesman has to visit dozens of potential faraway clients all on a regular basis. Each of them lives in a different city. The salesman spends a lot of time on the road and in the air. To spend more time with his family, he would like to keep each trip as short as possible and still visit all cities. The problem is to find a travel route that takes him to each city in turn, and then back home at the end of the trip, as quickly and efficiently as possible.
This problem is a lot harder than it sounds. For a mere handful of cities, anybody could design the shortest possible route. But once the number of cities increases beyond a few dozen, the optimal route becomes surprisingly difficult to find. The traveling salesman problem is what computer scientists call a “nondeterministic, polynomial-hard” problem. It is among the hardest of all puzzles that can be imagined, mainly because the number of potential solutions increases exponentially as new cities are added.
Thousands of papers have been written about this problem, because it isn’t just for sales forces. Designers of computer chips face it too. Such chips contain thousands to millions of components that are wired together and exchange data. Because short wires between them can save energy and accelerate computations, designers of such chips need to find shortest possible routes that connect many circuit components (“cities”). Truckers who deliver goods to multiple department stores also know this problem, as does Federal Express, and so do school buses that pick up multiple children within a school district. Even bumblebees face it: A foraging bee might visit hundreds of flowers before returning to the hive, and cannot afford to waste energy on excessive travel. 
It’s possible to calculate perfectsolutions to the traveling salesman problem for up to thousands of “cities,” using sophisticated mathematical techniques with deceptively simple names like “cutting plane” and “branch-and-bound.” Such techniques can produce near-perfectsolutions for up to millions of cities.But even an algorithm as blind and mindless as that used by biological evolution can tackle the problem, by instructing a computer to start with a completely arbitrary solution—any solution at all, no matter how bad. The computer’s program then mutates the solution randomly, changes the route between a few cities (or stores, or schools, or flowers), and checks to see whether the new route is shorter than the old one. If so, the program selects that mutant. Next, it tries a new mutation, and checks whether this mutation shortens the route. If not, it rejects the mutation, reverts to the original route, and begins again with a new mutation. Over many generations, this simple algorithm produces shorter and shorter routes, and eventually arrives at good if not perfect solutions. 
Evolutionary algorithms like this are also being put to work in some surprising places. Military planners use them to plot optimal routes for unmanned drones that patrol hostile territories. Cryptographers use them to encode sensitive data. Fund managers use them to predict the movements of financial markets. And automotive engineers use them to change how an engine operates, by optimizing the time or pressure at which fuel is injected into the engine. And those algorithms do indeed improve fuel efficiency.
What they don’t do is revolutionize engine design. 
The evolutionary algorithms that mimic biological evolution are powerful tools, but they’re still missing something. They are still deficient in the recombination department so central to biological innovations. Nature is better at recombination, much better, for one simple reason: standards.
As we’ve seen in chapter 2, standards like the universal energy standard ATP and the universal genetic code are a sign of life’s common origin. The absence of such standards makes recombination more difficult in technology, which often uses ingenuity as a substitute. It took plenty of ingenuity to recombine a compressor, a combustion chamber, and a turbine to lift a plane’s many tons of metal into the air. The same holds for the combustion engines of today’s cars, whose parts are connected through one-of-a-kind links, like pistons and valves that need to be precision engineered to fit a cylinder. And likewise for signature inventions of the Industrial Revolution. The first practical steam engines combined steam-powered toys originally invented in second-century Alexandria with vacuum pumps from seventeenth-century Germany. Bench vises joined two of the simple machines of antiquity, a lever-handle and a screw. The first bicycles combined three, the wheel, the lever, and the pulley. All of these combinatorial innovations required ingenuity.
It’s not that standards are absent from technology, far from it. Technology relies not only on universal laws of nature established by science, but also on standardized ways of measuring quantities like temperature, mass, or electric charge. But most technologies are deficient in a certain kind of standard, the one that allows nature to combine the old to make the new. Nature needs these standards, precisely because it does not have the ingenuity of human inventors.
All the different things that proteins can do—catalyze reactions, transport molecules, support cells—emerge from strings of building blocks connected in the same way, through a standardized chemical connection called the peptide bond,where an atom of nitrogen from one amino acid bonds with an atom of carbon from its neighbor. Even though each amino acid has a different shape, they can all connect in the same way, because they share a universal interface. And this standard, used by all organisms, has made life as we know it possible. It allows nature to cobble together—blindly, without any ingenuity—the astronomical numbers of genotypes needed to find innovations.
Standards that make recombination mindlessly easy do not just exist in proteins. RNA strings also use a standardized chemical bond to link their parts. Furthermore, life’s standard of information storage—DNA—allows bacteria to exchange genes and create new metabolisms from new combinations of the enzymes they encode. And finally, regulation circuits use a standardized way to regulate genes, based on the principle that regulator proteins can bind specific short words on DNA, allowing nature to combine old regulators into countless new circuits by changing these words. If we could take a small number of different objects, create a standard way to link them, and recombine them into every conceivable configuration—mindlessly—our powers to innovate could be just as immeasurable as those of nature.
Such standardization is clearly not beyond human technology: Our hardworking Lego blocks hint at it, and so does a much older human technology.
The sixteenth-century Venetian Andrea Palladio may be the most influential architect in Western history. Throughout a long and successful career, he conceived at least sixteen of the urban palazzos that housed Venice’s wealthiest families, built thirty country villas, and designed several churches. The floor plans of Palladio’s buildings are not identical. Far from it. They differ in a thousand ways. His buildings are different in size, shape, orientation, and the arrangement of their rooms. Yet they share an architectural essence, even if most of us would find that essence hard to pinpoint. More than twenty years ago, the art historian George Hersey and computer specialist Richard Freedman searched for this element, the secret behind Palladian floor plans. If rules behind these plans exist, they thought, then we must be able to find an algorithm to create any number of Palladian floor plans.
To distill the essence of Palladio’s style, they analyzed dozens of Palladian villas: how their rooms were oriented, how their walls were placed, whether the lengths of adjacent rooms had certain proportions, and so on. And they succeeded. Their work culminated in a computer program that executes a recipe to create new Palladian floor plans. Its creations differ in many details, in the sizes, orientation, and arrangements of rooms, but all of the new designs are recognizably Palladian. 
The algorithm behind this program starts from the outline of a building, usually rectangular in shape, and draws vertical or horizontal lines through it—walls that subdivide the building into rooms. One such line would split the building into two rooms, two parallel lines would split the building into three rooms, and so on. Each room could again be split by horizontal or vertical lines, and the resulting rooms can be split further, and so on, until only rooms with a desired size have been created. By splitting a rectangle multiple times, each time either vertically or horizontally, each time by one or more walls, one can create an infinite variety of floor plans.
The rules underlying Palladian floor plans are neither arbitrary nor random. Nor are they complicated. For example, when a room is split in two with one line, it is usually split either in the middle or such that one of the resulting rooms is twice as long as the other. If it is split with two parallel lines, most splits create three rooms where the middle room is twice as long as the others. By combining these and a few other rules, this most celebrated style of Renaissance architecture can be re-created by a computer. 
Nature’s stereotypical recombination doesn’t work exactlythe same way. Small amino acid parts are combined to make new proteins, while the outline of a Palladian building is subdivided to create a floor plan. But the similarities are more important: Both use a small number of standard building blocks and an even smaller number of rules to create enormously complex objects. And if these similarities exist already in preindustrial architecture, the odds that they exist in postindustrial technology—unappreciated perhaps—should be even better. 
As in the technology behind robots like YaMoR: digital electronics.
Each of the myriad transistors on an integrated circuit—the kind of computer chip guiding a robot—is really nothing more than a tiny electronic on-off switch that responds to electronic impulses: one denoted as a “0” turns the switch off, whereas the other, a “1,” turns it on. Together, these transistors transform an arriving stream of data into a departing stream that also contains only zeroes and ones, the familiar bitsor binary digits from the simple two-letter alphabet that computers read. Mathematicians describe this process more precisely, by saying that a circuit calculates the values of a function, that it takes an inputand computes an output38The kinds of functions that a digital circuit computes are named after the English mathematician and philosopher George Boole, who wrote about them in his 1854 book, An Investigation of the Laws of Thought on Which Are Founded the Mathematical Theories of Logic and Probabilities. Boole’s new branch of mathematics was an enormous advance, and Boolean logic functions, as they are called today, are still at the heart of all modern computers.
FIGURE 20.Truth tables
One of the simplest such functions is the AND function, which is needed whenever one searches, for example, an electronic database of sheet music for a specific composition, such as Mozart’s Magic Flute. The search engine would search for compositions containing the word “Mozart,” and it would report a yes or a no—encoded by the bits 1 and 0—for all compositions containing this word. It would do the same for the word “magic,” yielding two possible answers for each of these two partial questions, which makes four possible combinations of answers. Their digital one-zero version can be written in a form that mathematicians use to describe Boolean logic functions, a truth table. In the truth table of the AND function shown in figure 20a, the function’s input, the four possible combinations of partial answers are written to the left of the vertical line, and to the right are the possible final answers—the output—again encoded as zeroes and ones. Merely one of the four lines contains a yes as the final answer—only if both partial answers are yes has a score for TheMagic Flutebeen found.
If you wanted to find compositions whose title contained the word “Mozart” or“magic” (orboth), the search engine would have to compute another Boolean function: the OR function. Same input stream—everything with the word “Mozart” and “magic”—but a different rule. In this case, the output is a yes if at least one partial answer is a yes (figure 20b). As a result, the OR function would report not only The Magic Flutebut also every other one of Mozart’s 626 pieces,39as well as Santana’s “Black Magic Woman,” Stevie Wonder’s “If It’s Magic,” and hundreds more. An even simpler Boolean function, the NOT function (figure 20c) turns a yes into a no, and could help you find all compositions without the word “Mozart” in them.
These and other more exotic Boolean logic functions—XOR, XNOR, NAND, NOR—allow us to translate complex questions from natural languages into the strings of binary numbers that rule the world of computers. What’s more, binary numbers can encode any decimal number, and can be added, subtracted, multiplied, and divided just like decimal numbers. The integrated circuits of even the most sophisticated computers perform nothing but basic arithmetic and simpler Boolean logic functions like the AND function. With the simplest of all possible alphabets—zeroes and ones—and Boolean logic, digital computers can recognize images, encrypt information, deliver voice mail, and predict next Tuesday’s weather. Arithmetic, it turns out, is even more important than we learned in grade school.
FIGURE 21.Logic gates
Another remarkable fact about Boolean functions is that even the most complicated Boolean function can be computed by stringing together simpler functions, such that the output of one function becomes the input of another. It’s a bit like multiplication (3 × 4), which can be written as a series of additions (4 + 4 + 4). More than that, even though the number of possible Boolean functions is virtually infinite, each of them can be computed by stringing together only AND, OR, and NOT functions. This matters for computers, because in an integrated circuit, transistors are wired into units of computation that compute a simple Boolean function and that are known as logic gates. Figure 21 shows some of the symbols that chip designers use for the simple AND, OR, and NOT gates. Each gate has one or two wires to the left for its input bits, and one on the right for its output bit. In figure 22 a few gates are wired to perform the simplest possible arithmetic operation of adding two binary digits—this already requires six logic gates, each with multiple transistors. Today’s chips of course add, subtract, multiply, and divide much longer numbers of sixty-four binary digits, and require millions of gates. 
FIGURE 22.A circuit adding two binary digits
Most integrated circuits are hardwired in the factory, but robots like YaMoR are equipped with programmable hardware, chips that can be rewired to alter what some logic gates do—changing an AND gate into an OR gate, for example—and how these gates are wired. Some programmable chips can even be rewired while the chip is working. With more than a million logic gates, such chips are not just simple toys but powerful and flexible computing engines that could eventually help machines learn much as we do—by rewiring their own hardware—and create autonomous robots that can not just explore the world but also learn about its potholes and other pitfalls. 
If this sounds familiar, it’s because such learning resembles evolution, which alters life’s genotypes one molecule at a time. A programmable circuit’s logic gates and wiring are an analog of a genotype that can be altered to explore new computations, the analog of new phenotypes. Like evolution, the learning process requires plenty of trial and error. It reinforces good behavior, and punishes bad behavior. (But not as severely as evolution does. If your—or a future robot’s—golf game is weak, you may need to improve your stance, your grip, or your swing, but you need not die.) What is more, such learning need not destroy old knowledge. As you learn to play golf, you can still sit, walk, run, or jump, even though the neural circuit responsible for these skills gets rewired. And the parallels to evolution don’t end here. The wires connecting logic gates are generic links, just as flexible as the peptide bonds of proteins, because the output of any one gate can be fed into any other gate. As with proteins, such links can be built, destroyed, and modified without much ingenuity to create electronic circuits that can be wired in astronomically many ways. 
Standard links. Few kinds of logic gates. These principles already suffice to create chips that play chess more powerfully than mankind’s best, to find a single page in a million different books, or to “print” objects in three dimensions. The capabilities of real-world programmable circuits are so reminiscent of nature’s innovation powers that they suggest a profound question: Are entire libraries of digital circuits—huge circuit collections that can be created through recombining logic gates in every possible way—organized like the library of biological circuits? The answer can tell us whether the warp drives of biological innovation could be mounted on the spaceships of technological innovation.
Karthik Raman provided this answer. A graduate from the Indian Institute of Science, one of India’s top universities, Karthik came to my lab as a postdoctoral researcher. And he did not come alone. He also brought an effervescent enthusiasm for science, dogged tenacity in the face of failure—as inevitable in science as in evolution—and a wizardlike talent for analyzing complex data. When I invited him to map libraries of programmable circuits, he jumped right on it.
Although commercially available programmable chips have more than a million gates, some back-of-the envelope calculations convinced us that we should study smaller circuits. A library of circuits with a mere sixteen logic gates contains 1046such circuits—a number already large beyond imagination—and this number increases exponentially with the number of gates, to 10100circuits with only thirty-six gates. Huge numbers like this also made the decision of whether to build circuits in hardware or to study them in the computer easy: Millions of circuits are most easily analyzed inside a computer. 
A sixteen-gate circuit could in principle compute 1019—a million trillion—Boolean functions, but we didn’t know whether the library’s circuits encoded that many. Perhaps its circuits could compute only a few functions, like addition or multiplication. To find out, Karthik first cast a net wide enough to haul in as many volumes as possible from the circuit library. He created many circuits with random wirings, two million of them, and found that they computed more than 1.5 million logic functions, only a few of them as familiar as the AND function. Even though he had hauled in only a small fraction of circuits—there were still 1040circuits left, and 1012times more functions to explore—his enormous catch taught us that even simple circuits can compute numerous Boolean functions.
Because the library hosts many more circuits than there are functions—1026times more, to be precise—we knew that there must be multiple synonymous texts, circuits computing the same logic function, but we didn’t know how they were organized. To find out, Karthik started with a circuit that computed an arbitrary logic function and changed it to one of its neighbors in the library, for example by reconnecting the input of one gate to the input of another. If this “mutated” circuit still computed the same logic function, Karthik kept it. If not, he tried another rewiring, and repeated that until he had found a circuit with the same function. From that new circuit he took another step, and another, and so on, such that each step preserved the circuit’s function. Karthik started random walks like this from more than a thousand different circuits, each one computing a different function that needed to be preserved.
The networks of circuits he found reached even farther through the library than the genotype networks from earlier chapters: From most circuits one could walk all the waythrough the circuit library without changing a circuit’s logic function. Two circuits may share nothing, not a single gate or wire, except the logic function they express, yet they can still be part of a huge network of circuits connectable through many small wiring changes. What’s more, we found that this holds for every single function we studied. It is a fundamental property of digital logic circuits. The library of digital electronics is like biology, only more so.
Karthik next turned to the neighborhoods of different circuits computing the same function, created all their neighbors, and listed the logic functions that each of them computed. He found that these neighborhoods are just as diverse as those in biology. More than 80 percent of functions are found near one circuit but not the other. This is good news for the same reason as in biology: One can explore ever more logic functions while rewiring a circuit without changing its capabilities. A circuit’s neighborhood contains circuits with some sixty new functions, but a mere ten rewiring steps make a hundred new functions accessible, a hundred rewirings put four hundred new functions within reach, and a thousand changes can access almost two thousand new functions. 
And the similarities continued. Earlier I mentioned the multidimensional fabric of biological innovability, the almost unimaginably complex, densely woven tissue of genotype networks. Karthik found that it has a counterpart in the circuit library, where a circuit with any function could be reached from any starting circuit by changing only a small percentage of wires. A fabric just like that of life’s innovability exists in digital electronics, and it can accelerate the search for a circuit best suited for any one task. 
Circuit networks thus have all it takes to become the warp drives of programmable hardware, in precisely the same way that genotype networks are the warp drives of evolution. They have the potential to help future generations of YaMoRs learn many new skills, from simple self-preservation like avoiding deadly staircases to complex skills like doing the dishes or playing ball with children. In this vision, their digital brains can rewire themselves step by little step, and explore many new behaviors, while being able to preserve old behavior—conserving the old while exploring the new. I wouldn’t even be surprised if our brains used a similar strategy to learn. We already know that they continually rewire the synaptic connections between our neurons, but perhaps our brains also explore new connections in the same way that organisms explore a genotype network. If so, the very same principle allowing biological innovation could be at work in the engines of human creativity.
Unfortunately, our ignorance in this area is still nearly absolute. We know next to nothing about the material basis of human creativity. We doknow, however, that the kind of creativity we discovered is not free, because Karthik found its price tagIt was a familiar one.
When Karthik analyzed logic circuits that differed in their complexity—their number of logic gates—he found that the simplest circuits could not be rewired without destroying their function. Change one wire in such a circuit, and you destroy the circuit’s function. Every gate and every wire matters. Such simple circuits have no innovability, because they cannot explore new configurations and computations. For rewiring, one needs more complex circuits. The more complex they are, the more rewiring they tolerate. Their apparently superfluous gates and wires are like collections of spare parts—piles of Edison’s precious junk—that help compute new digital functions. Just as in biology, innovability comes from complexity, apparently unnecessary, but actually vital. This is one of nature’s lessons for innovable technologies: If we want to open nature’s black box of innovation, Ockham’s razor is much too dull. Like oil and water, simplicity and innovability don’t mix.
This doesn’t mean that simplicity and elegance are absent from powerful innovable technologies. Quite the opposite. But they hide beneath the visible world. The basic principle behind them is simplicity itself: With a limited number of building blocks connected in a limited number of ways, you can create an entire world. Out of such building blocks and standard links between them, nature has created a world of proteins, regulation circuits, and metabolisms that sustains life, that has brought forth simple viruses and complex humans, and ultimately, our culture and technology, from the Iliadto the iPad. The simplicity and the elegance of innovable technologies are hidden behind the visible world, just like nature’s libraries, whose faint reflection we see in the Tree of Life, like a shadow in Plato’s cave.

