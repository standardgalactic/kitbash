CHAPTER SIX
The Hidden Architecture

In 1944, the Nobel Prize–winning theoretical physicist Erwin Schrödinger published a series of his lectures under the title What Is Life? The brief book was an attempt to reconcile physics with what was then known, in the days before Watson and Crick, about evolution. The book is brimming with ideas, and one of them has spilled into the mainstream of popular science culture: It is the idea that evolution increases order and decreases disorder—what Schrödinger called “negative entropy.” Four years later, the American electrical engineer Claude Shannon connected the thermodynamic concept of entropy to the problem of transferring information through a telegraph line. The concepts of evolution and information have been linked ever since, usually in a fairly primitive way. Disorder: bad. Order: good. Positive entropy: bad. Negative entropy—now also known as information—good.
In the years since Schrödinger’s book, we have become more sophisticated in thinking about entropy. Order and information remain central to evolution, but in recent years we have also learned, thanks to genotype networks, that perfect order is as hostile to innovation as total disorder. Nature doesn’t just toleratedisorder. It needssome disorder to discover new metabolisms, regulatory circuits, and macromolecules—in short, to innovate.
Let’s put Lego blocks to another metaphorical use, and consider the difference between a disorderly jumble of those familiar plastic tiles and an arrangement in which every tile has been presorted into a “proper” place, and where a child must assemble them in a specific sequence to build a pirate ship following a plan helpfully provided by Lego. The disordered jumble of Lego tiles has greater potential for innovation than the carefully organized one, and not just because it stimulates a child’s natural creativity to find new ways for building pirate ships. A deeper reason is that there are many more ways to build a pirate ship than those contained in Lego’s instruction book.
In biology this simple fact is manifest in the multiple solutions that nature found—courtesy of genotype networks—for problems like protecting organisms against freezing. And it is also deeply connected to a biological phenomenon little appreciated until the end of the twentieth century, but in fact so widespread that it deserves to be called a hallmark of life: robustness,the persistence of life’s features in the face of change.
The meaning of robustness is best illustrated with the difference between typographical mistakes in a traditional book and in a computer program. A book containing the letter sequence
N smll stp fr mn, n gnt lp fr mnknd
would raise eyebrows, but the meaning of this sentence remains understandable. However, a single misplaced letter or as little as a missing comma in a thousand pages of computer code can bring a million-dollar software package to a crash. Software bugs like this cause billions of dollars in economic loss every year. Human language is robust. Programming language, not so much.
The suspicion that life is robust arose at least as far back as the 1940s, when the biologist and philosopher C. H. Waddington studied flies with different genotypes and discovered that they had indistinguishable bodies, down to the minutest details of their wings’ venation and the numbers of bristles that cover their backsides. He called the phenomenon through which development can produce “one definite end-result regardless of minor variations in conditions” canalization—another word for robustness. And although his research hinted that the body plans of flies are robust to genetic change—there are many ways to build a fly’s body—research into robustness remained a backwater for another half century.
But almost overnight in the 1990s, robustness entered center stage with a flourish when molecular biologists were baffled by a discovery superficially unrelated to Waddington’s: Many genes apparently serve no purpose. 
What’s baffling about such genes is why they would exist at all. Not only does a superfluous gene waste scarce resources, but mutations that incessantly rain down on DNA would eventually erode it, transforming it over time into something like an abandoned building that crumbles to dust over the years. 
Many of these “purposeless genes” were unearthed after the genome of an organism that we already met in chapter 5 had become fully sequenced. It is a microbe, the brewer’s yeast Saccharomyces cerevisiaethat helps us make beer and wine, and it is as useful for understanding cell biology as fruit flies are for embryology. The yeast genome in hand, biologists realized that thousands of its genes had an unknown role in the microbe’s life. To reveal this role, they began to engineer “knockout mutations” into the genome, so called because they delete a single gene, an entire meaningful paragraph from a genomic text. The logic of the experiment is essentially like analyzing the workings of a car by eliminating one part at a time: Remove the disk rotor, and if stepping on the brake pedal no longer slows the car, you have learned that the rotor is needed for braking. In the same way, if you knock out a particular yeast gene and find that its cells can no longer divide, the gene was involved in cell division. Knock out a fruit fly gene and if the mutant no longer forms wings, you know that the gene helps build wings.
The results of gene knockout experiments had trickled into the scientific literature gene by gene, until gene-knockout technology became powerful enough to delete thousands of genes. That’s what researchers at Stanford did in impressive experiments starting in the late 1990s, when they used the list of yeast genes revealed by the yeast genome and set out to delete every single yeast gene. They created some six thousand different yeast mutants, each of them missing a gene, placed these mutants into chemical environments where their unmutated ancestor could have thrived, and examined each mutant for specific defects, clues about the missing gene’s function. 
What they found was completely unexpected. Thousands of these mutants do just as well as their ancestor and show no obvious defects. The genes that had been deleted to create these mutant genomes served no obvious purpose. Since then, scientists have blocked countless genes in many other organisms. And these genes tell the same story as a vowel-free English sentence: Like natural language, life is robust—in this case to gene deletions. 
Discoveries like this do mostly one thing: They create new questions. One of them was how?What mechanism creates robustness?
For some genes the mechanism was straightforward. These genes were duplicates, stretches of DNA that occur more than once in a genome, like pages in a book that someone has photocopied twice by mistake. Gene duplications happen when an organism copies or repairs DNA, and are by no means rare: About half of the genes in our own genome have duplicates. Since identical duplicates can do the same job, one of them can take over if you knock out the other. Like the redundant power supplies that hospitals use to safeguard against power failure, like redundant computer memory to prevent data loss, like redundant circuitry in commercial aircraft to prevent crashes, some genes are only “useless” until they’re needed. 
But many of the dispensable genes have no duplicate—they are single-copy genes—and for them the causes of robustness are not as simple.
We understand those causes best for genes that encode the enzymes of metabolism. A metabolism’s chemical reaction network resembles the dense road network of a city’s core, like that formed by the right-angled streets of midtown Manhattan. A driver who wants to get from 42nd Street and Second Avenue to 48th Street and Seventh Avenue has any number of choices for following the street grid six blocks north and seven blocks west. The major arteries have multiple lanes—think of them as redundant, because even if one is blocked, the driver can continue in another. But even a complete roadblock is not a problem, because the driver can use a different part of the grid, and a really intrepid driver might even cut through parking lots with entrances on two parallel streets. Such detours slow down but don’t halt the journey.
A knocked-out metabolic gene is a bit like a blocked road that halts the flow of molecules through a network of metabolic reactions. The detours around the roadblock are alternate metabolic pathways, sequences of chemical reactions that can absorb the backed-up molecular traffic, synthesize needed molecules in different ways, and ensure that life in metabolism city goes on. This isn’t just an abstract metaphor. Biotechnologists can create metabolic roadblocks by knocking out metabolic genes, and when they do, organisms like brewer’s yeast often survive by rerouting the flow of essential molecules. In metabolism, this kind of robustness is even more important than redundancy. 
Robustness isn’t limited to metabolism and whole genomes. It is just as pervasive in individual proteins like lysozyme. This protein kills bacteria by destroying their wall of protective molecules. It appears not only in human saliva, tears, and even mother’s milk, but in a large number of other animals, and even in viruses that attack bacteria. When scientists want to find out how a protein like this works, they do something akin to knocking out genes in a genome, but on a smaller scale—they change individual letters in the protein’s amino acid string and observe the effects of each change. When they engineered more than two thousand lysozyme variants, each one with a single altered amino acid, they found that some sixteen hundred variants—more than 80 percent—could still kill bacteria. Proteins like lysozyme, and there are many, are as robust as metabolisms. And the same holds for regulation circuits—we already heard about a circuit in the bacterium Escherichia colithat can be rewired in the laboratory without ill effects (chapter 5).
The most obvious benefit of such robustness is that it keeps organisms alive. Its importance goes back all the way to the first self-replicating RNA molecules and the fatal error catastrophe, in which small errors compound over time until replication becomes impossible (chapter 2). That was a true catch-22: RNA molecules have to self-replicate with few errors to acquire the ability to self-replicate with few errors. But only a bit of the robustness in today’s RNA could lower the bar for this problem to a manageable height: Because a few replication errors in a robust molecule do not erode its ability to self-replicate, robustness provides a stay of execution by error catastrophe, perhaps long enough to stumble upon better replicators. 
But the importance of robustness goes far beyond that. It explains the mystery of genotype networks and of innovability.
To see why, we need to revisit nature’s libraries, where each metabolism (or protein, or regulation circuit) is represented by a single text, and where each of this text’s neighbors differs in a single letter, a single reaction, or a single enzyme and its gene. We know from gene deletion experiments that many of these neighbors, for example metabolisms where a single reaction has been eliminated through a gene knockout, suffer no ill effects. This means that even when the genotypehas changed, there need not be any change in the phenotype,in the organism itself and its observable features. An organism like this is robust. The extent of its robustness is reflected in the number of its neighbors—variants a single small change away—whose phenotype remains unaffected by the change: The more neighbors with the same phenotype, the more robust the organism is. Think of this phenomenon at its theoretical limits: If a metabolism, or a protein, or a regulatory circuit had no viable neighbors it would be maximally fragile. Change one of its parts, and death follows. At the other extreme, if every possible change were viable, if every neighboring metabolism had the same phenotype, the metabolism would be maximally robust: No single change could kill it. 
These extremes do not exist in the real world. No real organism completely lacks robustness, and no organism is perfectly robust. But all organisms, their structures and activities, are to some extentrobust, and it is precisely this robustness that allows populations to explore nature’s enormous libraries. The number of texts with any one meaning in these libraries is vast, but these texts fill a tiny fraction of the library, like a droplet of molecules in an ocean. In the complete absence of robustness, many texts might tell the same story, but none of their neighbors would. No explorer could browse one text and find a neighboring one with a single page—or word, or letter—changed but its meaning nonetheless intact. Genotypes with the same phenotype would be like stars in the sky—a billion twinkles isolated by light-years of empty space.
Luckily, the biological world is different. Starting at any one robust text, we can step to one of its many neighbors with the same meaning, and we can step to one of itsrobust neighbors, and so on, never changing this meaning, and thus exploring ever-new regions of nature’s libraries that harbor untold innovations. Robustness allows somedisorder in genotypes, and permits nature to explore new configurations of its Lego blocks through the genotype networks it helps create.
Genotype networks are yet another example of the pervasive self-organization we first encountered in chapter 2—the same phenomenon that pervades both the living and nonliving worlds, from the formation of galaxies to the assembly of membranes. But they are a peculiar example of self-organization. Unlike galaxies, which self-assemble through the gravitational attraction of cosmic matter, or biological membranes, which self-organize through the love-hate relationship of lipid molecules with water, genotype networks do not emerge over time. They exist in the timeless eternal realm of nature’s libraries. But they certainly have a form of organization—so complex that we are just beginning to understand it—and this organization arises all by itself. And as with galaxies and membranes, the principle behind their self-organization is simple: Life is robust. This robustness is both necessary for genotype networks—otherwise synonymous texts would be isolated from one another—and it is sufficient. Wherever metabolisms, proteins, and regulatory circuits are robust, genotype networks emerge.
Robustness is sufficient to create genotype networks, but genotype networks alone are not sufficient for evolution. The reason is that evolution must meet two demands, seemingly at odds with one another. It must be simultaneously conservative and progressive, like some aviation pioneer embarking on a transatlantic flight in the Wright brothers’ original flyer: Certain in the knowledge that he must invent a new design to complete the journey, he must also keep the old one in the air until he does. Nature must keep what works alive while exploring the new. Genotype networks are essential for exploration. But they aren’t made for conservation.
This bears emphasizing, because the exciting new discoveries about genotype networks can tempt us to forget the critical importance of natural selection. Conservation is the job of natural selection—evolution’s memory—and its power to conserve even tiny improvements, given enough time, is so great as to seem absurdly unbelievable. Literally so. In the OriginCharles Darwinwrote about eyes, surely among the most spectacular innovations in life’s history, “To suppose that the eye with all its inimitable contrivances for adjusting the focus to different distances, for admitting different amounts of light, and for the correction of spherical and chromatic aberration, could have been formed by natural selection, seems, I freely confess, absurd in the highest degree.” 
When light passes through our eye, the lens projects a fantastically accurate, undistorted image of the outside world onto our light-sensing retina. To do so, it must refractlight’s path, changing its direction at a precise angle. It’s not just the lens’s shifting shape that makes this possible, but also the less appreciated and peculiar lens material—an ancient innovation that required nothing but new regulation.
Shine a flashlight obliquely onto a body of water, and you will see that the light ray kinks at the surface. Dissolve sugar in the water, and the kink’s angle gets sharper—the more sugar you dissolve, the sharper it gets. (The food industry uses this principle to measure the amount of sugar in wine, soft drinks, and juices.) Our eyes refract light just like that, except that they use proteins instead of sugar. These proteins—crystallins—occur at very high concentrations in the lens, which allows the lens to refract light strongly.
Crystallins are so uncannily good at refracting light that it’s tempting to think that they were tailor-made for constructing lenses, and therefore rare. Not true. Many crystallins are metabolic enzymes, the very same enzymes that promote chemical reactions elsewhere in the body, albeit in smaller numbers. Different organisms use different enzymes as crystallins. What distinguishes them from other proteins is that they do not clump easily, not even when they are expressed at the extreme concentrations needed in the eye. Eyes build their lenses out of proteins like the one that detoxifies alcohol, just because they confer transparency—the same way you might use an old brick as a bookend simply because it happens to be heavy. Crystallins are also some of the sturdiest proteins around, so long-lived that the crystallins that make up the lens of the human eye last an entire lifetime, from birth to death. But sometimes they wear out and start to clump, making the lens milky white. When this happens a cataract has formed, with consequences both well known and disastrous: blindness. 
Though Darwin knew nothing of protein chemistry, he did suspect—and today we know—that the fancy eyes of vertebrates with their sophisticated lenses are the last in a long list of gradual improvements. Long before our ancestors started co-opting nonclumping metabolic proteins, theirancestors, like some worms and starfish, were using flat patches of light-sensitive cells that were at least good enough to find a shadow to cower in and hide from predators. After millions of years, these cells eventually congregated in shallow bowls, eyecupsthat can detect light’s direction better, which deepened into pit eyesthat can detect it very well, and even further into pinholecameras whose tiny openings can produce real images. From there it was one more step to lenses, transparent tissues of higher density that—thanks to crystallins—could focus light. Eventually these lenses became able to flex or move to create sharp images.
All these small, gradual improvements are worth preserving, and natural selection did. We know, because many animals still have them: eyecups in some flatworms, pit eyes in some snails, pinhole camera eyes in the nautilus—a relative of squids that builds many-chambered shells—and simple lenses in organisms as primitive as jellyfish. 
It’s a bit like the stunning grandeur of medieval cathedrals, with soaring spires, columns of heavy massive stones assembled with exquisite precision, and vaulted ceilings so high that our gaze gets lost in their semidarkness. The finished product—like the human eye—is literally incredible without the knowledge that it was built one brick at a time
The same is true for all molecular innovations. The amino acid text of the Arctic cod’s antifreeze proteins didn’t originate in a single step, like Athena springing from the brow of Zeus. But every single letter of an ancestor’s amino acid text that changed in the right direction, lowering a body fluid’s freezing point by as little as a tenth of a degree, could expand its descendants’ habitat by miles. A greater range means a larger and more varied food supply. It means a change well worth preserving, and a long sequence of such tiny changes can expand life’s frigid frontier by long distances. Genotype networks are crucial to find each such change, and natural selection is crucial to preserve it.
Better variants that improve an organism incrementally are important for innovation, but they are not the only kind of change that DNA experiences. Many mutations neither harm nor help when they first arise. Suchneutralchanges are a consequence of life’s robustness and the disorder it allows.
That neutral changes could matter for innovation—and why—was not always clear. In fact, the relationship between natural selection and neutral change was central to a historical controversy that tore at the fabric of Darwinism in the last third of the twentieth century. The revolution in molecular biology, then well under way, had revealed that populations of wild organisms, from mammals to fruit flies and down to bacteria, harbored astonishing amounts of genetic variation: The DNA of thousands of genes in members of the same species varied in its letter sequence. Most scientists, good Darwinians as they were, believed that the fate of most of these variants was determined by natural selection—variants that appeared frequently must improve survival or reproduction.
But these selectionists were opposed by a vocal minority, the neutralists, who argued that most of these variants make no difference to the organism and are invisible to selection. At least when they first appear, they are neutral. In the eyes of some, like the paleontologist Stephen Jay Gould, the very existence of neutral change compromised the importance of natural selection in evolutionary innovation. 
The history of science and technology offers loose analogies for how neutral changes—dormant discoveries—can become valuable for future innovations. Number theory provides one such analogy. It is a branch of mathematics about which the American mathematician Leonard Dickson reportedly said, “Thank God that number theory is unsullied by any application.” This was as true in 1919 as it had been since Euclid, but within decades unrelated developments—digital computers and networked communication between them—placed the theorems of number theory at center stage of the Internet economy, where they ensure the secure communications that make e-commerce and online banking possible. In a similar vein, the German physicist Heinrich Hertz, whose experiments validated the electromagnetic theory of James Clerk Maxwell, saw no practical purpose to his discovery. He reportedly said that it was “of no use whatever” and “just an experiment that proves Maestro Maxwell was right.” Less than forty years later, his discoveries led to the first commercially licensed radio station in the world—KDKA in Pittsburgh, which still broadcasts on the frequency band of 1020 kilohertz. 
But back to biology, where the neutralists’ most outspoken proponent was the Japanese scientist Motoo Kimura, who had developed a sophisticated and successful mathematical theory to explain the evolutionary fate of such neutral mutations. Kimura asserted that mostgenetic variation seen in nature is neutral. The genomic era has taught us that he was wrong on that count—neutral variants are no more frequent than those providing an advantage. However, his hunch of neutral change’s being important was dead on, though it took another few decades to understand why.
One reason is that neutral change is critical for navigating genotype networks. Neutral change provides the browsers of nature’s libraries with a safe path to innovations through treacherous territory of meaningless texts. Without genotype networks and the neutral changes they allow, the exploration of nature’s libraries would be just about impossible.
Another reason is that a change that is neutral when it first appears doesn’t have to stay that way. Once-neutral changes can turn into essential parts of innovations—like the theorems of number theory. And once they do, natural selection can preserve them. Which means that both selectionists and neutralists had a point, because both kinds of changes are essential in evolution. After neutral changes have paved the way to an innovation, selection preserves those neutral changes that contributed to the innovation.
A single example from a well-studied RNA enzyme known as the hammerhead ribozyme can illustrate to what extent neutrality and genotype networks can accelerate evolution’s search for innovations. The job of this particular RNA enzyme is to cleave RNA at a particular point along its nucleotide strand. The shape of the ribozyme, named for its apparent resemblance to the hammerhead shark, is what allows it to perform this job—adequately but not necessarily optimally. Somewhere out in the vast library of all RNA molecules might be new shapes, new phenotypes that would endow the ribozyme with sharper blades.
If no genotype networks existed, then a crowd of readers in the RNA library—an evolving RNA population—would have to congregate around the forty-three-letter-long text that encodes the RNA, and could only explore the shapes that are one letter change away. This particular RNA enzyme happens to have 129 neighbors, and because we can compute their shapes, we can determine that there are forty-six new shapes in this neighborhood. That’s the number of shapes evolution can explore without genotype networks.
And with them? If we only step to the text’s neutral neighbors—those with the same hammerhead shape—and determine the shape of all theirneighbors, we already find 962 new shapes. And if we just walk one step further, to thoseneighbors’ neutral neighbors, we find 1,752 new shapes. Just two steps along this ribozyme’s genotype network, we can access almost forty times more shapes than in its immediate vicinity. The genotype network of the hammerhead shape of course extends much further than just two steps, and it has more than 1019members, too many to count all the new shapes near them with current computers. But we can say with certainty that countless millions and billions of new shapes are near them, all explorable because evolution’s readers can spread out along the genotype network without suffering death. 
That’s how much genotype networks accelerate innovation. They are like the warp drives of Star Trek,science fiction’s solution for faster-than-light interstellar travel. Extrapolate from the hammerhead ribozyme and imagine that evolution had unfolded merely forty times more slowly without genotype networks. Instead of being four billion years along its path, life would have evolved only as far as it did during the planet’s first hundred million years. A few kinds of bacteria would be around, but certainly no multicellular organisms, let alone fish, land plants, dinosaurs, or nonfiction book authors. And genotype networks accelerate evolution much more than fortyfold—so much more we can’t even yet compute it. Without them, life would never have crawled out of the primordial soup.
Science fiction also has another solution to faster-than-light travel: changing the shape of space itself. Inventive science-fiction authors have postulated technologies like “wormhole drives” that allow instantaneous travels between places thousands of light-years apart. It turns out that genotype networks also do something similar. They shrink the distance between texts in the libraries of metabolisms, macromolecules, and regulatory circuits.
FIGURE 19.The square stands for the entire library, the circle for a neighborhood of some genotypic text (dot) in the library.
Imagine a crowd of evolution’s readers—organisms in a population—congregating near a text describing a circuit with a specific expression code that helps shape some body part, like a bird’s wing. Now imagine that somewhere in the library of regulatory circuits a newcode exists that modifies the wing to make it slightly more aerodynamic or lighter. The further the readers must travel to find it, the more time they need to find this innovation.
Browsing through such an enormous library seems, at first glance, like hunting for a particular needle in a haystack. You might find the right needle immediately, but chances are you would have to examine most of the haystack—perhaps all of it—before achieving success. Common sense dictates that the same applies to the library, that a new expression code is like a single needle in a haystack many times the size of the universe.
But common sense fails in this library. We had already learned this from our discovery that there are innumerable circuits with the same expression code—the haystack has many needles—but the library is even more bizarre, as we found out by searching for circuits with specific new expression codes. In this search, we created arbitrary expression codes—thousands of them—and for each such code we used our computers to generate a pair of circuits, where the first circuit produced one of these codes, and the second produced the other. The two circuits differed also in most of their wiring pattern, in the who-regulates-whom among the circuit genes. We then changed the first circuit gradually, one wire at a time, requiring that each such gene regulation change preserve the circuit’s expression code. How close could we get to the second circuit? Very close, we found out, for example to within 85 percent of the second circuit’s wiring for circuits of twenty genes. In other words, starting from anywhere in the library—anywhere—you need not walk very far, only fifteen steps away from a genotype network, before finding the genotype network of anyother circuit. It is as if your needle were alwaysnearby, no matter where you started to search. 
If this doesn’t sound strange enough, get ready for something even stranger.
Imagine that the square in figure 19 is the library, and the dot is a single text in it. The circle around this dot has a radius that is 15 percent as long as the sides—this is how far a reader would have to travel from a genotype network, on average, before finding a specific new expression code, as we had found out from exploring the circuit library. A simple calculation shows that a circle with a radius of fifteen centimeters, inside a square that is one hundred centimeters on a side, has an area of 707 square centimeters, a little more than 7 percent of the square’s area
Actual libraries aren’t two-dimensional, of course. They exist in three dimensions. For simplicity’s sake, let’s say that our library building is housed in a three-dimensional cube, and the area of the library containing circuits with a new expression code is now a sphere. If so, then the sphere inscribed inside the library will now have a radius 15 percent as long as the sides of the cube, just as with the square. The ratio of their volumes, however, becomes very different. The volume of the sphere covers not 7 percent of that of the cube, but only 1.4 percent.
The libraries of regulatory circuits, of course, aren’t three- or even four-dimensional. They occupy higher dimensions, where cubes become hypercubes and balls become hyperspheres. In four dimensions, our hypersphere—still with the same radius—contains 0.2 percent of a hypercube’s volume. In five dimensions, it covers 0.04 percent, and so on.
In the number of dimensions where our circuit library exists—get ready for this—the sphere contains neither 0.1 percent, 0.01 percent, nor 0.001 percent. It contains less than 0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001 percent, or one 10-100th, of the library. This is the tiny fraction of the circuit library a reader needs to explore, starting from its own genotype network, to find a circuit with any one expression code. That it is so small emerges from a simple geometric principle in spaces of ever-higher dimensions: A ball with constant radius occupies ever-decreasing and ever-tinier fractions of a cube’s volume. (This volume decreases not just for my example of a 15 percent ratio of volumes, but for any ratio, even one as high as 75 percent, where the volume drops to 49 percent in three dimensions, to 28 percent in four, to 14.7 percent in five, and so on, to ever-smaller fractions.)33
The same counterintuitive phenomenon holds in other libraries of innovation: The more dimensions they have—the larger their collection of metabolisms or molecules—the smaller the distance to find specific innovations. A browser who starts with a metabolism that can survive on some foods and then blindly searches for one that can thrive on others needs to change only a few reactions and explore a tiny fraction—too small to imagine—of the metabolic library before stumbling upon the right text. The same holds true for RNA. Starting from an existing RNA molecule, a nearby molecule with a new shape—anynew shape you choose—will be found after changing only a few of the molecule’s nucleotide building blocks and having explored a tiny fraction of the library. 
The astonishing fact that evolution needs to explore one 10-100thof a library to secure the arrival of the fittest goes a long way to explain how blind search produces life’s immense diversity. Evolution does not have to search the entire haystack, because the haystack contains more than one needle. In fact, thanks to robustness, and the genotypic disorder it permits, the haystack contains too many needles to count, and they are organized into sprawling but navigable networks.
And if we remember that the neighborhood of each text is extremely diverse, we have understood one more feature of the library’s organization: Genotype networks not only range far and wide but also are tightly interwoven. They form a dense tissue of networks, each genotype network surrounded by many others, interwoven with them on all sides, a tissue so complex that it looks nowhere the same, consisting of millions, billions, or more of different strands, each one corresponding to a different phenotype. If each strand had a different color, this tissue would be woven in such an intricate way that near any one strand, threads of billions of other colors would pass. Only a high-dimensional space can host such a fabric, whose texture is intricate beyond our grasp. This fabric is different from anything we know. It is hidden behind the visible splendor of each living thing, yet all this splendor emerges from it.
Because genotype networks and their fabric are a consequence of robustness, robustness is immensely valuable to innovation. But valuable things are usually not free, and robustness is no exception. Its price—a high one—is complexity.
It’s almost too easy to criticize complexity. In Lewis Carroll’s Through the Looking-Glass, Alice is navigating the tale’s fantastic chessboard when she is attacked by the Red Knight, who mistakes her for a white pawn. In the nick of time, Alice is rescued by his opposite number, the White Knight—tellingly, an inventor—who is eager to show his new friend his latest innovations, including boxes that open on the bottom to keep out the rain, a device for trapping mice when they appear on a horse’s back, and a dessert made of blotting paper, sealing wax, and gunpowder:
“You see,” he went on after a pause, “it’s as well to be provided for everything. That’s the reason the horse has all those anklets round his feet.”
“But what are they for?” Alice asked in a tone of great curiosity.
“To guard against the bites of sharks,” the Knight replied. “It’s an invention of my own.”
The White Knight is so handicapped by his complex and fantastic inventions that he is literally unable to ride and to accompany Alice on her journey, and so he quickly departs the story. He lives on, however, as an object lesson in the importance of simplicity.
Long before Carroll wrote his story, the fourteenth-century English friar William of Ockham had already expressed an enthusiasm for simplicity when he coined a now famous principle of parsimony: that phenomena should always be understood using the fewest possible facts, or “entities,” as Ockham called them. This ideal—often called Ockham’s (or Occam’s) razor—is usually held up to scientific explanations that are supposed to be both truthful and beautiful. But it could apply equally to the kinds of machines inventors and engineers build, even though engineers already have their own, more earthy motto: KISS, for Keep It Simple, Stupid.
The ideal of simplicity is not just an aesthetic ideal or a philosophical principle. In engineering it also has an economic angle. It costs money to manufacture the parts of a machine. More parts cost more money, a prospect that any sane manufacturer wants to avoid. In addition, assembling a complex machine is more error-prone. Simplicity is better for building machines that work. 
Anybody who has struggled to understand living beings, and has despaired at their complexity, will sympathize with this yearning for simplicity. Life seems unnecessarily complex in many ways. The regulation circuit that divides insects into fourteen segments contains dozens of molecules,36but scientists have known for many years that just twomolecules interacting in the right way could achieve the same goal. As if to spite us, thousands of insect species segment their bodies in a way that not only took decades to understand but that no self-respecting human engineer would ever devise. And remember the road networks of metabolisms, full of redundant lanes, alternative routes, and unused back alleys. They all raise the same question: Why? Why doesn’t ruthlessly efficient nature get rid of all this complexity?
The answer is “the environment”—or rather, “the environments.” What looks like a wastefully complex suite of genes is actually the secret to survival in more than one environment.
In the kind of nutrient-poor environment in which E. colihas only a single carbon source to manufacture those sixty essential biomass units that include amino acids and DNA nucleotides, nearly three-quarters of the bacterium’s metabolic reactions are completely dispensable. Knock them out and life continues—robustness.
But environments change. If the sole source of carbon changes from glucose to ethanol, some of those “dispensable” reactions can keep the biomass factories running. Each of the eighty carbon sources from which E. colican synthesize biomass needs some dedicated reactions. And carbon is only one of the essential elements—metabolizing sources of other elements needs further reactions. A large collection of metabolic reactions makes an organism viable in multiple environments. In biology, increased complexity means increased robustness to environmental change.
For the same reason of changing environments, duplicate genes often persist in the genomes of organisms. Duplicate genes, like humans, are created equal, but they do not stay that way for long. They accumulate mutations that alter their DNA and its molecular meaning, and lead to increased specialization on one environment. Some human duplicate enzymes are best at cleaving molecules in the chemical environment of the liver, whereas others operate optimally in the brain. One duplicate yeast protein is best at importing glucose into the cell when this nutrient is abundant, whereas its duplicate partner specializes at scavenging glucose when it is scarce. The redundancy of many gene duplicates is more apparent than real, because they ensure robustness to changing environments.
The world of technology provides examples as well, for even though engineers prize simplicity, they must also design for changing environments. If you want to travel with a river’s current, a simple wooden raft will do the trick. But to cross the river or steer the raft, you already need more complexity: a rudder. If you want to avoid getting soaked by waves, you need a hull. To navigate upriver, you need oars or a sail. The simplest sail—the kind of square rig that Phoenicians and Egyptians had already built five thousand years ago—works well to sail downwind, but it is less effective when wind directions change, and useless for sailing upwind. To do that well you need a more complex fore-and-aft rig with two sails, a jib in front of the mast and a mainsail behind. Navigating a changing environment—current, waves, and wind—needs complex technology.
The converse is equally true, at least in biology. Over time, unchanging environments result in less complexity, because robustness becomes less important. To find examples, you don’t have to look much farther than a houseplant—or, more accurately, to the insects living on one.
Aphids, also called plant lice, blackflies, and greenflies, have been blood enemies of farmers and gardeners for millennia, though only a few hundred of the more than four thousand aphid species suck the sap of agriculturally valuable plants—not only of the houseplants in suburban homes, but of cotton, fruit trees, and grain crops. They were complicit in both the Irish potato famine of the 1840s and the Great French Wine Blight of the 1850s. They are among the most destructive of all insect parasites. Yet aphids are also valuable, at least to science. For deep inside them live other, even smaller organisms that can teach us a lot about both robustness and complexity.
Many people know that aphids suck sap, but fewer know that sap is a very poor food. It lacks essential molecules, including several amino acids. To get these, aphids have teamed up with relatives of the bacteriumEscherichia coli,a species called Buchnera aphidicolathat inhabits the bodies of aphids.
The alliance between Buchneraand aphids benefits both species and is also known as an endosymbiotic mutualism. It is a remarkably close relationship. Buchneradoes not just live on or near aphids. Its cells live insidethe aphid’s cells, where they provide their host with a vital service: They manufacture essential food molecules, especially amino acids that aphids cannot manufacture themselves, and that plant sap does not contain. Buchnerais a tiny food factory that keeps aphids alive.
For its services Buchneraalso gets something in return. By living inside an aphid’s cell, Buchnerafloats in a broth of molecules that is rich enough to provide almost all the food the bacterium needs. And not just food: The aphid’s cell walls provide Buchnera with a safe and comfortable home. By dragging Buchnerawith them everywhere, aphids insulate them from heat, cold, rain, and other environmental hazards. Buchneraneeds to take no notice of overgrazed plants, lurking predators, or any other threat. So long as its aphid home survives, the bacterium thrives. Like a vacationer idling its time away in the gently lapping waves of a tepid ocean, Buchnerais sheltered from a hostile world. 
Buchnera’s vacation has been going on for a very long time. The host and the bacterium first cohabited more than a hundred million years ago, and have lived together ever since. Over that much time, one might expect significant changes to any organism. That’s what happened to Buchnera,and those changes reveal much about the relationship between robustness and complexity.
To understand that relationship, it is useful to compare Buchnerato its cousin, Escherichia coli,that marvel of metabolic flexibility, able to survive on dozens of different food sources, and highly robust to changing chemical environments. E. coli’s complex metabolic network harbors more than a thousand chemical reactions, a large collection of skills for surviving in a changeable and uncertain world.
The metabolism of Buchnera’s ancestors once resembled that of E. coli. But no longer. Now its metabolic network has a puny 263 metabolic reactions. Its alliance with aphids started when dinosaurs still walked the earth, and since then it has lost nearly three-quarters of the reactions that E. colistill harbors. A steady stream of DNA copying errors eroded the genes that are needed for these reactions, and many of them disappeared through gene deletions that occur naturally in DNA. Buchnerahas survived hundreds of such deletions. 
It takes no genius to see why Buchneracould survive all these deletions and become so much simpler than E. coli. Hundreds of genes and metabolic reactions have become superfluous in Buchnera,because its world has stood still for more than a hundred million years. While its host aphid struggles in an ever-changing environment, Buchnerabathes in a steady if monotonous diet of nutrients. To survive in a simple, unchanging world, a simple metabolism does the trick, and complexity becomes not only superfluous but wasteful.
Buchnerais special but not unique. Many microbes live on or inside other, larger organisms. Some serve their hosts, others exploit them. A well-known human example is the bacterium Mycoplasma pneumoniae,a cause of the “walking pneumonia” that does not tie patients to their beds. This parasite shuttles from body to human body, and relies on human cells to supply its food. Its metabolism is even simpler than that of Buchnera:It needs a mere 189 reactions to survive on the rich molecular buffet that human cells provide. Incredibly, it has even shed part of metabolism’s universal core, the most ancient citric acid cycle. What’s more, its extreme minimalism helps it resist antibiotics that attack the enzymes building the bacterial cell wall: It no longer makes this wall, and even hijacks membrane molecules from our own body to prevent its molecular innards from spilling. 
A corollary of this increase in simplicity is a corresponding decrease in robustness: not just robustness to mutations, but robustness to environmental change—the two are linked. A metabolism that is robust to knocking out enzyme-coding genes will also be robust to changing environments. If E. coliwere to live in a single, fixed environment—one, for example, where glucose is the only source of carbon—it could do without 70 percent of the chemical reactions in its complex metabolism. But in Buchnerathis is no longer the case. Fully 90 percent of its 263 reactions are essential. Eliminate one of them and you kill the organism.
Put another way, the metabolic road network of E. colihas many alternate routes, but Buchnera’sdoesn’t. It is more like a single-lane road without exits. Block it anywhere and all traffic piles up behind the roadblock—the place where an essential molecule can no longer be made. E. coli is robust, both to the DNA mutations that eliminate metabolic reactions and to changing environments. Buchnera is not robust to either.
E. coliand B. aphidocolaare only two specks of dust in a vast library of metabolisms, and what holds for them—an organism viable in a changing environment is more complex and robust—might not be universal. We cannot examine all metabolisms, for there are too many. But we can examine many of them computationally, and thus do what pollsters do for human populations: learn about a very large population from random samples that reflect the population’s properties. By exposing such a random sample of metabolisms to changing environments, we can learn whether E. coli and Buchneraare unusual or typical.
To this end, researchers in my laboratory create hundreds of metabolic networks that contain as few reactions as possible and yet can still sustain life. We call such networks minimal metabolisms. Make them any smaller and you destroy their ability to sustain life. We can create minimal metabolisms that can sustain life in one environment, but also in two, three, and more environments, up to dozens of them, each one differing only in available nutrients.
One lesson from such minimal metabolisms is that living in many environments generallyrequires complexity. In one study we analyzed environments that differ in their sources of sulfur, a chemical element as essential as carbon. We first identified minimal metabolisms—there are more than one—that can sustain life on only onesulfur source, and found that such metabolisms need fewer than twenty chemical reactions. But to sustain life on fivedifferent sulfur sources, a metabolism already needs at least twenty-five reactions. And to be viable in forty different environments, it needs more than sixty chemical reactions. In other words, a metabolism that can sustain life in more and more environments needs more and more reactions. It needs to be more complex. 
The same metabolism also becomes more robust: We can remove more and more reactions from it, while it remains viable in any one environment. The more reactions a metabolism contains, the more reactions it can do without in any one environment. These reactions are neutral in one environment, but they can become essential in a different environment. Thus E. coliand Buchneraare not unusual, but special cases of a general principle: Life’s complexity and robustness increase with its exposure to environmental change. 
With this recognition a circle is closing. Environmental change requires complexity, which begets robustness, which begets genotype networks, which enable innovations, the very kind that allow life to cope with environmental change, increase its complexity, and so on, in an ascending spiral of ever-increasing innovability. At the core of this innovability is the self-organized multidimensional fabric of genotype networks, hidden behind life’s visible splendor, but creating this splendor. It is the hidden architecture of life.

