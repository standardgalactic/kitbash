Algorithmic Symmetry in Evolution
Skip to content
Open sidebar
ChatGPT
4o
ChatGPT
4o
Share
PLUS
You said:
Symmetry and simplicity spontaneously emerge from 
the algorithmic nature of evolution 
Iain G. Johnstona,b,c,d,1, Kamaludin Dinglee,1, Sam F. Greenburyf,g, Chico Q. Camargoh, Jonathan P. K. Doyei, 
Sebastian E. Ahnertd,f,j, and Ard A. Louisc,2 
aDepartment of Mathematics, University of Bergen, Bergen 5007, Norway;bComputational Biology Unit, University of Bergen, Bergen 5008, Norway; 
cRudolf Peierls Centre for Theoretical Physics, University of Oxford, Oxford OX1 3PU, United Kingdom;dThe Alan Turing Institute, British Library, London 
NW1 2DB, United Kingdom; eCentre for Applied Mathematics and Bioinformatics, Department of Mathematics and Natural Sciences, Gulf University for 
Science and Technology, Hallwaly, Kuwait; fTheory of Condensed Matter Group, Cavendish Laboratory, University of Cambridge, Cambridge CB3 0HE, 
United Kingdom; gDepartment of Metabolism, Digestion and Reproduction, Imperial College London, London SW7 2AZ, United Kingdom;hDepartment of 
Computer Science, University of Exeter, Exeter EX4 4QF, United Kingdom; iPhysical and Theoretical Chemistry Laboratory, Department of Chemistry, 
University of Oxford, Oxford OX1 3QZ, United Kingdom; and jDepartment of Chemical Engineering and Biotechnology, University of Cambridge, 
Cambridge CB3 0AS, United Kingdom 
Edited by Günter Wagner, Department of Ecology & Evolutionary Biology, Yale University, New Haven, CT; received July 27, 2021; accepted December 20, 
2021 
Engineers routinely design systems to be modular and symmetric 
in order to increase robustness to perturbations and to facilitate 
alterations at a later date. Biological structures also frequently 
exhibit modularity and symmetry, but the origin of such trends 
is much less well understood. It can be tempting to assume—by 
analogy to engineering design—that symmetry and modularity 
arisefromnaturalselection.However,evolution,unlikeengineers, 
cannot plan ahead, and so these traits must also afford some 
immediate selective advantage which is hard to reconcile with 
the breadth of systems where symmetry is observed. Here we 
introduce an alternative nonadaptive hypothesis based on an 
algorithmic picture of evolution. It suggests that symmetric struc- 
tures preferentially arise not just due to natural selection but 
also because they require less specif i c information to encode and 
are therefore much more likely to appear as phenotypic variation 
through random mutations. Arguments from algorithmic infor- 
mation theory can formalize this intuition, leading to the pre- 
diction that many genotype-phenotype maps are exponentially 
biased toward phenotypes with low descriptional complexity. A 
preference for symmetry is a special case of this bias toward com- 
pressible descriptions. We test these predictions with extensive 
biological data, showing that protein complexes, RNA secondary 
structures, and a model gene regulatory network all exhibit the 
expected exponential bias toward simpler (and more symmetric) 
phenotypes. Lower descriptional complexity also correlates with 
higher mutational robustness, which may aid the evolution of 
complex modular assemblies of multiple components. 
evolution | development | algorithmic information theory 
E 
volution proceeds through genetic mutations which generate 
the novel phenotypic variation upon which natural selection 
can act. The relationship between the space of genotypes and 
the space of phenotypes can be encapsulated as a genotype- 
phenotype(GP)map(1-3).Thesecanbeviewedalgorithmically, 
where random genetic mutations search in the space of (devel- 
opmental) algorithms encoded by the GP map, a relationship 
that has been highlighted, for example, in plants (4), in Dawkins' 
"biomorphs" (5), and in biomolecules (6). 
Genetic mutations are random in the sense that they occur 
independently of the phenotypic variation they produce. This 
doesnot,however,meanthattheprobabilityP(p)thataGPmap 
produces a phenotype p upon random sampling of genotypes will 
be anything like a uniformly random distribution. Instead, highly 
general (but rather abstract) arguments based on the coding 
theorem of algorithmic information theory (AIT) (7) predict 
that the P(p) of many GP maps should be highly biased toward 
phenotypes with low Kolmogorov complexity K(p) (8). High 
symmetry can, in turn, be linked to low K(p) (6, 9-11). An 
intuitive explanation for this algorithmic bias toward symmetry 
proceeds in two steps: 1) Symmetric phenotypes typically need 
less information to encode algorithmically, due to repetition 
of subunits. This higher compressibility reduces constraints on 
genotypes, implying that more genotypes will map to simpler, 
more symmetric phenotypes than to more complex asymmetric 
ones (2, 3). 2) Upon random mutations these symmetric pheno- 
typesaremuchmorelikelytoariseaspotentialvariation(12,13), 
so that a strong bias toward symmetry may emerge even without 
natural selection for symmetry. 
Symmetry in Protein Quaternary Structure and Polyominoes 
We i rst explore evidence for this algorithmic hypothesis by 
studying protein quaternary structure, which describes the 
multimeric complexes into which many proteins self-assemble 
in order to perform key cellular functions (Fig. 1A and 
SI Appendix, Fig. S1 and section S1). These complexes can form 
in the cell if proteins evolve attractive interfaces allowing them 
Signif i cance 
Why does evolution favor symmetric structures when they 
only represent a minute subset of all possible forms? Just as 
monkeys randomly typing into a computer language will pref- 
erentially produce outputs that can be generated by shorter 
algorithms, so the coding theorem from algorithmic informa- 
tion theory predicts that random mutations, when decoded 
by the process of development, preferentially produce pheno- 
types with shorter algorithmic descriptions. Since symmetric 
structures need less information to encode, they are much 
more likely to appear as potential variation. Combined with 
an arrival-of-the-frequent mechanism, this algorithmic bias 
predicts a much higher prevalence of low-complexity (high- 
symmetry) phenotypes than follows from natural selection 
alone and also explains patterns observed in protein com- 
plexes, RNA secondary structures, and a gene regulatory net- 
work.
ChatGPT said:
This paper by Johnston et al. presents a compelling
nonadaptive
explanation for the widespread emergence of
symmetry and simplicity
in biological systems, grounded in
algorithmic information theory (AIT)
. Here's a narrative academic summary of the core argument and findings:
Summary: Algorithmic Origins of Symmetry in Evolution
In contrast to traditional adaptive explanations that attribute biological symmetry to natural selection's optimization for robustness or efficiency, Johnston et al. argue that
symmetry arises spontaneously
from the
algorithmic structure of genotype-phenotype (GP) maps
. Their thesis is rooted in
Kolmogorov complexity
, a measure of the minimal algorithmic description required to generate a given phenotype.
Key Argument
:
Biological evolution operates via random genetic mutations, which are blind to phenotype. However, the mapping from genotype to phenotype is not uniform. Due to
compressibility biases
, simpler (i.e., more symmetric or modular) phenotypes are vastly
overrepresented
in the space of all possible genotypes. This means that such forms are
more likely to arise by chance
, even without any selective pressure for symmetry.
This follows from the
coding theorem of AIT
, which states that the probability of randomly generating a string (or structure) via a universal Turing machine is
exponentially related to its inverse algorithmic complexity
:
P
(
p
)
∝
2
−
K
(
p
)
P(p) \propto 2^{-K(p)}
P
(
p
)
∝
2
−
K
(
p
)
Thus,
low-complexity phenotypes
—those with internal redundancy or symmetry—occur with disproportionately high frequency.
Evidence and Applications
Protein Complexes
:
The authors analyze quaternary protein structures and find that
symmetric protein assemblies dominate
, beyond what adaptive explanations alone can account for. These symmetric complexes are easier to encode and therefore more likely to be produced via random genetic variation.
RNA Secondary Structures
:
Simulations of RNA folding confirm a
strong algorithmic bias
: structures with high internal symmetry or repetition emerge far more frequently than random sampling would predict.
Model Gene Regulatory Networks
:
In synthetic regulatory networks, topologies that are
modular and symmetric
are significantly more probable within the genotype space, confirming the prevalence of
low-K structures
.
Implications
Arrival of the Frequent
:
The paper emphasizes a key evolutionary dynamic: even without natural selection,
frequent emergence
of low-complexity forms biases evolutionary trajectories. Selection then works on what is available, not just what is ideal.
Robustness and Evolvability
:
Simpler, symmetric phenotypes not only emerge more readily, but also tend to be
more robust to mutations
. This promotes modular assembly and facilitates further evolution of complexity.
Bridges Evolution and Computation
:
The framework unites developmental biology, evolution, and computer science by treating evolution as a
search through a space of generative algorithms
, rather than just as a fitness-optimizing process.
Conclusion
Symmetry and simplicity in biological forms may not always be products of adaptive necessity. Instead, they may be
byproducts of the algorithmic structure of biological encoding systems
. Evolution, acting on genotype-phenotype maps biased by compressibility, is more likely to stumble upon symmetric structures—not because symmetry is selected for, but because it is statistically and algorithmically
easier to generate
.
This perspective shifts the evolutionary paradigm:
not all order is ordered by selection—some of it simply arises from the structure of the search space itself
.
Would you like this adapted into a diagrammatic summary, or rephrased for a general audience next?
You said:
Fig. 1.(A) Protein complexes self-assemble from individual units. (B) Frequency of 6-mer protein complex topologies found in the PDB versus the number 
of interface types, a measure of complexity˜K(p). Symmetry groups are in standard Schoenf l ies notation: C6, D3, C3, C2, and C1. There is a strong preference 
for low-complexity/high-symmetry structures. (C) Histograms of scaled frequencies of symmetries for 6-mer topologies found in the PDB (dark red) versus 
the frequencies by symmetry of the morphospace of all possible 6-mers illustrate that symmetric structures are hugely overrepresented in the PDB database. 
(D) Polyomino complexes self-assemble from individual units (here a binds to A) just as the proteins do. (E) Scaled frequency of polyominoes that i x in 
evolutionary simulations with a i tness maximum at 16-mers, versus the number of interface types (a measure of complexity˜K(p)) exhibits a strong bias 
toward high-symmetry structures, similar to protein complexes. (F) Histograms of the frequency of symmetry groups for all 16-mers (light) and for 16-mers 
appearing in the evolutionary runs (dark) quantify how strongly biased variation drives a pronounced preference for high-symmetry structures. 
to bind to each other (14-16). We analyzed a curated set of 
34,287 protein complexes extracted from the Protein Data 
Bank (PDB) that were categorized into 120 different bonding 
topologies (16). In Fig. 1B, we plot, for all complexes involving 
sixsubunits(6-mers),thefrequencywithwhichaproteincomplex 
of topology p appears against the descriptional complexity 
˜ 
K(p), an approximate measure of its true Kolmogorov assembly 
complexity K(p), def i ned here as the minimal number of 
distinct interfaces required to assemble the given structure 
under general self-assembly rules (Materials and Methods). This 
2 of 8PNAS 
https://doi.org/10.1073/pnas.2113883119 
Johnston et al 
Symmetry and simplicity spontaneously emerge from the algorithmic 
nature of evolution 
Downloaded 
from https://www.pnas.org 
by 156.34.188.210 
on 
May 
15, 
2025 
from 
IP 
address 156.34.188.210. 
EVOLUTION BIOPHYSICS 
AND COMPUTATIONAL 
BIOLOGY 
def i nition of ˜ 
K(p) can also be thought of as a measure of the 
minimal number of evolutionary innovations needed to make 
a self-assembling complex. The highest-probability structures 
all have relatively low ˜ 
K(p). Since structures with higher 
symmetry need less information to describe (6, 9-11), the most 
frequentlyobservedcomplexesarealsohighlysymmetric.Fig.1C 
and SI Appendix, Figs. S2A and S3A further demonstrate that 
structures found in the PDB are signif i cantly more symmetric 
than the set of all possible 6-mers (Materials and Methods). 
Similar biases toward high-symmetry structures obtain for other 
sizes (SI Appendix, Fig. S2B). 
In order to understand the evolutionary origins of this bias 
toward symmetry we turn to a tractable GP map for protein qua- 
ternary structure. In the Polyomino GP map, two-dimensional 
tiles self-assemble into polyomino structures (17) that model 
protein complex topologies (18) (Fig. 1D). The sides represent 
the interfaces that bind proteins together. Within the Polyomino 
GP map,thegenomes arebit stringsusedtodescribeaset oftiles 
and their interactions. The phenotypes are polyomino shapes p 
that emerge from the self-assembly process. Although this model 
is highly simplif i ed, it has successfully explained evolutionary 
trends in protein quaternary structure such as the preference of 
dihedral over cyclic symmetry in homomeric tetramers (15, 17) 
or the propensity of proteins to form larger aggregates such as 
hemoglobin aggregation in sickle cell anemia (18). 
To explore the strong preference for simple structures, we 
performed evolutionary simulations where i tness is maximized 
for polyominoes made of 16 blocks (Materials and Methods). 
With 16 tile types and 64 interface types, the GP map denoted 
asS16,64allowsall13,079,255possible16-merpolyominotopolo- 
gies(SI Appendix, Table 1)tobemade.Fig.1Edemonstratesthat 
evolutionary outcomes are exponentially biased toward 16-mer 
structures with low ˜ 
K(p) (using the same complexity measure 
as for the proteins [Materials and Methods]), even though every 
16-mer has the same i tness. 
The extraordinary strength of the bias toward high symmetry 
can be further illustrated by examining the prevalence of the 
two highest-symmetry groups in the outcomes of evolutionary 
simulations. For 16-mers, there are 5 possible structures in 
class D4(all symmetries of the square) and 12 in C4(fourfold 
rotational symmetry). Even though these 17 structures represent 
just over a millionth of all 16-mer phenotypes, they make 
up about 30% of the structures that i x in the evolutionary 
runs, demonstrating an extremely strong preference for high 
symmetry (see also SI Appendix, Fig. S3B). Comparing the 
histograms in Fig. 1 C and F shows that the polyominoes exhibit 
a qualitatively similar bias toward high symmetry as seen for 
the proteins. We checked that this strong bias toward high 
symmetry/low ˜ 
K(p) holds for a range of other evolutionary 
parameters (such as mutation rate) and for other polyomino 
sizes (SI Appendix, Fig. S6 and section S3C). Natural selection 
explains why 16-mers are selected for (as opposed to other sizes). 
However, since every 16-mer is equally i t, natural selection does 
not explain the remarkable preference for symmetry observed 
here, which is instead caused by bias in the arrival of variation.
ChatGPT said:
Here is a detailed academic-style synthesis of
Figure 1
and the corresponding experimental evidence presented by Johnston et al., with focus on how their findings support the
algorithmic bias hypothesis
:
Algorithmic Bias Toward Symmetry: Empirical Validation through Protein and Polyomino Topologies
Figure 1
in Johnston et al.'s study provides a multi-layered empirical validation of their central thesis: that
evolutionary variation is strongly biased toward symmetric and simple phenotypes due to their lower algorithmic (descriptional) complexity
, not necessarily because such forms are directly selected for.
A. Protein Quaternary Structures and Interface Complexity
(Fig. 1A-C): Real Proteins
Self-assembly Basis
: Multimeric protein complexes form by subunits binding via specific interfaces.
Descriptional Complexity Measure
: The authors define an approximate Kolmogorov complexity, ˜K(p), as the
number of distinct interfaces
required to assemble a structure.
Finding (Fig. 1B)
: In a dataset of 34,287 six-subunit (6-mer) complexes from the Protein Data Bank (PDB), the frequency of observed topologies is
inversely correlated
with ˜K(p). The most frequently occurring complexes are the most
symmetric
, with fewer interface types.
Symmetry Overrepresentation (Fig. 1C)
: Comparing real 6-mer frequencies (PDB data) against the theoretical morphospace of all possible 6-mers reveals a
drastic overrepresentation of symmetric complexes
, especially those in symmetry groups like C6 (cyclic) and D3 (dihedral).
B. Polyomino Model as a Minimal GP Map
(Fig. 1D-F): Simulated Evolutionary System
Rationale
: To isolate and examine the
arrival of variation
, the authors use a simplified model—
Polyomino GP maps
, where square tiles with binding rules represent abstracted protein subunits.
Genome-Phenotype Mapping
: Each genome is a bit string that encodes a tile set and interaction rules. Phenotypes are 2D structures emerging from tile self-assembly.
Experimental Design
:
Fitness landscape
: All structures with 16 tiles are assigned equal fitness.
S16,64 space
: The chosen map allows for the complete enumeration of 13,079,255 possible 16-tile (16-mer) topologies.
Key Findings
:
Complexity Bias (Fig. 1E)
: Despite equal fitness across all 16-mers, those that fix in simulations have significantly lower ˜K(p), confirming that the variation
does not arise uniformly
, but is
skewed toward simple, symmetric forms
.
Symmetry Inflation (Fig. 1F)
: The two most symmetric classes, D4 (square group, 5 structures) and C4 (fourfold rotation, 12 structures), comprise
~30% of all fixed phenotypes
, despite being
only ~0.0001% of the total morphospace
.
Robustness of Result
: This dramatic skew persists under different mutation rates and polyomino sizes (see SI Appendix), suggesting it's a
structural property of the GP map
, not an artifact of simulation parameters.
Interpretation and Broader Implications
Selection Explains Fitness Peak (16-mer Target)
: Natural selection selects for structures of a specific size (e.g., 16 tiles), but
does not account for which structure within that size emerges most frequently
.
Algorithmic Bias Explains Within-Class Preference
: The
frequency distribution within 16-mers
is governed by the
algorithmic compressibility
of each phenotype. More symmetric forms require fewer rules to encode, and hence, arise more frequently via mutation.
Arrival-of-the-Frequent Mechanism
: This process underscores the importance of
developmental bias
—natural selection can only act on what is produced. If symmetric structures arise exponentially more often, they will dominate even neutral or nearly-neutral evolutionary trajectories.
Conclusion
The study elegantly demonstrates that the
bias in variation generation
, due to the algorithmic structure of the genotype-phenotype map,
overwhelms uniform expectation and shapes the space of possible evolutionary outcomes
. Symmetry, rather than being solely an outcome of selection for robustness or aesthetics, is here revealed as a
computationally inevitable attractor
, born from the logic of compression and representation.
Would you like this formatted into a slide deck or annotated figure summary next?
You said:
Give some more analogies to explain it
ChatGPT said:
Certainly. Here are
multiple analogies
from different domains to help clarify the core insight of Johnston et al.'s work: that
symmetry and simplicity emerge more frequently in evolution not because they're always advantageous, but because they're algorithmically easy to generate
.
1. The Monkey and the Typewriter (AIT Classic)
Imagine a monkey randomly typing on a typewriter programmed in Python. The chance that it randomly types:
python
Copy code
print
(
"AAAAAAAA"
)
...is far greater than it typing:
python
Copy code
print
(
"JX7zqU9#1!Lp$%g"
)
Why? Because the first has
lower algorithmic complexity
. It's easier to describe. Likewise, symmetrical biological forms like hexagons or radial limbs are
easier to express
in biological code (genotypes) than messy asymmetrical ones. So they appear more often just by chance.
2. LEGO Instructions
If you had to randomly assemble LEGO sets without instructions:
A symmetric tower (same bricks stacked up) is
much more likely
to appear by accident.
A detailed dragon with unique parts everywhere? Not so much.
Nature works like this:
the "instructions" (DNA) are random mutations
, and the structures they build are more often
simple and symmetric
, because they
require fewer unique parts and connections
.
3. Origami Folding
If you were folding origami at random:
Folding a square in half repeatedly is
easy
, and will generate
symmetrical patterns
.
Getting a detailed crane requires an exact sequence of steps—
harder to hit by accident
.
Evolution often "folds" biology the same way:
symmetric, compressible forms are more accessible
.
4. Music Notes on a Piano
Smash your hand randomly on a piano: you're more likely to hit
chords with harmonic patterns
than a perfectly dissonant 12-tone serial composition.
Why?
Harmonic patterns (like C-E-G)
are
spaced regularly
. They appear more naturally when sampling randomly. Similarly,
symmetry is the harmonic chord of evolution
—not because it's always "beautiful," but because it's
statistically abundant
.
5. City Grid vs. Spaghetti Streets
If you were randomly assigning road layouts:
A
grid system
(like Manhattan) is easier to code with rules like "repeat every 200 meters."
Organic medieval layouts
(like old Rome) require many special instructions.
Even if no one plans the grid,
random developmental rules
are more likely to produce it than chaotic uniqueness—
not because it's better
, but because
it's easier to describe
.
6. CAPTCHA Generators
Simple CAPTCHAs like
0000
or
ABABAB
appear more frequently in random generation than something like
gTr6#QwL
.
Why?
Patterned strings have fewer "surprises"
, and can be generated by shorter instructions. Biological variation works the same:
structured outputs dominate
, not by design, but by
informational bias
.
Would you like some analogies that are specific to genetics or developmental biology next? Or more that relate to computation and software?
You said:
I thought that the design for a pyramid would be obvious from shaking a square cart full of oranges
ChatGPT said:
That's a
brilliant and intuitive analogy
—and it dovetails beautifully with the thesis of the paper.
Let's expand on it:
The Pyramid of Oranges Analogy
Imagine a square cart filled with oranges. You shake it gently.
What happens?
The oranges settle into
layers
.
The base forms a
square lattice
, and above it,
each orange fits into the gaps between the ones below
.
This naturally forms a
pyramidal or tetrahedral shape
—with
symmetry, regularity, and stability
,
without any intention
.
Why does this happen?
Because
gravity + sphere-packing + minimum-energy configurations
naturally produce
simple, symmetric structures
.
It's not because the oranges "want" to make a pyramid.
It's because the
rules of space-filling and stability
favor a small subset of possible arrangements
—and most of those are
symmetric
.
This is exactly what Johnston et al. argue about
evolution
:
Random mutations are like
shaking the cart
.
The genotype-phenotype map is the
geometry of the cart
.
Phenotypes like pyramids are
favored not because they're selected
, but because
they're vastly more likely to arise
given the shape of the system.
Compression and Stability: Deeper Connection
A pyramid of oranges is not only
stable
—it's also
easy to describe
:
"Four at the base, three on top, then two, then one."
Compare that to describing a chaotic pile:
"One here, then skip two spaces, then one... but rotated... wait, it rolled—start over."
So the pyramid is both:
Low energy
(physically stable)
Low complexity
(algorithmically compressible)
This duality—
geometry favors stability
, and
information theory favors simplicity
—
explains why such forms dominate in both oranges and organisms
.
Would you like a diagram or metaphor tree comparing all of these examples under a unified theme like "algorithmic emergence"?
You said:
To assign complexity values for the polyominoes, a measure similar to 
that used for the proteins was applied. First, the minimal complexity over 
the different genomes that generate polyomino p is estimated by sampling 
and i nding the shortest rule set after removing redundant information. 
The search for a minimal complexity genome will be more accurate for 
high-probability polyominoes than for low-probability polyominoes. We 
checked that for most structures, only a fairly limited amount of sampling 
provided an accurate estimate of the minimal complexity; the minimal 
complexity genome is often the most likely to be found. The effects of 
i nite sampling are illustrated further in SI Appendix, section S3 and Fig. S5. 
The complexity ˜ 
K(p) of polyomino p is then given by the number of 
interfaces in the minimal genomes—thus, the number of genome regions 
encoding interfaces that play an active role in forming the i nal structure. 
A longer discussion of different choices of complexity measure, showing 
that the qualitative behavior is not very sensitive to details in the choice 
of approximate measure of algorithmic (Kolmogorov) information, can be 
found in SI Appendix, section S3C. 
Evolutionary simulations of polyomino structures are performed follow- 
ing methods described in ref. 17: A population of N binary polyomino 
genomes is maintained at each time step. The assembly process is performed 
for each genome, and the resulting structure is recorded. UND genomes 
are assigned zero i tness. Other structures are assigned a i tness value 
based on the applied i tness function. These i tness values are used to 
perform roulette wheel selection, whereby a genome giwith i tness f(gi) 
is selected with probability f(gi)/ ? 
jf(gj). Selection is performed N times 
(with replacement) to build the population for the next time step. Selected 
genomes are cloned to the next generation, then point mutations are 
applied with probability μ at each locus. A point mutation changes a 0 to a 
1 and vice versa in the genome. We do not employ cross-over or elitism in 
these simulations. 
We employ several different i tness functions. In the unit i tness protocol, 
all polyomino structures that are not UND are assigned i tness 1. In the 
random i tness protocol, each polyomino structure is assigned a i tness value 
uniformly randomly distributed on [0,1], and these values are reassigned for 
each individual evolutionary run. In the size i tness protocol, a polyomino of 
size s has i tness 1/(|s − s∗| + 1), so that polyominoes of size s∗have 
unit 
i tness and other sizes have i tness decreasing with distance from s∗. The 
simulations for Fig. 1E were done with N = 100 and μ = 0.1 per genome, 
per generation. A number of other evolutionary parameters are compared 
in SI Appendix, section 3C and Fig. S6, showing that our main result—that 
the outcome of evolutionary dynamics exhibit an exponential bias toward 
simple structures—is not very sensitive to details such as mutation rate or 
the choice of i tness function. 
RNA Secondary Structure GP Map. For L = 30 RNA, we randomly gener- 
ated 32,000 sequences, and for L = 100, we generated 100,000 random 
sequences. As in refs. 25, 26, secondary structure (SS) is computationally pre- 
dicted using the fold routine of the Vienna package (23) based on standard 
thermodynamics of folding. All folding was performed with parameters set 
to their default values (in particular, the temperature is set at T = 37◦C). 
We then calculated the neutral set size [NSS(p)], the number of sequences 
mapping to a SS p, for each SS found by random sampling, by using the 
neutral set size estimator described in ref. 27, which is known to be quite 
accurate for larger NSS structures (25). We used default settings except for 
the total number of measurements (set with the -m option), which we set to 
1insteadofthedefault10,forthesakeofspeed,butthisdoesnotnoticeably 
affect the outcomes we present here. 
RNA structures can be represented in standard dot-bracket notation, 
wherebracketsdenotebondsanddotsdenoteunbondedpairs.Forexample, 
...((...)).... means that the i rst three bases are not bonded, the fourth 
and i fth are bonded, the sixth through ninth are unbonded, the tenth base 
is bonded to the i fth base, the eleventh base is bonded to the fourth base, 
and the i nal four bases are unbonded. For shorter strands such as L = 30, 
the same SS can be found multiple times in the fRNAdb. 
For longer strands, i nding multiple examples of the same SS becomes 
more rare, so that SS frequencies cannot be easily directly extracted from 
the fRNAdb. However, it seems reasonable, especially for larger structures, 
that i ne details of the structures are not as important as certain more 
gross structural features that are captured by a more coarse-grained pic- 
ture of the structure. In this spirit, we make use of the well-known RNA 
abstract shape method (29) where the dot-bracket SS are abstracted to 
one of i ve hierarchical levels, of increasing abstraction, by ignoring details 
such as the length of loops but including broad shape features. For the 
L = 100 data we choose the i fth or highest level of abstraction which 
only measures the stem arrangement. This choice of level is needed to 
achieve multiple examples of the same structure in the fRNAdb database, 
so that a frequency can be directly determined with statistical signif i- 
cance. The SS were converted to abstract shapes with the online tool 
available at https://bibiserv.cebitec.uni-bielefeld.de/rnashapes. Using these 
coarse-grained structures means that the theoretical probability P(p) can 
be directly calculated from random sampling of sequences, where NGis 
the number of sequences, which for an RNA GP map for length L RNA is 
given by NG= 4L. A similar calculation of the P(p) for RNA structures for 
L from 40 to 126 at different levels of coarse-graining can be found in 
ref. 26. 
To generate the distributions of natural RNA we took all available se- 
quencesofL = 30andL =100fromthenoncodingfRNAdb(28).Asinref.25, 
weremovedasmallfraction(∼1%)ofthenaturalRNAsequencescontaining 
nonstandard nucleotide letters, e.g., N or R, because the standard folding 
packages cannot treat them. Similarly, a small fraction (∼2%) of sequences 
were also discarded due to the neutral set size estimator failing to calculate 
the NSS (this is only relevant for L = 30). We have further checked that re- 
movingbyhandanysequencesthatwereassignedputativeroles,orareclear 
repeats, does not signif i cantly affect the strong correlation between the 
frequencies found in the fRNA database and those obtained upon random 
sampling of genotypes. For a further discussion of the question of how well 
frequency in the databases tracks the frequency in nature, see also refs. 25, 
26 and SI Appendix, Fig. S10, where a comparison with the Rfam database is 
also made. Note that the similar behavior we i nd across structure prediction 
methods, strand lengths, and databases would be extremely odd if artif i cial 
biases were strong on average in the fRNA database. We used 40,554 unique 
RNA sequences of L = 30, taken from the fRNAdb, corresponding to 17,603 
unique dot-bracket structures. Similarly, we used 932 unique fRNAdb L = 
100 RNA sequences, corresponding to 17 unique level 5 abstract structures/ 
shapes. 
To estimate the complexity of an RNA SS, we i rst converted the dot- 
bracket representation of the structure into a binary string p and then 
used the Lempel-Ziv-based complexity measure from ref. 8 to estimate 
its complexity. To convert to binary strings, we replaced each dot with 
the bits 00, each left bracket with the bits 10, and each right bracket 
with 01. Thus, an RNA SS of length n becomes a bit string of length 
2n. Because level 5 abstraction only contains left and right brackets, i.e., 
[and], we simply convert the left bracket to 0 and the right to 1 be- 
fore estimating the complexity of the resulting bit string via the Lempel- 
Ziv-based complexity measure from ref. 8. The level 5 abstract trivial shape 
with no bonds is written as underscore, and this we simply represented 
as a single 0 bit. SI Appendix, section S4 provides more background on 
RNA structures, and SI Appendix, section S5B provides more detail of the 
complexity measure. 
GRN of Budding Yeast Cell Cycle. The budding yeast (Saccharomyces cere- 
visiae) cell cycle GRN system from ref. 30 consists of 60 coupled ODEs relating 
156 biochemical parameters. The model parameter space (i.e., genotype 
space) was sampled by picking random values for each of the parameters 
by multiplying the wild-type value by one of {0.25,0.50,...,1.75,2.00}, 
chosen with uniform probability. The ODEs generate concentration-time 
curves for different biochemicals involved in cell cycle regulations. All runs 
were i rst simulated for 1,000 time steps, with every time step corresponding 
to 1 min. Next, we identif i ed the period of every run (usually on the order 
of 90 time steps), took one full oscillation, and coarse-grained it to 50 time 
steps. This way, if two genotypes produce curves which are identical up 
to changes in period, they should ultimately produce identical or nearly 
identical time series and binary string phenotypes. For every genotype or 
set of parameters, the curves for the CLB2/SIC1 complex are then discretized 
into binary strings using the up-down method (31): for every discrete value 
of t = δt,2δt,3δt,..., we calculate the slope dy/dt of the concentration 
curve, and if dy/dt ≥ 0, a 1 gets assigned to the jth bit of the output string; 
otherwise, a 0 is assigned to it. All strings with the same up-down prof i le 
were classif i ed as one phenotype. To generate the P(p) in Fig. 4, 5 × 106 
inputs were sampled. Complexity˜K(p) is assigned by using the Lempel-Ziv 
measure from ref. 8 (see also SI Appendix, section S5B) applied to binary 
output strings. As shown in ref. 8, this methodology works well for cou- 
pled differential equations, and the choice of input discretization, sample 
size, and initial conditions does not qualitatively affect the probability- 
complexity relationships obtained. The wild-type curve can be observed in 
in i gure 2 of ref. 30, where it is labeled Clb2T.
ChatGPT said:
Excellent—what you've shared is the detailed
methodological foundation
of Johnston et al.'s study, which operationalizes their core hypothesis across three distinct genotype-phenotype (GP) systems:
Unified Summary of Complexity Estimation and Simulation Protocols
The authors test their
algorithmic bias hypothesis
—that evolution preferentially produces low-complexity (i.e., symmetric or modular) phenotypes—across three biologically meaningful domains:
1. Polyomino Protein Complexes
Phenotypes
: 2D self-assembling structures made of square tiles (polyominoes), modeling protein quaternary structures.
Genotypes
: Bitstrings encoding tile types and binding interfaces.
Complexity Measure (˜K(p))
:
Determined as the
minimum number of unique interfaces
needed to build a given structure.
This acts as a
proxy for Kolmogorov complexity
: simpler structures (e.g., with repeated motifs) need fewer interface rules.
Key Feature
:
High-probability structures tend to have minimal genomes (shortest descriptions).
Sampling bias
due to finite search is mitigated by the fact that simpler structures dominate and are easier to find.
Evolutionary Protocol
:
Population size
: N = 100.
Mutation rate
: μ = 0.1 per genome per generation.
Selection
: Roulette-wheel based on fitness (unit, size-specific, or random).
Fitness neutrality
: Many simulations fix structure size (e.g., 16 tiles), allowing structure
form
to vary without adaptive pressure—highlighting
variation bias
rather than
selection
.
2. RNA Secondary Structure (SS)
Phenotypes
: Folded RNA shapes (e.g., hairpins, loops), computed from sequences using the Vienna RNA folding package.
Genotypes
: Nucleotide sequences (L = 30 and L = 100).
Complexity Measure
:
Convert dot-bracket notation (e.g.,
((..))..
) to binary strings:
Dots →
00
,
(
→
10
,
)
→
01
Estimate Lempel-Ziv complexity (LZ78) from the resulting bit string.
Coarse-Graining
:
For long sequences, structural frequencies are measured using
abstract shape levels
(level 5), reducing detail to general topology (e.g., number of stems).
This enables
statistically meaningful counts
of shape occurrences.
Findings
:
Natural RNA and randomly generated sequences both show an
exponential bias toward low-complexity (high-symmetry)
shapes.
This bias persists across abstraction levels and dataset sources, suggesting it's not an artifact of the folding algorithm or database bias.
3. Budding Yeast Gene Regulatory Network (GRN)
Phenotypes
: Binary time series derived from ODE simulations of the yeast cell cycle (e.g., up/down slope of protein concentration over time).
Genotypes
: Parameter sets modifying 60 coupled ODEs (156 parameters total).
Complexity Measure
:
Time series discretized via slope sign (dy/dt ≥ 0 → 1, else → 0).
Output sequences are compressed using the
Lempel-Ziv algorithm
, yielding ˜K(p).
Sampling
:
5 million parameter sets sampled.
No dependence on particular model discretization or initial conditions—results are
robust
.
General Insights Across All Three Models
:
Variation bias
dominates: Low-complexity structures appear
orders of magnitude more frequently
, even in the absence of selection.
The
Kolmogorov complexity proxy (˜K(p))
consistently correlates
negatively
with phenotype frequency.
These findings are
insensitive to evolutionary parameters
like mutation rate or fitness function choice—supporting the view that
algorithmic information, not adaptive fitness, governs the emergence of form
.
Would you like a table summarizing these three systems side-by-side, or a visual conceptual diagram of how the GP map filters randomness into structured outcomes?
You said:
Just a simplified explanation
ChatGPT said:
Sure. Here's a simplified explanation of what the researchers did and found:
What They Wanted to Know:
Why do we see so many
symmetric and simple shapes
in biology—like proteins that come together in neat patterns, or RNA that folds into regular loops?
Is it because those shapes are
better
and were chosen by natural selection?
Or is it because those shapes are
easier to make in the first place
?
What They Did:
They looked at
three different systems
:
Protein complexes
made of building blocks that stick together.
RNA molecules
that fold into loops and stems.
Gene networks
that control how cells behave over time.
In each case, they:
Simulated
random changes
(mutations).
Measured how
often different shapes appeared
.
Calculated how
simple
or
complicated
each shape was.
How They Measured Simplicity:
They used a trick from computer science called
Lempel-Ziv compression
(like what ZIP files do).
The idea: if a shape can be described in just a few rules or patterns (like "repeat this tile" or "mirror this side"), it's
simple
.
What They Found:
Simple and symmetric shapes
showed up
way more often
than random chance would suggest.
Even when
all shapes were equally "fit"
, the simple ones
dominated
.
This happened because
there are more ways to randomly create simple shapes
than complex ones.
Why It Matters:
It means that evolution isn't just about "survival of the fittest"—it's also about
arrival of the frequent
.
In other words,
some shapes are more likely to show up
, just because they're
easier to build
.
So:
Symmetry isn't always selected—it's often just what happens when you shake the box.
Let me know if you want this turned into an infographic or short presentation.
4o
Search
Deep research
Create image
ChatGPT can make mistakes. Check important info. See
Cookie Preferences
.